<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  
    

    
  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="paper,KDD,搜索,EBR,语义检索,向量,淘宝," />





  <link rel="alternate" href="/atom.xml" title="蘑菇先生学习记" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/picture/logo.ico?v=5.1.0" />






<meta name="description" content="今天得空带来一篇分享，KDD’21的Applied Data Science Track中，淘宝搜索发表的一篇EBR文章[9]：Embedding-based Product Retrieval in Taobao Search。论文要讨论的几大问题提前预览下：  搜索场景中，query如何充分地进行语义表征？电商平台的query通常是短query，如何对有限长度的query进行充分的语义表征？">
<meta name="keywords" content="paper,KDD,搜索,EBR,语义检索,向量,淘宝">
<meta property="og:type" content="article">
<meta property="og:title" content="KDD&#39;21 | 淘宝搜索中语义向量检索技术">
<meta property="og:url" content="xtf615.com/2021/10/07/taobao-ebr/index.html">
<meta property="og:site_name" content="蘑菇先生学习记">
<meta property="og:description" content="今天得空带来一篇分享，KDD’21的Applied Data Science Track中，淘宝搜索发表的一篇EBR文章[9]：Embedding-based Product Retrieval in Taobao Search。论文要讨论的几大问题提前预览下：  搜索场景中，query如何充分地进行语义表征？电商平台的query通常是短query，如何对有限长度的query进行充分的语义表征？">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="/picture/machine-learning/taobao_sr.png">
<meta property="og:image" content="/picture/machine-learning/MGDSPR.png">
<meta property="og:image" content="/picture/machine-learning/mgsu.png">
<meta property="og:image" content="/picture/machine-learning/taobao_arts.png">
<meta property="og:image" content="/picture/machine-learning/taobao_deploy.png">
<meta property="og:image" content="/picture/machine-learning/taobao_comp.png">
<meta property="og:image" content="/picture/machine-learning/taobao_ablation.png">
<meta property="og:image" content="/picture/machine-learning/taobao_ab_test.png">
<meta property="og:image" content="/picture/qr_sr_code.png">
<meta property="og:updated_time" content="2021-10-07T12:27:07.690Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KDD&#39;21 | 淘宝搜索中语义向量检索技术">
<meta name="twitter:description" content="今天得空带来一篇分享，KDD’21的Applied Data Science Track中，淘宝搜索发表的一篇EBR文章[9]：Embedding-based Product Retrieval in Taobao Search。论文要讨论的几大问题提前预览下：  搜索场景中，query如何充分地进行语义表征？电商平台的query通常是短query，如何对有限长度的query进行充分的语义表征？">
<meta name="twitter:image" content="/picture/machine-learning/taobao_sr.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="xtf615.com/2021/10/07/taobao-ebr/"/>





  <title> KDD'21 | 淘宝搜索中语义向量检索技术 | 蘑菇先生学习记 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">蘑菇先生学习记</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <!-- <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form> -->

<!-- <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'WgLy48WeXh1aXsWx1x7L','2.0.0');
</script> -->



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2021/10/07/taobao-ebr/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                KDD'21 | 淘宝搜索中语义向量检索技术
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-10-07T20:18:11+08:00">
                2021-10-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/搜索/" itemprop="url" rel="index">
                    <span itemprop="name">搜索</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读量 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>今天得空带来一篇分享，KDD’21的Applied Data Science Track中，淘宝搜索发表的一篇EBR文章[9]：<strong>Embedding-based Product Retrieval in Taobao Search</strong>。论文要讨论的几大问题提前预览下：</p>
<ul>
<li>搜索场景中，query如何<strong>充分地进行语义表征</strong>？电商平台的query通常是短query，如何对有限长度的query进行充分的语义表征？</li>
<li>搜索场景中，<strong>用户历史行为序列如何建模</strong>？如何防止<strong>引入和当前query无关的历史行为</strong>导致相关性问题？</li>
<li>搜索场景中，基于向量的检索系统(EBR)如何<strong>保证相关性</strong>？ EBR是基于向量的检索，不是完全匹配的检索，很容易检索到和当前query不相关的商品，那么该如何保证相关性？</li>
</ul>
<a id="more"></a>
<p>下面按照<strong>Motivation，Solution，Evaluation和Summarization</strong>来介绍。</p>
<h1 id="1-Motivation"><a href="#1-Motivation" class="headerlink" title="1. Motivation"></a>1. Motivation</h1><p><strong>研究对象</strong>：电商平台的商品搜索引擎(product search engines)。</p>
<p><strong>整体淘宝搜索系统包括四阶段</strong>：match-prerank-rank-rerank，召回，粗排，精排，重排。本文重点在于召回。</p>
<p><img src="/picture/machine-learning/taobao_sr.png" alt="淘宝商品搜索系统"></p>
<p><strong>挑战</strong>：电商平台的文本通常较短，没有语法结构，因此要考虑海量的用户历史行为。基于词匹配(lexical matching)的搜索引擎(倒排索引)，性能好、可控性强，尽管存在一些语义鸿沟问题，但仍被广泛的应用在现有的搜索引擎架构中。但是，这种搜索引擎无法有效区分<strong>相同query下</strong>， 不同用户的<strong>兴趣差异</strong>，无法捕捉用户<strong>个性化</strong>的特征。因此，如何<strong>高效</strong>地检索出<strong>【最相关】、【最能够满足用户需求】</strong>的产品，发现<strong>【query语义】</strong>和【<strong>用户个性化历史行为】</strong>之间的关系，是电商平台主要的挑战。</p>
<p><strong>工业界经典的EBR系统文章有，</strong></p>
<p><strong>电商平台：</strong></p>
<ul>
<li>[1]亚马逊：Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. <strong>Semantic product search</strong>. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2876–2885.</li>
<li>[2]京东：Han Zhang, Songlin Wang, Kang Zhang, Zhiling Tang, Yunjiang Jiang, Yun Xiao, Weipeng Yan, and Wen-Yun Yang. 2020. <strong>Towards Personalized and Semantic Retrieval: An End-to-End Solution for E-commerce Search via Embedding Learning</strong>. arXiv preprint arXiv:2006.02282 (2020).</li>
</ul>
<p><strong>其它：</strong></p>
<ul>
<li>[3] Facebook：Jui-Ting Huang, Ashish Sharma, Shuying Sun, Li Xia, David Zhang, Philip Pronin, Janani Padmanabhan, Giuseppe Ottaviano, and Linjun Yang. 2020. <strong>Embedding-based retrieval in facebook search</strong>. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2553–2561.</li>
<li>[4] 百度：Miao Fan, Jiacheng Guo, Shuai Zhu, Shuo Miao, Mingming Sun, and Ping Li. 2019. <strong>MOBIUS: towards the next generation of query-ad matching in baidu’s sponsored search</strong>. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2509–2517.</li>
<li>[5] Google：Tao Wu, Ellie Ka-In Chio, Heng-Tze Cheng, Yu Du, Steffen Rendle, Dima Kuzmin, Ritesh Agarwal, Li Zhang, John Anderson, Sarvjeet Singh, et al. 2020. <strong>Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.</strong> In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2821–2828.</li>
</ul>
<p>作者指出上述大多数文章<strong>避重就轻</strong>，只强调在指标上提升很多，却没有说明<strong>向量召回会降低相关性</strong>，引入很多相关性的CASE。</p>
<p>作者也部署了向量检索系统在淘宝搜索中，观察了很长一段时间，有几个发现：</p>
<ul>
<li>短期效果很好；长期来看，基于embedding的方法由于不是词匹配，即：缺乏【<strong>完整匹配</strong>(exact match)】query所有terms的能力，很容易造成相关性BAD CASE。</li>
<li>为了能够保证相关性，作者采用了一个相关性控制模块，来对检索到的商品做过滤。控制模块对EBR检索后的结果，做进一步的完整匹配过滤，只保留那些能够<strong>完整匹配</strong>结构化字段的商品，给到后续的排序阶段。作者统计了下，这几乎会过滤掉30%的商品，即：30%的商品相关性较低，被过滤的商品既耗费计算资源，又不能够参与到后续精排，导致本来可以进入后续排序的相关性商品无法进入排序，整体指标下降。</li>
<li>因此，本文的主要目标是期望基于向量的模型能够检索到<strong>更多相关的商品</strong>，<strong>有更多相关的商品</strong>能够参与到后续排序阶段中，从而在保证相关性的墙体下，提高整个系统的线上指标。</li>
</ul>
<p>随机负采样在召回阶段被广泛使用，用于训练大规模的深度语义检索模型，来保证训练阶段的样本空间和推理阶段是一致的[2,3]。然而，仍然存在一些离线训练和线上推理不一致的情况[1,2]。例如，推理阶段，模型需要从所有的候选集中，选择和目标Query最相关的top-K个商品，需要一个全局的比较能力。而大部分工作如京东和亚马逊[1,2]都是采用hinge pairwise loss作为训练目标，而hinge pairwise loss本身只具备局部的比较能力。</p>
<p><strong>这篇文章的核心贡献总结如下：</strong></p>
<ul>
<li><strong>模型</strong>：提出了一种<strong>多粒度深度语义商品检索模型</strong>(Multi-Grained Deep Semantic Product Retrieval (MGDSPR) Model)，能够动态地捕捉用户搜索语义和个性化交互历史行为的关系，兼顾<strong>语义</strong>和<strong>个性化</strong>。</li>
<li><strong>训练和推理的一致性</strong>：为了保证训练和推理的一致性，使得模型具备全局比较能力，采用了softmax交叉熵损失函数，而不是hinge pairwise损失函数。</li>
<li><strong>相关性保证</strong>：提出了两种不需要额外训练过程，就能够保证检索更多相关性商品的方法。1.即：<strong>在softmax基础上引入温度参数</strong>，对用户隐式反馈(点击数据)进行相关性噪声的平滑。2.<strong>混合正样本和随机负样本</strong>来产生”<strong>相关性提升</strong>“的困难负样本。进一步，作者采用了<strong>相关性控制模块</strong>来进一步保证EBR系统相关性。</li>
<li><strong>实验和分析</strong>：在真实的工业级数据上，阐明了MGDSPR的有效性。进一步分析了MGDSPR对<strong>搜索系统每个阶段</strong>的影响，介绍了应用向量检索在商品搜索过程中的宝贵经验和教训。</li>
</ul>
<h1 id="2-Solution"><a href="#2-Solution" class="headerlink" title="2. Solution"></a>2. Solution</h1><p><strong>问题形式化</strong>：$\mathcal{U}={u_1,…,u_u,…,u_n}$表示$N$个用户集合；$\mathcal{Q}={q_1,…,q_u,…,q_N}$表示相应的queries，$\mathcal{I}={i_1,…,i_i,…,i_M}$表示$M$个物品的集合。同时，作者将用户$u$的历史行为根据离当前的时间间隔划分为3个子集合，</p>
<ul>
<li><strong>实时行为序列</strong>(当前时间戳前的若干行为)：$\mathcal{R}^u={i_1^u,…,i_t^u,…,i_T^u}$；</li>
<li><strong>短期行为序列</strong>(不包括在$\mathcal{R}^u$中的10天内的行为)：$\mathcal{S}^u={i_1^u,…,i_t^u,…,i_T^u}$；</li>
<li><strong>长期行为序列</strong>(不包括在$\mathcal{R}^u$和$\mathcal{S}^u$中的1个月内的行为序列)：$\mathcal{L}^u={i_1^u,…,i_t^u,…,i_T^u}$。</li>
</ul>
<p><strong>任务</strong>：给定用户$u$的历史行为序列$(\mathcal{R}^u, \mathcal{S}^u, \mathcal{L}^u)$，在时间$t$发起了一次搜索请求$q_u$，我们期望返回物品的集合$i \in \mathcal{I}$来满足该用户的搜索需求。具体而言，目标是基于用户$(\text{query}, \text{behaviors})$和物品<strong>items</strong>之间的得分$z$，从$\mathcal{I}$中预测出Top-$K$候选物品。即：<br>$$<br>z = \mathcal{F}(\phi(q_u, \mathcal{R}^u, \mathcal{S}^u, \mathcal{L}^u), \psi(i))<br>$$<br>其中，$\mathcal{F}(\cdot)$是打分函数，$\phi(\cdot)$是query/behaviors的编码器，$\psi(i)$是item编码器。作者也是采用了双塔的召回模型，$\mathcal{F}$用内积函数来表示。下文主要介绍用户towers和物品towers。</p>
<p>先介绍下<strong>整体的网络框架结构</strong>：</p>
<p><img src="/picture/machine-learning/MGDSPR.png" alt="MGDSPR网络结构"></p>
<p>典型的<strong>双塔结构</strong>，在user tower部分做的比较重，item tower部分做的比较轻量。user tower输出的用户表征向量和item tower输出的物品表征向量做点积得到预测值，再使用sampled softmax损失函数在全局item pool中进行优化。其中，</p>
<ul>
<li><p><strong>user tower</strong>包含三个重量的部分，</p>
<ul>
<li>query语义表征；</li>
<li>用户实时、短期、长期历史行为序列个性化表征；</li>
<li>以及二者如何融合起来的组件。</li>
</ul>
<p>分别对应图中user tower的左侧、中间和上半部分。</p>
</li>
<li><p><strong>item tower</strong>包含三个轻量的部分，</p>
<ul>
<li>item ID；</li>
<li>item的辅助信息；</li>
<li>以及二者如何融合起来的组件。</li>
</ul>
</li>
<li><p><strong>优化</strong>：</p>
<ul>
<li>sampled softmax损失函数。</li>
<li>优化策略：温度参数对训练集进行噪声平滑、在embedding空间生成困难负样本。</li>
</ul>
</li>
</ul>
<p>下面将分别围绕上述三个部分user tower， item tower和优化方法展开，最后介绍系统架构。</p>
<h2 id="2-1-User-Tower"><a href="#2-1-User-Tower" class="headerlink" title="2.1  User Tower"></a>2.1  User Tower</h2><h3 id="2-1-1-多粒度语义单元-Multi-Granular-Semantic-Unit"><a href="#2-1-1-多粒度语义单元-Multi-Granular-Semantic-Unit" class="headerlink" title="2.1.1 多粒度语义单元(Multi-Granular Semantic Unit)"></a>2.1.1 多粒度语义单元(Multi-Granular Semantic Unit)</h3><p>淘宝搜索的query通常是中文。经过query分词后，每个分词结果的长度通常小于3。因此，作者提出了一种【<strong>多粒度语义单元</strong>】来多粒度地挖掘query语义。具体而言，输入：</p>
<ul>
<li>当前query的<strong>分词结果</strong>$q_u={w_1^u, …, w_n^u}$，比如：{红色,连衣裙}</li>
<li>每个词$w$又由<strong>字构成</strong>，$w^u={c_1^u,…,c_m^u}$，比如：{红,色}</li>
<li>该用户的<strong>历史搜索行为</strong>$q_{his}={q_1^u,…,q_k^u} \in \mathbb{R}^{k \times d}$，比如：{绿色，半身裙，黄色，长裙}</li>
</ul>
<p>其中，词：$w_n \in \mathbb{R}^{1\times d}$，字：$c_m \in \mathbb{R}^{1 \times d}$，$q_k \in \mathbb{R}^{1 \times d}$，即：每个词、字、query整体的embedding维度数都设置为$d$。可以获得如下6种粒度的表征，$Q_{mgs} \in \mathbb{R}^{6 \times d}$，</p>
<ul>
<li>$q_u$ <strong>unigram</strong>单字粒度的表征做mean-pooling，${q_1}_{gram} \in \mathbb{R}^{1 \times d}$</li>
<li>$q_u$ <strong>2-gram</strong>的表征做mean-pooling，${q_2}_{gram} \in \mathbb{R}^{1 \times d}$</li>
<li>$q_u$<strong>分词粒度</strong>的词的表征做mean-pooling，$q_{seg} \in \mathbb{R}^{1 \times d}$</li>
<li>$q_u$<strong>分词粒度的序列</strong>，用Transformer作为序列Encoder后，再对最后1层隐层向量做mean pooling，${q_{\text{seg_seq}}} \in \mathbb{R}^{1 \times d}$</li>
<li><strong>历史搜索词</strong>$q_{his}$和当前搜索词的表征$q_{seg}$做attention后，加权融合，$q_{\text{his_seq}} \in \mathbb{R}^{1 \times d}$</li>
<li><strong>混合表征</strong>：上述5种表征向量相加得到，$q_{mix} \in \mathbb{R}^{1 \times d}$</li>
</ul>
<p>最终，$Q_{mgs} \in \mathbb{R}^{6 \times d}$由上述6种拼接而成。具体计算公式如下：</p>
<p><img src="/picture/machine-learning/mgsu.png" alt="image-20210910132747682"></p>
<p>其中，$Trm$即为Transformer，$q_{his}$的计算同$q_{seg}$。</p>
<p>可以看到，作者从两个方面来充分地对query进行语义表征，<strong>由此可以回答开篇的第一个问题</strong>，query如何<strong>充分地进行语义表征</strong>？</p>
<ul>
<li>query<strong>字面上的组织方式多样</strong>：字粒度，2-gram粒度，词粒度。</li>
<li>query的<strong>表征方法多样</strong>：pooling，transformer，concat，addition等。</li>
</ul>
<p>当然，只讲结果，没有讲为什么这么做。有点过于经验性/实验性驱动，而不是问题/动机驱动。</p>
<h3 id="2-1-2-用户行为注意力机制-User-Behaviors-Attention"><a href="#2-1-2-用户行为注意力机制-User-Behaviors-Attention" class="headerlink" title="2.1.2 用户行为注意力机制(User Behaviors Attention)"></a>2.1.2 用户行为注意力机制(User Behaviors Attention)</h3><p>用户行为包括：用户的<strong>实时、短期或长期</strong>的点击或者购买行为。用户$u$在$t$时刻点击item $i$，用$i_t^u$来表示。对于物品$i_t^u$的表征向量，首先使用ID和side information(叶子类目、一级类目、品牌和所属店铺)做嵌入，然后对得到的嵌入向量<strong>做pooling或者拼接在一起。</strong></p>
<p>不同于广告和推荐场景中常用的<strong>target-item注意力机制</strong>(如DIN，DIEN等)，此处使用query注意力机制来捕捉<strong>用户历史行为</strong>和<strong>当前query</strong>的<strong>语义相关性</strong>。目的是发现哪些<strong>历史行为</strong>和本次query<strong>相关</strong>，来<strong>丰富用户在当前query下的语义/意图表征</strong>。比如：历史购买行为，篮球鞋、裙子，此次搜索query是红裙，显然篮球鞋历史行为(可能送人的)对此次query毫无帮助，直接引入还会带来噪声，而裙子历史行为对此次query是有帮助的。</p>
<p>具体而言，在搜索场景中，用户的<strong>历史行为</strong>和<strong>当前query</strong>可能<strong>都无关</strong>，参考[6]的做法，作者加了一个<strong>全零的向量</strong>到用户的<strong>行为数据</strong>中，来消除<strong>潜在噪声</strong>和解决<strong>用户历史行为和当前query可能完全无关</strong>的情况。</p>
<p><strong>这个优化点非常巧妙，如果不加全零向量，模型无论如何都会强制关注到至少一个行为，这在历史行为和当前query都无关的时候，显然是噪声。加了零向量后，在完全无关的时候，模型attend到这个零向量即可，不会引入额外的噪声。个人认为这个优化点在搜索场景中至关重要，也是和推荐场景差别较大的地方，鲜有论文会提到这点。</strong></p>
<p>接下来介绍如何融合用户的<strong>实时行为、短期行为和长期行为。</strong></p>
<ul>
<li><p><strong>实时点击行为序列</strong>：$\mathcal{R}^u={i_1^u, …, i_t^u, …, i_T^u}$，其中，$i_t^u$是ID和辅助特征嵌入拼接在一起实现。</p>
<ul>
<li>首先使用<strong>LSTM</strong>来捕捉用户行为的演变，得到LSTM的隐层输出，$\mathcal{R}_{lstm}^u={h_1^u, …, h_t^u, …, h_T^u}$。</li>
<li>接着，参考<strong>SDM</strong>[7]的做法，使用多头自注意力机制来从$\mathcal{R}_{lstm}^u$中汇聚多个潜在的兴趣点，得到$\mathcal{R}^u_{\text{self_att}}={h_1^u, …, h_t^u,…,h_T^u}$。</li>
<li>接着，加一个全零的向量进去，得到：$\mathcal{R}_{\text{zero_att}}^u={0, h_1^u, …, h_t^u,…,h_T^u} \in \mathbb{R}^{(T+1) \times d}$。</li>
<li>最后，使用注意力机制，来获取和$Q_{mgs}$最相关的实时历史行为表征，$H_{real}=softmax(Q_{mgs} \cdot R_{\text{zero_att}}^T) \cdot \mathcal{R}_{\text{zero_att}}^T$。 $H_{real} \in \mathbb{R}^{6 \times d}$，注意这个向量的维度数，实际上等价于拿组成$Q_{mgs}$的6个向量分别和实时行为做attention后，再拼接起来。</li>
</ul>
</li>
<li><p><strong>短期点击行为序列</strong>：$\mathcal{S}^u={i_1^u, …, i_t^u, …, i_T^u}$，其中，$i_t^u$是ID和辅助特征嵌入拼接在一起实现。</p>
<p>和实时行为序列表征相比，少了第一步LSTM，其它都一样。</p>
<ul>
<li>使用多头自注意力机制从$\mathcal{S}^u$中汇聚得到$\mathcal{S}^u_{\text{self_att}}$</li>
<li>同样，加一个全零的向量进去，得到：$\mathcal{S}_{\text{zero_att}}^u={0, h_1^u, …, h_t^u,…,h_T^u} \in \mathbb{R}^{(T+1) \times d}$。</li>
<li>最后，使用注意力机制，来获取和$Q_{mgs}$最相关的短期历史行为表征，$H_{short}=softmax(Q_{mgs} \cdot S_{\text{zero_att}}^T) \cdot \mathcal{S}_{\text{zero_att}}^T$ $\in \mathbb{R}^{6 \times d}$</li>
</ul>
</li>
<li><p><strong>长期点击/购买/收藏行为序列</strong>：$\mathcal{L}^u={i_1^u, …, i_t^u, …, i_T^u}$，考虑到线上用户行为变化很快，$i_t^u$是ID和辅助特征嵌入做mean pooling得到，和实时行为、短期行为中用的”<strong>拼接</strong>“方式不同。</p>
<p>除此之外，使用4种属性序列来描述1个月内用户的长期行为序列，包括：</p>
<ul>
<li>item ID序列($\mathcal{L}_{item}^u$)</li>
<li>shop ID序列($\mathcal{L}_{shop}^u$)</li>
<li>叶子节点类目ID($\mathcal{L}_{leaf}^u$)</li>
<li>品牌ID($\mathcal{L}_{brand}^u$)</li>
</ul>
<p>每种属性行为使用用户的点击、购买、收藏行为来表示。例如：物品序列$\mathcal{L}_{item}^u$包含了用户的物品点击序列$\mathcal{L}_{\text{click_item}}^u$，购买序列$\mathcal{L}_{\text{buy_item}}^u$和收藏序列$\mathcal{L}_{\text{collect_item}}^u$，全部拼接在一起，形成长期行为序列，$L_{item}^u={0, h_{click}, h_{buy}, h_{collect}}$，可以看到同样添加了零向量。则，使用query对长期行为应用注意力机制捕捉这种长期行为表征。<br>$$<br>H_{\text{a_item}}=softmax(Q_{mgs} \cdot L_{\text{item}}^T) \cdot L_{\text{item}}^T \in \mathbb{R}^{6 \times d}<br>$$<br>则：长期行为表征向量为：$H_{long}=H_{\text{a_item}} + H_{\text{a_shop}} + H_{\text{a_leaf}} + H_{\text{a_brand}} \in \mathbb{R}^{6 \times d}$。</p>
</li>
</ul>
<p><strong>由此可以回答开篇的第二个问题</strong>，query注意力机制而非target-item注意力机制以及引入零向量，能够保证捕捉和query相关的历史行为信息。</p>
<h3 id="2-1-3-语义表征和个性化行为表征融合-Fusion-of-Semantics-and-Personalization"><a href="#2-1-3-语义表征和个性化行为表征融合-Fusion-of-Semantics-and-Personalization" class="headerlink" title="2.1.3 语义表征和个性化行为表征融合 (Fusion of Semantics and Personalization)"></a>2.1.3 语义表征和个性化行为表征融合 (Fusion of Semantics and Personalization)</h3><p><strong>输入：</strong></p>
<ul>
<li>多粒度query语义表征：$Q_{mgs}$</li>
<li>个性化序列表征：$(H_{real}, H_{short}, H_{long})$</li>
</ul>
<p>使用自注意力机制来捕捉二者的关系。特别的，作者添加了$[CLS]$ token在首位，形成输入：$I={[CLS], Q_{mgs}, H_{real}, H_{short}, H_{long}}$。</p>
<p><strong>输出：</strong></p>
<p>然后将self自注意力机制的输出作为user tower的表征，$H_{qu} \in \mathbb{R}^{1 \times d}$<br>$$<br>H_{qu} = \text{Self_Att}^{first}([[CLS], Q_{mgs}, H_{real}, H_{short}, H_{long})<br>$$<br>$first$我理解是指用单头自注意力机制即可。$[CLS]$模仿BERT中的结构，可学习的向量，浓缩信息。</p>
<h2 id="2-2-Item-Tower"><a href="#2-2-Item-Tower" class="headerlink" title="2.2 Item Tower"></a>2.2 Item Tower</h2><p>根据作者的实验经验，使用Item ID和Item的Title来获得Item的表征$H_{item}$。具体而言，给定item $i$的ID，其嵌入为：$e_i \in \mathbb{R}^{1 \times d}$。给定title的分词结果$T_i={w_1^i, w_2^i, …, w_N^i}$，得到物品的表征，$H_{item} \in \mathbb{R}^{1 \times d }$，即：<br>$$<br>H_{item} = e + tanh(W_t \cdot \frac{\sum_{i=1}^N w_i}{N})<br>$$<br>其中，$W_t$是可学习的变换矩阵。作者表示，通过实验发现，使用LSTM、Transformer等来捕捉title上下文感知的表征，其效果还不如上述简单的mean-pooling。给出的理由是：大部分的title由关键词堆叠而成，且缺乏语法结构。个人理解，可能想说字面上的语义信息足够凸显，上下文信号较弱，不需要复杂的模型来捕捉语义。</p>
<h2 id="2-3-Loss-Function"><a href="#2-3-Loss-Function" class="headerlink" title="2.3 Loss Function"></a>2.3 Loss Function</h2><p>为了保证训练时的样本空间和在线推理时的样本空间一致，大部分工作会使用随机负采样的方法。但是这些工作都采用了pairwise hinge loss作为损失函数，只能进行局部的比较，和在线推理时需要的全局比较不一致。为此，作者使用了softmax交叉熵损失函数，具体而言，给定正样本$i^{+}$，<br>$$<br>\hat{y}(i^{+}|q_u) = \frac{\exp(\mathcal{F}(q_u, i^{+}))}{\sum_{i^{\prime} \in I}\exp(\mathcal{F}(q_u, i^{\prime}))}<br>$$</p>
<p>$$<br>L = -\sum_{i \in I} y_i \log(\hat{y}_i)<br>$$</p>
<p>$I$是全部的item集合。实际上就是softmax交叉熵损失，然后因为$I$的数量很大，使用sampled softmax来优化即可。此处没有太大的创新点。在sampled softmax中，仍然需要负样本，参考[2]京东的做法，作者使用同一个batch内的其它样本作为当前正样本$i^{+}$的负样本对，这个效果和使用随机任意的样本作为负样本差不多，而前者还能省不少计算资源。</p>
<p>接着，为了提高EBR系统的相关性，增加更多相关性的样本进入后续的排序阶段。作者提出了两种优化策略，</p>
<ul>
<li><p><strong>对训练集中的样本进行噪声平滑</strong>：作者引入了温度参数$\tau$。此处也没有什么太大的创新点。$\tau$无穷小时，相当于拟合one-hot分布，无限拉大正样本和负样本之间的差距；$\tau$无穷大时，相当于拟合均匀分布，无视正样本还是负样本。作者认为，训练集中用户的点击和购买行为包含有不少噪声数据，不仅受到query-product相关性的影响，也受到图片、价格、用户偏好等诸多因素的影响，即用户点击/购买的item不一定和query相关，如果一味地拟合点击/购买行为，可能会带来很多相关性问题，因此引入温度参数来平滑，温度参数参数越大，则平滑的作用越明显，让模型不去过分关注点击样本，也花点”心思”去关注没有点击但是可能是相关的样本。形如：<br>$$<br>\hat{y}(i^{+}|q_u) = \frac{\exp(\mathcal{F}(q_u, i^{+})/\tau)}{\sum_{i^{\prime} \in I}\exp(\mathcal{F}(q_u, i^{\prime})/\tau)}<br>$$</p>
</li>
<li><p><strong>生成相关性增强的困难负样本</strong>：先前有些工作[8]会引入额外的人工标注数据来提升EBR模型的相关性。和这些工作不同，作者提出了一种在embedding空间自动生成困难负样本的方法。特别的，给定一个训练样本$(q_u, i^{+}, i^{-})$，其中$i^{-}$是随机负采样的item表征，$q_u$是用户表征，$i^+$是正样本item的表征，为了得到困难负样本：</p>
<p>使用$q_u$去Item Pool中找到和其<strong>点积最大</strong>的top-N个负样本集合：$I_{hard}$，然后通过插值的方式，来混合正样本$i^{+} \in \mathbb{R}^{1 \times d}$和困难负样本$I_{hard} \in \mathbb{R}^{N \times d}$，即：<br>$$<br>I_{mix} = \alpha i^{+} + (1-\alpha)I_{hard}<br>$$<br>$I_{mix} \in \mathbb{R}^{N \times d}$，形成N个困难负样本。其中，$\alpha \in \mathbb{R}^{N \times 1}$是从均匀分布$U(a,b)$中采样到的，$0 \leq a &lt; b \leq 1$，显然，$\alpha$越接近1，生成的样本越接近正样本，即：生成的样本越困难。把生成的样本也纳入损失函数的计算：<br>$$<br>\hat{y}(i^{+}|q_u) = \frac{\exp(\mathcal{F}(q_u, i^{+})/\tau)}{\sum_{i^{\prime} \in I \cup I_{mix}}\exp(\mathcal{F}(q_u, i^{\prime})/\tau)}<br>$$<br>可以通过调参$a$和$b$来控制负样本的”困难程度”。</p>
<p>好奇的是，实现上如何高效地对$q_u$和Item Pool中所有负样本计算top-N点积？难道也是拿当前batch中的样本来计算的？另外，万一top-N里头存在相关的会有影响吗？</p>
</li>
</ul>
<p><strong>由此可以回答开篇的第三个问题</strong>，如何保证EBR系统的相关性。</p>
<h2 id="2-4-系统架构"><a href="#2-4-系统架构" class="headerlink" title="2.4 系统架构"></a>2.4 系统架构</h2><p>最后，我们来欣赏下淘宝搜索引擎的系统架构。</p>
<p><img src="/picture/machine-learning/taobao_arts.png" alt="淘宝搜索引擎架构"></p>
<p><strong>搜索的整个过程如下：</strong></p>
<ul>
<li>用户发起一次请求</li>
<li>触发多通道检索系统，形成未排序的商品集合<ul>
<li>基于倒排索引的文本匹配</li>
<li>基于Item的协同过滤</li>
<li>基于向量的检索</li>
</ul>
</li>
<li>多阶段排序<ul>
<li>粗排</li>
<li><strong>相关性排序</strong></li>
<li>精排</li>
<li>重排</li>
<li>混排：商品、广告、多模态内容</li>
</ul>
</li>
</ul>
<p>本文重点在基于向量的检索：</p>
<ul>
<li><strong>离线</strong>：使用分布式Tensorflow对过去<strong>1周内</strong>的搜索日志数据进行训练，<strong>天级更新</strong>模型参数。</li>
<li><strong>部署</strong>：item tower离线算好所有product的向量，并存在ANN索引系统里，product量级巨大，分片存，共6列，借助层次聚类算法做量化降低存储开销(实际上猜测就是Faiss)；query/user network做实时serving。实际检索的时候，能够实现类似布尔检索系统的高效检索。笔者当时针对Facebook[3]的文章，花了很长的时间做调研和理解，详细地写过一篇ANN检索的底层工程实现细节，感兴趣的可以参考下，语义向量召回之ANN检索：<a href="https://mp.weixin.qq.com/s/GDkY09tKmhEo1WZWmFK9Ug" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/GDkY09tKmhEo1WZWmFK9Ug</a></li>
<li><strong>性能</strong>：实时检索9600个item。98%的item在10ms内能检索完，即：98线为10ms。很强的性能了。</li>
</ul>
<p><img src="/picture/machine-learning/taobao_deploy.png" alt="部署"></p>
<p>还有个很重要的相关性模块还没有介绍。开篇提到过，EBR检索系统在<strong>个性化和模糊匹配方面做的很好</strong>，但是相关性上缺点也很大。归根结底在于，EBR不是完全匹配的方式，在搜索里，其实就是指不是Term Query。也即，结构化检索，比如品牌，颜色，类型等结构化字段，这些结构化字段能够很大程度上保证相关性。但是EBR却做不到这点。比如：用户检索阿迪达斯运动鞋，那么完全匹配查询能够去检索品牌：阿迪达斯，类目：运动鞋；但是EBR可能在embedding空间检索到耐克运动鞋，这显然是不相关的，会影响用户的体验。因此，作者在ANN结果的后面，又加了层相关性控制模块，对query进行了查询理解，识别出品牌、类目等意图，然后对item的title中也挖掘出品牌、类目等结构化字段，然后用这些查询理解的意图对item做term query，过滤掉未命中这些结构化字段取值的item。</p>
<p>作者还提到，Facebook[3]的文章是通过EBR系统来弥补基于完全匹配的检索系统在个性化、模糊匹配上的不足；而淘宝搜索出发点相反，是通过基于完全匹配的检索系统来提升EBR系统的<strong>相关性</strong>。总之，二者相辅相成。</p>
<h1 id="3-Evaluation"><a href="#3-Evaluation" class="headerlink" title="3. Evaluation"></a>3. Evaluation</h1><p>离线实验以及实现细节也是工业界文章的核心亮点，值得大家好好品。</p>
<h2 id="3-1-Settings"><a href="#3-1-Settings" class="headerlink" title="3.1 Settings"></a>3.1 Settings</h2><ul>
<li><p><strong>离线指标</strong>：</p>
<ul>
<li>$\text{Recall@K}$。用户点击或者购买的item作为ground truth，去预测Top-K Item。作者提到，在检索阶段，用AUC做离线指标时，和线上的GMV指标无法保持一致，而召回指标则可以。</li>
<li>$P_{good}$。相关性指标，Top-K结果中有多少个结果和query强相关，即：相关性item的数量比例。是否相关的label不是人工标注的，而是采用了一个很强的相关性模型(在单独的人工标注数据集上的AUC能够达到<strong>0.915</strong>)来打标。</li>
<li>$Num_{prank}, Num_{rank}$。衡量EBR检索系统对各个阶段的影响指标。即：预测的Top-K Item中，有多少个会进入后续的各个排序环节，进入越多，说明相关性保证的越好。</li>
</ul>
</li>
<li><p><strong>在线指标</strong>：</p>
<ul>
<li>$GMV$ = #pay amount.</li>
<li>线上相关性标注指标，$P_{good}$展示给用户的item中，和query相关的占比，$P_{good}$和$P_{\text{h_good}}$，前者用模型打标，后者外包标注。</li>
</ul>
</li>
<li><p><strong>实现细节</strong>：</p>
<ul>
<li><strong>网络结构：</strong><ul>
<li>实时行为序列最大长度50，长短期行为序列最大长度都是100，超过的mask掉，使用带mask机制的attention实现即可。</li>
<li>user tower, item tower, LSTM等结构的隐层维度数为128。</li>
<li>实时行为中，LSTM结构2层，dropout=0.2，LSTM之间加残差连接，自注意力机制头的数量是8。</li>
</ul>
</li>
<li><strong>训练：</strong><ul>
<li>batch大小为256。</li>
<li>困难负样本中，均匀分布a和b的值为0.4，0.6；生成的困难负样本数量为684。</li>
<li>温度参数$\tau=2$。</li>
<li>随机初始化所有参数。</li>
<li>AdaGrad，初始学习率0.1。</li>
<li>梯度裁剪，当梯度的L2范数超过3时做裁剪。</li>
</ul>
</li>
<li><strong>配置：</strong><ul>
<li>分布式机器学习平台，20个参数服务器，100个GPU作为worker，配置是Tesla P100。</li>
<li>训练时间：3500万步，耗时54小时。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>数据集，</strong></p>
<p>淘宝真实的搜索行为数据集，2020年12月连续8天的点击和购买日志，过滤掉了作弊用户行为。</p>
<ul>
<li><strong>训练集</strong>：前7天作为训练集，约47亿条（item维度的）。</li>
<li><strong>测试集</strong>；从第8天中，随机从搜索系统数据中抽100W条数据；从推荐系统数据中抽50W条购买数据。</li>
</ul>
<p>全量的候选item的数量级是1亿，和线上真实推断时的候选集保持一致。</p>
</li>
</ul>
<h2 id="3-2-离线对比实验"><a href="#3-2-离线对比实验" class="headerlink" title="3.2 离线对比实验"></a>3.2 离线对比实验</h2><ul>
<li><p><strong>Baseline</strong>：$\alpha$-DNN，MLP结构，很强的baseline。静态特征，统计特征，序列特征做pooling作为输入。怎么训练的没说清楚，难道是二分类任务？</p>
</li>
<li><p><strong>MGDSPR</strong>：本文的方法，如上文所述。作者提到一点，加入统计特征到MGDSPR中，recall指标并没有提升。挺神奇的。</p>
<p><img src="/picture/machine-learning/taobao_comp.png" alt="对比实验"></p>
</li>
</ul>
<p>提升还是挺大的，尤其是相关性样本的占比，以及进入粗排的相关性item的数量。</p>
<h2 id="3-3-消融实验"><a href="#3-3-消融实验" class="headerlink" title="3.3 消融实验"></a>3.3 消融实验</h2><p>几大组件，唯一没说清楚的是，不使用mgs, trm等时，用的什么做baseline？拼接？</p>
<ul>
<li>mgs：2.1.1中提出的多粒度语义单元，对recall和相关性指标都有用。</li>
<li>trm：2.1.3中的语义表征和个性化行为表征做融合，对recall和相关性指标都有用。</li>
<li>$\tau$： 2.3中的温度参数。对召回指标负向，但是对相关性指标提升非常显著。</li>
<li>$I_{mix}$，对召回指标负向，对相关性指标帮助大。</li>
</ul>
<p><img src="/picture/machine-learning/taobao_ablation.png" alt="消融实验"></p>
<p>看了消融实验，对召回指标帮助大的是mgs和trm；对相关性指标帮助大的是温度参数和困难负样本。</p>
<h2 id="3-4-Online-A-B-Test"><a href="#3-4-Online-A-B-Test" class="headerlink" title="3.4 Online A/B Test"></a>3.4 Online A/B Test</h2><p><img src="/picture/machine-learning/taobao_ab_test.png" alt="线上A/B实验"></p>
<p>有挺大的线上指标提升。</p>
<p>其它的分析实验比较常规，总结下来就是：</p>
<ul>
<li>softmax收敛速度比pairwise loss快，recall指标也高不少。</li>
<li>温度参数和困难负样本对相关性的提升很大。</li>
</ul>
<h1 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h1><p>总体而言，这篇文章干货很多，细读会发现很多细节。有几大亮点，</p>
<ul>
<li><strong>多粒度语义单元</strong>，对query语义的多粒度挖掘和表征，值得在搜索场景中尝试。</li>
<li><strong>用户行为序列在搜索场景中的建模方法</strong>，query attentive而不是target-item attentive以及零向量的引入是最大亮点，长短期融合等也值得实践。</li>
<li><strong>EBR系统对相关性的保证</strong>，softmax损失函数+温度参数；在embedding空间生产困难负样本。</li>
</ul>
<p><strong>个人认为还有几个疑问没解释清楚：</strong></p>
<ul>
<li><strong>多粒度语义单元结构如此复杂</strong>，里头每个组件都是有效的吗？过于empirically/experimentally实验驱动，而不是问题驱动。</li>
<li><p><strong>困难负样本生成的时候</strong>，如何高效地对所有Item求点积最大的top-N？这里头Top-N是否有可能存在和当前query相关的item，是否会产生负面影响？</p>
</li>
<li><p><strong>相关性模块</strong>：EBR和完全匹配的Term Query结果取交集保证相关性，那和直接用完全匹配做召回相比，增益在哪里？我理解这种只可能在召回候选集合item数量远大于排序候选集合item数量的时候才有效，EBR提前考虑了个性化因素，能够防止满足个性化需求的item无法进入排序阶段。</p>
</li>
<li><strong>实验的一些细节</strong>，baseline的训练方式没说清楚。消融实验中，不使用那4个组件时，模型用什么方式替代没说清楚。</li>
</ul>
<p>总之，同以往的EBR文章一样，值得细品和实践！</p>
<p>这是KDD 21工业界文章的第一篇分享，更多KDD 21 工业界文章参见：<a href="https://zhuanlan.zhihu.com/p/388115800" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/388115800</a></p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>[1] Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, and Bing Yin. 2019. <strong>Semantic product search</strong>. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2876–2885.</p>
<p>[2] Han Zhang, Songlin Wang, Kang Zhang, Zhiling Tang, Yunjiang Jiang, Yun Xiao, Weipeng Yan, and Wen-Yun Yang. 2020. <strong>Towards Personalized and Semantic Retrieval: An End-to-End Solution for E-commerce Search via Embedding Learning</strong>. arXiv preprint arXiv:2006.02282 (2020).</p>
<p>[3] Jui-Ting Huang, Ashish Sharma, Shuying Sun, Li Xia, David Zhang, Philip Pronin, Janani Padmanabhan, Giuseppe Ottaviano, and Linjun Yang. 2020. <strong>Embedding-based retrieval in facebook search</strong>. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2553–2561.</p>
<p>[4] Miao Fan, Jiacheng Guo, Shuai Zhu, Shuo Miao, Mingming Sun, and Ping Li. 2019. <strong>MOBIUS: towards the next generation of query-ad matching in baidu’s sponsored search</strong>. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2509–2517.</p>
<p>[5] Tao Wu, Ellie Ka-In Chio, Heng-Tze Cheng, Yu Du, Steffen Rendle, Dima Kuzmin, Ritesh Agarwal, Li Zhang, John Anderson, Sarvjeet Singh, et al. 2020. <strong>Zero-Shot Heterogeneous Transfer Learning from Recommender Systems to Cold-Start Search Retrieval.</strong> In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management. 2821–2828.</p>
<p>[6] Qingyao Ai, Daniel N Hill, SVN Vishwanathan, and W Bruce Croft. 2019. <strong>A zero attention model for personalized product search</strong>. In Proceedings of the 28th ACM International Conference on Information &amp; Knowledge Management. 379–388.</p>
<p>[7] Fuyu Lv, Taiwei Jin, Changlong Yu, Fei Sun, Quan Lin, Keping Yang, and Wilfred Ng. 2019. SDM: <strong>Sequential deep matching model for online large-scale recommender system</strong>. In Proceedings of the 28th ACM International Conference on Information &amp; Knowledge Management. 2635–2643.</p>
<p>[8] Thanh V Nguyen, Nikhil Rao, and Karthik Subbian. 2020. <strong>Learning Robust Models for e-Commerce Product Search</strong>. arXiv preprint arXiv:2005.03624 (2020).</p>
<p>[9] Embedding-based Product Retrieval in Taobao Search: <a href="https://arxiv.org/abs/2106.09297" target="_blank" rel="noopener">https://arxiv.org/abs/2106.09297</a></p>
<p>也欢迎关注我的公众号”<strong>蘑菇先生学习记</strong>“，更快更及时地获取推荐系统前沿进展！</p>
<p><img src="/picture/qr_sr_code.png" alt="qr"></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/picture/wechatpay.JPG" alt="xuetf WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/picture/alipay.JPG" alt="xuetf Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/paper/" rel="tag"># paper</a>
          
            <a href="/tags/KDD/" rel="tag"># KDD</a>
          
            <a href="/tags/搜索/" rel="tag"># 搜索</a>
          
            <a href="/tags/EBR/" rel="tag"># EBR</a>
          
            <a href="/tags/语义检索/" rel="tag"># 语义检索</a>
          
            <a href="/tags/向量/" rel="tag"># 向量</a>
          
            <a href="/tags/淘宝/" rel="tag"># 淘宝</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/10/07/recsys2021/" rel="next" title="Recsys2021 | 推荐系统论文整理和导读">
                <i class="fa fa-chevron-left"></i> Recsys2021 | 推荐系统论文整理和导读
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/10/07/kdd21/" rel="prev" title="KDD 21 | 工业界搜推广nlp论文整理">
                KDD 21 | 工业界搜推广nlp论文整理 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
         <div id="uyan_frame"></div>
    
  </div>

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400"
               alt="xuetf" />
          <p class="site-author-name" itemprop="name">xuetf</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">70</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">127</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://lsxj615.com/" title="小王子" target="_blank">小王子</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/xuetf/" title="My Github" target="_blank">My Github</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Motivation"><span class="nav-number">1.</span> <span class="nav-text">1. Motivation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Solution"><span class="nav-number">2.</span> <span class="nav-text">2. Solution</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-User-Tower"><span class="nav-number">2.1.</span> <span class="nav-text">2.1  User Tower</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-多粒度语义单元-Multi-Granular-Semantic-Unit"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1 多粒度语义单元(Multi-Granular Semantic Unit)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-用户行为注意力机制-User-Behaviors-Attention"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2 用户行为注意力机制(User Behaviors Attention)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-3-语义表征和个性化行为表征融合-Fusion-of-Semantics-and-Personalization"><span class="nav-number">2.1.3.</span> <span class="nav-text">2.1.3 语义表征和个性化行为表征融合 (Fusion of Semantics and Personalization)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-Item-Tower"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 Item Tower</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-Loss-Function"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 Loss Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-系统架构"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 系统架构</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Evaluation"><span class="nav-number">3.</span> <span class="nav-text">3. Evaluation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Settings"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Settings</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-离线对比实验"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 离线对比实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-消融实验"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 消融实验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-Online-A-B-Test"><span class="nav-number">3.4.</span> <span class="nav-text">3.4 Online A/B Test</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Summarization"><span class="nav-number">4.</span> <span class="nav-text">Summarization</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#References"><span class="nav-number">5.</span> <span class="nav-text">References</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xuetf</span>
</div>




<script type="text/x-mathjax-config">
 MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
 tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
 TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
 messageStyle: "none"
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>

<!-- <script charset="utf-8" src="/js/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

<script charset="utf-8" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>











        

<div class="busuanzi-count">

  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  



  
    
  
 
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2122877"></script>
      <!-- UY END -->
  



	





  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  <!-- custom analytics part create by xiamo -->
<script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("DFlRFg5OyISCpmUurUC3Vk4s-gzGzoHsz", "0ayDjXz6ELVOVmPMjLQH3llQ");</script>
<script>
function showTime(Counter) {
  var query = new AV.Query(Counter);
  $(".leancloud_visitors").each(function() {
    var url = $(this).attr("id").trim();
    query.equalTo("url", url);
    query.find({
      success: function(results) {
        if (results.length == 0) {
          var content = '0 ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
          return;
        }
        for (var i = 0; i < results.length; i++) {
          var object = results[i];
          var content = object.get('time') + ' ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
        }
      },
      error: function(object, error) {
        console.log("Error: " + error.code + " " + error.message);
      }
    });

  });
}

function addCount(Counter) {
  var Counter = AV.Object.extend("Counter");
  url = $(".leancloud_visitors").attr('id').trim();
  title = $(".leancloud_visitors").attr('data-flag-title').trim();
  var query = new AV.Query(Counter);
  query.equalTo("url", url);
  query.find({
    success: function(results) {
      if (results.length > 0) {
        var counter = results[0];
        counter.fetchWhenSave(true);
        counter.increment("time");
        counter.save(null, {
          success: function(counter) {
            var content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(counter, error) {
            console.log('Failed to save Visitor num, with error message: ' + error.message);
          }
        });
      } else {
        var newcounter = new Counter();
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {
          success: function(newcounter) {
              console.log("newcounter.get('time')="+newcounter.get('time'));
            var content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(newcounter, error) {
            console.log('Failed to create');
          }
        });
      }
    },
    error: function(error) {
      console.log('Error:' + error.code + " " + error.message);
    }
  });
}
$(function() {
  var Counter = AV.Object.extend("Counter");
  if ($('.leancloud_visitors').length == 1) {
    addCount(Counter);
  } else if ($('.post-title-link').length > 1) {
    showTime(Counter);
  }
}); 
</script>
  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
