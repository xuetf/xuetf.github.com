<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蘑菇先生学习记</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="xtf615.com/"/>
  <updated>2017-07-13T08:46:11.812Z</updated>
  <id>xtf615.com/</id>
  
  <author>
    <name>xuetf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>独立成分分析</title>
    <link href="xtf615.com/2017/07/12/ICA/"/>
    <id>xtf615.com/2017/07/12/ICA/</id>
    <published>2017-07-12T07:26:23.000Z</published>
    <updated>2017-07-13T08:46:11.812Z</updated>
    
    <content type="html"><![CDATA[<p>　　前文提到的PCA是一个信息提取的过程，将原始数据进行降维。而本文提到的独立成分分析ICA（Independent Components Analysis）是一个信息解混过程，ICA认为观测信号是若干个统计独立的分量的线性组合。即假设观察到的随机信号x服从模型\(x=As\),其中s为未知源信号，其分量(代表不同信号源)相互独立，A为一未知混合矩阵(As实现不同信号源的线性组合)。ICA的目的是通过且仅通过观察x来估计混合矩阵A以及源信号s。<br><a id="more"></a></p>
<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><p>　　让我们从经典的鸡尾酒宴会问题(cocktail party problem)谈起。假设在宴会中有n个人，他们可以同时说话，我们也在房间中的一些角落共放置了n个声音接收器(microphone)用来记录声音。宴会过后，我们从n个麦克风中得到了一组数据\(\{x^{(i)}\left(x_1^{(i)},x_2^{(i)},…,x_n^{(i)}\right),i=1,2,…m\}\),上标i代表采样的时间顺序，每个时刻n个声音组合得到1组样本，并且在每个时刻，每个麦克风都会得到一种n个声音的线性组合，也就是说每组样本包含了n种线性组合，m个时刻共得到了m组采样，并且每一组采样都是n维的。我们的目标是单单从这m组采样数据中分辨出每个人说话的信号。<br>　　将问题细化一下，有n个信号源\(s(s_1,s_2,…,s_n)^T,s \in \mathbb{R}^n\),每一维都是一个人的声音信号，每个人发出的声音信号独立。s是一个矩阵，假设m组样本，则s规格为\(n*m\),每一行代表一个人m个时刻的声音序列，总共有n行，即n个人的声音序列。A是一个未知的混合矩阵(mixing matrix)，用来组合叠加信号s，矩阵计算相当于s进行了线性组合，线性组合的系数由混合矩阵A来决定的。则：<br>$$x=As$$<br>　　x的意义在上文解释过，这里的x不是一个向量，是一个矩阵，其中每个列向量是\(x^{(i)},x^{(i)}=As^{(i)}\),\(x^{(i)}\)列向量是n维的，即n个接收器在i时刻接收到的序列，\(x^{(i)}\)每个分量代表i时刻不同接收器得到的所有n个声音的线性组合。例如第一个分量代表第一个接收器在第i时刻接收到的所有声音的线性组合，第n个分量代表第n个接收器在i时刻接收到的所有声音的线性组合。<br>　　表示成图如下：<br><img src="/picture/machine-learning/ica1.jpg" alt="ica"><br><img src="/picture/machine-learning/ica2.png" alt="ica"><br>　　\(x^{(i)}\)的每个分量都由\(s^{(i)}\)的分量线性表示。A和s都是未知的，x是已知的，我们要想办法根据x来推出s。这个过程也称作盲信号分离。<br>　　令\(W=A^{-1}\)，那么\(s^{(i)}=A^{-1}x^{(i)}=Wx^{(i)}\),则可将W表示成：<br>$$W=\begin{bmatrix}——w_1^T—— \\\ … \\\ ——w_n^T—— \end{bmatrix}$$<br>　　其中，\(w_i \in \mathbb{R}^n\),显然W是\(n*n\)规格的。得到：<br>$$s_j^{(i)}=w_j^{T}x^{(i)}$$</p>
<h2 id="ICA的不确定性"><a href="#ICA的不确定性" class="headerlink" title="ICA的不确定性"></a>ICA的不确定性</h2><p>　　由于w和s都不确定，那么在没有先验知识的情况下，无法同时确定这两个相关参数。比如上面的公式s=wx。当w扩大两倍时，s只需要同时扩大两倍即可，等式仍然满足，因此无法得到唯一的s。同时如果将人的编号打乱，变成另外一个顺序，如上图的蓝色节点的编号变为3,2,1，那么只需要调换A的列向量顺序即可，因此也无法单独确定s。这两种情况称为原信号不确定。<br>　　还有一种ICA不适用的情况，那就是信号不能是高斯分布的。假设只有两个人发出的声音信号符合多元正态分布\(s \sim N(0,I)\)，I是\(2*2\)的单位矩阵，s的概率密度函数以均值0为中心，投影面是椭圆的山峰状，因为\(x=As\),因此x也是高斯分布的，均值为0，协方差为\(E[xx^T]=E[Ass^TA^T]=AA^T\)。<br>　　令R是正交阵(\(RR^T=R^TR=I\)),令\(A’=AR\)，如果将\(A\)替换成\(A’\)。那么\(x’=A’s\)，s的分布仍然是多元高斯分布，则\(x’\)的均值仍然为0，协方差为：<br>$$E[x’(x’)^T]=E[A’ss^T(A’)^T]=E[ARss^T(AR)^T]=ARR^TA^T=AA^T$$<br>　　因此，不管混合矩阵是\(A\)还是\(A’\),x的分布情况是一样的，此时混合矩阵不是唯一的，因此无法确定原信号。</p>
<h1 id="密度函数与线性变换"><a href="#密度函数与线性变换" class="headerlink" title="密度函数与线性变换"></a>密度函数与线性变换</h1><p>　　在讨论ICA算法之前，我们先来回顾一下概率和线性代数里的知识。<br>　　假设我们的随机变量s有概率密度函数\(p_s(s)\)(连续值是概率密度函数，离散值是概率)。为了简单，我们再假设s是实数，有一个随机变量\(x=As\),A和x都是实数。令\(p_x\)是x的概率密度，那么怎么求\(p_x\)呢？<br>　　令\(W=A^{-1}\),首先将式子变幻成\(s=Wx\),然后得到\(P_x(x)=p_s(Ws)\),求解完毕。可惜这种方法是错误的。比如s符合均匀分布的话，即\(s \sim Uniform[0,1]\),那么s的概率密度\(P_s(s)=1\{0 \leq s \leq 1\}\),现在令A=2，即\(x=2s\),也就是说x在[0,2]上均匀分布，则\(p_x(x)=0.5\),因此，按照前面的推导会得到\(p_x(x)=p_s(0.5s)=1\),显然是不对的。正确的公式是：\(p_x=p_s(Wx)|w|\)<br>　　推导方法如下：<br>$$F_X(a)=P(X \leq a)=P(AS \leq a)= p(s \leq Wa)=F_s(Wa) \\\\<br>p_x(a)=F_X’(a)=F_S’(Wa)=p_s(Wa)|W|$$<br>　　更一般地，如果s是向量，A是可逆的方阵，那么上式仍成立。</p>
<h1 id="ICA算法"><a href="#ICA算法" class="headerlink" title="ICA算法"></a>ICA算法</h1><p>　　ICA算法归功于Bell和Sejnowski，这里使用最大似然估计来解释算法，原始的论文中使用的是一个复杂的方法Infomax principal。<br>　　我们假定每个\(s_i\)有概率密度\(p_s\),那么给定时刻原信号的联合分布是：<br>$$p(s)=\prod_{i=1}^n p_s(s_i)$$<br>　　这个公式有一个假设前提：每个人发出的声音信号各自独立。有了p(s),我们可以求得p(x):<br>$$p(x) = p_s(Wx)|W|=|W|\prod_{i=1}^n p_s(w_i^T x_i)$$<br>　　左边是每个采样信号x(n维向量)的概率，右边是每个原信号概率乘积的|W|倍。<br>　　前面提到过，如果没有先验知识，我们无法求得W和s。因此我们需要知道\(p_s(s_i)\)，我们打算选取一个概率密度函数赋给s，但是我们不能选取高斯分布的密度函数。在概率论里面，我们知道密度函数p(x)由累积分布函数（CDF）F(x)求导得到。F(x)要满足两个性质是，单调递增和取值范围在[0,1]。我们发现sigmoid函数很适合，定义域为负无穷到正无穷，值域为0到1，缓慢递增。我们假定s的累积分布函数符合sigmoid函数：<br>$$g(s)=\frac{1}{1+e^{-s}}$$<br>　　求导后：<br>$$P_s(s)=g’(s)=\frac{e^s}{(1+e^s)^2}$$<br>　　这就是s的密度函数，这里s是实数。<br>　　如果我们预先知道s的分布函数，那就不用假设了。但是在缺失的情况下，sigmoid函数能够在大多数问题上取得不错的效果。由于上式中P_s(s)是个对称函数，因此E[s]=0,那么\(E[x]=E[As]=0\),x的均值也为0.<br>　　知道了\(p_s(s)\),就剩下W了。给定采样后的训练样本\(\{x^{(i)}(x_1^{(i)},x_2^{(i)},…,x_n^{(i)},i=1,2…,m\}\)，样本对数似然估计如下，使用前面得到的x的概率密度函数：<br>$$\ell(W)=\sum_{i=1}^m \left(\sum_{j=1}^n log \ g’(w_j^T x^{(i)}) + log |W| \right)$$<br>　　接下来就是对W球到了，这里牵涉一个问题就是对行列式|W|进行求导的方法，属于矩阵微积分。这里先给出结果：<br>$$\nabla_w|W|=|W|(W^{(-1)})^T$$<br>　　最终得到的求导公式如下，\(log g’(s)\)的导数是\(1-2g(s)\)（可以自己验证）：<br>$$W:=W+\alpha \left(\begin{bmatrix}1-2g(w_1^T x^{(i)}) \\\ 1-2g(w_2^T x^{(i)}) \\\ … \\\ 1-2g(w_n^T x^{(i)})\end{bmatrix} {x^{(i)}}^T+(W^T)^{-1} \right)$$<br>　　其中\(\alpha\)是梯度上升速率，人为指定。<br>　　当迭代求出W后，便可得到\(s^{(i)}=Wx^{(i)}\)来还原出原始信号。<br>　　注意：我们计算最大似然估计时，假设了\(x^{(i)}和x^{(j)}\)之间是独立的，然而对于语音信号或者其他具有时间连续依赖特性（如温度），这个假设不成立。但是在数据足够多时，假设独立对效果影响不大，同时如果事先打乱样例，并运行随机梯度上升算法，那么就能够加快收敛速度。<br>　　回顾鸡尾酒宴会问题，s是人发出的信号，是连续值，不同时间点的s不同，每个人发出的信号之间独立(\(s_i和s_j\)之间独立)。s的累积概率分布韩式sigmoid函数，但是所有人发出声音信号都符合这个分布。A(W的逆矩阵)代表了s相对于x的位置变化，x是s和A变化后的结果。</p>
<h1 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h1><p>　　当n=3时，原始信号正弦、余弦、随机信号。如下图所示，也就相当于S矩阵：<br><img src="/picture/machine-learning/ica3.jpg" alt="ica"><br>　　经过随机混合，由6个麦克风录制下来，观察到的x信号如下，相当于X矩阵：<br><img src="/picture/machine-learning/ica4.jpg" alt="ica"><br>　　在使用ICA算法之前，需要对数据进行预处理，可使用PCA和白化。PCA、白化处理后，可以看到6路信号减少为3路，ICA仅需要这3路混合信号即可还原源信号。<br><img src="/picture/machine-learning/ica5.jpg" alt="ica"><br>　　使用ICA算法,进行多步迭代优化，就会按照信号之间独立最大的假设，将信号解混输出。得到原始S信号如下图所示：<br><img src="/picture/machine-learning/ica6.jpg" alt="ica"></p>
<h1 id="PCA和ICA的联系和区别"><a href="#PCA和ICA的联系和区别" class="headerlink" title="PCA和ICA的联系和区别"></a>PCA和ICA的联系和区别</h1><p>　　不管是PCA还是ICA，都不需要你对源信号的分布做具体的假设；如果观察到的信号为高斯，那么源信号也为高斯，此时PCA和ICA等价。下面稍作展开。<br>　　假设你观察到的信号是n维随机变量\(x=(x_1,\ldots,x_n)^T\).主成分分析（PCA）和独立成分分析（ICA）的目的都是找到一个方向，即一个n维向量\(w=(w_1,\ldots,w_n)^T\)使得线性组合\(\sum_{i=1}^nw_ix_i=w^Tx\)的某种特征最大化。</p>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA　　"></a>PCA　　</h2><p>　　PCA认为一个随机信号最有用的信息体包含在方差里。为此我们需要找到一个方向\(\mathbf{w}_1\)，使得随机信号x在该方向上的投影\(w_1^Tx\)的方差最大化。接下来，我们在与\(w_1\)正交的空间里到方向\(w_2\)，使得\(w_2^Tx\)的方差最大，以此类推直到找到所有的n个方向\(w_1,\ldots,w_n\). 用这种方法我们最终可以得到一列不相关的随机变量：\(w_1^Tx,\ldots,w_n^Tx\)。<br>　　如果用矩阵的形式，记\(W=(w_1,\ldots, w_n)\),那么本质上PCA是把原随机信号x变换成了\(y=Wx\),其中y满足,y的各分量不相关以及\(y_1,\ldots,y_n\)的方差递减。<br>　　特别地，当原随机信号x为高斯随机向量的时候，得到的y仍为高斯随机向量，此时它的各个分量不仅仅是线性无关的，它们还是独立的。<br>　　通过PCA，我们可以得到一列不相关的随机变量。至于这些随机变量是不是真的有意义，那必须根据具体情况具体分析。最常见的例子是，如果x的各分量的单位（量纲）不同，那么一般不能直接套用PCA。比如，若x的几个分量分别代表某国GDP, 人口，失业率，政府清廉指数，这些分量的单位全都不同，而且可以自行随意选取：GDP的单位可以是美元或者日元；人口单位可以是人或者千人或者百万人；失业率可以是百分比或者千分比，等等。对同一个对象（如GDP）选用不同的单位将会改变其数值，从而改变PCA的结果；而依赖“单位选择”的结果显然是没有意义的。</p>
<h2 id="ICA"><a href="#ICA" class="headerlink" title="ICA"></a>ICA</h2><p>　　ICA又称盲源分离(Blind source separation, BSS)，它假设观察到的随机信号x服从模型，其中s为未知源信号，其分量相互独立，A为一未知混合矩阵。ICA的目的是通过且仅通过观察x来估计混合矩阵A以及源信号s。大多数ICA的算法需要进行“数据预处理”（data preprocessing）：先用PCA得到y，再把y的各个分量标准化（即让各分量除以自身的标准差）得到z。预处理后得到的z满足下面性质：z的各个分量不相关；z的各个分量的方差都为1。<br>　　有许多不同的ICA算法可以通过z把A和s估计出来。以著名的FastICA算法为例，该算法寻找方向使得随机变量\(w^Tz\)的某种“非高斯性”(non-Gaussianity)的度量最大化。一种常用的非高斯性的度量是四阶矩\(\mathbb{E}[(w^Tx)^4]\)。类似PCA的流程，我们首先找\(w_1\)使得\(\mathbb{E}[(w_1^Tx)^4]\)最大；然后在与\(w_1\)正交的空间里找\(w_2\)，使得\(\mathbb{E}[(w_2^Tx)^4]\)最大，以此类推直到找到所有的\(w_1,w_2…,w_n\). 可以证明，用这种方法得到的\(w_1^T z,…,w_n^T z\)是相互独立的。<br>　　ICA认为一个信号可以被分解成若干个统计独立的分量的线性组合，而后者携带更多的信息。我们可以证明，只要源信号非高斯，那么这种分解是唯一的。若源信号为高斯的话，那么显然可能有无穷多这样的分解。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/28845451/answer/42537342" target="_blank" rel="external">知乎：独立成分分析 ( ICA ) 与主成分分析 ( PCA ) 的区别在哪里？</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　前文提到的PCA是一个信息提取的过程，将原始数据进行降维。而本文提到的独立成分分析ICA（Independent Components Analysis）是一个信息解混过程，ICA认为观测信号是若干个统计独立的分量的线性组合。即假设观察到的随机信号x服从模型\(x=As\),其中s为未知源信号，其分量(代表不同信号源)相互独立，A为一未知混合矩阵(As实现不同信号源的线性组合)。ICA的目的是通过且仅通过观察x来估计混合矩阵A以及源信号s。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="独立成分分析" scheme="xtf615.com/tags/%E7%8B%AC%E7%AB%8B%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>因子分析</title>
    <link href="xtf615.com/2017/07/10/Factor-Analysis/"/>
    <id>xtf615.com/2017/07/10/Factor-Analysis/</id>
    <published>2017-07-10T08:41:30.000Z</published>
    <updated>2017-07-11T09:13:28.649Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文主要介绍因子分析模型(Factor Analysis Model)。因子分析模型是对高斯混合模型存在的问题进行解决的一种途径。同时也是属于“空间映射”思想的一种算法。本文将对因子分析模型进行介绍，并使用EM算法进行求解。<br><a id="more"></a></p>
<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><p>　　在上一篇笔记中<a href="/2017/04/07/聚类算法/">混合高斯模型</a>，对于混合高斯模型来说，当训练数据样本数据小于样本的维度时，因为协方差矩阵是奇异的，导致不能得到高斯概率密度函数的问题。（\(\Sigma\)出现在分母）<br>　　追本溯源，这个问题可以认为数据信息缺乏的问题，即从训练数据中得不到模型所需要的全部信息。解决方法就是减少模型所需要的信息。本文提到的手段有两个，第一个就是不改变现有模型，但是加强模型的假设，例如可以对协方差矩阵进行限制，使协方差矩阵为对角矩阵，或者进一步假设对角矩阵上的对角线数值都相等，此时只要样本大于1就可以估计出限定的协方差矩阵。第二个手段则是降低模型的复杂度，提出一个需要更少参数的模型，因子分析模型就属于此类方法。本文重点讨论该模型。</p>
<h1 id="边缘和条件高斯分布"><a href="#边缘和条件高斯分布" class="headerlink" title="边缘和条件高斯分布"></a>边缘和条件高斯分布</h1><p>　　在讨论因子分析之前，先看看多元高斯分布中，条件和边缘高斯分布的求法，这个在后面因子分析的EM推导中有用。<br>　　假设x是有两个随机向量组成（可以看作将之前的\(x^{(i)}\)分成了两部分）<br>$$x=\begin{bmatrix}x_1 \\\ x_2 \end{bmatrix}$$<br>　　其中，\(x_1 \in \mathbb{R}^r, x_2 \in \mathbb{R}^s, 则x \in \mathbb{R}^{r+s}\)。假设x服从多元高斯分布\(x \sim N(\mu,\Sigma)\),其中：<br>$$\mu = \begin{bmatrix}\mu_1 \\\ \mu_2 \end{bmatrix}$$<br>$$\Sigma=\begin{bmatrix}\Sigma_{11} \ \Sigma_{12} \\\ \Sigma_{21} \ \Sigma_{22} \end{bmatrix}$$<br>　　其中，\(\mu_1 \in \mathbb{R}^r,\mu_2 \in \mathbb{R}^s,则\Sigma_{11} \in \mathbb{R}^{r*r},\Sigma_{12} \in \mathbb{R}^{r*s}\),由于协方差矩阵是对称的，故\(\Sigma_{12}=\Sigma_{21}^T \)。整体上看，\(x_1,x_2\)联合分布符合多元高斯分布。<br>　　那么只知道联合分布的情况下，如何求\(x_1\)的边缘分布呢？从上面\(\mu,\Sigma\)可以得出：<br>$$E[x_1]=\mu_1, \ Cov(x_1)=E[(x_1-\mu_1)(x_1-\mu_1)^T]=\Sigma_{11}$$<br>　　下面我们验证第二个结果：<br>$$Cov(x)=\Sigma \\\\<br>=\begin{bmatrix}\Sigma_{11} \ \Sigma_{12} \\\ \Sigma_{21} \ \Sigma_{22} \end{bmatrix} \\\\<br>=E[(x-\mu)(x-\mu)^T] \\\\<br>=E\left[\begin{bmatrix}x_1-\mu_1 \\\ x_2-\mu_2 \end{bmatrix} {\begin{bmatrix}x_1-\mu_1 \\\ x_2-\mu_2 \end{bmatrix}}^T \right] \\\\<br>=E \begin{bmatrix} (x_1-\mu_1)(x_1-\mu_1)^T \ (x_1-\mu_1)(x_2-\mu_2)^T \\\ (x_2-\mu_2)(x_1-\mu_1)^T \ (x_2-\mu_2)(x_2-\mu_2)^T \end{bmatrix}<br>$$<br>　　由此可见，多元高斯分布的边缘分布仍然是多元高斯分布。也就是说:<br>$$x_1 \sim N(\mu_1, \Sigma_{11})$$<br>　　上面求得是边缘分布，让我们考虑一下条件分布的问题，也就是\(x_1|x_2\)。根据多元高斯分布的定义：<br>$$x_1|x_2 \sim N(\mu_{1|2},\Sigma_{1|2})$$<br>　　且：<br>$$\mu_{1|2}=\mu_1 + \Sigma_{12} \Sigma_{22}^{-1}(x_2-\mu_2)$$<br>$$\Sigma_{1|2}=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1} \Sigma_{21}$$<br>　　这是接下来计算时需要的公式，这两个公式直接给出。</p>
<h1 id="因子分析模型"><a href="#因子分析模型" class="headerlink" title="因子分析模型"></a>因子分析模型</h1><h2 id="形式化定义"><a href="#形式化定义" class="headerlink" title="形式化定义"></a>形式化定义</h2><p>　　在因子分析模型中，我们假设有如下关于(x,z)的联合分布，其中z是隐含随机变量，且\( z \in \mathbb{R}^k\)<br>$$z \sim N(0,I)$$<br>$$x|z \sim N(\mu+\Lambda z,\Psi)$$<br>　　其中，模型的参数是向量\(\mu \in \mathbb{R}^n\),矩阵\(\Lambda \in \mathbb{R}^{n*k}\)以及对角矩阵\(\Psi \in \mathbb{R}^{n*n}\)。\(k\)的值通常取小于\(n\)。<br>　　因子分析模型<strong>数据产生过程</strong>的假设如下：</p>
<ul>
<li>1) 首先，在一个低维空间内用均值为0，协方差为单位矩阵的多元高斯分布生成m个隐含变量\(z^{(i)}\),\(z^{(i)}\)是k维向量，m是样本数目。</li>
<li>2) 然后使用变换矩阵\(\Lambda\)将z映射到n维空间\(\Lambda z\)。此时因为z的均值为0，映射后的均值仍然为0。</li>
<li>3) 再然后将n维向量\(\Lambda z\)再加上一个均值\(\mu\),对应的意义就是将变换后的z的均值在n维空间上平移。</li>
<li>4）由于真实样例x会有误差，在上述变换的基础上再加上误差\(\epsilon \in N(0,\Psi)\)</li>
<li>5) 最后的结果是认为训练样例生成公式为\(x=\mu+\Lambda z + \epsilon\)</li>
</ul>
<p>　　因此，我们也可以等价地定义因子分析模型如下：<br>$$z \sim N(0,I) \\\ \epsilon \sim N(0,\Psi) \\\ x=\mu+\Lambda z + \epsilon$$<br>　　其中，\(\epsilon和z\)是独立的。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>　　让我们看一个样本生成的例子方便理解因子分析模型。假设：\(z \in \mathbb{R}^1, x \in \mathbb{R}^2\)。z是一维向量，x为二维向量，再假设\(\Lambda=[1 \ 2]^T, \Psi=\begin{bmatrix} 1 \ 0 \\\ 0 \ 2 \end{bmatrix} \mu=[3 \ 1]^T\)<br>　　假设我们有m=5个二维样本点\(x^{(i)}\),两个特征如下：<br><img src="/picture/machine-learning/factor-analysis1.png" alt="factor1"><br>　　按照生成过程的5步。<br>　　１.第一步，我们首先认为在一维空间(这里k=1),存在着按高斯分布\(N(0,I)\)生成m个隐含变量\(z^{(i)}\)。如下：<br><img src="/picture/machine-learning/factor-analysis2.png" alt="factor2"><br>　　2. 然后使用某个\(\Lambda\)将一维的z映射到二维，图下：<br><img src="/picture/machine-learning/factor-analysis3.png" alt="factor3"><br>　　3. 之后加上\(\mu(\mu_1,\mu_2)^T\)，即将所有点的横坐标移动\(\mu_1\),纵坐标移动\(\mu_2\)，将直线移到一个位置，使得直线过点\(\mu\),原始左边轴的原点现在为\(\mu\)(红色点)<br><img src="/picture/machine-learning/factor-analysis4.png" alt="factor4"><br>　　4. 然而，样本点不可能这么规则，在模型上会有一定偏差，因此我们需要将上步生成的店做一些扰动，扰动\(\epsilon \sim N(0,\Psi)\).加入扰动后，得到黑色样本\(x^{(i)}\),如下：<br><img src="/picture/machine-learning/factor-analysis5.png" alt="factor5"><br>　　５.得到最终的训练样本，其中\(z,\epsilon\)均值均为0，因此\(\mu\)是原始样本点的均值。<br><img src="/picture/machine-learning/factor-analysis1.png" alt="factor1"><br>　　为了方便大家理解，在此举一个实际中使用因子分析模型的例子。<br>　　在企业形象或品牌形象的研究中，消费者可以通过一个有24个指标构成的评价体系，评价百货商场24个方面的优劣。但消费者主要关心的是三个方面，即商店的环境、商店的服务和商品的价格。因子分析方法可以通过24个变量，找出反映商店环境、商店服务水平和商店价格的三个潜在因子，对商店进行综合评价。<br>　　<strong>由以上的直观分析，我们知道了因子分析其实就是认为高维样本点实际上是由低维样本点经过高斯分布、线性变换、误差扰动生成的，因此高维数据可以使用低维来表示。</strong></p>
<h1 id="因子分析模型的推导"><a href="#因子分析模型的推导" class="headerlink" title="因子分析模型的推导"></a>因子分析模型的推导</h1><h2 id="似然函数推导"><a href="#似然函数推导" class="headerlink" title="似然函数推导"></a>似然函数推导</h2><p>　　上一节对因子分析模型进行了定义，以及从数据生成的角度对它进行了进一步阐述。本节则介绍上一节中定义的参数在模型中是如何被使用的。具体来讲，就是<strong>该模型对训练数据的似然函数是什么</strong>。<br>　　首先，重新列出模型的定义公式：<br>$$z \sim N(0,I) \\\ \epsilon \sim N(0,\Psi) \\\ x=\mu+\Lambda z + \epsilon$$<br>　　其中，误差\(\epsilon\)和隐含变量\(z\)是相互独立的。<br>　　使用高斯分布的矩阵表示法对模型进行分析。该方法认为z和x符合多元高斯分布，即:<br>$$\begin{bmatrix}z \\\ x \end{bmatrix} \sim N(\mu_{zx},\Sigma)$$<br>　　接下来就是求解\(\mu_{zx},\Sigma\)。<br>　　已知\(E[z]=0,E[\epsilon]=0\),则：<br>$$E[x]=E[\mu+\Lambda z + \epsilon]=\mu$$<br>　　故：<br>$$\mu_{zx}=\begin{bmatrix} \vec{0} \\\ \mu\end{bmatrix}$$<br>　　为了求解\(\Sigma\)，需要计算:<br>$$\Sigma_{zz}=E[(z-E[z])(z-E[z])^T] \\\ \Sigma_{zx}=\Sigma_{xz}^T=E[(z-E[z])(x-E[x])^T] \\\ \Sigma_{xx}=E[(x-E[x])(x-E[x])^T]$$<br>　　根据定义，可知\(\Sigma_{zz}=Cov(z)=I\),另外：<br>$$\Sigma_{zx}=E[(z-E[z])(x-E[x])^T] \\\ =E[z(\mu+\Lambda z + \epsilon - \mu)^T] \\\ =E[zz^T]\Lambda^T+E[z \epsilon^T]=\Lambda^T$$<br>　　上述公式最后一步,\(E[zz^T]=Cov(z)=I\)。并且，\(z,\epsilon\)相互独立，有\(E[z\epsilon^T]=E[z]E[\epsilon^T]=0\)<br>$$\Sigma_{xx}=E[(x-E[x])(x-E[x])^T]=E[(\Lambda z+\epsilon)(\Lambda z + \epsilon)^T]  \\\ =E[\Lambda z z^T \Lambda^T + \epsilon z^T \Lambda^T + \Lambda z \epsilon^T + \epsilon \epsilon^T] \\\ = \Lambda E[z z^T]\Lambda^T + E[\epsilon \epsilon^T]=\Lambda \Lambda^T + \Psi$$<br>　　将上述求解结果放在一起，得到：<br>$$\begin{bmatrix}z \\\ x \end{bmatrix} \sim N(\begin{bmatrix} \vec{0} \\\ \mu \end{bmatrix}, \begin{bmatrix}I \ 　\ \ \Lambda^T \\\ \Lambda \ \  \Lambda \Lambda^T + \Psi \end{bmatrix})$$<br>　　所以，得到ｘ的边际分布为：<br>$$x \sim N(\mu, \Lambda \Lambda^T + \Psi)$$<br>　　因而，对于一个训练集\(\{x^{(i)};i=1,2…,m\}\),我们可以写出参数的似然函数:<br>$$\ell(\mu,\Lambda,\Psi)=log \prod_{i=1}^m \frac{1}{(2\pi)^{n/2}|\Lambda \Lambda^T + \Psi|^{\frac{1}{2}}} * \\\ exp \left(-\frac{1}{2}(x^{(i)}-\mu)(\Lambda \Lambda^T + \Psi)^{-1} (x^{(i)}-\mu)^T \right)$$<br>　　由上式，若是直接最大化似然函数的方法求解参数的话，你会发现很难，因而下一节会介绍使用EM算法求解因子分析的参数。</p>
<h2 id="EM求解参数"><a href="#EM求解参数" class="headerlink" title="EM求解参数"></a>EM求解参数</h2><p>　　因子分析模型的EM求解直接套EM一般化算法中的E-step和M-step公式，对于E-step来说：<br>$$Q_i(z^{(i)})=p(z^{(i)}|x^{(i)};\mu,\Lambda,\Psi)$$<br>　　前面我们已经得到条件分布的期望和方差：<br>$$\mu_{z^{(i)}|x^{(i)}}=\Lambda^T(\Lambda \Lambda^T +\Psi)^{-1} (x^{(i)}-\mu) \\\ \Sigma_{z^{(i)}|x^{(i)}}=I-\Lambda^T (\Lambda \Lambda^T + \Psi)^{-1} \Lambda$$<br>　　代入上面两个公式，可以得到\(Q_i(z^{(i)})\)的概率密度函数了，即：<br>$$Q_i(z^{(i)})=\frac{1}{(2\pi)^{k/2}|\Sigma_{z^{(i)}|x^{(i)}}|^{1/2}}exp \left(-\frac{1}{2}(z^{(i)}-\mu_{z^{(i)}}|x^{(i)})^T \Sigma^{-1}_{z^{(i)}|x^{(i)}}(z^{(i)})-\mu_{z^{(i)}|x^{(i)}}) \right) $$　<br>　　在M-step中，需要最大化如下公式来求取<strong>参数\(\mu,\Lambda,\Psi\)</strong>:<br>$$\sum_{i=1}^m \int_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\mu,\Lambda,\Psi)}{Q_i(z^{(i)})}dz^{(i)} \\\\<br>=\sum_{i=1}^m \int_{z^{(i)}} Q_i(z^{(i)}) [log \ p(x^{(i)}|z^{(i)};\mu,\Lambda,\Psi) +log \ p(z^{(i)}) - log \ Q_i(z^{(i)})] dz^{(i)} \\\\<br>=\sum_{i=1}^m E_{z^{(i)} \sim Q_i}[log \ p(x^{(i)}|z^{(i)};\mu,\Lambda,\Psi) +log \ p(z^{(i)}) - log \ Q_i(z^{(i)})]$$<br>　　具体求解只需要分别对上述式子参数求偏导，令偏导函数为0即可求解。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文主要介绍因子分析模型(Factor Analysis Model)。因子分析模型是对高斯混合模型存在的问题进行解决的一种途径。同时也是属于“空间映射”思想的一种算法。本文将对因子分析模型进行介绍，并使用EM算法进行求解。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="无监督学习" scheme="xtf615.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="空间映射" scheme="xtf615.com/tags/%E7%A9%BA%E9%97%B4%E6%98%A0%E5%B0%84/"/>
    
  </entry>
  
  <entry>
    <title>主成分分析</title>
    <link href="xtf615.com/2017/07/08/PCA/"/>
    <id>xtf615.com/2017/07/08/PCA/</id>
    <published>2017-07-08T00:38:56.000Z</published>
    <updated>2017-07-12T01:51:28.525Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文主要介绍主成分分析算法(Principal Components Analysis,PCA)。该算法尝试搜寻数据所处的子空间，只需计算特征向量就可以进行降维。本文将尝试解释为什么通过特征向量计算能够实现降维。同时将介绍使用奇异值分解（SVD）方法来实现PCA求解。<br><a id="more"></a></p>
<h1 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h1><p>　　PCA解决了什么样的问题呢? 下面举一个例子来回答。<br>　　设想有一个数据集\(\{x^{(i)};i=1,…,m\}\),其中\(x^{(i)} \in \mathbb{R}^n \)。比如每个\(x\)代表一辆车，\(x\)的属性可能是车的最高速度，每公里耗油量等。如果有这样两个属性，一个以千米为单位的最大速度，一个以英里为单位的最大速度。这两个速度很显然是线性关系，可能因为数字取整等缘故有一点点扰动，但不影响整体线性关系。因此实际上，数据的信息量是n-1维度的。多一维度并不包括更多信息。PCA解决的就是将多余的属性去掉的问题。<br>　　再考虑这样一个例子，直升飞机驾驶员。每个驾驶员都有两个属性，第一个表示驾驶员的技能评估，第二个表示驾驶员对驾驶的兴趣程度。由于驾驶直升机难度较大，所以一般只有对其有很大的兴趣，才能较好的掌握这项技能。因此这两个属性是强相关的。实际上，根据已有的数据，可以将这两个属性使用坐标图进行展示，如下：<br><img src="/picture/machine-learning/pca1.png" alt="pca1"><br>　　由图可知，\(u_1\)展示了数据的相关性，称为主方向；\(u_2\)则反映了主方向之外的噪声，那么如何计算出主方向呢？</p>
<h1 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h1><p>　　运行PCA算法之前，数据一般需要预处理，预处理步骤如下：<br>1）令\(\mu=\frac{1}{m}\sum_{i=1}^m x^{(i)}\)<br>2) 使用\(x^{(i)}-\mu替换x^{(i)}\)<br>3）令\(\sigma_j^2=\frac{1}{m} \sum_i (x_j^{(i)})^2\)<br>4) 使用\(\frac{x_j^{(i)}}{\sigma_j}替换x_j^{(i)}\)<br>　　步骤1-2将数据的均值变成0，当已知数据的均值为0时，可以省略这两步。步骤3-4将数据的每个维度的方差变为1(此时均值已处理为0，故只需要求平方即可)，从而使得每个维度都在同一尺度都下被衡量，不会造成某些维度因数值较大而影响到。当预先知道数据处于同一尺度下时，可以忽略3-4步，比如图像处理中，已经预知了图像的每个像素都在0-255范围内，因而没有必要再进行归一化了。</p>
<h1 id="PCA算法"><a href="#PCA算法" class="headerlink" title="PCA算法"></a>PCA算法</h1><h2 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h2><p>　　如何找到数据的主方向呢？在二维空间下可以这样理解，有一个单位向量u，若从原点出发，这样定义u以后就相当于定义了一条直线。每个数据点在该直线上都有一个投影点，寻找主方向的任务就是寻找一个u使得投影点的方差最大化。<br>　　那么问题来了。问题1，能不能不从原点出发？可以，但那样计算就复杂了，我们归一化时已经将均值变为0，就是为了在寻找方向的时候使向量可以从原点出发，便于计算。问题2，多维空间下，多个主方向时怎么办？ 那就是不止寻找一个单位向量了，找到一个主方向后，将该主方向的方差影响去掉，然后再找主方向。如何去掉前一个主方向的方差影响呢？对于二维数据来说，是将所有数据点在垂直于该主方向的另一个方向上做投影，比如上图，要去掉主方向\(u_1\)的方差影响，需要在\(u_2\)方向上进行投影，多维空间上也可以类推。<br>　　以方差最大化来理解寻找主方向的依据是什么？直观上看，数据初始时会有一个方差，我们把这个方差当作数据包含的信息，我们找主方向的时候尽量使方差在子空间中最大化，从而能保留更多的信息。<br>　　再举一个例子来说明如何寻找主方向。比如下面图中的五个点。<br><img src="/picture/machine-learning/pca2.png" alt="pca2"><br>　　其中一个方向如下图所示:<br><img src="/picture/machine-learning/pca3.png" alt="pca3"><br>　　可以发现，上图中，直线上的黑点即原始数据在直线上的投影，投影的数据仍然保留着较大的方差。<br>　　相反如果取方向如下图所示：<br><img src="/picture/machine-learning/pca4.png" alt="pca4"><br>　　可以发现上图中，投影数据的方差很小。</p>
<h2 id="形式化定义"><a href="#形式化定义" class="headerlink" title="形式化定义"></a>形式化定义</h2><p>　　下面给出求主方向的形式化定义。<br>　　假设给定一个单位向量\(u\)和点\(x\),\(x\)到\(u\)的投影长度为\(x^T u\),即点\(x\)在\(u\)上的投影点，到坐标原点的距离为\(x^T u\).如下图所示:<br><img src="/picture/machine-learning/pca5.png" alt="pca5"><br>　　实际上就是向量内积。<br>　　因此，我们希望最大化投影方差，选择单位向量u使得下式最大化：<br>$$\frac{1}{m}\sum_{i=1}^m ({x^{(i)}}^T u)^2 = \frac{1}{m}\sum_{i=1}^m u^T x^{(i)} {x^{(i)}}^T u \\\\<br>=u^T \left(\frac{1}{m} \sum_{i=1}^m x^{(i)} {x^{(i)}}^T \right)u$$<br>　　上述平方展开可以根据\(X^2=X^T X\)得到，即\(({x^{(i)}}^T u)^2=({x^{(i)}}^T u)^T ({x^{(i)}}^T u)=u^T x^{(i)} {x^{(i)}}^T u\)<br>　　注意到，对于归一化后的数据，其投影点的均值也为0，因而才可以在方差的计算中直接平方。另外，该公式有一个约束条件,即\(||u||_2=1\)。<br>　　首先是协方差矩阵\(\Sigma=\frac{1}{m}\sum_{i=1}^m x^{(i)} {x^{(i)}}^T\)的理解。假设我们有两个特征a和b，有m个样本，则数据集表示为：<br>$$X^T=\begin{bmatrix} —-x^{(1)}—- \\\ —-x^{(2)}—- \\\ … \\\ —-x^{(m)}—- \end{bmatrix}=\begin{bmatrix} a_1 \ b_1 \\\\a_2 \ b_2 \\\ … \\\ a_m \ b_m \end{bmatrix}$$<br>　　则：<br>$$X=\begin{bmatrix}|　\ 　|　\ …　 \ | \\\\　 x^{(1)} \ x^{(2)}\ … \ x^{(m)} \\\\　 |　\ 　|　\ …　\ | \end{bmatrix}=\begin{bmatrix} a_1 \ a_2 \ … \ a_m \\\\b_1 \ b_2 \ … \ b_m \end{bmatrix}$$<br>　　则:<br>　　$$\Sigma=\frac{1}{m}\sum_{i=1}^m x^{(i)} {x^{(i)}}^T=\frac{1}{m}XX^T=\begin{bmatrix}\frac{1}{m} \sum_{i=1}^m a_i^2　\ \frac{1}{m} \sum_{i=1}^m a_i b_i \\\ \frac{1}{m} \sum_{i=1}^m a_i b_i　 \ \frac{1}{m} \sum_{i=1}^m b_i^2 \end{bmatrix}$$<br>　　这个最大化问题的解就是矩阵\(\Sigma=\frac{1}{m}\sum_{i=1}^m x^{(i)} {x^{(i)}}^T\)的特征向量。这是如何得到的呢？如下。<br>　　使用拉格朗日方程求解该最大化问题，则：<br>$$\ell=u^T \left(\frac{1}{m} \sum_{i=1}^m x^{(i)} {x^{(i)}}^T \right)u-\lambda(||u||_2-1)=u^T \Sigma u - \lambda(u^Tu-1)$$<br>　　对u求导：<br>$$\nabla_u \ell=\nabla_u(u^T (\Sigma)-\lambda(u^Tu-1))=\nabla_u u^T\Sigma u-\lambda \nabla_u u^T u \\\\<br>=\nabla_u tr(u^T\Sigma u)-\lambda \nabla_u tr(u^T u)=(\nabla_{u^T}tr(u^T \Sigma u))^T-\lambda(\nabla_{u^T}tr(u^T u))^T \\\\<br>={(\Sigma u)^T}^T-\lambda{u^T}^T=\Sigma u-\lambda u$$<br>令倒数为0，可知u就是\(\Sigma\)特征向量。<br>　　因为\(\Sigma\)是对称矩阵，因而可以得到相互正交的n个特征向量\(U^T=\{u^1,u^2,…,u^n\}\),那么如何达到降维的效果呢？选取最大的k个特征值所对应的特征向量即可。降维后的数据可以用如下式子来表达：<br>$$y^{(i)}=U^T x^{(i)}=\begin{bmatrix}u_1^T x^{(i)} \\\ u_2^T x^{(i)} \\\ … \\\ u_k^T x^{(i)}\end{bmatrix}$$<br>　　注意到，实际上通过特征向量来降维能够保证投影方差最大化，这也是我们的优化目标。</p>
<h1 id="PCA的应用"><a href="#PCA的应用" class="headerlink" title="PCA的应用"></a>PCA的应用</h1><p>　　压缩与可视化，如果将数据由高维降至2维和3维，那么可以使用一些可视化工具进行查看。同时数据的量也减少了。<br>　　预处理与降噪，很多监督算法在处理数据前都对数据进行降维，降维不仅使数据处理更快，还去除了数据中的噪声。是的数据的稀疏性变低，减少了模型假设的复杂度，从而降低了过拟合的概率。<br>　　具体的应用中，比如图片处理，对于一个100*100的图片，其原始特征长度为10000，，使用PCA降维后，大大减少了维度，形成了“特征脸”图片。而且还减少了噪声如光照等影响，使用PCA降维后的数据可以进行图片相似度计算，在图片检索中和人脸检测中都能达到很好的效果。</p>
<h1 id="奇异值分解（SVD）"><a href="#奇异值分解（SVD）" class="headerlink" title="奇异值分解（SVD）"></a>奇异值分解（SVD）</h1><p>　　奇异值分解时PCA的一种实现。前面我们提到PCA的实现手段是通过计算协方差矩阵\(\Sigma=\frac{1}{m} \sum_{i=1}^m x^{(i)} {x^{(i)}}^T\),然后对其特征值与特征向量进行求解。这样做的不好地方在于，协方差矩阵的维度是样本维度×样本维度。比如对于100×100的图片来说，如果以像素值作为特征，那么每张图片的特征维度是10000，则协方差矩阵的维度是10000×10000。在这样的协方差矩阵上求解特征值，耗费的计算量呈平方级增长。利用SVD可以求解出PCA的解，但是无需耗费大计算量，只需要耗费（样本量×样本维度）的计算量。下面介绍SVD:<br>　　SVD的基本公式如下：<br>$$A=UDV^T$$<br>　　即将\(A\)矩阵分解为\(U,D,V^T\)矩阵。其中，\(A \in \mathbb{R}^{m*n}, U \in \mathbb{R}^{m*n}, D \in \mathbb{R}^{n*n}\)，且\(D\)为对角矩阵，D对角线上的每个值都是特征值且已按照大小排好序，\(V^T \in \mathbb{R}^{n*n}\)。其中，U的列向量即是\(AA^T\)的特征向量，V的列向量是\(A^TA\)的特征向量。SVD的原理可以参见【参考】一节的知乎回答。令：<br>$$A=X=\begin{bmatrix}|　\ 　|　\ …　 \ | \\\\　 x^{(1)} \ x^{(2)}\ … \ x^{(m)} \\\\　 |　\ 　|　\ …　\ | \end{bmatrix}$$<br>　　因此计算量为X矩阵，即原始样本矩阵的大小。由前可知，协方差矩阵\(\Sigma=\frac{1}{m}XX^T\),那么U矩阵恰好为PCA的解。将PCA转化为SVD求解问题后，就可以进行加速了。因为SVD的求解有其特定的加速方法。本文不涉及。<br>　　SVD可以理解为PCA的一种求解方法。SVD也可以用于降维，一般情况下，D对角线中的前10%或20%的特征值已占全部特征值之和的90%以上。因而可以对\(UDV^T\)三个矩阵各自进行裁剪，比如将特征由n维降为k维。那么\(U \in \mathbb{R}^{m*k}, D \in \mathbb{R}^{k*k}, V^T \in \mathbb{R}^{k*n}\)即可。<br>　　在SVD的最后，Ng总结出一张表如下：<br><img src="/picture/machine-learning/pca6.png" alt="pca6"><br>　　表格中的内容很好理解，Ng特地强调的是这样的思考方式，寻找算法中的相同点和不同点有利于更好的理解算法。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/39234760/answer/80323126" target="_blank" rel="external">知乎：为什么PCA可以通过求解协方差矩阵计算，也可以通过分解内积矩阵计算？</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文主要介绍主成分分析算法(Principal Components Analysis,PCA)。该算法尝试搜寻数据所处的子空间，只需计算特征向量就可以进行降维。本文将尝试解释为什么通过特征向量计算能够实现降维。同时将介绍使用奇异值分解（SVD）方法来实现PCA求解。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="空间映射" scheme="xtf615.com/tags/%E7%A9%BA%E9%97%B4%E6%98%A0%E5%B0%84/"/>
    
      <category term="降维" scheme="xtf615.com/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="主成分分析" scheme="xtf615.com/tags/%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>基于ActiveMQ和Redis的分布式车辆实时数据处理</title>
    <link href="xtf615.com/2017/06/23/distributed-data-processing/"/>
    <id>xtf615.com/2017/06/23/distributed-data-processing/</id>
    <published>2017-06-23T06:12:09.000Z</published>
    <updated>2017-06-23T07:26:32.233Z</updated>
    
    <content type="html"><![CDATA[<p>　　本次毕业设计论文的题目是基于ActiveMQ和Redis的分布式车辆实时数据处理。阐述围绕四个方面展开，应用背景、相关技术、解决方案、设计实现。<br><a id="more"></a></p>
<h1 id="应用背景"><a href="#应用背景" class="headerlink" title="应用背景"></a>应用背景</h1><p>　　车联网依赖于物联网和传感器的快速发展。物联网使得车与平台、车与人、人与平台三者的交流沟通成为可能；而传感器技术使得车辆位置、状态等数据的采集成为可能。<br>　　数据是车联网平台的核心，车联网平台的业务依赖于对数据的分析、挖掘和展示。因此车联网的一个重要挑战在于海量数据的存储和处理，这也带来了实时性、负载能力等诸多难题。<br><img src="/picture/machine-learning/distributed3.png" alt="distributed"><br>　　此次分享主要围绕数据处理展开。这也是我的毕设研究内容，基于ActiveMQ和Redis这两个中间件，探讨并构建一套实时性好、响应速度快、负载能力强的车联网分布式车辆实时数据处理解决方案。</p>
<h2 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h2><p>　　车载终端，也就是传感器上报频率非常高。如果按照30s发送一次实时位置，假设我们支持3万辆车的接入能力，以最大负载来算，所有的车辆全部在线，那么1分钟内产生的实时位置数据为6万条，1小时产生的数据为360万条，1天按10小时算的话，也会产生3600万条数据。实际上，产生的数据远不止车辆实时位置，还包括表征车辆状态的CAN数据等，可见数据量是很惊人的。<br>　　另外，由于我们的云服务平台地图模块是基于Web端设计的，平台的载体是浏览器客户端，浏览器的性能瓶颈使得我们不可能一次性同时将上万级别的数据发送至地图模块处理，因此必须进行数据过滤、处理，达到流量控制的目的。<br>　　全车监控的难点在于车辆数以及产生的位置数据众多，很难实现对所有车进行实时车辆位置的定位。一旦车辆众多，既可能造成数据传输到客户端过程中出现卡死现象，也可能在对车辆进行渲染展示时造成百度地图卡死现象。上图采取聚合操作，聚合会将邻近的车辆聚合在一起，并在聚合中心上显示车辆数，一个聚合中心内可能会有上千辆车。一旦有大量新数据产生，位置移动渲染过程以及聚合计算过程将会给浏览器和地图带来很大的负载压力。假如采取轮询的方式轮询这上万辆车，进行实时位置获取，那么势必更会造成客户端性能下降。如下图所示：<br><img src="/picture/machine-learning/distributed1.png" alt="distributed"><br>　　而单车监控的难点在于实时性的控制。如下图所示，会放大到最细粒度图层，并实时绘制轨迹。用户可能同时对多辆车进行实时监控。实时监控的难点在于数据的及时性。轮询的方式首先及时性不够，会受到轮询时间间隔的影响，同时仍然会加大客户端的负载，造成用户体验下降。<br><img src="/picture/machine-learning/distributed2.png" alt="distributed"><br>　　因此针对大数据量导致的客户端负载难点，本文需要考虑对大数据量进行多次的过滤和处理，根据一定的策略实现流量控制的目的。针对实时性要求，本文需要从多方面进行设计，既包括数据采集架构来加快数据采集的及时性；又包括读写吞吐量的提升来加快数据快速处理；同时还包括数据流转的方式设计，抛弃传统的轮询方式，构建消息驱动的方式来监听数据；最后需要设计复杂的地图监控的逻辑，包括车辆移动、聚合、轨迹绘制、全车监控和实时监控切换逻辑等。<br>　　因此，这里的核心问题在于，海量数据实时性处理需求与地图和浏览器客户端性能瓶颈之间的矛盾。本文的目标不仅是能够支持大数据量的处理、存储，还需要实现实时性、地图模块稳定性、平台运行流畅、用户体验好等目标。</p>
<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p>　　为了解决这样的难题，我们的核心组件或需求应该至少包括如下几个部分，<br>　　首先需要一个高效、响应速度快、高可用的数据采集架构，能够应付车载终端源源不断采集的数据。其次需要实现海量的数据存储，一边在不断采集数据，一边就需要保存这些数据。保存数据的目的在于进行离线分析，例如历史轨迹回放，驾驶行为分析等。再进一步，如果要进行在线分析的话，就需要实时性数据处理架构，例如车辆实时监控，远程诊断。中间两个步骤分别对应于离线分析和在线分析需求。处理完之后的数据，需要传输到表现层进行渲染，因此需要一个数据推送便捷、高效的架构，尤其是针对在线分析的功能。最后一步就是Web端渲染展示，例如基于百度地图实现车辆实时监控功能。<br><img src="/picture/machine-learning/distributed4.png" alt="distributed"></p>
<h1 id="核心技术"><a href="#核心技术" class="headerlink" title="核心技术"></a>核心技术</h1><p>　　这里涉及两种技术。</p>
<h2 id="ActiveMQ"><a href="#ActiveMQ" class="headerlink" title="ActiveMQ"></a>ActiveMQ</h2><p>　　ActiveMQ是Apache出品，最流行，能力最强劲的开源消息总线，有两种消息模型，P2P点对点模式和发布订阅模式。<br>　　MQ核心应用场景包括，异步处理、应用解耦、流量削峰、消息通讯。</p>
<ul>
<li>其中异步处理能够提升系统的响应速度，处在业务处理前端的生产者服务器在处理完业务请求后，将数据写入消息队列，不需要等待消费者服务器处理就可以直接返回，响应延迟减少。</li>
<li>应用解耦能够提高系统的高可用性，即使消费者服务器发生故障，数据也可以在消息队列服务器中存储堆积，生产者服务器可以继续处理业务请求，系统整体表现无障碍，消费者服务器恢复正常后，继续处理消息队列中的数据。</li>
<li>流量削峰能够消除并发访问高峰，它是将突然增加的访问请求数据放入消息队列中，等待消费者服务器依次处理，不会对整个系统负载造成太大压力。</li>
<li>而消息通讯则经常用在广播、通知、聊天等业务中，对于新增的用户，不需要额外增加一个接口来通知，只需要使用发布订阅模型就能轻松扩展。</li>
</ul>
<p>　　在车联网项目中，使用ActiveMQ搭建消息队列服务器，通过异步的方式处理车载终端采集的数据，大幅度提高车载终端的响应能力，随着接入终端数的不断增加，可通过横向扩展，快速提升吞吐量。</p>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><p>　　Redis是一个开源、内存存储的数据结构服务器，可用作数据库，高速缓存、消息队列代理等。</p>
<ul>
<li>在易用性方面，Redis支持包括字符串，Hash表，链表，集合，有序结合在内的多种数据结构。</li>
<li>读写吞吐量方面，Redis基于内存存储，支持主从模式减少单机器并发量，支持分布式读写分离模型，提供基于管理批量读写。</li>
<li>高可用方面，Redis支持分布式集群部署、Redis主从复制、Sentinel哨兵支持单点故障转移。</li>
<li>最后，拥有众多的优秀客户端，例如Spring-data-redis、jedis等。</li>
</ul>
<p>　　在车联网项目中，将使用Redis构建分布式缓存集群。Redis提供了业务数据的内存存储和批量读写功能，可提高关键数据的快速读写。并提供主从热备、主从热切换功能，保证数据的高可靠性。</p>
<h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><p>　　该解决方案会围绕此前介绍的核心架构展开。</p>
<h2 id="数据采集架构"><a href="#数据采集架构" class="headerlink" title="数据采集架构"></a>数据采集架构</h2><p>　　前置机承担数据采集、初步校验解析、下发控制指令等工作，并将数据转发至消息队列服务器。<br>　　而消息队列服务器通过异步处理可提高前置机的响应速度和数据采集能力，随着接入终端数的不断增加，可通过横向扩展，快速的提升吞吐量，因为松耦合的软件体系结构，所以不同的业务服务器只需要采用订阅/发布的方式获取相关数据，并与数据层进行交互。<br><img src="/picture/machine-learning/distributed5.png" alt="distributed"></p>
<h2 id="数据存储架构"><a href="#数据存储架构" class="headerlink" title="数据存储架构"></a>数据存储架构</h2><p>　　结合不同的数据特点，采用不同的方式进行存储，如MySql、mongoDB、redis，并且结合不同的使用场景进行存储设计。<br>　　如图MYSQL可用于存储用户数据、车辆数据等平台中比较固定的一些业务数据。Redis缓存使用读写分离模型，适用于少量写，大量读的数据，加快业务的处理。MongoDB采用分表分片模式，用于存储海量的数据，将一些大表根据需要进行拆分，例如车辆状态数据就可能有上百/上千个属性。<br>　　因为异构数据库管理的复杂度较高，所以封装统一的访问层，从外部看，业务层仅连接一个单一的数据源。也就是统一数据访问模块。<br><img src="/picture/machine-learning/distributed6.png" alt="distributed"></p>
<h2 id="数据处理架构"><a href="#数据处理架构" class="headerlink" title="数据处理架构"></a>数据处理架构</h2><p>　　传统的方案是基于存储+轮询。构建DBP数据处理模块监听接收MQ中的数据，存储到非关系型数据库MongoDB，WEB端地图模块再通过轮询的方式读取MongoDB中的数据，再进行渲染处理。<br>　　该方案存在着诸多弊端。首先，实时性方面，存储到数据库中，再从数据库中取数据，本身步骤是繁琐多余的，比直接将数据传送到地图模块进行处理慢的多，因此会造成实时性的降低；其次，在性能方面，由于是采用轮询机制，并且需要监控每一辆在线的车，正常情况下是需要为每辆车都进行轮询查看有没有最新消息，因此会受到车辆数的影响，随着车辆的增加，性能越来越低。另外，性能还受到网络的影响，大量的数据库连接请求会降低数据库的吞吐能力。最后，稳定性方面，地图模块的稳定性会受到轮询方式的影响，由于JS是单线程的，随着车辆数的增加，轮询势必会影响地图模块的正常操作，造成用户体验下降。<br>　　本文的方案是基于缓存+消息中间件+websocket技术，能够兼顾负载能力、实时性、稳定性、流畅度等多项目标。<br>　　核心部分包括：</p>
<ul>
<li>基于Redis构建分布式缓存集群能够加快数据处理。</li>
<li>基于ActiveMQ构建数据处理模块，以消息驱动的方式对数据进行监听处理。</li>
<li>基于Websocket、百度地图实现实时监控，Websocket能够实现数据的主动推送，不需要前端进行轮询。</li>
</ul>
<h3 id="物理结构"><a href="#物理结构" class="headerlink" title="物理结构"></a>物理结构</h3><p>　　前置机模块采集车辆的位置、终端告警、CAN数据、行为数据、状态等数据，发送到消息服务器集群的全局队列MQ。这部分对应于前文提到的数据采集架构。<br>　　后台数据处理机部分的数据处理模块以异步的方式监听该队列中的数据，接收下来进行数据解析、过滤、清洗后，调用前文提到的数据存储架构中的统一数据访问模块存储到MongoDB、MYSQL或Redis当中。<br>　　对于在线分析功能，也就是实时监控的位置、告警、CAN状态数据，数据处理模块处理完后，会进行二次转发至ActiveMQ消息服务器的Location、Alarm、CAN主题。Web服务器会以发布订阅的方式监听获取主题里的数据，进行二次处理后，通过Websocket主动将数据推送至地图模块，进而进行监控或渲染。<br>　　我们可以看到这里面数据监听和处理有两处地方，<br>　　第一处是数据处理机中的数据处理模块，该模块承担着数据消费处理的核心任务，必须保证效率，所做的事情很单纯，接收解析数据后，保存到数据库当中。<br>　　第二处是Web服务器的监听模块，这部分主要用于数据的在线分析功能，也就是车辆实时监控、告警、CAN数据等，这里面主要是对数据进行二次处理。<br>　　为什么不直接在数据处理模块进行数据二次处理，并将这些数据使用WEBSOCKET推送到地图模块呢？原因在于效率，如果让数据处理模块承担这么多工作，这部分的消费就会很慢，这是数据处理的第一道门，这部分的效率慢的话，会直接导致后续业务应用的障碍。基于单一职责原则，这部分只负责数据的二次转发，数据二次处理放到WEB服务器进行处理。<br><img src="/picture/machine-learning/distributed7.png" alt="distributed"></p>
<h3 id="数据处理流程图"><a href="#数据处理流程图" class="headerlink" title="数据处理流程图"></a>数据处理流程图</h3><p>　　车载终端采集车辆数据第一次转发至MQ，数据处理模块进行第一次流量控制。<br>　　第一次流量控制主要工作是，会排除那些不存在在线监控用户的车辆数据，也就是说该车辆数据不存在监控它的在线用户，那就没必要发送到地图了。<br>　　如何判断某个数据是否存在在线用户监控它呢？这部分就需要Redis来提供大量快速的读操作，用户登录的时候会在车辆和在线用户归属关系的缓存中记录。排除后的数据只剩下存在在线用户监控的车辆数据，数据处理模块会将这部分剩余的数据二次转发到消息服务器中另外的Topic中。WEB应用模块接收下来后会进行第二次流量控制。<br>　　为了介绍第二次流量控制，这里首先介绍一下两种监控场景，全车监控和实时监控。<br>全车监控在地图级别比较大的时候，邻近的车辆会聚合起来。聚合物上面数字代表这里面聚合的车辆数目。地图放大的时候，车辆会显示出来。实时监控会实时绘制车辆的轨迹图。由于全车监控和单车监控粒度不同，全车监控会因为车辆数众多，导致地图聚合操作，而单车监控会放大到最细粒度图层，并实时绘制轨迹，故二者在粒度、精度、及时性方面要求不同。为了区分这两种方式的监控，在ActiveMQ中专门设置了两种主题，MonitorLocation对应全车监控，RealLocation对应单车实时监控。同样，用户在打开实时监控某辆车时，会在实时监控缓存中记录，因此数据处理模块在进行二次转发的时候，能够将这两种数据区分开来，发送到不同的主题当中。<br>　　在进行第二次流量控制的时候，针对全车监控，根据用户目前的地图级别、用户所处的视野、车辆位移来进行流量控制。首先是用户的视野，比如用户目前视野在福建，其他省份看不清，此时其他省份车辆位置就不需要发送过来进行监控。其次是地图级别，地图级别越大，地图图层越细，车辆移动的效果也就更明显，反之，如果地图级别缩小至全国级别，那么车辆移动很不明显，基本会处在聚合物当中，只有当位移比较大的时候，地图上才会有效果。因此需要根据地图级别以及车辆的位移来进行流量控制。整体策略是，只发送处在用户视野当中，并且位移能够明显被感知的情况。<br>　　而针对实时监控，我们不进行过滤和流量控制，只要存在监控该车的在线用户，则立即发送至前端地图模块进行实时轨迹绘制。<br>　　这样的区分能够完美的支持全车监控和单车监控场景。<br>　　紧接着，设计数据推送模块。对于处理完的数据，通过websocket和stomp.js并集成Spring，实现主动推送至前端地图模块的目的。抛弃了传统的轮询机制，能够大幅提高系统负载能力和性能，满足实时性要求。<br>　　最后，需要基于百度地图实现车辆实时监控，实现整个监控流程，包括车辆位置移动、车辆轨迹绘制、轨迹点保存、车辆聚合、全车监控和单车监控以及相互间的切换逻辑，其中聚合部分，对百度地图中的聚合操作进行优化。<br><img src="/picture/machine-learning/distributed8.png" alt="distributed"></p>
<h1 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h1><p>　　接着介绍一下实现细节。</p>
<h2 id="基于Redis构建分布式缓存"><a href="#基于Redis构建分布式缓存" class="headerlink" title="基于Redis构建分布式缓存"></a>基于Redis构建分布式缓存</h2><p>　　首先是基于Redis构建分布式缓存。从缓存集群、高可用架构、缓存API封装、缓存数据结构设计入手。</p>
<h3 id="缓存集群"><a href="#缓存集群" class="headerlink" title="缓存集群"></a>缓存集群</h3><p>　　首先是缓存集群，Redis提供了主从热备机制，主服务器的数据同步到从服务器，具体而言，采用一主多从的方式，主从之间进行数据同步，主节点接收到写操作后，直接返回成功，然后在后台用异步方式把数据同步到从节点上。主从另一个目的是进行读写分离，这是当单机读写压力过高的一种通用型解决方案。其主机的角色只提供写操作或少量的读，把多余读请求通过负载均衡算法分流到单个或多个slave服务器上。<br>　　Redis支持主从热切换。通过Sentinel哨兵组件实时监控主服务器状态并负责选举主服务器。当发现主服务器异常时根据一定的算法重新选举主服务器，并将问题服务器从可用列表中去除，原来的主节点恢复后以slave的身份重新加入。由于主节点IP发生变化，故在主节点地址发生变化后要及时通知到客户端，客户端收到新地址后，使用新地址继续发送新请求。<br><img src="/picture/machine-learning/distributed9.png" alt="distributed"></p>
<h3 id="高可用方案"><a href="#高可用方案" class="headerlink" title="高可用方案"></a>高可用方案</h3><p>　　接着是高可用方案设计。本文高可用方案包括: 构建Redis主从模式集群和Sentinel哨兵集群。使用1个主节点，3个从节点。主节点提供读写操作，从节点只提供读操作。因为数据处理模块是数据采集模块，存在着大量的读写操作，故基于本地化策略，减少网络传输消耗的时间，选择主节点Master安装在dbp模块，其余3个从节点，前期可以安装在单台机器的3个端口，后期测试稳定后，可以将其中一个安装在web端模块所在的服务器，基于本地化策略提供大量读操作，其余两个从节点单独使用两台服务器安装。另外，还需要配置3个哨兵，主节点dbp安装1个哨兵，另外3台从服务器选其中两台各安装一个，构建一个Sentinel集群，作为HA高可用方案，防止主节点单点失败。<br><img src="/picture/machine-learning/distributed10.png" alt="distributed"></p>
<h3 id="缓存API的封装"><a href="#缓存API的封装" class="headerlink" title="缓存API的封装"></a>缓存API的封装</h3><p>　　我们的目标是针对Redis缓存，定义一个通用的、轻量级的客户端访问框架，能够提供给业务层不同业务进行调用。<br>　　选择Redis的Java版本客户端Jedis进行API封装，Jedis提供了丰富的Redis底层数据结构操作方法并且Jedis能够配置连接池，也能够使用sentinel机制，通过连接sentinel集群支持HA高可用方案。<br>　　为了进一步简化API的封装以及集成Spring应用，我们选择组件spring data redis作为更上层的接口封装工具。并和jedis配套使用，spring-data-redis使用jredis作为底层连接Redis集群的工具。简化了大量复杂的数据操作方法。<br>　　更高层次的抽象，需要我们自己来定义。本文针对Redis不同的数据结构分别定制了RedisStringUtil，RedisSetUtil，RedisMapUtil，RedisListUtil四种工具类的封装，能够实现单条或批量操作。并支持自定义序列化方法。<br>　　这是部分API工具。RedisBaseUtil定义一些通用的操作。<br><img src="/picture/machine-learning/distributed11.png" alt="distributed"></p>
<h3 id="缓存数据结构"><a href="#缓存数据结构" class="headerlink" title="缓存数据结构"></a>缓存数据结构</h3><p>　　缓存数据结构强调一点。对于那些频繁读写某个类的部分字段的缓存。推荐使用hash结构。例如终端快照，<tss:终端号,属性,属性值>，可支持单独获取和修改某个或某些属性。如果大家听说过memcache的话，会发现在memcahche如果要实现这点，必须要把整个对象取出来，反序列化后，获取某个字段，再修改对象字段，序列化后存到缓存中，效率极其低下。Redis只需要一步，单独修改该字段即可。</tss:终端号,属性,属性值></p>
<h2 id="基于ActiveMQ构建实时数据处理模块"><a href="#基于ActiveMQ构建实时数据处理模块" class="headerlink" title="基于ActiveMQ构建实时数据处理模块"></a>基于ActiveMQ构建实时数据处理模块</h2><p>　　该部分是针对二次转发的主题中的数据进行接收处理，包括消息驱动实现数据监听，数据处理类图设计，全车监控流量控制。</p>
<h3 id="消息驱动"><a href="#消息驱动" class="headerlink" title="消息驱动"></a>消息驱动</h3><p>　　消息驱动主要是介绍Spring和MQ，Websocket集成。整体流程如图所示。具体配置代码也很简单。<br><img src="/picture/machine-learning/distributed12.png" alt="distributed"></p>
<h2 id="数据处理类图设计"><a href="#数据处理类图设计" class="headerlink" title="数据处理类图设计"></a>数据处理类图设计</h2><p>　　数据处理部分主要介绍使用设计模式来设计类之间的关系。为了实现低耦合、高内聚的设计，我们将数据接收、数据处理、数据发送逻辑独立出来。<br>　　其中最后一步数据发送逻辑是由上文中提到的spring-websocket组件SimpMessageSendingOperations来充当，只需要将其注入到数据处理类中，就可以直接调用方法convertAndSendToUser发送到前端进行渲染展示。<br>　　数据接收方面，我们使用MessageListenerAdapter来作为数据监听器代理类，然后委托给我们自定义的不同监听器类来执行，不同的监听器监听不同的主题，在这里，我们使用VehicleTrackListener来监听全车监控队列MonitorLocation，使用RealLocationListener来监听单车实时监控队列RealLocation，使用CanListener来监听CAN数据队列，AlarmListener来监听Alarm告警数据队列。监听器只做一件最简单的事情，就是接收数据。后续扩展非常方便，自定义监听器就可以。<br>　　数据处理方面，我们定义数据处理抽象父类MessageDispatcher，以及不同的子类，VehicleTrackDispatcher对应于全车监控数据处理，RealLocationDispatcher对应于单车监控数据处理，CanDispathcer对应于CAN数据处理，AlarmDispatcher对应于告警数据处理。<br>其中，MessageDispatcher父类定义了数据处理模板方法sendMessage，sendMessage定义了整个数据处理框架，首先获取所有的在线用户列表，然后遍历每条数据，获取有权限查看该车辆数据的所有在线用户，如果存在这样的在线用户，并且isDispatcher方法返回True，则进行发送。<br>　　isDispatcher是抽象方法，用于判断是否需要发送该数据，不同子类进行重载，根据不同数据各自的处理细节进行定制，例如全车监控需要根据用户视野和地图级别进行监控，单车监控则不进行拦截，默认返回True即可。<br>　　这部分扩展也非常方便，假如需要处理新的类型的数据。定义新的子类继承父类，如果处理逻辑类似，那么就可以共用sendMessage逻辑。重载抽象方法isDispatcher方法即可。如果不同逻辑的话，直接覆盖父类的sendMessage方法，自定义即可。<br><img src="/picture/machine-learning/distributed13.jpg" alt="distributed"></p>
<h3 id="全车监控流量控制"><a href="#全车监控流量控制" class="headerlink" title="全车监控流量控制"></a>全车监控流量控制</h3><p>　　接下来是全车流量控制，其中重点部分是视野和位移逻辑。全车监控流量控制的方法是综合考虑用户所在的地图视野、地图级别、地图聚合功能、前后两次车辆位移。首先是判断车辆位置是否处在用户视野范围，进一步判断移动位移是否足够大。<br><img src="/picture/machine-learning/distributed14.jpg" alt="distributed"></p>
<h2 id="基于Websocket-百度地图实现车辆监控"><a href="#基于Websocket-百度地图实现车辆监控" class="headerlink" title="基于Websocket/百度地图实现车辆监控"></a>基于Websocket/百度地图实现车辆监控</h2><h3 id="websocket"><a href="#websocket" class="headerlink" title="websocket"></a>websocket</h3><p>　　使用Websocket推送数据到前端，前端使用Stomp.js、Socket.js实现数据接收。这里面是使用Stomp协议进行数据传输的，Spring很容易进行配置，参考下官方文档。</p>
<h3 id="初次加载性能优化"><a href="#初次加载性能优化" class="headerlink" title="初次加载性能优化"></a>初次加载性能优化</h3><p>　　接着介绍下初次加载性能优化，我们的需求是在用户登录时，显示其视野内，有权限查看的所有车辆的最后一次位置。由于当时开发时MongoDB不支持这样复杂的批量查询，至于现在支不支持，没有查过。如果要查询的话，只能一条一条查询，性能很差。全车监控在实时性方面，只要用户在线的时候，视野内的、位移明显的最新数据能够实时展示即可，而对于初次登录的最后一次视野范围内车辆位置的精度要求不是非常高。<br>　　我们的解决方案是借助MYSQL批量查询功能，使用Quartz定时任务，在后台每30分钟将MongoDB中所有车辆的最后一次位置保存到MySQL终端快照表中，这样终端快照表中的数据就是最新的位置数据。初次加载地图时，我们只需要将车辆用户归属关系的表和终端快照表做一次连接，加上视野范围的限制条件，就能一次性批量查询出用户有权限查看的、最后一次视野范围内的车辆位置。经过这样的设计，能够实现秒级的响应性能。</p>
<h3 id="地图聚合优化"><a href="#地图聚合优化" class="headerlink" title="地图聚合优化"></a>地图聚合优化</h3><p>　　聚合功能是将邻近的车辆图标聚合在一起，减少地图上的图标数量，从而减轻地图操作，最终减轻负载的一种功能。<br>　　百度地图提供了相应的聚合功能，但是在我们实际测试过程中，发现百度地图聚合功能性能极差，在最新版的谷歌浏览器中测试，5000个点左右，对地图进行放大缩小操作，响应时间在3s左右，10000点响应时间在7s左右，30000点响应时间在20s左右，性能表现极差。我们平台目前拥有3万辆车，我们的目标是在3万辆车同时展示的最大负载情况下，依然能够实现秒级以内的性能体验，也就是说用户对地图的基础操作，应该在1s左右就能够得到响应，这样才能提高用户的体验。为了实现这样的性能提升，我们基于百度聚合功能进行性能优化。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>　　本文重点研究基于ActiveMQ和Redis构建分布式车辆实时数据处理环境，并实现车联网平台的核心业务，实时监控模块。<br>　　车联网平台大数据实时处理是一种很棘手的挑战，本文中提到的实时数据处理方法是众多应对方法中的一种。我认为本课题可以通过尝试更多方法对大数据实时处理方法进行深入探讨和研究具体方法包括：</p>
<ul>
<li>基于Storm实现实时流数据处理。Storm是一个在线实时、分布式以及具备高容错的计算系统。随着车联网平台数据进一步增加，我们可以通过搭建Storm集群，基于分布式算法来对车辆数据进行实时处理分析。</li>
<li>基于Spark构建大数据实时处理环境。Spark实现了内存级别的分布式处理模式，使用户无需关注复杂的内部工作机制，无需具备丰富的分布式系统知识及开发经验，即可实现大规模分布式系统的部署与大数据的并行处理。<br>具体改进上，可以将本文中提到的，基于web服务器监听方式的数据处理方法单独隔离出来，使用storm或spark分布式集群来处理，这样能够减轻web服务器的压力。</li>
</ul>
<p>　　总之，希望通过本文的研究，能够提供一种车联网实时数据处理的解决方案。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本次毕业设计论文的题目是基于ActiveMQ和Redis的分布式车辆实时数据处理。阐述围绕四个方面展开，应用背景、相关技术、解决方案、设计实现。&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="xtf615.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="xtf615.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="redis" scheme="xtf615.com/tags/redis/"/>
    
      <category term="ActiveMQ" scheme="xtf615.com/tags/ActiveMQ/"/>
    
      <category term="车联网" scheme="xtf615.com/tags/%E8%BD%A6%E8%81%94%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>基于股评的情感分析和股市投资策略研究</title>
    <link href="xtf615.com/2017/05/14/stock-sentiment-analysis/"/>
    <id>xtf615.com/2017/05/14/stock-sentiment-analysis/</id>
    <published>2017-05-14T13:26:39.000Z</published>
    <updated>2017-05-15T02:06:49.881Z</updated>
    
    <content type="html"><![CDATA[<p>　　本次双学位论文的题目是基于股评的情感分析和投资策略研究。阐述围绕四个方面展开，研究背景和内容、构建情感分析模型、构建时间序列预测模型以及总结展望。<br><a id="more"></a></p>
<h1 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h1><p>　　首先是研究背景。<br>　　本文的研究是基于股票市场，股市是一国经济的晴雨表，然而股市受政策、新闻、舆论的影响非常大，容易波动剧烈。因此对股市进行研究很有必要。<br>　　其次随着互联网新媒体的发展，人们越来越倾向于通过互联网平台来交流信息。实时股评中包含丰富的金融信息，体现投资者的情绪变化。因此对股市的研究可以考虑从股评入手进行挖掘分析。<br>　　最后新理论和技术的兴起。行为金融学使得对于股评的挖掘有了理论基础。文本挖掘、机器学习、时间序列模型等技术兴起使得股评挖掘成为了可能。<br><img src="/picture/machine-learning/double-degree2.png" alt="double-degree"></p>
<h1 id="研究内容"><a href="#研究内容" class="headerlink" title="研究内容"></a>研究内容</h1><p>　　因此本文的研究内容是，<strong>对股评进行情感分析并构建情感指标，结合股价建立时间序列模型，对股票走势提供一定的预测能力</strong>。这里面主要包含两方面的工作：</p>
<ul>
<li>第一，构建情感分析分类模型，实现对股票评论情感倾向的快速判断。</li>
<li>第二，构建时间序列预测模型，对股市走势提供一定的预测能力。<br><img src="/picture/machine-learning/double-degree3.png" alt="double-degree"><h1 id="构建情感分析模型"><a href="#构建情感分析模型" class="headerlink" title="构建情感分析模型"></a>构建情感分析模型</h1><h2 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h2>　　首先是数据的获取。对于股评数据，选择东方财富网的“上证指数吧”提取股评数据。为此我专门使用Python语言设计了一款爬虫程序，爬取了3554页评论，时间跨度从2016-08-25到2017-3-15，共包含283905条股票评论。如图是其中几条股评以及设计的爬虫程序目录。<br><img src="/picture/machine-learning/double-degree4.png" alt="double-degree"><br><img src="/picture/machine-learning/double-degree5.png" alt="double-degree"><br>　　对于股票行情数据，使用开源财经接口包TuShare获取数据，采集的数据包括：日期、开盘价、最高价、收盘价、最低价、成交量、价格变动、涨跌幅等数据，实现对股票数据采集、清洗加工到存储的过程。<br><img src="/picture/machine-learning/double-degree6.png" alt="double-degree"><h2 id="构建流程"><a href="#构建流程" class="headerlink" title="构建流程"></a>构建流程</h2>　　接着是情感分析模型的构建流程。<strong>目标是构建一套情感分析和机器学习模型，挖掘股评中的情绪，实现对股票评论情感倾向的快速判断</strong>。<br>　　具体流程包括使用有监督机器学习分类方法、使用向量空间模型来进行文本表示、使用中文分词对句子进行切分，使用卡方统计量作为特征选择的指标、使用文本挖掘算法进行模型训练。<br><img src="/picture/machine-learning/double-degree7.png" alt="double-degree"><br>　　在构建过程中，首先我人工标注了5000条左右的看涨看跌数据，然后将数据集进行划分，3份作为训练，1份作为测试。最后进行模型训练以及使用多种指标在测试集上进行评估。如准确率、召回率等。如图，这是特征选择时得到的有用的特征项。可以看到“跑”这个词很大程度上反映了看跌股评。<br><img src="/picture/machine-learning/double-degree8.png" alt="double-degree"><br>　　下图是不同模型得到的指标。可以看到基于多项式的贝叶斯估计分类器在各项指标上综合表现最好，准确率得到了90%。我们选择该分类器来对28万多条的股评进行看涨看跌倾向判断。<br><img src="/picture/machine-learning/double-degree9.png" alt="double-degree"><h1 id="构建时间序列预测模型"><a href="#构建时间序列预测模型" class="headerlink" title="构建时间序列预测模型"></a>构建时间序列预测模型</h1><h2 id="指标选择"><a href="#指标选择" class="headerlink" title="指标选择"></a>指标选择</h2>　　首先是指标的选择。对于情感指标，本文选择看涨指数。计算得到以日为单位的情感指标时间序列数据。如下公式所示：<br>$$BI=ln(\frac{1+M^{bull}}{1+M^{bear}})$$<br>　　对于股票指标，选择收盘价和涨跌幅进行研究。得到以日为单位的收盘价和涨跌幅时间序列数据。<br><img src="/picture/machine-learning/double-degree10.png" alt="double-degree"><h2 id="基于股票价格的股票预测模型"><a href="#基于股票价格的股票预测模型" class="headerlink" title="基于股票价格的股票预测模型"></a>基于股票价格的股票预测模型</h2>　　首先是基于股票价格的股票预测模型。这里面先不考虑情感指标，单纯的基于股票价格。具体的构建步骤包括：<br>　　平稳性检验。使用ADF单位根检验。如下图是原始的收盘价时间序列，明显有个趋势，检验结果p值大于显著性水平也表明序列不平稳。<br><img src="/picture/machine-learning/double-degree11.png" alt="double-degree"><br><img src="/picture/machine-learning/double-degree12.png" alt="double-degree"><br>　　进行一阶差分后，进行ADF检验，发现序列已经平稳了。<br><img src="/picture/machine-learning/double-degree13.png" alt="double-degree"><br><img src="/picture/machine-learning/double-degree14.png" alt="double-degree"><br>　　接着是参数的选择。ARMA(p,q)有p,q两个参数。根据自相关图拖尾特征得到q=1，根据偏自相关图的拖尾特征得到p=2。进一步使用AIC准则进行参数选择，AIC越小表明模型越好，使用AIC准则同样得到q=1,p=2。<br><img src="/picture/machine-learning/double-degree15.png" alt="double-degree"><br>　　最后使用该模型进行预测。如图是原始数据和预测数据绘制的图。<br><img src="/picture/machine-learning/double-degree16.png" alt="double-degree"><br>　　根据均方根误差指标来检验：<br>$$RMSE=\sqrt{\frac{\sum_{i=1}^n(Y_{obs,i}-Y_{model,i})^2}{n}}$$<br>　　发现均方根误差为19.4138，偏大一点，不够理想。<h2 id="相关性分析"><a href="#相关性分析" class="headerlink" title="相关性分析"></a>相关性分析</h2>　　我们考虑基于情感看涨指数序列进行改进。<br>　　首先进行看涨指数序列和过去股票涨跌幅序列相关性分析。如下图是二者绘制在一起的图，可以看出来趋势挺一致的。<br><img src="/picture/machine-learning/double-degree17.png" alt="double-degree"><br>　　进一步使用pearson相关系数分析：<br>$$\rho_{X,Y}=corr(X,Y)=\frac{cov(X,Y)}{\sigma_X \sigma_Y}=\frac{E[(X-\mu_X)(Y-\mu_Y)]}{\sigma_X \sigma_Y}$$<br>　　得到相关系数为0.677，属于较强相关，因此看涨指数一定程度上反映了股价涨跌幅趋势。<br>　　注意：这里的相关性分析的主体是看涨指数序列与过去股票涨跌幅。看涨指数不受未来股票价格走势的影响。这个是下文构建带外生变量的ARIMA模型的前提。<h2 id="基于外生变量的ARIMA模型"><a href="#基于外生变量的ARIMA模型" class="headerlink" title="基于外生变量的ARIMA模型"></a>基于外生变量的ARIMA模型</h2>　　进一步我们构建基于外生变量的ARIMA模型。外生变量是指在经济机制中受外部因素影响的变量，可以影响内部变量。股评情感指数可以看作是很多外生变量的综合反映，反映了宏观经济、公司基本面信息、政策、重大事件等诸多股票价格变动的外在因素。<br>　　因此本文构建以收盘价为内生变量，股评看涨指数为外生变量的ARIMA模型，如图是拟合结果，均方差误差已经缩小至5.7。<br><img src="/picture/machine-learning/double-degree18.png" alt="double-degree"><br>　　进一步输出模型的AIC值，足够小表明模型稳定。<br><img src="/picture/machine-learning/double-degree19.png" alt="double-degree"><br>　　最后对模型进行系数检验，系数标准差很小且z值检验接近于0，可认为显著性水平高，为下面进一步预测奠定基础。<br><img src="/picture/machine-learning/double-degree20.png" alt="double-degree"><br>　　最后我们使用外生变量的ARIMA模型进行未来股价的预测及投资策略研究。本文主要研究短期预测。首先是静态预测，我们使用模型对未来n天数据进行预测，得到该表，可以看到3-15预测很准，3-16号预测数值相差较大，3-17趋势预测错误。<br><img src="/picture/machine-learning/double-degree21.png" alt="double-degree"><br>　　上面我们发现对第二天预测的结果表现不错，我们使用滚动预测，通过添加最新的数据预测第二天的数据，得到该表。发现趋势全部预测正确，数值方面存在一点偏差。<br><img src="/picture/machine-learning/double-degree22.png" alt="double-degree"><br>　　最后总结下投资策略选择，如图是预测的走势和实际走势图，很一致。<br><img src="/picture/machine-learning/double-degree23.png" alt="double-degree"><br>　　将其和历史数据一起绘制，从整体来看，更加吻合。<br><img src="/picture/machine-learning/double-degree24.png" alt="double-degree"><br>　　因此既可以根据看涨指数和涨跌幅的强相关性，能够大致得到股票收盘价格的整体趋势变化情况。也可以结合股票历史收盘价格序列以及看涨指数，使用带外生变量的ARIMA模型，来对股票走势进行预测。</li>
</ul>
<h1 id="总结展望"><a href="#总结展望" class="headerlink" title="总结展望"></a>总结展望</h1><p>　　最后总结展望一下。本文结合股票价格和情感指标，构建时间序列预测模型，对股市短期投资策略提供一定的参考。后续的工作：</p>
<ul>
<li>可以使用算法融合思想提高情感分析的精度。</li>
<li>推广研究对象，不局限于上证指数，实现对单一股票的分析。</li>
<li>也可以推广研究指标，不局限于收盘价格和看涨指数，可以对开盘价、转手率等进行研究或构建新的情感指标。</li>
<li>最后，也可以不局限于短期预测，探索长期预测的模型和方法。<br><img src="/picture/machine-learning/double-degree25.png" alt="double-degree"></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本次双学位论文的题目是基于股评的情感分析和投资策略研究。阐述围绕四个方面展开，研究背景和内容、构建情感分析模型、构建时间序列预测模型以及总结展望。&lt;br&gt;
    
    </summary>
    
      <category term="金融学" scheme="xtf615.com/categories/%E9%87%91%E8%9E%8D%E5%AD%A6/"/>
    
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="金融" scheme="xtf615.com/tags/%E9%87%91%E8%9E%8D/"/>
    
      <category term="情感分析" scheme="xtf615.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>K-means和混合高斯模型</title>
    <link href="xtf615.com/2017/04/07/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>xtf615.com/2017/04/07/聚类算法/</id>
    <published>2017-04-07T12:14:27.000Z</published>
    <updated>2017-07-10T08:40:54.653Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文主要的内容包括：无监督学习中的K均值(k-means)聚类算法、混合高斯分布模型(Mixture of Gaussians, MoG)、求解MoG模型的期望最大化(EM)算法，以及EM一般化形式。<br><a id="more"></a></p>
<h1 id="k-means算法"><a href="#k-means算法" class="headerlink" title="k-means算法"></a>k-means算法</h1><p>　　在聚类问题中，给定一组数据\(\{x^{(1)},…,x^{(m)}\}\)，\(x^{(i)} \in \mathbb{R}^n\)，但是未给标签\(y^{(i)}\)。因此这是个无监督学习问题，需要聚类算法去发掘数据中的隐藏结构。</p>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><p>　　k-means算法的具体流程如下：</p>
<ul>
<li>1）随机初始化k个聚类中心\(\mu_1,\mu_2,…,\mu_k \in \mathbb{R}^n\)</li>
<li>2）为每个样本数据选择聚类中心，即将其类别标号设为距离其最近的聚类中心的标号：<br>  $$c^{(i)}:=arg \min_j ||x^{(i)}-\mu_j||^2$$</li>
<li>3）更新聚类中心，即更新为属于该聚类中心的所有样本的平均值：<br>  $$\mu_j=\frac{\sum_{i=1}^m I\{c^{(i)}=j\}x^{(i)}}{\sum_{i=1}^m I\{c^{(i)}=j\}}$$</li>
<li>4）重复2、3步骤，直到聚类中心不变或变化低于阈值为止。</li>
</ul>
<p>　　在上述问题中，k是k-means算法的参数，是聚类中心的数量。\(\mu_j\)代表目前对某个聚类中心的猜测。为了初始化聚类中心，我们可以随机选取k个训练样本作为聚类中心初始值。下图是k=2时的一个聚类算法演示过程：<br><img src="/picture/machine-learning/cluster1.png" alt="cluster"></p>
<h2 id="优化函数"><a href="#优化函数" class="headerlink" title="优化函数"></a>优化函数</h2><p>　　聚类算法能够保证收敛吗？我们定义k-means的优化函数为：<br>$$J(c,\mu)=\sum_{i=1}^m ||x^{(i)}-\mu_{c^{(i)}}||^2$$<br>　　\(J\)衡量了每个样本距离其中心的距离平方和。可以将k-means算法看作是目标函数J的坐标下降(coordinate descent，在SVM中SMO算法中介绍过)过程。在第2步中，我们保持聚类中心不变，将样本类别设为距离最近的中心的类别，此时对于修改了类别中心的样本，其距离的平方会变小，即\(\sum_{修改类别的样本}||x-\mu||^2\)的值变小，而没有修改类别的样本J不变，从而整体变小。在第三步中，我们保持样本类别不变，更新了聚类中心点的值，这样使得对每个类别而言，其目标函数项会变小，即\(\sum_{属于某类的样本}||x-\mu||^2\)变小，从而整体变小。因此\(J\)会不断减小，从而保证收敛，通常这也意味着\(c、\mu\)也会收敛。理论上，不同的聚类中心可能会导致相同的收敛值J，称作震荡。但在实际中很少发生。<br>　　上述目标函数\(J\)是非凸的(non-convex)，因此坐标下降法不能保证收敛到全局最优值，容易陷入局部最优值。一个较为简单的解决方法是随机初始化多次，以最优的聚类结果(即J最小)为最终结果。<br>　　在聚类结束后，如果一个中心没有得到任何样本，那么需要去除这个中心点或者重新初始化。<br>　　聚类算法可用于离群点检测。比如飞机零件评测、信用卡消费行为异常监控等。</p>
<h1 id="混合高斯分布"><a href="#混合高斯分布" class="headerlink" title="混合高斯分布"></a>混合高斯分布</h1><p>　　混合高斯分布(MoG)也是一种无监督学习算法，常用于聚类。当聚类问题中各个类别的尺寸不同、聚类间有相关关系的时候，往往使用MoG更合适。对一个样本来说，MoG得到的是其属于各个类的概率(通过计算后验概率得到)，而不是完全的属于某个类，这种聚类方法被称作软聚类。一般来说，任意形状的概率分布都可以用多个高斯分布函数取近似，因而MoG的应用比较广泛。</p>
<h2 id="形式化表述"><a href="#形式化表述" class="headerlink" title="形式化表述"></a>形式化表述</h2><p>　　在MoG问题中，<strong>数据属于哪个分布可以看成是一个隐含变量</strong>\(z\)。与k-means的硬指定不同，我们首先认为\(z^{(i)}\)满足一定的概率分布，并使用联合概率分布来进行建模，即:\(p(x^{(i)},z^{(i)})=p(x^{(i)}|z^{(i)})p(z^{(i)})\)。其中，\(z^{(i)} \sim Multinomial(\phi)\)即z服从多项式分布(\(\phi_j \geq 0, \sum_{j=1}^k \phi_j=1,\phi_j=p(z^{(i)}=j)\))。\(x^{(i)}|z^{(i)} \sim \mathcal{N}(\mu_j,\Sigma_j)\),即在给定z的条件下，x服从高斯分布。令\(k\)为\(z^{(i)}\)取值范围的数量。<strong>MoG模型假设每个\(x^{(i)}\)的产生有两个步骤，首先从k个类别中按多项式分布随机选择一个\(z^{(i)}\)，然后在给定\(z^{(i)}\)条件下，从k个高斯分布中选择使得联合概率最大的高斯分布，并从该分布中生成数据\(x^{(i)}\)</strong>。<br>　　(注意：学习一个模型的关键在于理解其<strong>数据产生</strong>的假设。后面学习因子分析模型时，也要重点关注其<strong>数据产生</strong>的假设(低维空间映射到高维空间,再增加噪声)，这是上手的突破口。)<br>　　因此我们模型的参数是:\(\phi,\mu,\Sigma\)，为了估计这些参数，我们写出似然函数：<br>$$\mathcal{l}(\phi,\mu,\Sigma)=\sum_{i=1}^m log \ p(x^{(i)};\phi,\mu,\Sigma) \\\ = \sum_{i=1}^m log \ \sum_{z^{(i)}=1}^k p(x^{(i)}|z^{(i)};\mu,\Sigma)p(z^{(i)};\phi)$$<br>　　由于\(z^{(i)}\)是未知的，如果对上述求导并设为0来求解问题，会很难求解出最大似然估计值。<br>　　随机变量\(z^{(i)}\)指明了每个样本x^{(i)}到底是从哪个高斯分布生成的。如果\(z^{(i)}\)已知，则极大似然估计就变得很容易，重写为：<br>$$\mathcal{l}(\phi,\mu,\Sigma) = \sum_{i=1}^m log \ \sum_{z^{(i)}=1}^k p(x^{(i)}|z^{(i)};\mu,\Sigma)+log \ p(z^{(i)};\phi)$$<br>　　求导得到极大似然估计结果为：<br>$$\phi_j=\frac{1}{m}\sum_{i=1}^m I\{z^{i}=j\}\\\\<br>\mu_j=\frac{\sum_{i=1}^m I\{z^{i}=j\}x^{(i)}}{\sum_{i=1}^m I\{z^{(i)}=j\}}\\\\<br>\Sigma_j=\frac{\sum_{i=1}^m I\{z^{(i)}=j\}(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^m I\{z^{(i)}=j\}}<br>$$<br>　　实际上，如果\(z^{(i)}\)的值已知，那么极大似然估计和之前生成算法中的GDA很类似，这里的\(z^{(i)}\)就相当于生成算法的类标签。所不同的是，GDA里的y是伯努利分布，而这里的z是多项式分布，并且每个样例有不同的协方差矩阵，而GDA中认为只有1个。<br>　　然而在我们的问题中，\(z^{(i)}\)是未知的，该如何解决？</p>
<h1 id="EM算法和混合高斯模型"><a href="#EM算法和混合高斯模型" class="headerlink" title="EM算法和混合高斯模型"></a>EM算法和混合高斯模型</h1><p>　　最大期望算法是一种迭代算法，主要有两个步骤。在我们的问题中，第一步E-step，尝试猜测\(z^{(i)}\)的值；第二步M-step,基于猜测，更新模型参数的值。<br>　　循环下面步骤，直到收敛：{<br>　　　　E：对于每个i和j,计算(即对每个样本i，计算由第j个高斯分布生成的概率，每个高斯分布代表一种类别，也就是z的分布):<br>$$w_j^{(i)}:= p(z^{(i)}=j|x^{(i)};\phi,\mu,\Sigma)=\frac{p(x^{(i)}|z^{(i)}=j;\mu,\Sigma)p(z^{(i)}=j;\phi)}{\sum_{l=1}^k p(x^{(i)}|z^{(i)}=l;\mu,\Sigma)p(z^{(i)}=l;\phi)}$$<br>　　　　M: 更新参数：<br>$$\phi_j:=\frac{1}{m}\sum_{i=1}^m w_j^{(i)}$$<br>$$\mu_j := \frac{\sum_{i=1}^m w_j^{(i)}x^{(i)}}{\sum_{i=1}^m w_j^{(i)}}$$<br>$$\Sigma_j := \frac{\sum_{i=1}^m w_j^{(i)}(x^{(i)}-\mu_j)(x^{(i)}-\mu_j)^T}{\sum_{i=1}^m w_j^{(i)}}$$</p>
<p>　　在E步中，我们将其他参数\(\Phi,\mu,\Sigma\)看作常量，计算\(z^{(i)}\)的后验概率，也就是估计隐含类别变量。其中，\(p(x^{(i)}|z^{(i)}=j;\mu,\Sigma)\)根据高斯密度函数得到，\(p(z^{(i)}=j;\phi)\)根据多项式分布得到。因此\(w_j^{(i)}\)代表隐含类变量\(z^{(i)}\)的软估计。<br>　　在M步中，估计好后，利用上面的公式重新计算其他参数，\(\phi_j\)是多项式分布的参数，决定了样本属于第j个高斯分布的概率。因为每个样本都会计算属于不同高斯分布生成的概率，所以可根据每个样本属于第j个高斯分布的概率来求平均得到。\(\mu_j,\Sigma\)是高斯分布的参数。<br>　　计算好后发现最大化似然估计时，\(w_j^{(i)}\)的值又不对了，需要重新计算，周而复始，直至收敛。<br>　　ＥＭ算法同样会陷入局部最优化，因此需要考虑使用不同的参数进行初始化。
　　</p>
<h1 id="一般化EM算法"><a href="#一般化EM算法" class="headerlink" title="一般化EM算法"></a>一般化EM算法</h1><p>　　上述EM算法是对于混合高斯模型的一个例子。到目前为止，我们还没有定量地给出EM的收敛性证明，以及一般化EM的推导过程。下面重点介绍这些内容。</p>
<h2 id="Jensen不等式"><a href="#Jensen不等式" class="headerlink" title="Jensen不等式"></a>Jensen不等式</h2><p>　　若f为凸函数，即\(f’’(x) \geq 0\)。注意，并不要求f一定可导，但若存在二阶导数，则必须恒大于等于0。再令X为随机变量，则存在不等式:<br>$$f(E[X]) \leq E[f(x)]$$<br>　　进一步，若二阶导数恒大于0，则不等式等号成立当且仅当x=E[x],即x是固定值。<br>　　若二阶导数的不等号方向逆转，则不等式的不等号方向逆转。<br><img src="/picture/machine-learning/cluster2.png" alt="cluster2"></p>
<h2 id="EM算法一般化形式"><a href="#EM算法一般化形式" class="headerlink" title="EM算法一般化形式"></a>EM算法一般化形式</h2><p>　　假设有一个训练集\(\{x^{(1)},x^{(2)},…,x^{(m)}\}\),由m个独立的样本构成，我们的目标是拟合包含隐变量的模型\(p(x,z)\),似然函数如下：<br>$$\ell (\theta)=\sum_{i=1}^m log p(x;\theta) \\\\<br>= \sum_{i=1}^m log \sum_{z^{(i)}} p(x,z;\theta)$$<br>　　直接对上式求导来求似然函数估计会非常困难。注意，这里的\(z^{(i)}\)是隐变量，并且和上面一样，如果\(z^{(i)}\)已知，那么似然估计很容易。但无监督算法中\(z^{(i)}\)未知。<br>　　在这种情况下，EM算法给出了最大似然估计的一种有效的求法。直接最大化\(\ell\)很困难。相反，我们通过构造\(\ell\)的下界(E-step)，并且最优化下界(M-step)来解决。<br>　　对每一个样本i，令\(Q_i\)为关于隐含变量z的分布,是一种概率(\(\sum_i Q_i(z)=1, Q_i(z) \geq 0\))<br>$$\sum_i log p(x^{(i)};\theta)=\sum_i log \sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta)\\\\<br>=\sum_{i} log \sum_{z^{(i)}} Q_i(z^{(i)})\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\\\\<br>= \sum_{i} log E\left[\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right] \\\\<br>\geq  \sum_{i}  E\left[log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\right] \\\\<br>= \sum_{i}\sum_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$$<br>　　上面推导根据Jensen不等式，log函数二阶导函数小于0，因此是非凸的，故不等号逆转。<br>　　因此有：<br>$$\ell(\theta) \geq \sum_{i}\sum_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}=lowbound(\theta)$$<br>　　现在，对任意分布\(Q_i\),\(lowbound(\theta)\)给出了\(\ell(\theta)\)的下界。\(Q_i\)的选择有很多种，我们该选择哪种呢? 假设目前已经求出了\(\theta\)的参数，我们肯定希望在\(\theta\)处使得下界更紧，最好能够使得不等式取等号。后面我们会证明，随着EM的迭代，\(\ell\)会稳步增加，逼近等号成立。<br>　　为了使得对于特定的\(\theta\)下界更紧，我们需要使得Jensen不等式取到等号。即\(X=E[X]\)时取到等号。当X为常数时，能够保证该条件成立。故令：<br>$$\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)};\theta)}=c$$<br>　　通过选择合适的\(Q_i(z^{(i)})\)，能够使得c不受\(z^{(i)}\)的影响。可以选择\(Q_i(z^{(i)})\)满足下式：<br>$$Q_i(z^{(i)}) \propto p(x^{(i)},z^{(i)};\theta)$$<br>　　又因为，\(\sum_{z^{(i)}} Q_i(z^{(i)})=1\),以及\(Q_i(z^{(i)})=\frac{p(x^{(i)},z^{(i)};\theta)}{c}\)<br>　　两边求和，<br>$$\sum_{z^{(i)}} Q_i(z^{(i)})=\sum_{z^{(i)}} \frac{p(x^{(i)},z^{(i)};\theta)}{c}=1$$<br>故，$$\sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta)=c$$<br>则：$$Q_i(z^{(i)})=\frac{p(x^{(i)},z^{(i)};\theta)}{c}=\frac{p(x^{(i)},z^{(i)};\theta)}{\sum_{z^{(i)}} p(x^{(i)},z^{(i)};\theta)}\\\\<br>=\frac{p(x^{(i)},z^{(i)};\theta)}{p(x^{(i)};\theta)} \\\\<br>=p(z^{(i)} | x^{(i)};\theta)$$<br>　　因此，只要令\(Q_i\)为给定\(\theta\)以及观察值x下，\(z^{(i)}\)的后验概率分布即可。<br>　　因此EM算法迭代过程如下：<br>　　E-step:对每一个样本i,令：<br>$$Q_i(z^{(i)}):=p(z^{(i)}|x^{(i)};\theta)$$<br>　　M-step,令：<br>　　$$\theta:=arg \max_\theta \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$$<br>　　如何保证算法的收敛性？假设\(\theta^{(t)}\)和\(\theta^{(t+1)}\)是连续两次EM算法迭代求得的参数值。我们可以证明：\(\ell(\theta^{(t+1)}) \geq \ell(\theta^{(t)})\),这意味着随着迭代次数增加，最大似然值也在稳步增加。为了得到这样的结果，这里的关键在于Q的选择。假设EM算法初始参数值为\(\theta^{(t)}\),选择Q_i^{(t)}(z^{(i)}):=p(z^{(i)}|x^{(i)};\theta^{(t)}).前面我们知道，这样的选择能够保证Jensen不等式等号成立，即使得\(\ell\)的下界最紧，根据前面，我们有：<br>$$\ell(\theta^{(t)})=\sum_i \sum_{z^{(i)}} Q_i^{(t)}(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta^{t})}{Q_i^{(t)}(z^{(i)})}$$<br>进而：<br>$$\ell(\theta^{(t+1)}) \geq \sum_i \sum_{z^{(i)}} Q_i^{(t)}(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta^{t+1})}{Q_i^{(t)}(z^{(i)})} \\\\<br>\geq \sum_i \sum_{z^{(i)}} Q_i^{(t)}(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta^{t})}{Q_i^{(t)}(z^{(i)})} \\\\<br>=\ell(\theta^{(t)})$$<br>第一个式子是根据前面的Jensen不等式：<br>$$\ell(\theta) \geq \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$$<br>当\(Q_i=Q_i^{(t)}\)时，取到等号，此时\(\theta=\theta^{(t+1)}\)。<br>第二个式子通过极大似然估计得到\(\theta^{(t+1)}\)值，也就是M-step：<br>$$arg \max_\theta \sum_i \sum_{z^{(i)}} Q_i(z^{(i)}) log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$$<br>　　为了便于理解，这里以一幅图来对EM算法进行总结。<br><img src="/picture/machine-learning/cluster3.png" alt="cluster3"><br>　　上述所展现的内容就是前面所述的主要思想，存在一个我们不能直接进行求导的似然函数，给定初始参数，我们找到在初始参数下紧挨着似然函数的下界函数，在下界上求极值来更新参数。然后以更新后的参数为初始值再次进行操作，这就是EM进行参数估计的方法。<br>　　当然似然函数不一定是图4中那样只有一个极值点，因而EM算法也有可能只求出局部极值。当然，可以像K-means那样多次选择初始参数进行求解，然后取最优的参数。<br>　　在EM的一般化形式中，可以将目标函数看作是：<br>$$J(Q,\theta)=\sum_{i=1}^m \sum_{z^{(i)}} Q_i(z^{(i)})log \frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}$$<br>　　这样，EM算法就可以看作是对目标函数的坐标上升过程。在E-step中，\(\theta\)不变，调整Q使函数变大；在M-step中，Q不变，调整\(\theta\)使目标函数变大。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文主要的内容包括：无监督学习中的K均值(k-means)聚类算法、混合高斯分布模型(Mixture of Gaussians, MoG)、求解MoG模型的期望最大化(EM)算法，以及EM一般化形式。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="无监督学习" scheme="xtf615.com/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="k-means" scheme="xtf615.com/tags/k-means/"/>
    
      <category term="混合高斯分布" scheme="xtf615.com/tags/%E6%B7%B7%E5%90%88%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83/"/>
    
      <category term="期望最大化算法" scheme="xtf615.com/tags/%E6%9C%9F%E6%9C%9B%E6%9C%80%E5%A4%A7%E5%8C%96%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>Advice for applying Machine Learning(2)</title>
    <link href="xtf615.com/2017/04/03/practice-ml-advice/"/>
    <id>xtf615.com/2017/04/03/practice-ml-advice/</id>
    <published>2017-04-03T07:21:13.000Z</published>
    <updated>2017-04-04T09:25:50.068Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文对<a href="/2017/04/01/ml-advice/">Advice for applying Machine Learning</a>一文中提到的算法诊断等理论方法进行实践，使用Python工具，具体包括数据的可视化(data visualizing)、模型选择(choosing a machine learning method suitable for the problem at hand)、过拟合和欠拟合识别和处理(identifying and dealing with over and underfitting)、大数据集处理（dealing with large datasets）以及不同代价函数(pros and cons of different loss functions)优缺点等。<br><a id="more"></a></p>
<h1 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h1><h2 id="数据集获取"><a href="#数据集获取" class="headerlink" title="数据集获取"></a>数据集获取</h2><p>　　使用\(sklearn\)自带的\(make\_classification\)方法获取数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</div><div class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</div><div class="line">X, y = make_classification(<span class="number">1000</span>, n_features=<span class="number">20</span>, n_informative=<span class="number">2</span>, </div><div class="line">                           n_redundant=<span class="number">2</span>, n_classes=<span class="number">2</span>, random_state=<span class="number">0</span>)</div><div class="line">columns = map(<span class="keyword">lambda</span> i:<span class="string">"col_"</span>+ str(i),range(<span class="number">20</span>)) + [<span class="string">"class"</span>]</div><div class="line">df = DataFrame(np.hstack((X, y[:, <span class="keyword">None</span>])), columns=columns)</div></pre></td></tr></table></figure>
<p>　　我们对二分类问题进行讨论，选取了1000个样本，20个特征。下表是部分数据：<br><img src="/picture/machine-learning/practice-advice1.jpg" alt="practice"><br>　　显然尽管维度很少，直接看这个数据很难得到关于问题的任何有用信息。我们通过可视化数据来发现规律。</p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>　　我们使用\(Seaborn\)开源库来进行可视化。<br>　　第一步我们使用pairplot方法来绘制任意两个维度和类别的关系，我们使用前100个数据，5个维度特征来进行绘图。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">_ = sns.pairplot(df[:<span class="number">100</span>], vars=[<span class="string">"col_8"</span>, <span class="string">"col_11"</span>, <span class="string">"col_12"</span>, <span class="string">"col_14"</span>, <span class="string">"col_19"</span>], hue=<span class="string">"class"</span>, size=<span class="number">1.5</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice2.png" alt="practice"><br>　　上图25幅图，是5个维度特征两两组合的结果。对角线的柱状图反映了同一个维度不同类别之间取值的差异，从图中可以看出特征11和特征14取值在不同类别间差异显著。再观察散点图，散点图反映了任意两个维度组合特征和类别的关系，我们可以根据是否线性可分或者是否存在明显的相关来判断组合特征在类别判断中是否起到作用。如图特征11和特征14的散点图，我们发现基本上是线性可分的，而特征12和特征19则存在明显的反相关。对于相关性强的特征我们必须舍弃其一，对于和类别相关性强的特征必须保留。<br>　　我们继续观察特征与特征之间以及特征与类别之间的相关性：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">10</span>))</div><div class="line">plt.xticks(rotation=<span class="number">90</span>)</div><div class="line">_ = sns.heatmap(df.corr()) <span class="comment">#df.corr()是求相关系数函数</span></div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice3.png" alt="practice"><br>　　如上图，我们使用热力图来绘制不同特征之间以及特征与类别之间的相关性。首先看最后一行，反映了类别和不同特征之间的关系。可以看到，特征11和类别关系最密切，即特征11在类别判断中能起到很重要的作用。特征14、12次之。再看特征12和特征19，我们发现存在着明显的反相关，特征11和特征14正相关性也很强。因此存在一些冗余的特征。因为我们很多模型是假设在给定类别的情况下，特征取值之间是独立的，比如朴素贝叶斯。而剩余的其他特征大部分是噪声，既和其他特征不相关，也和类别不相关。</p>
<h1 id="模型初步选择"><a href="#模型初步选择" class="headerlink" title="模型初步选择"></a>模型初步选择</h1><p>　　一旦我们对数据进行可视化完，就可以快速使用模型来进行粗糙的学习(回顾前文提到的bulid-and-fixed方法)。由于机器学习模型多样，有的时候很难决定先用哪一种方法，根据一些总结的经验，我们使用如下图谱入手：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image</div><div class="line">Image(filename=<span class="string">'machine-learning-method.png'</span>, width=<span class="number">800</span>, height=<span class="number">600</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/machine-learning-method.png" alt="practice"><br>　　因为我们有1000个样本，并且是有监督分类问题，根据图谱推荐使用\(LinearSVC\)，我们首先使用线性核函数的SVM来尝试建模。回顾一下\(SVM\)的目标函数：<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2+C \sum_{i=1}^m \zeta_i \\\ 使得, y^{(i)}(w^T x^{(i)} + b) \geq 1-\zeta_i, 　　i=1,…,m \\\ \zeta_i \geq 0,　　i=1,…,m$$<br>　　上式使用的是L2-regularized,L1-loss(\(C \sum_{i=1}^m \zeta_i\))(具体含义参加<a href="/2017/03/28/SVM支持向量机/#软间隔分类器">SVM支持向量机-软间隔分类器一节</a>)。因此penalty=’l2’,loss=’hinge’,即：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html</span></div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</div><div class="line"><span class="comment"># 二者间距较大，存在过拟合的嫌疑，即训练集拟合的很好，分数很高。但是测试集分数很低</span></div><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">10.0</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), <span class="string">"LinearSVC(C=10.0,penalty='l2',loss='hinge')"</span>,</div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.01</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice4.png" alt="practice"><br>　　上式是学习曲线，对应我们之前提到的诊断方法中的方差/误差分析图。我们在下一小节介绍该图的细节。我们现在先关注上图，我们只使用了20%(np.linspace第二个参数)，即200个数据进行训练测试。由图中可以看出，训练分数和泛化分数二者间距较大，并且训练分数处在一个很高的水准，根据之前介绍的偏差方差分析，我们可以得出，上述存在过拟合(over-fitting)的问题。注意，该学习曲线和之前偏差方差分析图存在区别：<br><img src="/picture/machine-learning/advice1.jpg" alt="advice"></p>
<p>　　区别在于，之前使用的是误差，这里使用的是得分。因此测试集和训练集分数曲线相对位置调换，训练集分数曲线在上，测试集分数曲线在下。随着样本的增多，误差曲线下降，这里分数曲线则是上升。但是相同点在于，过拟合图对应的学习曲线，训练分数(误差)和泛化分数(误差)二者间距较大，且训练分数(误差)处在一个高水准。</p>
<h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><p>　　这里我们先介绍下学习曲线绘制方法。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># http://scikit-learn.org/stable/modules/learning_curve.html#learning-curves</span></div><div class="line"><span class="keyword">from</span> sklearn.learning_curve <span class="keyword">import</span> learning_curve</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_learning_curve</span><span class="params">(estimator, title, X, y, ylim=None, cv=None,</span></span></div><div class="line">                        train_sizes=np.linspace<span class="params">(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>)</span>,baseline=None):</div><div class="line">    <span class="string">"""</span></div><div class="line">    Generate a simple plot of the test and traning learning curve.</div><div class="line"></div><div class="line">    Parameters</div><div class="line">    ----------</div><div class="line">    estimator : object type that implements the "fit" and "predict" methods</div><div class="line">        An object of that type which is cloned for each validation.</div><div class="line"></div><div class="line">    title : string</div><div class="line">        Title for the chart.</div><div class="line"></div><div class="line">    X : array-like, shape (n_samples, n_features)</div><div class="line">        Training vector, where n_samples is the number of samples and</div><div class="line">        n_features is the number of features.</div><div class="line"></div><div class="line">    y : array-like, shape (n_samples) or (n_samples, n_features), optional</div><div class="line">        Target relative to X for classification or regression;</div><div class="line">        None for unsupervised learning.</div><div class="line"></div><div class="line">    ylim : tuple, shape (ymin, ymax), optional</div><div class="line">        Defines minimum and maximum yvalues plotted.</div><div class="line"></div><div class="line">    cv : integer, cross-validation generator, optional</div><div class="line">        If an integer is passed, it is the number of folds (defaults to 3).</div><div class="line">        Specific cross-validation objects can be passed, see</div><div class="line">        sklearn.cross_validation module for the list of possible objects</div><div class="line">    """</div><div class="line">    </div><div class="line">    plt.figure()</div><div class="line">    train_sizes, train_scores, test_scores = learning_curve(</div><div class="line">        estimator, X, y, cv=<span class="number">5</span>, n_jobs=<span class="number">1</span>, train_sizes=train_sizes)</div><div class="line">    <span class="keyword">print</span> train_sizes</div><div class="line">    <span class="keyword">print</span> <span class="string">'-------------'</span></div><div class="line">    <span class="keyword">print</span> train_scores</div><div class="line">    train_scores_mean = np.mean(train_scores, axis=<span class="number">1</span>)</div><div class="line">    train_scores_std = np.std(train_scores, axis=<span class="number">1</span>)</div><div class="line">    test_scores_mean = np.mean(test_scores, axis=<span class="number">1</span>)</div><div class="line">    test_scores_std = np.std(test_scores, axis=<span class="number">1</span>)</div><div class="line"></div><div class="line">    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,</div><div class="line">                     train_scores_mean + train_scores_std, alpha=<span class="number">0.1</span>,</div><div class="line">                     color=<span class="string">"r"</span>)</div><div class="line">    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,</div><div class="line">                     test_scores_mean + test_scores_std, alpha=<span class="number">0.1</span>, color=<span class="string">"g"</span>)</div><div class="line">    plt.plot(train_sizes, train_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"r"</span>,</div><div class="line">             label=<span class="string">"Training score"</span>)</div><div class="line">    plt.plot(train_sizes, test_scores_mean, <span class="string">'o-'</span>, color=<span class="string">"b"</span>,</div><div class="line">             label=<span class="string">"Cross-validation score"</span>)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> baseline:</div><div class="line">        plt.axhline(y=baseline,color=<span class="string">'red'</span>,linewidth=<span class="number">5</span>,label=<span class="string">'Desired Performance'</span>) <span class="comment">#baseline</span></div><div class="line">    plt.xlabel(<span class="string">"Training examples"</span>)</div><div class="line">    plt.ylabel(<span class="string">"Score"</span>)</div><div class="line">    plt.legend(loc=<span class="string">"best"</span>)</div><div class="line">    plt.grid(<span class="string">"on"</span>) </div><div class="line">    <span class="keyword">if</span> ylim:</div><div class="line">        plt.ylim(ylim)</div><div class="line">    plt.title(title)</div></pre></td></tr></table></figure></p>
<p>　　简要解释下几个重要点。首先是参数，estimator代表模型，title标题，X是样本数据集，y是标签集，ylim是学习曲线y轴的取值范围(min,max)，cv是交叉验证折数，train_sizes=np.linspace(.1, 1.0, 5)代表划分训练集，np.linspace(.1, 1.0, 5)返回的结果[ 0.1  ,  0.325,  0.55 ,  0.775,  1.   ]，即等间隔划分数据集，第一个参数是起始，第二个参数是终点，最后一个参数是划分份数。因为学习曲线的x轴代表样本的数量，即画出指标在训练集和验证集上样本数量变化的情况。我们不可能对每个样本量取值(从1一直递增到1000)都进行绘图，即不能画出平滑的曲线，而是取一些关键的点进行训练绘图，上述得到的train_sizes就是每次训练的样本占总样本的比例的数组。<br>　　接着是重要的一些代码。train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=5, n_jobs=1, train_sizes=train_sizes)返回的train_sizes是根据传入的train_sizes比例数组计算的实际训练样本数量数组。train_scores是训练集的得分，是一个二维数组，第一维等于train_sizes数组大小,即每次训练的分数，第二维等于交叉验证份数cv,即每次交叉验证的得分数组。test_scores是测试集的得分。因此可以取平均进行绘图，plt.fill_between方法是图中阴影的部分。</p>
<h1 id="过拟合处理"><a href="#过拟合处理" class="headerlink" title="过拟合处理"></a>过拟合处理</h1><p>　　有许多方法可以解决过拟合问题。</p>
<h2 id="增加样本数量"><a href="#增加样本数量" class="headerlink" title="增加样本数量"></a>增加样本数量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">10.0</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), <span class="string">"LinearSVC(C=10.0,penalty='l2',loss='hinge')"</span>,</div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.01</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>), baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/practice-advice5.png" alt="practice"><br>　　这里修改linspace第二个参数为1，使用全部样本进行训练。我们发现泛化分数随着样本的增多不断增大，并且泛化分数和训练分数的间距不断缩小。但是高偏差的时候间距也是小的，我们继续进一步判断，发现训练分数和泛化分数都处在一个较高的水准，高于期望分数，而高偏差时，训练分数和泛化分数都比较低，低于理想分数。因此此时不存在过拟合或欠拟合的问题。</p>
<h2 id="减少特征"><a href="#减少特征" class="headerlink" title="减少特征"></a>减少特征</h2><p>　　根据前面的可视化分析，我们发现特征11和14和类别关联紧密，因此可以考虑先手动选择这两种特征进行训练。同样只在20%的样本上进行训练：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">10.0</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), <span class="string">"LinearSVC(C=10.0,penalty='l2',loss='hinge') Features: 11&amp;14"</span>,</div><div class="line">                    df[[<span class="string">"col_11"</span>, <span class="string">"col_14"</span>]], y, ylim=(<span class="number">0.8</span>, <span class="number">1.0</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice6.png" alt="practice">　<br>　　和最早的那幅过拟合图相比，这里的结果已经好很多，基本上解决了过拟合的问题。但是这里的特征选择方法有点作弊嫌疑，首先是因为手动选择的，其次是因为我们是在1000个样本上进行选择的，而我们最终却只使用200个样本进行训练绘图。下面进行特征自动选择：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</div><div class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest, f_classif</div><div class="line"><span class="comment"># SelectKBest(f_classif, k=2) will select the k=2 best features according to their Anova F-value</span></div><div class="line">plot_learning_curve(Pipeline([(<span class="string">"fs"</span>, SelectKBest(f_classif, k=<span class="number">2</span>)), <span class="comment"># select two features</span></div><div class="line">                               (<span class="string">"svc"</span>, LinearSVC(C=<span class="number">10.0</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>))]),</div><div class="line">                    <span class="string">"SelectKBest(f_classif, k=2) + LinearSVC(C=10.0,penalty='l2',loss='hinge')"</span>,</div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.0</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice7.png" alt="practice">　<br>　　上述使用\(SelectKBest\)选择2个特征，我们发现在这个数据集上特征选择表现很好。注意，这种特征选择方法只是减少模型复杂度的一种方法。其他方法还包括，减少线性回归中多项式的阶数，减少神经网络中隐藏层的数量和节点数，增加高斯核函数的bandwidth(\(\sigma\)),或减小\(\gamma\)等(参考<a href="http://blog.csdn.net/wusecaiyun/article/details/49681431?locationNum=4" target="_blank" rel="external">SVM C和gamma参数理解</a>)。</p>
<h2 id="修改目标函数正则化项"><a href="#修改目标函数正则化项" class="headerlink" title="修改目标函数正则化项"></a>修改目标函数正则化项</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#C表征了对离群点的重视程度，越大越重视，越大越容易过拟合。</span></div><div class="line"><span class="comment">#减小C可以一定程度上解决过拟合</span></div><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">0.1</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), <span class="string">"LinearSVC(C=0.1,penalty='l2',loss='hinge')"</span>, </div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.01</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/practice-advice8.png" alt="practice">　<br>　　惩罚因子\(C\)决定了你有多重视离群点带来的损失，显然当所有离群点的松弛变量(\(\zeta\))的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题，即C越大，你越希望在训练数据上少犯错误，而实际上这是不可能/没有意义的，于是就造成过拟合。<br>　　因此这里减少\(C\)能够一定程度上减少过拟合。<br>　　我们可以使用网格搜索来寻找最佳C。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#使用网格搜索</span></div><div class="line"><span class="keyword">from</span> sklearn.grid_search <span class="keyword">import</span> GridSearchCV</div><div class="line">est = GridSearchCV(LinearSVC(penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), </div><div class="line">                   param_grid=&#123;<span class="string">"C"</span>: [<span class="number">0.0001</span>,<span class="number">0.001</span>, <span class="number">0.01</span>, <span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>]&#125;)</div><div class="line">plot_learning_curve(est, <span class="string">"LinearSVC(C=AUTO)"</span>, </div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.0</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div><div class="line"><span class="keyword">print</span> <span class="string">"Chosen parameter on 100 datapoints: %s"</span> % est.fit(X[:<span class="number">100</span>], y[:<span class="number">100</span>]).best_params_</div></pre></td></tr></table></figure></p>
<p>输出结果：<strong>Chosen parameter on 100 datapoints: {‘C’: 0.01}</strong><br><img src="/picture/machine-learning/practice-advice9.png" alt="practice">　<br>　　特征选择看起来比修改正则化系数来的好。还有一种正则化方法，将LinearSVC的penalty设置为L1,官方文档解释为<strong>The ‘l1’ leads to coef_ vectors that are sparse</strong>,即L1可以导致稀疏参数矩阵，参数为0的特征不起作用，则相当于隐含的特征选择。不过注意,LinearSVC不支持L1-regularized和L1-loss,L1-regularized对应penalty=’l1’,L1-loss对应loss=’hinge’。可参考<a href="https://www.quora.com/Support-Vector-Machines/Liblinear-does-not-support-L1-regularized-L1-loss-hinge-loss-support-vector-classification-Why" target="_blank" rel="external">Liblinear does not support L1-regularized L1-loss ( hinge loss ) support vector classification. Why?</a>因此需要把loss改成’squared_hinge’。另外，此时不能用对偶问题来解决。故dual=False。<br><img src="/picture/machine-learning/practice-advice10.png" alt="practice">　<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">0.1</span>, penalty=<span class="string">'l1'</span>, loss=<span class="string">'squared_hinge'</span>,dual=<span class="keyword">False</span>), </div><div class="line">                    <span class="string">"LinearSVC(C=0.1, penalty='l1')"</span>, </div><div class="line">                    X, y, ylim=(<span class="number">0.8</span>, <span class="number">1.0</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.05</span>, <span class="number">0.2</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice11.png" alt="practice">　<br>　　结果看起来不错。<br>　　学习到的参数如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">est = LinearSVC(C=<span class="number">0.1</span>, penalty=<span class="string">'l1'</span>, loss=<span class="string">'squared_hinge'</span>,dual=<span class="keyword">False</span>)</div><div class="line">est.fit(X[:<span class="number">150</span>], y[:<span class="number">150</span>])  <span class="comment"># fit on 150 datapoints</span></div><div class="line"><span class="keyword">print</span> <span class="string">"Coefficients learned: %s"</span> % est.coef_</div><div class="line"><span class="keyword">print</span> <span class="string">"Non-zero coefficients: %s"</span> % np.nonzero(est.coef_)[<span class="number">1</span>]</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice12.png" alt="practice">　<br>　　可以看到特征11的权重最大，即最重要。</p>
<h1 id="欠拟合处理"><a href="#欠拟合处理" class="headerlink" title="欠拟合处理"></a>欠拟合处理</h1><p>　　之前使用的数据集分类结果都比较理想，我们尝试使用另一个二分类数据集。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_circles</div><div class="line">X, y = make_circles(n_samples=<span class="number">1000</span>, random_state=<span class="number">2</span>)<span class="comment">#只有2个特征</span></div><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">0.25</span>), <span class="string">"LinearSVC(C=0.25)"</span>, </div><div class="line">                    X, y, ylim=(<span class="number">0.4</span>, <span class="number">1.0</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>))<span class="comment">#效果非常差</span></div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice13.png" alt="practice"><br>　　由上图可以看出，训练分数和泛化分数差距很小，并且训练分数明显低于期望分数。根据之前的方差/偏差分析可知，这里存在着明显的偏差，即欠拟合问题。<br>　　我们首先对数据进行可视化观察：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 环形数据，外圈的数据是一种类别，内圈的数据是一种类别</span></div><div class="line">columns = map(<span class="keyword">lambda</span> i:<span class="string">"col_"</span>+ str(i),range(<span class="number">2</span>)) + [<span class="string">"class"</span>]</div><div class="line">df = DataFrame(np.hstack((X, y[:, <span class="keyword">None</span>])), </div><div class="line">               columns = columns)</div><div class="line">_ = sns.pairplot(df, vars=[<span class="string">"col_0"</span>, <span class="string">"col_1"</span>], hue=<span class="string">"class"</span>, size=<span class="number">3.5</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice14.png" alt="practice"><br>　　根据上图，该数据集是环形数据，外圈的点代表一种类别，内圈的点代表另一种类别。显然上述数据是线性不可分的，使用再多数据或者减少特征都没用，我们的模型是错误的，需要进行欠拟合处理。</p>
<h2 id="增加或使用更好的特征"><a href="#增加或使用更好的特征" class="headerlink" title="增加或使用更好的特征"></a>增加或使用更好的特征</h2><p>　　我们尝试增加特征，根据散点图，显然不同类别距离原点的距离不同，我们可以增加到原点的距离这一特征。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#解决欠拟合方法1：增加特征</span></div><div class="line"><span class="comment"># X[:, [0]]**2 + X[:, [1]]**2)计算的是离原点的距离</span></div><div class="line">X_orginal_distance = X[:, [<span class="number">0</span>]]**<span class="number">2</span> + X[:, [<span class="number">1</span>]]**<span class="number">2</span><span class="comment">#X[:, [0]]将得到的列数据变成二维的形式，[[  8.93841424e-01],[ -7.63891636e-01]...]</span></div><div class="line">df[<span class="string">'col_3'</span>] = X_orginal_distance </div><div class="line"><span class="comment">#可以看到完全线性可分</span></div><div class="line">_ = sns.pairplot(df, vars=[<span class="string">"col_0"</span>, <span class="string">"col_1"</span>,<span class="string">"col_3"</span>], hue=<span class="string">"class"</span>, size=<span class="number">3.5</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice15.png" alt="practice"><br>　　由最后一幅图，我们发现根据col_3新特征，就能将类别完全线性分隔开，因此col_3特征在区分类别上能起决定性作用。不妨看看热力图：<br><img src="/picture/machine-learning/practice-advice16.png" alt="practice"><br>　　根据热力图，我们发现col_3和类别存在着非常强的负相关性。使用新增完的特征集进行预测：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">X_extra = np.hstack((X,X[:,[<span class="number">0</span>]]**<span class="number">2</span>+X[:,[<span class="number">1</span>]]**<span class="number">2</span>))</div><div class="line">plot_learning_curve(LinearSVC(C=<span class="number">10</span>,penalty=<span class="string">'l2'</span>,loss=<span class="string">'hinge'</span>), <span class="string">"LinearSVC(C=10,penalty='l2',loss='hinge')"</span>, </div><div class="line">                    X_extra, y, ylim=(<span class="number">0</span>, <span class="number">1.01</span>),</div><div class="line">                    train_sizes=np.linspace(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice17.png" alt="practice"><br>　　根据结果，完全分开了样本。我们可以进一步思考，是否可以让模型进行自动生成新特征？</p>
<h2 id="使用更复杂的模型"><a href="#使用更复杂的模型" class="headerlink" title="使用更复杂的模型"></a>使用更复杂的模型</h2><p>　　<strong>使用复杂的模型，相当于更换了目标函数</strong>。根据上面数据集非线性可分的特点，我们可尝试非线性分类器，使用RBF核的SVM进行分类。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</div><div class="line"><span class="comment"># note: we use the original X without the extra feature</span></div><div class="line"><span class="comment"># 使用RBF核，最小间隔gamma设为1.</span></div><div class="line">plot_learning_curve(SVC(C=<span class="number">10</span>, kernel=<span class="string">"rbf"</span>, gamma=<span class="number">1.0</span>),</div><div class="line">                    <span class="string">"SVC(C=10, kernel='rbf', gamma=1.0)"</span>,</div><div class="line">                    X, y, ylim=(<span class="number">0.5</span>, <span class="number">1.1</span>), </div><div class="line">                    train_sizes=np.linspace(<span class="number">.1</span>, <span class="number">1.0</span>, <span class="number">5</span>),baseline=<span class="number">0.9</span>)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice18.png" alt="practice"><br>　　注意上述建模使用的是原始数据集X，而没有用新的特征。可以发现结果很理想，RBF核会将特征映射到高维空间，因此得到的非线性模型效果很好。</p>
<h1 id="大数据集和高维特征处理"><a href="#大数据集和高维特征处理" class="headerlink" title="大数据集和高维特征处理"></a>大数据集和高维特征处理</h1><h2 id="SGDClassfier增量学习"><a href="#SGDClassfier增量学习" class="headerlink" title="SGDClassfier增量学习"></a>SGDClassfier增量学习</h2><p>　　如果数据集增大，特征增多，那么上述SVM运行会变慢很多。根据之前的图谱推荐，此时可以使用\(SGDClassifier\)，该分类器也是一个线性模型,但是使用随机梯度下降法(stochastic gradient descent),\(SGDClassifier\)对特征缩放很敏感，因此可以考虑标准化数据集，使特征均值为0，方差为1.<br>　　\(SGDClassifier\)允许增量学习，会在线学习，在数据量很大的时候很有用。此时不适合采用交叉验证，我们采取progressive validation方法，即将数据集等分成块，每次在前一块训练，在后一块验证，并且使用增量学习，后面块的学习是在前面块学习的基础上继续学习的。　<br>　　首先生成数据，20万+200特征+10个类别。　<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">X, y = make_classification(<span class="number">200000</span>, n_features=<span class="number">200</span>, n_informative=<span class="number">25</span>, </div><div class="line">                           n_redundant=<span class="number">0</span>, n_classes=<span class="number">10</span>, class_sep=<span class="number">2</span>,</div><div class="line">                           random_state=<span class="number">0</span>)</div></pre></td></tr></table></figure></p>
<p>　　建模和验证：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd_score</span><span class="params">(X,y)</span>:</span></div><div class="line">    est = SGDClassifier(penalty=<span class="string">"l2"</span>, alpha=<span class="number">0.001</span>)</div><div class="line">    progressive_validation_score = []</div><div class="line">    train_score = []</div><div class="line">    <span class="keyword">for</span> datapoint <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">199000</span>, <span class="number">1000</span>):</div><div class="line">        X_batch = X[datapoint:datapoint+<span class="number">1000</span>]</div><div class="line">        y_batch = y[datapoint:datapoint+<span class="number">1000</span>]</div><div class="line">        <span class="keyword">if</span> datapoint &gt; <span class="number">0</span>:</div><div class="line">            progressive_validation_score.append(est.score(X_batch, y_batch))</div><div class="line">        est.partial_fit(X_batch, y_batch, classes=range(<span class="number">10</span>)) <span class="comment">#增量学习或称为在线学习</span></div><div class="line">        <span class="keyword">if</span> datapoint &gt; <span class="number">0</span>:</div><div class="line">            train_score.append(est.score(X_batch, y_batch))</div><div class="line">            </div><div class="line">    plt.plot(train_score, label=<span class="string">"train score"</span>,color=<span class="string">'blue'</span>)</div><div class="line">    plt.plot(progressive_validation_score, label=<span class="string">"progressive validation score"</span>,color=<span class="string">'red'</span>)</div><div class="line">    plt.xlabel(<span class="string">"Mini-batch"</span>)</div><div class="line">    plt.ylabel(<span class="string">"Score"</span>)</div><div class="line">    plt.axhline(y=<span class="number">0.8</span>,color=<span class="string">'red'</span>,linewidth=<span class="number">5</span>,label=<span class="string">'Desired Performance'</span>) <span class="comment">#baseline</span></div><div class="line">    plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">sgd_score(X,y)</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice19.png" alt="practice"><br>　　上图表明，在50次mini-batches滞后，分数提高就很少了，因此我们可以提前停止训练。由于训练分数和泛化分数差距很小，其训练分数较低，因此可能存在欠拟合的可能。<br>然而SGDClassifier不支持核技巧，根据图谱可以使用kernel approximation。<br>　　The advantage of using approximate explicit feature maps compared to the kernel trick, which makes use of feature maps implicitly, is that explicit mappings can be better suited for online learning and can significantly reduce the cost of learning with very large datasets. The combination of kernel map approximations with SGDClassifier can make non-linear learning on large datasets possible.<br>　　相较于核函数隐示的映射，kernel approximation使用显示的映射方法，这对在线学习非常重要，可以减少超大数据集的学习代价。使用SGDClassifier配合kernel approximation可以在大数据集上实现非线性学习的目的。</p>
<h2 id="手写体数字识别"><a href="#手写体数字识别" class="headerlink" title="手写体数字识别"></a>手写体数字识别</h2><p>　　现在尝试对手写体数字问题进行建模。</p>
<h3 id="可视化-1"><a href="#可视化-1" class="headerlink" title="可视化"></a>可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits</span></div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</div><div class="line">digits = load_digits(n_class=<span class="number">6</span>)</div><div class="line">X = digits.data</div><div class="line">y = digits.target</div><div class="line">n_samples, n_features = X.shape</div><div class="line"><span class="keyword">print</span> <span class="string">"Dataset consist of %d samples with %d features each"</span> % (n_samples, n_features)</div><div class="line"></div><div class="line"><span class="comment"># Plot images of the digits</span></div><div class="line">n_img_per_row = <span class="number">20</span> <span class="comment">#最大为32，即展示1024个样本</span></div><div class="line">img = np.zeros((<span class="number">10</span> * n_img_per_row, <span class="number">10</span> * n_img_per_row)) <span class="comment"># 200*200规格的像素矩阵</span></div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_img_per_row):</div><div class="line">    ix = <span class="number">10</span> * i + <span class="number">1</span> <span class="comment">#空1个像素点</span></div><div class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n_img_per_row):</div><div class="line">        iy = <span class="number">10</span> * j + <span class="number">1</span></div><div class="line">        img[ix:ix + <span class="number">8</span>, iy:iy + <span class="number">8</span>] = X[i * n_img_per_row + j].reshape((<span class="number">8</span>, <span class="number">8</span>))<span class="comment">#1行64个特征是通过8*8展平的,存入分块矩阵</span></div><div class="line"></div><div class="line">plt.imshow(img, cmap=plt.cm.binary)</div><div class="line">plt.xticks([])</div><div class="line">plt.yticks([])</div><div class="line">_ = plt.title(<span class="string">'A selection from the 8*8=64-dimensional digits dataset'</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/practice-advice20.png" alt="practice"><br>　　手写体数字的64维特征就是一个8*8数字图片每个像素点平铺开来的。因此我们可以通过上面代码进行重建图片。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> digits.images.shape <span class="comment">#三维数组(1083L, 8L, 8L)，1083个样本</span></div><div class="line"><span class="keyword">print</span> img.shape <span class="comment">#二维数组(200L,200L),每个样本占8*8小分块矩阵。每8行20个样本，一共可以放400个样本。</span></div><div class="line"><span class="comment">#可以扩大该二维数组，例如(320L,320L), 每个样本占8*8小分块矩阵， 每8行展示32个样本，最大可以展示1024个样本。即32*32</span></div><div class="line"><span class="comment"># digits.images[0] == img[1:9,1:9]</span></div><div class="line"><span class="comment"># digits.images[1] == img[1:9,11:19]</span></div><div class="line">plt.matshow(digits.images[<span class="number">1</span>],cmap=plt.cm.gray)  <span class="comment">#第二个样本为数字1</span></div><div class="line">plt.matshow(img[<span class="number">1</span>:<span class="number">9</span>,<span class="number">11</span>:<span class="number">19</span>],cmap=plt.cm.gray)  <span class="comment">#第二个样本数字1</span></div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice21.png" alt="practice"><br>　　上述代码展示一个数字的结果，可以发现digits.images<a href="/2017/04/01/ml-advice/">1</a>和img[1:9,11:19]都是代表第二个样本，我们可以从图中看出第二个样本数字是1。<br>　　进一步可视化：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Helper function based on </span></div><div class="line"><span class="comment"># http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#example-manifold-plot-lle-digits-py</span></div><div class="line"><span class="comment"># 我们之前已经讨论过手写数字的数据，每个手写的阿拉伯数字被表达为一个8*8的像素矩阵，</span></div><div class="line"><span class="comment"># 我们曾经使用每个像素点，也就是64个特征，使用logistic和knn的方法（分类器）去根据训练集判别测试集中的数字。</span></div><div class="line"><span class="comment"># 在这种做法中，我们使用了尚未被降维的数据。其实我们还可以使用降维后的数据来训练分类器。</span></div><div class="line"><span class="comment"># 现在，就让我们看一下对这个数据集采取各种方式降维的效果。</span></div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> offsetbox</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_embedding</span><span class="params">(X, title=None)</span>:</span></div><div class="line">    x_min, x_max = np.min(X, <span class="number">0</span>), np.max(X, <span class="number">0</span>)</div><div class="line">    X = (X - x_min) / (x_max - x_min)</div><div class="line"></div><div class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</div><div class="line">    ax = plt.subplot(<span class="number">111</span>)</div><div class="line">    </div><div class="line">    <span class="comment"># 绘制每个样本这两个维度的值以及实际的数字</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(X.shape[<span class="number">0</span>]):</div><div class="line">        plt.text(X[i, <span class="number">0</span>], X[i, <span class="number">1</span>], str(digits.target[i]),</div><div class="line">                 color=plt.cm.Set1(y[i] / <span class="number">10.</span>),</div><div class="line">                 fontdict=&#123;<span class="string">'weight'</span>: <span class="string">'bold'</span>, <span class="string">'size'</span>: <span class="number">12</span>&#125;)</div><div class="line"></div><div class="line">    <span class="keyword">if</span> hasattr(offsetbox, <span class="string">'AnnotationBbox'</span>):</div><div class="line">        <span class="comment"># only print thumbnails with matplotlib &gt; 1.0</span></div><div class="line">        shown_images = np.array([[<span class="number">1.</span>, <span class="number">1.</span>]])  <span class="comment"># 定义一个标准点</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(digits.data.shape[<span class="number">0</span>]):<span class="comment">#样本数</span></div><div class="line">            dist = np.sum((X[i] - shown_images) ** <span class="number">2</span>,axis=<span class="number">1</span>)<span class="comment">#计算要展示的点和目前所有的点的距离，</span></div><div class="line">            <span class="comment">#axis=1代表横着加，即每个样本x^2+y^2; 得到该样本和所有的点的距离的数组;axis=0，按列加，就变成了把每个样本的x^2全加起来，y^2全部加起来。</span></div><div class="line">            <span class="keyword">if</span> np.min(dist) &lt; <span class="number">4e-3</span>: <span class="comment">#选择最近的距离</span></div><div class="line">                <span class="keyword">continue</span> <span class="comment"># don't show points that are too close</span></div><div class="line">            shown_images = np.r_[shown_images, [X[i]]] <span class="comment"># 纵向合并</span></div><div class="line">            imagebox = offsetbox.AnnotationBbox(</div><div class="line">                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),</div><div class="line">                X[i])<span class="comment">#X[i]代表每个样本的两个维度的值，即横轴和纵轴的值，即两个维度决定的位置画出灰度图</span></div><div class="line">            ax.add_artist(imagebox)</div><div class="line">    plt.xticks([]), plt.yticks([])</div><div class="line">    <span class="keyword">if</span> title <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        plt.title(title)</div></pre></td></tr></table></figure></p>
<h3 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h3><p><strong>随机降维</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#降维——随机投影</span></div><div class="line"><span class="comment">#把64维数据随机地投影到二维上</span></div><div class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> (manifold, datasets, decomposition, ensemble,</div><div class="line">                     discriminant_analysis, random_projection)</div><div class="line">rp = random_projection.SparseRandomProjection(n_components=<span class="number">2</span>, random_state=<span class="number">42</span>)<span class="comment">#随机投影到两个维度</span></div><div class="line">stime = time.time()</div><div class="line">X_projected = rp.fit_transform(X)</div><div class="line">plot_embedding(X_projected, <span class="string">"Random Projection of the digits (time: %.3fs)"</span> % (time.time() - stime))</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice22.png" alt="practice"></p>
<p><strong>PCA降维</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># PCA降维</span></div><div class="line"><span class="comment"># linear线性降维</span></div><div class="line"><span class="comment"># TruncatedSVD是pca的一种方式，不需要计算协方差矩阵，适用于稀疏矩阵</span></div><div class="line"><span class="comment"># PCA for dense data or TruncatedSVD for sparse data</span></div><div class="line"><span class="comment">#implemented using a TruncatedSVD which does not require constructing the covariance matrix</span></div><div class="line"><span class="comment"># LSA的基本思想就是，将document从稀疏的高维Vocabulary空间映射到一个低维的向量空间，我们称之为隐含语义空间(Latent Semantic Space).</span></div><div class="line">X_pca = decomposition.TruncatedSVD(n_components=<span class="number">2</span>).fit_transform(X)</div><div class="line">stime = time.time()</div><div class="line">plot_embedding(X_pca,<span class="string">"Principal Components projection of the digits (time: %.3fs)"</span> % (time.time() - stime))</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice23.png" alt="practice"></p>
<p><strong>LDA线性变换</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">print(<span class="string">"Computing Linear Discriminant Analysis projection"</span>)</div><div class="line">X2 = X.copy()</div><div class="line">X2.flat[::X.shape[<span class="number">1</span>] + <span class="number">1</span>] += <span class="number">0.01</span>  <span class="comment"># Make X invertible</span></div><div class="line">stime = time.time()</div><div class="line">X_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=<span class="number">2</span>).fit_transform(X2, y)</div><div class="line">plot_embedding(X_lda,</div><div class="line">               <span class="string">"Linear Discriminant projection of the digits (time %.2fs)"</span> %</div><div class="line">               (time.time() - stime))</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice24.png" alt="practice"></p>
<p><strong>t-SNE非线性变换</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE</span></div><div class="line"><span class="comment">#非线性的变换</span></div><div class="line"><span class="comment">#最小化KL距离，Kullback-Leibler </span></div><div class="line">tsne = manifold.TSNE(n_components=<span class="number">2</span>, init=<span class="string">'pca'</span>, random_state=<span class="number">0</span>)</div><div class="line">stime = time.time()</div><div class="line">X_tsne = tsne.fit_transform(X)</div><div class="line">plot_embedding(X_tsne,</div><div class="line">               <span class="string">"t-SNE embedding of the digits (time: %.3fs)"</span> % (time.time() - stime))</div></pre></td></tr></table></figure></p>
<p><img src="/picture/machine-learning/practice-advice25.png" alt="practice"><br>　　可以发现，在该数据集上，非线性变换的结果比线性变换的结果更理想。</p>
<h1 id="目标函数选择"><a href="#目标函数选择" class="headerlink" title="目标函数选择"></a>目标函数选择</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># adapted from http://scikit-learn.org/stable/auto_examples/linear_model/plot_sgd_loss_functions.html</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">modified_huber_loss</span><span class="params">(y_true, y_pred)</span>:</span></div><div class="line">    z = y_pred * y_true</div><div class="line">    loss = <span class="number">-4</span> * z</div><div class="line">    loss[z &gt;= <span class="number">-1</span>] = (<span class="number">1</span> - z[z &gt;= <span class="number">-1</span>]) ** <span class="number">2</span></div><div class="line">    loss[z &gt;= <span class="number">1.</span>] = <span class="number">0</span></div><div class="line">    <span class="keyword">return</span> loss</div><div class="line">xmin, xmax = <span class="number">-4</span>, <span class="number">4</span></div><div class="line">xx = np.linspace(xmin, xmax, <span class="number">100</span>)</div><div class="line">lw = <span class="number">2</span></div><div class="line">plt.plot([xmin, <span class="number">0</span>, <span class="number">0</span>, xmax], [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>], color=<span class="string">'gold'</span>, lw=lw,</div><div class="line">         label=<span class="string">"Zero-one loss"</span>)</div><div class="line">plt.plot(xx, np.where(xx &lt; <span class="number">1</span>, <span class="number">1</span> - xx, <span class="number">0</span>), color=<span class="string">'teal'</span>, lw=lw,</div><div class="line">         label=<span class="string">"Hinge loss"</span>)</div><div class="line">plt.plot(xx, -np.minimum(xx, <span class="number">0</span>), color=<span class="string">'yellowgreen'</span>, lw=lw,</div><div class="line">         label=<span class="string">"Perceptron loss"</span>)</div><div class="line">plt.plot(xx, np.log2(<span class="number">1</span> + np.exp(-xx)), color=<span class="string">'cornflowerblue'</span>, lw=lw,</div><div class="line">         label=<span class="string">"Log loss"</span>)</div><div class="line">plt.plot(xx, np.where(xx &lt; <span class="number">1</span>, <span class="number">1</span> - xx, <span class="number">0</span>) ** <span class="number">2</span>, color=<span class="string">'orange'</span>, lw=lw,</div><div class="line">         label=<span class="string">"Squared hinge loss"</span>)</div><div class="line">plt.plot(xx, np.exp(-xx), color=<span class="string">'red'</span>,lw=lw,linestyle=<span class="string">'--'</span>,</div><div class="line">         label=<span class="string">"Exponential loss"</span>)</div><div class="line">plt.plot(xx, modified_huber_loss(xx, <span class="number">1</span>), color=<span class="string">'darkorchid'</span>, lw=lw,</div><div class="line">         linestyle=<span class="string">'--'</span>, label=<span class="string">"Modified Huber loss"</span>)</div><div class="line">plt.ylim((<span class="number">0</span>, <span class="number">8</span>))</div><div class="line">plt.legend(loc=<span class="string">"upper right"</span>)</div><div class="line">plt.xlabel(<span class="string">r"Decision function $f(x)$"</span>)</div><div class="line">plt.ylabel(<span class="string">"$L(y, f(x))$"</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/practice-advice26.png" alt="practice"><br>　　不同的代价函数有不同的优点：</p>
<ul>
<li>0-1 loss:在分类问题中使用。这是ERM用的代价函数，然而是非凸的，因此必须使用其他代价函数来近似替代。</li>
<li>hinge loss:在SVM中使用，体现最大间隔思想，不容易受离群点影响，有很好的鲁棒性，然后不能提供较好的概率解释。</li>
<li>log loss:在逻辑回归使用，能提供较好的概率解释，然而容易受离群点影响。</li>
<li>Exponential loss: 指数代价，在Boost中使用，容易受离群点影响，在AdaBoost中能够实现简单有效的算法。</li>
<li>perceptron loss:在感知机算法中使用。类似hinge loss，左移了一下。不同于hinge loss,percptron loss不对离超平面近的点进行惩罚。</li>
<li>squared hinge loss: 对hinge loss进行改进，平方损失。</li>
<li>modified huber loss: 对squared hinge loss进一步改进，是一种平滑损失，能够容忍离群点的影响。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://see.stanford.edu/materials/aimlcs229/ML-advice.pdf" target="_blank" rel="external">斯坦福机器学习：Advice for applying Machine Learning</a><br><a href="https://jmetzen.github.io/2015-01-29/ml_advice.html" target="_blank" rel="external">Advice for applying Machine Learning</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文对&lt;a href=&quot;/2017/04/01/ml-advice/&quot;&gt;Advice for applying Machine Learning&lt;/a&gt;一文中提到的算法诊断等理论方法进行实践，使用Python工具，具体包括数据的可视化(data visualizing)、模型选择(choosing a machine learning method suitable for the problem at hand)、过拟合和欠拟合识别和处理(identifying and dealing with over and underfitting)、大数据集处理（dealing with large datasets）以及不同代价函数(pros and cons of different loss functions)优缺点等。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法诊断" scheme="xtf615.com/tags/%E7%AE%97%E6%B3%95%E8%AF%8A%E6%96%AD/"/>
    
      <category term="偏差方差分析" scheme="xtf615.com/tags/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="学习曲线" scheme="xtf615.com/tags/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/"/>
    
      <category term="目标函数" scheme="xtf615.com/tags/%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0/"/>
    
  </entry>
  
  <entry>
    <title>Advice for applying Machine Learning</title>
    <link href="xtf615.com/2017/04/01/ml-advice/"/>
    <id>xtf615.com/2017/04/01/ml-advice/</id>
    <published>2017-04-01T09:24:05.000Z</published>
    <updated>2017-04-02T01:53:07.123Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文对Ng提到的关于机器学习应用实践上的建议进行整理总结。主要内容包括：诊断(Diagnostics for debugging learning algorithms)、误差分析(error enalysis)、销蚀分析(ablative analysis)、过早优化(premature optimization)。并结合“自动驾驶直升机”应用探讨如何对存在问题进行诊断。<br><a id="more"></a></p>
<h1 id="ML算法诊断"><a href="#ML算法诊断" class="headerlink" title="ML算法诊断"></a>ML算法诊断</h1><p>　　考虑前面”生成算法”一文中讨论的垃圾邮件分类问题。前面我们使用50000+词语的词典作为特征向量集，本文将从中挑选100个词作为特征集。并使用”Learning Theory(2)”中提到的贝叶斯逻辑回归进行分类。代价函数如下，多了正则化项：<br>$$\max_{\theta} \sum_{i=1}^m log p(y^{(i)}|x^{(i)},\theta)-\lambda ||\theta||^2$$<br>　　使用梯度上升方法来进行极大似然估计，注意因为我们要最大化上述式子，故正则化项前为减号。(之前我们的目标是最小化，因为之前第一项对数似然取负号,故要加上正则化项,这里相当于对之前整个式子取负号,将最小化转成最大化,相应的变为减正则化项)。<br>　　目前研究状况是测试误差达到了20%, 这个结果显然不能接受，我们下一步要怎么做呢？<br>　　可能的方法包括：</p>
<ul>
<li><strong>尝试获取更多的训练数据</strong>(Try getting more training examples)</li>
<li><strong>尝试减少特征</strong>(Try a smaller set of features)</li>
<li><strong>尝试增加特征</strong>(Try a larger set of features)</li>
<li><strong>尝试选择更好特征</strong>(Try changing the features)</li>
<li><strong>尝试对梯度下降方法多迭代几次</strong>(Run gradient descent for more iterations)</li>
<li><strong>尝试使用牛顿法</strong>，牛顿法收敛更快(Try Newton’s method)</li>
<li><strong>修改正则化系数</strong>\(\lambda\)(Use a different value for \(\lambda\))</li>
<li><strong>尝试其他算法</strong>，如SVM算法(Try using an SVM)<br>　　可能的方法数以百计，我们只列出这么多。对于上述8种改进方法，如果一一尝试的话非常耗时。比如第一条，增加数据一般会达到比较好的效果，但对于一些应用来说，收集数据是很困难耗时的事情，如果你花了三个月的时间来收集数据，但最后发现增加数据并没有使算法效果编号，那就悲催了！<br>　　更好的解决方法是，使用诊断法来发现问题所在。<h2 id="偏差-方差分析"><a href="#偏差-方差分析" class="headerlink" title="偏差/方差分析"></a>偏差/方差分析</h2>　　第一个方法是判断问题是出在高方差还是高偏差。一般来说，高方差反映了过拟合问题，即训练误差很小但泛化误差却很大。而高偏差反映了模型本身存在问题或特征太少等问题，此时训练误差和泛化误差都很大。<h3 id="高方差诊断"><a href="#高方差诊断" class="headerlink" title="高方差诊断"></a>高方差诊断</h3><img src="/picture/machine-learning/advice1.jpg" alt="advice"><br>　　上图是高方差情况下，训练误差和泛化误差随样本数量变化的情况。该图有几个重要特征：</li>
<li><strong>泛化误差随样本m增大而降低</strong>。<br>  Test error still decreasing as m increases,并且不断逼近期望误差，意味着增加数据可以起到作用。</li>
<li><strong>训练误差和泛化误差之间差距很大</strong>。<br>  Large gap between training and test error，训练误差一直比期望误差理想，意味着可能存在过拟合。</li>
</ul>
<h3 id="高偏差诊断"><a href="#高偏差诊断" class="headerlink" title="高偏差诊断"></a>高偏差诊断</h3><p><img src="/picture/machine-learning/advice2.jpg" alt="advice"><br>　　上图是高偏差的情况下，训练误差和泛化误差随样本数量变化的情况。该图有几个重要特征：</p>
<ul>
<li><strong>训练误差很大</strong>。<br>  Even training error is unacceptably high, 比期望的误差还大。</li>
<li><strong>训练误差和泛化误差之间差距很小</strong>。<br>  Small gap between training and test error.</li>
</ul>
<p>　　二者最明显的区别就在于，<strong>训练误差和泛化误差间的差距大小</strong>以及<strong>训练误差和理想误差的差距大小</strong>。<br>　　前者体现在，<strong>\(m\)较大</strong>的时候，高方差对应的训练误差和泛化误差的差距较大，高偏差对应的训练误差和泛化误差的差距较小。<br>　　后者体现在，在<strong>\(m\)较小</strong>的时候，高方差的训练误差比理想误差还小,或者说维持在一个较优的水平；而高偏差的训练误差一般比理想误差大，维持在一个较差的水平。<br>　　上述图片也称作学习曲线。根据上面的分析，我们可以对前面提到的8条解决思路前4条进行分类。</p>
<ul>
<li>尝试获取更多的训练数据。———— <strong>解决高方差</strong></li>
<li>尝试减少特征。————<strong>解决高方差</strong></li>
<li>尝试增加特征。————<strong>解决高偏差</strong></li>
<li>尝试选择更好特征。———— <strong>解决高偏差</strong></li>
</ul>
<h2 id="收敛与目标函数分析"><a href="#收敛与目标函数分析" class="headerlink" title="收敛与目标函数分析"></a>收敛与目标函数分析</h2><p>　　考虑下面的情景，仍然是针对垃圾邮件分类问题：</p>
<ul>
<li>使用贝叶斯逻辑回归(BLR)可以达到垃圾邮件上的2%错误率，正常邮件上2%的错误率。<br>  正常邮件上的如此高的错误率是无法接受的。</li>
<li>使用SVM模型可以达到垃圾邮件10%的错误率，正常邮件0.01%的错误率。<br>  可以接受。</li>
<li>显然这个场景下SVM表现更好。但是因为计算效率上的考虑，你想使用逻辑回归，该如何解决？<br>　　<br>对于这种情况，有如下两种分析。</li>
<li><strong>算法是否收敛</strong>？(Is the algorithm(gradient descent for BLR) converging?)<br>　　算法收敛程度和训练优化算法以及迭代次数关系很大。训练优化算法包括梯度下降、牛顿法、SMO等</li>
<li><strong>目标优化函数是否合适</strong>？(Are you optimizing the right function?)<br>　　目标函数是否正确包括目标函数里的参数设置，例如BLR中正则化项系数\(\lambda\)，SVM对偶问题中的惩罚因子\(C\)。另外，不同模型使用的目标函数不同，例如SVM使用对偶问题目标函数，因此目标函数还和模型相关。<br>　　这两种情况都有可能造成上面的SVM优于BLR的问题。如果BLR没有收敛,SVM比BLR收敛的更好，所以SVM效果更好。如果模型的目标函数没有找对，也可能造成上述问题。<br>　　对于函数是否收敛来说，我们可以画出迭代次数与目标函数值的趋势图，但是这样的趋势图在通常情况下很难分辨出目标函数是否稳定的趋势，因为在训练的后期目标函数的每步优化往往都只提高一点。<br><img src="/picture/machine-learning/advice3.jpg" alt="advice"><br>　　上图很难看出是否收敛，目标函数似乎还在增长.(注意本文使用的是最大化目标函数)<br>　　这里介绍一种更直观的方法。<br>　　首先我们关注的是分类的准确率，并且对于正常邮件应当给予更高的权重。<br>$$a(\theta)=\max_{\theta} \sum_{i} w^{(i)} I\{h_\theta(x^{(i)})=y^{(i)}\}$$<br>　　\(w^{(i)}\)代表权重，在正常邮件中权值更大。<br>　　我们令\(\theta_{SVM}\)为SVM模型学习到的参数结果，\(\theta_{BLR}\)为Bayesian logistic regression学习到的参数结果。<br>　　显然根据我们前面的假设,SVM效果比BLR好，则:<br>$$a((\theta_{SVM}) &gt; a(\theta_{BLR})$$<br>　　再来观察目标函数值对比。<br>　　BLR尝试最大化如下目标函数:<br>$$J(\theta) = \sum_{i=1}^m log p(y^{(i)}|x^{(i)},\theta)-\lambda ||\theta||^2$$<br>　　SVM尝试最小化如下的原始目标函数为:<br>$$\min_{w,b} \frac{1}{2}||w||^2 + C\sum_{i=1}^m \zeta \\\\<br>使得， y^{(i)} (w^T  x^{(i)}-b) \geq 1- \zeta<br>$$<br>　　转成对偶问题后，变成最大化对偶问题目标函数：<br>$$\max_{\alpha} W(\alpha) = \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j ＜x^{(i)},x^{(j)}＞ \\\ 使得， \alpha_i \geq 0,　　i=1,…,m \\\ \sum_{i=1}^m \alpha_i y^{(i)} = 0$$</li>
</ul>
<p>　　我们将比较\(J(\theta_{SVM})和J(\theta_{BLR})\)</p>
<ul>
<li>情况1<br>$$a(\theta_{SVM}) &gt; a(\theta_{BLR})且J(\theta_{SVM})&gt;J(\theta_{BLR})$$<br>我们注意到，BLR尝试最大化目标函数，SVM尝试最大化对偶目标函数。\(J(\theta_{SVM})&gt;J(\theta_{BLR})\)表明SVM收敛得比BLR好。因此问题可能出在优化算法，应该改进训练优化算法,例如使用牛顿法替换梯度下降，使之收敛更快。</li>
<li>情况2<br>$$a(\theta_{SVM}) &gt; a(\theta_{BLR})且J(\theta_{SVM}) \leq J(\theta_{BLR})$$<br>这种情况表明，BLR收敛没问题，SVM收敛性能比BLR更差，结果却更优。意味着目标函数\(J(\theta)\)存在问题，其不能真实反应人们在该问题上的需要(后面无人机诊断实例就能明白)，应该改进目标函数。要么进行调参，要么考虑换模型，也就间接地更改了目标函数。</li>
</ul>
<p>　　因此，我们可以对解决思路后四条进行分类。</p>
<ul>
<li>尝试对梯度下降方法多迭代几次。————<strong>解决优化算法(optimization algorithm)</strong></li>
<li>尝试使用牛顿法。———— <strong>解决优化算法(optimization algorithm)</strong></li>
<li>修改目标函数参数(\(\lambda,C\)等)。————<strong>解决目标函数(optimization objective)</strong></li>
<li>尝试其他算法(SVM算法),相当于修改目标函数。————<strong>解决目标函数(optimization objective)</strong></li>
</ul>
<h2 id="诊断实例"><a href="#诊断实例" class="headerlink" title="诊断实例"></a>诊断实例</h2><p>　　Ng和他的一些学生正在做一个自动驾驶直升机飞行的项目。本文以此为例子来分析Ng之前在遇到问题时是如何入手解决的。<br><img src="/picture/machine-learning/advice4.png" alt="advice"><br>　　首先对于一个能够自动驾驶直升机的程序来说，要经过如下步骤：</p>
<ul>
<li>建立一个精确的模拟器(Build a simulator of helicopter)</li>
<li>选择一个代价函数。(Choose a cost function)<br>$$eg:　　J(\theta)=||x-x_{desired}||^2$$</li>
<li>使用强化学习算法在模拟器中飞行来对代价函数进行最小化优化。(Run reinforcement learning algorithm to fly helicoper in simulation)<br>$$得到输出参数:\theta_{RL}= arg \min_{\theta}{J(\theta)}$$<br>　　假设已经做了如上步骤。但是得到的控制参数\(\theta_{RL}\)驾驶的实际效果比真人驾驶的效果差很多。此时该如何入手解决呢？<br>　　可能的措施包括：</li>
<li><strong>提升模拟器性能</strong>。(使其更符合真实环境)</li>
<li><strong>修改代价函数J</strong>(使最优化代价函数能够反映出飞行表现良好)</li>
<li><strong>修改RL算法</strong>(优化算法，使代价函数更好得收敛)<br>　　我们假设在理想情况下，即上述步骤都很完美得完成了。</li>
<li>直升机模拟器是精确的。(能够很好模拟真实环境)</li>
<li>最小化代价函数意味着能够正确的自动驾驶。(该代价函数能够反映实际需求:完美飞行)</li>
<li>RL算法在模拟器环境下正确得最小化了代价函数。(算法没问题：能求解问题)<br>　　如果上述条件都满足，那么毫无疑问，直升机会在实际环境中飞行得很好。<br>　　我们使用如下的诊断方法：</li>
<li>如果算法求出的控制参数\(\theta_{RL}\)在模拟器中飞行得很好，但是在实际环境中却表现很差。问题很可能出在模拟器上。比如，模拟器无法真实模拟出现实环境的气压、风向等因素。</li>
<li>让真实的人来驾驶直升飞机，得到参数\(\theta_{human}\)，如果\(J(\theta_{RL})&gt;J(\theta_{human})\),即人操作得到的代价函数更小，也就说明算法收敛不够，那么需要考虑改进优化算法，使算法更加收敛，可以考虑修改强化模型的优化算法或改成其他模型。</li>
<li>如果\(J(\theta_{RL})&lt;J(\theta_{human})\),则问题出在代价函数的设计上，代价函数已经很好得收敛了，结果却不好。即该代价函数最小化并不能代表飞行好。(Minimizing it doesn’t correspond to good autonomous flight)此时需要对代价函数重新设计。<br>　　因此我们需要为算法设计诊断方法来发现问题所在。即使你的算法表现良好，你也可以运用诊断方法来更加深入理解整个运行机制。这有助于理解问题的本质，有助于得到一个直观的感觉，什么样的改进能起作用，什么样的改进不起作用。同时运行诊断方法以及后面谈到的误差分析方法能够更好得对问题和观点进行阐述，从而写出更具有研究性的论文。<h1 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h1>　　误差分析用来判读误差的来源。<br>　　实际过程中，一个系统可能由多个部件组成，比如一个基于人脸的性别识别系统，可能由如下几个部件组成，按流程处理的先后顺序如下：<br><img src="/picture/machine-learning/advice5.jpg" alt="advice"><br>　　所谓的误差分析，做法就是对每个部件用基准值代替算法的输出，然后观察最后结果的变化，可能的误差分析结果如下：<br><img src="/picture/machine-learning/advice6.jpg" alt="advice"><br>　　如上图，系统整体的性能是85%准确率。我们使用一个已经对背景进行消除的照片进行建模(相当于拍了一张不带背景的照片，即不需要我们模型进行预处理)，此时得到的准确率是85.1%，显然只有0.1%的提升; 我们再在此基础上进行处理，固定其他因素不变，直接将人脸所在位置告诉模型(不需要模型进行人脸位置的检测),然后进行建模(注意此时是在第一步的基础上的，即用不带背景的照片进行人脸检测),发现性能为91%，相较于85.1%提升了5.9%。同理对于器官检测，我们可以告诉模型眼睛所在位置，得到95%的准确率，提升4%等等。如果最终将所有的处理都用基准值代替，即所有的步骤人工告知模型，那么最后Logistic得到的结果是100%.<br>　　经过这样的分析，我们可以得出，对于较多的部分是人脸识别和眼睛识别。当然，器官识别中不同的基准值代替顺序可能会有不同的分析结果，所以可以调整顺序不断进行比较，找到问题的瓶颈所在。<h2 id="销蚀分析"><a href="#销蚀分析" class="headerlink" title="销蚀分析"></a>销蚀分析</h2>　　销蚀分析与误差分析不同，误差分析师一步步用基准值代替算法输出，比较的是系统当前性能与最高性能的差别。而销蚀分析考虑的是系统性能和底线性能(baseline)的差异。<br>　　比如，对于拉简邮件分类器来说，先构建一个初始分类器，然后考虑一些比较高级的特征，比如邮件的语法风格，主机信息，标题等。先将所有特征全部加入分类器，然后逐个剔除，观察性能的下降幅度，将那些性能下降少或者反而导致性能提升的特征去除。<br><img src="/picture/machine-learning/advice7.jpg" alt="advice"><br>　　如上图，显然Email text parser features最重要。</li>
</ul>
<h1 id="如何开始ML问题的解决"><a href="#如何开始ML问题的解决" class="headerlink" title="如何开始ML问题的解决"></a>如何开始ML问题的解决</h1><h2 id="途径1：精心设计法-Careful-design"><a href="#途径1：精心设计法-Careful-design" class="headerlink" title="途径1：精心设计法(Careful design)"></a>途径1：精心设计法(Careful design)</h2><p>　　对问题进行深入分析，提取正确的特征，收集正确的数据，设计正确的算法架构，最终实现它。好处在于能一次性能到可扩展的算法，甚至可能会创造一些新的算法。有点类似瀑布流开发模式。</p>
<h2 id="途径2：构建修改法-Build-and-fix"><a href="#途径2：构建修改法-Build-and-fix" class="headerlink" title="途径2：构建修改法(Build-and-fix)"></a>途径2：构建修改法(Build-and-fix)</h2><p>　　使用一些粗糙但是快速的方法进行初步构建。然后使用诊断法和误差分析法来分析问题所在，并修正误差。好处在于可以较快的构建应用，快速占领市场。因为互联网上的成功产品，很多往往不是做的最好的，而是最早占领市场的。</p>
<h2 id="过早优化-Premature-statistical-optimiztion"><a href="#过早优化-Premature-statistical-optimiztion" class="headerlink" title="过早优化(Premature statistical optimiztion)"></a>过早优化(Premature statistical optimiztion)</h2><p>　　通常情况下，是很难发现系统哪个部分是比较容易或者比较难构建的，也很难发现系统哪部分需要花更多时间进行开发。也因此上述途径1的精心设计方法很容易陷入过早优化问题，即对系统的某个部分过早的进行精心设计，却不知这部分设计是否是真的对系统性能有很大影响。<br><img src="/picture/machine-learning/advice8.jpg" alt="advice"><br>　　The only way to find out what needs work is to implement something quickly,and find out what parts break。即通过快速入手一些工作来发现哪部分是需要多花时间，哪部分不需要多花时间。一个较好的建议是先对数据进行分析，比如为什么数据中这些属性是负的，当找出数据中的规律或者数据中的错误时，往往会发现系统性能差不是需要更复杂的算法，而是更强大的预处理。</p>
<h2 id="过度理论-over-theorizing"><a href="#过度理论-over-theorizing" class="headerlink" title="过度理论(over-theorizing)"></a>过度理论(over-theorizing)</h2><p>　　在做研究时，要把注意力集中在关键问题上，不要轻易的相信某些理论对算法有用而花大量的时间在那些理论上。比如如果要检测出图片中的物体，可能有人会说三维微分几何对这个问题有用，但是在你确认这个确实有用前，不要浪费精力在这个上面。<br><img src="/picture/machine-learning/advice9.jpg" alt="advice"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li>花在设计诊断方法上的时间是值得的。</li>
<li>需要根据自己的直接和经验来来设计正确的诊断方法</li>
<li>误差分析和销蚀分析用于可以提供对问题的深入理解</li>
<li>两种途径入手机器学习问题：精心设计法(容易陷入过早优化)、构建修改法。</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文对Ng提到的关于机器学习应用实践上的建议进行整理总结。主要内容包括：诊断(Diagnostics for debugging learning algorithms)、误差分析(error enalysis)、销蚀分析(ablative analysis)、过早优化(premature optimization)。并结合“自动驾驶直升机”应用探讨如何对存在问题进行诊断。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="算法诊断" scheme="xtf615.com/tags/%E7%AE%97%E6%B3%95%E8%AF%8A%E6%96%AD/"/>
    
      <category term="偏差方差分析" scheme="xtf615.com/tags/%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="学习曲线" scheme="xtf615.com/tags/%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/"/>
    
      <category term="误差分析" scheme="xtf615.com/tags/%E8%AF%AF%E5%B7%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="销蚀分析" scheme="xtf615.com/tags/%E9%94%80%E8%9A%80%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Learning Theory(2)</title>
    <link href="xtf615.com/2017/03/30/Learning-Theory-2/"/>
    <id>xtf615.com/2017/03/30/Learning-Theory-2/</id>
    <published>2017-03-30T03:44:06.000Z</published>
    <updated>2017-03-31T07:19:33.634Z</updated>
    
    <content type="html"><![CDATA[<p>　　本部分将继续讨论学习理论的相关知识。学习理论内容包括：模型/特征选择(model/feature selection)、贝叶斯统计和正则化(Bayesian statistics and Regularization)。本文重点在于贝叶斯统计和正则化。将重点理解这句话，从贝叶斯估计的角度来看,正则化项对应于模型的先验概率。<br><a id="more"></a></p>
<h1 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h1><p>　　假设我们尝试在许多不同的模型中为我们的学习问题寻找最合适的模型。例如我们可能想在众多多项式回归模型\(h_\theta(x)=g(\theta_0+\theta_1x+\theta_2 x^2 + … + \theta_k x^k)\)中进行寻找，那么就需要确定k的值是多少(0,1,…,or 10)。我们怎样才能自动选择一个合适的模型，该模型能对偏差和方差进行很好的权衡呢？又或者该如何为SVM模型选择惩罚参数\(C\)和正则化项? 该如何为局部加权回归选择带宽参数?<br>　　更具体地讨论，我们考虑有限模型集合\(\mathcal{M}=\{M_1,…,M_d\}\),我们将从该集合中选择模型。例如对于上面的问题，模型\(M_i\)可以代表i阶多项式模型。当然，该模型集合也可以包含不同种类的模型，例如SVM、神经网络或者逻辑回归等。</p>
<h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>　　选择模型最简单的方式，就是根据ERM经验风险最小化原理，对每个模型M，取训练误差最小的模型。显然，这样最终会容易选择那些过拟合的模型。例如考虑选择多项式模型，显然阶数越高，训练集拟合的就越好，则训练误差也越小，因此这种方法选择的模型总是会出现高方差、高阶数。<br>　　简单的对其进行修改，我们就可以得到保留交叉验证的方法或称作简单交叉验证(hold-out cross validation also called simple cross validation),具体做法如下：<br>　　- 随机划分数据S为\(S_{train}\)(如70%的数据)、\(S_{cv}\)(如30%)。\(S_{cv}\)称作保留交叉验证集。<br>　　- 对每个模型\(M_i\)，在\(S_{train}\)上进行训练,得到假设\(h_i\)<br>　　- 对得到的每个假设\(h_i\),在\(S_{cv}\)上测试，求出误差\(\hat{\epsilon}_{S_{cv}}(h_i)\),即假设\(h_i\)在验证集上的经验误差。<br>　　- 选择误差最小的模型作为最终模型。<br>　　通过在验证集上进行测试，我们得到了一个对模型更好的估计。在实际使用过程中，对于得到的最终模型，我们可以将该模型在全部的数据集上重新训练，以利用更多的数据，达到更好的效果。<br>　　该方法的劣势在于分出过多的数据用来测试，对于标注数据难得的实际问题来说(比如医学实验),这是不能容忍的。因而产生了如下的改进方法，即k折交叉验证。<br>　　k折交叉验证(k-fold cross validation)，做法如下：<br>　　- 将标注数据集S随机平均分成k份,每份有m/k个样本,记为\(S_1,…,S_k\)<br>　　- 对于每一个模型\(M_i\),<br>　　　\(For \ j = 1,…,k\)<br>　　　　分别在\(S_1 \cup S_2…\cup S_{j-1} \cup S_{j+1} \cup S_k\)上训练，即除了\(S_j\)以外的子样本集上进行训练，得到假设\(h_{ij}\)<br>　　　　再使用\(h_{ij}\)对保留的\(S_j\)进行测试，得到误差\(\hat{\epsilon}_{S_j}(h_{ij})\)<br>　　　模型\(M_i\)的泛化误差可以通过计算\(\hat{\epsilon}_{S_j}(h_{ij})\)的平均值来估计。<br>　　- 选择泛化误差估计值最小的模型\(M_i\)作为最终的模型。同样，可以使用全部的数据集对最终模型进行训练。<br>　　k通常取值为10。此时保留的验证集大小每次只有1/k,比之前的30%小的多。但是这个过程的缺点是比较耗时，我们需要对每个模型训练k次。<br>　　当样本很少的时候，我们也可能取极端情况k=m。称为留一交叉验证(leave-one-out cross validation)，即每次训练只保留1个样本作为验证集。<br>　　上面讨论的交叉验证用于选择模型，同样，交叉验证也可以用于评估一个模型的好坏，例如可以使用交叉验证在不同测试集上对模型性能进行评估。</p>
<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>　　特征选择是一类比较特殊的模型选择问题。考虑你面对一个监督学习问题，该问题的特征数量n非常巨大(甚至有 \(n \gg m\)),但是实际上只有部分特征和学习任务是相关的。即使使用一个简单的线性模型，例如感知机，按照之前VC维分析，n个特征有n+1个参数，也需要O(n)级别的样本数才能得到一个较好的模型。如果训练数据不够，那么就会导致过拟合的问题，因此需要考虑特征选择。</p>
<h2 id="前向-后向选择"><a href="#前向-后向选择" class="headerlink" title="前向/后向选择"></a>前向/后向选择</h2><p>　　对于n个特征来说，特征子集的数量有\(2^n\)个，如何进行选择呢?穷举法计算量太大，必然不可行。本部分介绍一种启发式的算法，前向选择法(Forward Search)。步骤如下：<br>　　- 初始化特征子集为\(\mathcal{F}=\varnothing\)<br>　　- 重复如下步骤：<br>　　　1) For i = 1,…,n, If \(i \notin \mathcal{F}\),let \(\mathcal{F} = \mathcal{F} \cup \{i\}\),使用交叉验证来评估特征集\(\mathcal{F}_i\)<br>　　　2) 令\(\mathcal{F}\)为上面步骤中评估性能最好的特征子集，即选择提升最大的特征加入原特征子集。<br>　　- 直到性能不再提升，或已经达到设置的阙值k个特征上限。<br>　　该算法也被称作wrapper model feature selection，因为它将模型的训练和评测包含在算法的内部。<br>　　根据前向选择法，可以容易得到后向选择法(Backward Search)，即初始化特征集包含所有的特征，然后每次删除对模型性能影响最不大的特征。<br>　　上面的方法虽然可以达到较优的特征选择结果，但是由于其反复多次调用模型训练算法，因而计算量非常大，尤其是在训练数据量比较大的时候。为了使得特征选择更简便，提出了一种更简单的特征选择方法——过滤法。</p>
<h2 id="过滤特征选择"><a href="#过滤特征选择" class="headerlink" title="过滤特征选择"></a>过滤特征选择</h2><p>　　过滤特征选择(Filter Feature Selection),采用一种启发式的规则对特征进行评分，评分指标衡量了特征对于样本标记结果y的影响程度，或称作特征的信息量大小。选择评分较优的k个特征，其计算量相对于前后向搜索算法来说已经非常小了。<br>　　一个可能的评分函数是衡量\(x_i\)和y的相关性，从而选择出与类别标记y最相关的特征\(x_i\)。而相关性可以使用互信息(mutual information,MI)来表示，当\(x_i\)是离散变量时，MI的计算公式如下：<br>$$MI(x_i,y)=\sum_{x_i}\sum{y_i} p(x_i,y) log \frac{p(x_i,y)}{p(x_i)p(y)}$$<br>其中\(p(x_i,y)\)指特征和类别的联合概率分布,\(p(x_i,y),p(x_i),p(y)\)都可以通过训练集来估计出经验概率分布。<br>　　为了更直观的理解，互信息也可以表示为KL(Kullback-Leibler)距离的形式：<br>$$MI(x_i,y)=KL(p(x_i,y) || p(x_i)p(y))$$<br>　　KL距离的作用是衡量分布之间的差异。就此例来说，如果\(x_i,y\)相互独立，那么它们的KL距离为0,如果它们之间的关联关系比较强，那么KL距离会变大。<br>　　使用MI进行衡量后，我们得到了各个特征的评分，那么选择多少个特征可以让模型效果最好呢?标准的方法还是采用交叉验证进行选择。例如，选择出k个特征，那么对特征子集{1},{1,2},{1,2,3},…,{1,2,3…,k}分别进行交叉验证，看哪一个子集效果最好。</p>
<h1 id="贝叶斯估计"><a href="#贝叶斯估计" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h1><p>　　在开始前，强烈建议先阅读这篇博文<a href="http://blog.csdn.net/daunxx/article/details/51725086" target="_blank" rel="external">贝叶斯线性回归(Bayesian Linear Regression)</a>,这篇文章写得非常好! 本文会截取部分内容，并修改一些符号标记为我们之前比较习惯使用的标记。<br>　　这部分将讨论如何应对过拟合的问题。为了讨论贝叶斯统计，我们首先从极大似然估计、最大后验估计谈起。</p>
<h2 id="关于参数估计"><a href="#关于参数估计" class="headerlink" title="关于参数估计"></a>关于参数估计</h2><p>　　在很多的<strong>机器学习</strong>或数据挖掘的问题中，我们所面对的只有数据，但数据中潜在的<strong>概率密度函数</strong>是不知道的，其概率密度分布需要我们从数据中估计出来。想要确定数据对应的概率密度分布，就需要确定两个东西：<strong>概率密度函数的形式</strong> 和 <strong>概率密度函数的参数</strong>。<br>　　有时可能知道的是概率密度函数的形式(高斯、伯努利等等)，但是不知道具体的参数，例如均值或者方差；还有的时候可能不知道概率密度的类型，但是知道一些估计的参数，比如均值和方差。<br>　　关于上面提到的需要确定的两个东西：概率密度函数的<strong>形式</strong>和<strong>参数</strong>，我们目前所接触的大部分教材知识，基本都是：给了一堆数据，然后假设其概率密度函数的形式为<strong>高斯分布</strong>，或者是混合高斯分布，那么，剩下的事情就是对高斯分布的参数，\(\mu\)和\(\sigma^2\) 进行估计。所以，参数估计便成了极其最重要的问题。<br>　　其实，常用的参数估计方法有：极大似然估计、最大后验估计、贝叶斯估计、最大熵估计、混合模型估计。他们之间是有递进关系的，想要理解后一个参数估计方法，最好对前一个参数估计有足够的理解。</p>
<h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><p>　　首先回顾一下极大似然估计。<br>　　这里先以一个分类问题来说明一般参数估计面对的数据形式。考虑一个\(M\)类的问题，特征向量服从\(p(x|\omega_i),i=1,2…,M\)分布。这是现实情况中最常见的一种数据存在形式，数据集合\(X\)是由\(M\)个类别的数据子集\(X_m,m=1,2…,M\)组成的，第\(m\)类别的数据子集\(X_m\) 对应的概率密度函数是\(p(x|\omega_m)\)。\(\omega\)可以理解为不同类别的数据子集可以建立不同的模型，如果所有类别子集采用同一个模型，实际上\(\omega\)可以省略不写。<br>　　前面已经介绍过了，想要确定数据的概率分布，需要知道概率密度函数的 <strong>形式</strong> 和 <strong>参数</strong>，这里首先做一个基本假设：概率分布的形式已知，比如假设每个类别的数据都满足高斯分布，那么，似然函数就可以以参数\(θ_i\)的形式表示，如果是高斯分布，则参数为\(\mu_i\)和\(\sigma_i^2\)，即\(θ_i=(μ_i,σ^2_i)\)。<br>　　为了强调概率分布\(p(x|\omega_i)\)和 \(θ_i\) 有关，将对应的概率密度函数记为\(p(x|\omega_i;θ_i)\)，这种记法属于频率概率学派的记法。这里的极大似然估计对应于一个\(类条件概率密度函数\)。<br>　　从上面的描述中可以知道，利用每一个类\(X_i\)中已知的特征向量集合，可以估计出其对应的参数\(θ_i\)。进一步<strong>假设每一类中的数据不影响其他类别数据的参数估计</strong>，那么上面的\(M\)个类别的参数估计就可以用下面这个统一的模型，独立的解决：<br>　　设\(x^{(1)},x^{(2)},…,x^{(m)}\)是从概率密度函数\(p(x;\theta)\)随机抽取的样本，那么就可以得到<strong>联合概率密度函数</strong>\(p(X;\theta)\),其中\(X=\{x^{(1)},x^{(2)},…,x^{(m)}\}\)是样本集合，假设不同的样本之间具有统计独立性，那么：<br>$$p(X;\theta)\equiv p(x^{(1)},x^{(2)},…,x^{(m)};\theta)=\prod_{k=1}^mp(x^{(k)};\theta)$$<br>　　注意，这里的\(p(x^{(k)};\theta)\)本来的写法是\(p(x^{(k)}|\omega_i;\theta)\),是一个类条件概率密度函数，只不过是因为这里用的是统一的模型，所以才可以将\(w_i\)省略。<br>　　需要重申一下，想要得到上面这个公式，是做了几个基本的假设的，<strong>第一</strong>：假设\(M\)个类别的数据子集的<strong>概率密度函数形式</strong>一样，只是参数的取值不同；<strong>第二</strong>：假设类别\(i\)中的数据和类别\(j\)中的数据是<strong>相互独立抽样</strong>的，即类别\(j\)的参数仅仅根据类别\(j\)的数据就可以估计出来，类别\(i\)的数据并不能影响类别\(j\)的参数估计，反之亦然；<strong>第三</strong>：每个类别内的样本之间具有<strong>统计独立性</strong>，即每个类别内的样本之间是独立同分布 (\(iid\)) 的。<br>　　此时，就可以使用极大似然估计(Maximum Likelihood，ML)来估计参数\(\theta\)了。如下：<br>$$\hat{\theta}_{ML}=\mathop{argmax}_\limits{\theta} \prod_{k=1}^m p(x^{(k)};\theta)$$<br>　　可以使用\(p(y^{(i)}|x^{(i)};\theta)\)替换\(p(x^{(k)};\theta)\),即对于给定样本\(x\)和参数\(\theta\),其类别为\(y\)的概率。得到：<br>$$\hat{\theta}_{ML}=\mathop{argmax}_\limits{\theta} \prod_{i=1}^m p(y^{(i)}|x^{(i)};\theta)　　　　　(1)$$<br>　　根据频率学派的观点，参数\(\theta\)不是随机的，而是固定的，\(\theta\)是一个固定的未知值或向量，我们可以通过极大似然估计来估计\(\theta\)的值。<br>　　极大似然估计有两个非常重要的性质：<strong>渐进无偏</strong> 和 <strong>渐进一致性</strong>，有了这两个性质，使得极大似然估计的成为了非常简单而且实用的参数估计方法。这里假设\(θ_0\)是密度函数\(p(x;θ)\)中未知参数的准确值。<br>　　极大似然估计是渐进无偏的，即：<br>$$\lim_{N \to \infty}E[\hat{\theta}_{ML}]=\theta_0$$<br>　　也就是说，这里认为估计值\(\hat{\theta}_{ML}\)本身是一个随机变量（因为不同的样本集合X会得到不同的\(\hat{\theta}_{ML}\)），那么其均值就是未知参数的真实值，这就是渐进无偏。<br>　　极大似然估计是渐进一致的，即：<br>$$\lim_{N \to \infty}prob{  \lVert \hat{\theta}_{ML}-  \theta_0 \rVert \leqslant \epsilon} = 1$$<br>　　这个公式还可以表示为：<br>$$\lim_{N \to \infty} E \lVert \hat{\theta}_{ML}-  \theta_0 \rVert^2 = 0$$<br>　　对于一个估计器而言，一致性是非常重要的，因为存在满足无偏性，但是不满足一致性的情况，比如，\(\hat{\theta}_{ML}\)在\(θ_0\)周围震荡。如果不满足一致性，那么就会出现很大的方差。<br>　　注意：以上两个性质，都是在渐进的前提下\(N \to \infty\)才能讨论的，即只有N足够大时，上面两个性质才能成立。</p>
<h2 id="最大后验估计"><a href="#最大后验估计" class="headerlink" title="最大后验估计"></a>最大后验估计</h2><p>　　在最大似然估计（ML）中，将\(θ\)看做是固定的未知参数，说的通俗一点，最大似然估计是\(θ\)的函数，其求解过程就是找到使得最大似然函数最大的那个参数\(θ\)。<br>　　从最大后验估计开始，将参数\(θ\)看成一个随机变量，并在已知样本集\(X=\{x^{(1)},x^{(2)},…,x^{(m)}\}\)的条件下，估计参数\(θ\)。<br>　　这里一定要注意，在最大似然估计中，参数\(θ\)是一个定值，只是这个值未知，最大似然函数是\(θ\)的函数，这里\(θ\)是没有概率意义的,代表的是频率学派。但还还有另外一个学派，即贝叶斯学派，和频率学派的观点不同，他们认为\(\theta\)是一个随机变量，服从某个先验分布，即\(\theta \sim p(\theta)\)。因此在最大后验估计中，\(θ\)是有概率意义的，\(θ\)有自己的分布，而这个分布函数，需要通过已有的样本集合\(X\)得到，即最大后验估计需要计算的是\(p(θ|X)\)<br>　　根据贝叶斯理论：<br>$$p(\theta|X)=\frac{p(\theta)p(X|\theta)}{p(X)}$$<br>　　这就是参数\(θ\)关于已有数据集合\(X\)的后验概率，要使得这个后验概率最大，和极大似然估计一样，这里需要对后验概率函数求导。由于分母中的\(p(X)\)相对于\(θ\)是独立的，所以可以直接忽略掉\(p(X)\)。<br>$$\hat{\theta}_{MAP}=arg\max_{\theta}p(\theta|X)=arg\max_{\theta}p(\theta)p(X|\theta)$$<br>　　注意：<strong>这里\(p(X|θ)\)和极大似然估计中的似然函数\(p(X;θ)\)是一样的，只是记法不一样</strong>。\(MAP\)和\(ML\)的区别是：MAP是在ML的基础上加上了p(θ)。<br>　　这里需要说明，虽然从公式上来看 \(MAP = ML \times p(θ)\)，但是这两种算法有本质的区别，\(ML\)将\(θ\)视为一个确定未知的值，而\(MAP\)则将\(θ\)视为一个随机变量。<br>　　在\(MAP\)中，\(p(θ)\)称为\(θ\)的先验。<strong>\(MAP\)和\(ML\)的关系是</strong>，假设\(θ\)服从均匀分布，即对于所有\(θ\)取值，p(θ)都是同一个常量，则\(MAP\)和\(ML\)会得到相同的结果。当然了，如果\(p(θ)\)的方差非常的小，也就是说，\(p(θ)\)是近似均匀分布的话，\(MAP\)和\(ML\)的结果自然也会非常的相似。</p>
<h2 id="贝叶斯估计-1"><a href="#贝叶斯估计-1" class="headerlink" title="贝叶斯估计"></a>贝叶斯估计</h2><p>　　<strong>以下所有的概率分布表述方式均为贝叶斯学派的表述方式</strong>。另外，在标题上加上全。</p>
<h3 id="贝叶斯估计核心问题"><a href="#贝叶斯估计核心问题" class="headerlink" title="贝叶斯估计核心问题"></a>贝叶斯估计核心问题</h3><p>　　为了防止标号混淆，这里定义已有的样本集合为\(S\)，而不是之前的\(X\)。样本集合\(S\)中的样本都是从一个 <strong>固定但是未知</strong> 的<strong>概率密度函数\(p(x)\)</strong>中独立抽取出来的，我们的目标是根据这些样本估计\(x\)的概率分布，记为\(p(x|S)\)，并且<strong>使得\(p(x|S)\)尽量的接近\(p(x)\)</strong>，这就是贝叶斯估计的核心问题。</p>
<h3 id="贝叶斯估计第一个重要元素"><a href="#贝叶斯估计第一个重要元素" class="headerlink" title="贝叶斯估计第一个重要元素"></a>贝叶斯估计第一个重要元素</h3><p>　　虽然\(p(x)\)是未知的，但是前面提到过，一个密度分布的两个要素为：<strong>形式</strong>和<strong>参数</strong>，我们可以假设\(p(x)\)的形式已知，但是参数θ的取值未知。<strong>这里就有了贝叶斯估计的第一个重要元素\(p(x|θ)\)</strong>，这是一个条件概率密度函数，准确的说，是一个类条件概率密度函数（具体原因参见本文前面关于极大似然估计的说明）。强调一下：\(p(x|θ)\)的形式是已知的，只是参数\(θ\)的取值未知。由于这里的\(x\)可以看成一个测试样本，所以这个<strong>条件密度函数</strong>，从本质上讲，<strong>是\(θ\)在点\(x\)处的似然估计</strong>。</p>
<h3 id="贝叶斯估计第二个重要元素"><a href="#贝叶斯估计第二个重要元素" class="headerlink" title="贝叶斯估计第二个重要元素"></a>贝叶斯估计第二个重要元素</h3><p>　　由于参数\(θ\)的取值未知，且，我们将\(θ\)看成一个随机变量，那么，在观察到具体的训练样本之前，关于\(θ\)的全部知识，可以用一个<strong>先验概率密度函数\(p(θ)\)</strong>来表示，对于训练样本的观察，使得我们能够把这个先验概率密度转化成为后验概率密度函数\(p(θ|S)\)，根据后验概率密度相关的论述知道，我们希望\(p(θ|S)\)在\(θ\)的真实值附近有非常显著的尖峰。这里的这个<strong>后验概率密度</strong>，<strong>就是贝叶斯估计的第二个重要元素</strong>。</p>
<h3 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h3><p>　　现在，将<strong>贝叶斯估计核心问题\(p(x|S)\)</strong>，和贝叶斯估计的<strong>两个重要元素</strong>：\(p(x|θ)、p(θ|S)\)联系起来：<br>$$p(x|S)=\int p(x,\theta|S) d\theta=\int p(x|\theta,S)p(\theta|S)d\theta　　　(1)$$</p>
<hr>
<p>　　以上等式都是基于训练集\(S\)的，我们可以暂且忽略S来理解。<br>　　<strong>第一个等式理解</strong>：联合概率密度和边缘概率密度关系。更一般的即：针对连续型随机变量\((X,Y)\),设它的联合概率密度为\(f(x,y)\)，则：<br>$$f_X(x)=\int_{ - \infty }^{ + \infty } f(x,y)dy$$<br>　　上式称为随机变量\((X,Y)\)关于X的边缘概率密度。同理可以求Y的边缘概率密度。我们将\(\theta\)替换y就可以得到，\(p(x)=\int p(x,\theta) d\theta\)。<br>　　<strong>第二个等式理解</strong>：条件概率和联合概率关系，即：<br>$$p(x|y)=\frac{p(x,y)}{p(y)}$$<br>　　同样，可以将\(\theta\)替换y，并整理就可以得到，\(p(x,\theta)=p(x|\theta)p(\theta)\)。<br>　　对每个式子加上\(|S\)即可得到上述公式，注意\(p(x|\theta,S)\)就是指在\(\theta和S\)条件下,相当于\(p(x|\theta)\)和\(p(x|S)\),也即\(p(x|(\theta,S))\)。</p>
<hr>
<p>　　上面式子中，\(x\)是测试样本，\(S\)是训练集。\(x\)和\(S\)的选取是独立进行的，因此，\(p(x|θ,S)\)可以写成\(p(x|θ)\)。所以，贝叶斯估计的核心问题就是下面这个公式：<br>$$p(x|S)=\int p(x|\theta)p(\theta|S)d\theta　　　　　(2)$$<br>　　下面这句话一定要理解：这里<strong>\(p(x|θ)\)是\(θ\)关于测试样本\(x\)这一个点的似然估计</strong>，而<strong>\(p(θ|S)\)则是\(θ\)在已有样本集合上的后验概率</strong>。这就是为什么本文一开始并没有直接讲贝叶斯估计，而是先说明极大似然估计和最大后验估计的原因。其中，\(p(x|θ)\)和极大似然估计中的似然函数\(p(x;θ)\)其实是一样的，而后验概率\(p(θ|S)\)为：<br>$$p(\theta|S)=\frac{p(S|\theta)p(\theta)}{p(S)}=\frac{p(S|\theta)p(\theta)}{\int p(S|\theta)p(\theta)d\theta}　　　(3)\\\\<br>p(S|\theta)=\prod_{k=1}^m p(x^{(k)}|\theta) \\\\<br>其中，p(S|θ)和极大似然估计中的p(S;θ)一样，\\\\<br>同理，p(x^{(k)}|\theta)和极大似然估计中的p(x^{(k)};\theta)是一样的。\\\\<br>不同点在于，关于\theta是未知的固定值还是随机变量的区别。<br>$$<br>　　在上述贝叶斯公式里，实际上后验概率也是条件概率的一种。条件概率：在某条件下事件发生的概率。后验概率：已知原分布下,在实际发生某事件时,原先某情况的可能性。二者关联我认为是，后验概率里的”原分布”相当于条件概率里的”某条件”的一种情况。<br>　　因此贝叶斯公式的分子，相当于条件概率里的\(P(S,\theta)\)联合概率，而分母是先通过条件概率\(P(S|\theta)p(\theta)\)得到联合概率\(P(S,\theta)\),然后通过联合概率求得边缘概率\(p(S)\)。<br>　　具体的，给定一个训练集\(S={\{(x^{(i)},y^{(i)})\}}_{i=1}^m\)，参数\(\theta\)的后验概率分布如下：<br>$$p(\theta|S)=\frac{p(S|\theta)p(\theta)}{p(S)}<br>=\frac{\left(\prod_{i=1}^m p(y^{(i)}|x^{(i)},\theta)\right)p(\theta)}{\int_{\theta}\left(\prod_{i=1}^m p(y^{(i)}|x^{(i)},\theta)p(\theta)\right)d\theta}　　 \\\\<br>其中，p(y^{(i)}|x^{(i)},\theta)=p(y^{(i)}|(x^{(i)},\theta)),即在x^{(i)},\theta已知情况下,样本类别为y^{(i)}的概率。<br>$$　<br>　　注意到前面似然估计中我们用的是，\(p(y^{(i)}|x^{(i)};\theta)\)的x和与\(\theta\)以分号隔开，表示\(\theta\)是一个具体的未知值。上述贝叶斯估计用的是\(p(y^{(i)}|x^{(i)},\theta)\)的x和\(\theta\)之间以逗号隔开，表示\(\theta\)是随机变量。<br>　　公式2中的\(p(y^{(i)}|x^{(i)},\theta)\)形式来源于所选模型，比如使用贝叶斯Logistic回归模型(bayesian logistic model,BLR),那么有：<br>$$p(y^{(i)}|x^{(i)},\theta)=h_\theta(x^{(i)})^{y^{(i)}}(1-h_\theta(x^{(i)}))^{1-y^{(i)}}\\\\<br>其中,h_\theta(x^{(i)})=\frac{1}{1+exp(-\theta^Tx^{(i)})}$$<br>　　在对新样本进行预测时，根据上述得到的公式(2)，可以使用如下公式计算后验概率：<br>$$p(y|x,S)=\int_{\theta} p(y|x,\theta)p(\theta|S)d\theta$$<br>　　上式中的\(p(\theta|S)\)后验概率使用贝叶斯公式(3)计算。<br>　　如果预测的是在给定x情况下y的值，则使用下列公式：<br>$$E[y|x,S]=\int_y yp(y|x,S)dy$$</p>
<h2 id="最大后验估计和贝叶斯估计的联系"><a href="#最大后验估计和贝叶斯估计的联系" class="headerlink" title="最大后验估计和贝叶斯估计的联系"></a>最大后验估计和贝叶斯估计的联系</h2><p>　　上述公式2称作全贝叶斯预测(fully Bayesian prediction)。可以看到，贝叶斯估计需要在在\(\theta\)上计算后验概率\(p(\theta|S)\)。不幸的是计算该后验分布非常困难，因为根据(3)，需要在\(\theta\)上求积分，即对所有的参数求积分，而\(\theta\)经常是高维度的。<br>　　因此实践中，经常对后验分布进行近似求解。一个通常的近似方法是对公式2中的后验分布中的\(\theta\)使用点估计来代替。即：<br>$$\hat{\theta}_{MAP}=arg\max_{\theta}p(\theta|S)=arg\max_{\theta}p(S|\theta)p(\theta)=arg\max_{\theta}(\prod_{i=1}^m p(y^{(i)}|x^{(i)},\theta))p(\theta)$$<br>　　\(p(y^{(i)}|x^{(i)},\theta)\)是\(\theta\)在样本点\((x^{(i)},y^{(i)})\)的点估计，实际上该公式就是最大后验估计中的公式。即<strong>最大后验估计是贝叶斯估计的一种近似。</strong><br>　　 从以上可以看出，一方面，极大似然估计和最大后验概率都是参数的点估计。在频率学派中，参数固定了，预测值也就固定了。<strong>最大后验概率是贝叶斯学派的一种近似手段</strong>，因为完全贝叶斯估计不一定可行。</p>
<h1 id="贝叶斯估计和正则化"><a href="#贝叶斯估计和正则化" class="headerlink" title="贝叶斯估计和正则化"></a>贝叶斯估计和正则化</h1><p>　　正则化，对于监督学习而言，我们有如下的目标函数：<br>$$\theta^{*}=arg \min_{\theta} \sum_{i} L(y^{(i)},f(x^{(i)};\theta))+\lambda \Omega(\theta)$$<br>　　其中，第一项\(L(y^{(i)},f(x^{(i)};\theta))\)衡量我们的模型对第\(i\)个样本的预测值\(f(x^{(i)};\theta)\)和真实标签\(y^{(i)}\)之间的误差。我们要最小化这一项，根据ERM，即训练误差最小化。但我们不仅要保证训练误差最小，我们更希望模型的泛化误差小，所以加上第二项，也就是对参数\(\theta\)的正则化函数\(\Omega(\theta)\)取约束我们的模型，使其尽量简单，即惩罚复杂的模型，约束要优化的参数。这个正则化函数就是我们常说的\(L_0,L_1,L_2\)范数。这是防止过拟合的重要手段。<br>　　上述方法我们经常使用极大似然估计来最优化。注意此时估计时，是<strong>需要加上正则化项</strong>才能防止过拟合的。<br>　　那么前面我们提到的贝叶斯估计，又是如何做到防止过拟合呢? 我们知道全贝叶斯估计很难计算，因此使用最大后验估计来近似。这里我们直接讨论最大后验估计。<strong>我们要从最大后验估计推导出上述目标函数的形式，即加了正则化项的极大似然估计。</strong><br>　　$$\hat{\theta}_{MAP}=arg\max_{\theta}p(\theta|S)=arg\max_{\theta}p(S|\theta)p(\theta)=arg\max_{\theta}(\prod_{i=1}^m p(y^{(i)}|x^{(i)},\theta))p(\theta)$$<br>　　　当\(\theta\)的先验概率分布满足均值为0的正态分布的时候，对于\(\theta\)的每一个分量\(\theta_j\)，都有：<br>$$p(\theta_j)=\mathcal{N}(\theta_j|0,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{\theta_j^2}{2\sigma^2}}$$<br>　　此时，根据\(\theta_i\)之间独立同分布，有，\(p(\theta) = \prod_{j=1}^n p(\theta_i)\)</p>
<p>　　对最大后验估计两边取对数有：<br>$$log(\hat{\theta}_{MAP})=arg\max_{\theta} \sum_{i=1}^m \left(log \ p(y^{(i)}|x^{(i)},\theta)\right)+log \ p(\theta) \\\\<br>=arg\min_{\theta} -\sum_{i=1}^m \left(log \ p(y^{(i)}|x^{(i)},\theta)\right)-log \ p(\theta)$$<br>　<br>　　代入公式展开有：<br>$$\theta^{*}=log(\hat{\theta}_{MAP})=arg\min_{\theta} -\sum_{i=1}^m \left(log \ p(y^{(i)}|x^{(i)},\theta)\right)-log \ p(\theta)\\\\<br>=arg\min_{\theta} -\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)},\theta)-\sum_{j=1}^n log \ p(\theta) \\\\<br>= arg\min_{\theta} -\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)},\theta)+\frac{1}{2\sigma^2}\sum_{j=1}^n \theta_j^2+nlog(\sqrt{2\pi\sigma^2}) \\\\<br>= arg\min_{\theta} -\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)},\theta)+\lambda\sum_{j=1}^n \theta_j^2 \\\\<br>(\lambda=\frac{1}{\sigma^2},常数可以去掉)<br>$$<br>　　对比下式：<br>$$\theta^{*}=arg \min_{\theta} \sum_{i} L(y^{(i)},f(x^{(i)};\theta))+\lambda \Omega(\theta)$$<br>　　可以看到，似然函数部分对应于损失函数(训练误差)，而先验概率部分对应于正则化项。此处是\(L_2\)正则化，等价于参数\(\theta\)的先验概率分布满足正态分布。<br>　　最终的公式就是岭回归计算公式。与上面最大似然估计推导出的最小二乘相比，最大后验估计就是在最大似然估计公式乘以高斯先验，这就理解了L2正则就是加入高斯先验知识。<br>　　拓展，当先验概率分布满足均值为0的拉普拉斯分布的时候，即:<br>$$p(\theta_j)=\mathcal{Lplace}(\theta_j|0,b)=\frac{1}{2b}e^{-\frac{|\theta_j|}{b}}$$<br>　　此时根据最大后验估计可以推导出：<br>$$\theta^{*}= arg\min_{\theta} -\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)},\theta)+\lambda\sum_{j=1}^n |\theta_j| \\\\<br>(\lambda=\frac{1}{b})<br>$$<br>　　最终的公式就是Lasso计算公式。与上面最大似然估计推导出的最小二乘相比，最大后验估计就是在最大似然估计公式乘以拉普拉斯先验，这里就理解了L1正则就是加入拉普拉斯先验知识。<br>　　我们之前学习的线性回归的代价函数使用的最小二乘法，实际上是在最大似然法基础上加上残差的正态分部假设得出的。同样如果假设残差是拉普拉斯分布，得出的就是最小一乘。<br>　　总结一句，<strong>从贝叶斯估计的角度来看,正则化项对应于模型的先验概率。</strong></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="http://blog.csdn.net/daunxx/article/details/51725086" target="_blank" rel="external">贝叶斯线性回归</a><br><a href="http://www.jianshu.com/p/a47c46153326" target="_blank" rel="external">回归系列之L1和L2正则化</a><br><a href="http://blog.csdn.net/zhuxiaodong030/article/details/54408786" target="_blank" rel="external">从贝叶斯角度深入理解正则化</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本部分将继续讨论学习理论的相关知识。学习理论内容包括：模型/特征选择(model/feature selection)、贝叶斯统计和正则化(Bayesian statistics and Regularization)。本文重点在于贝叶斯统计和正则化。将重点理解这句话，从贝叶斯估计的角度来看,正则化项对应于模型的先验概率。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="正则化" scheme="xtf615.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
      <category term="特征选择" scheme="xtf615.com/tags/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
    
      <category term="贝叶斯估计" scheme="xtf615.com/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/"/>
    
      <category term="概率论" scheme="xtf615.com/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
      <category term="极大似然估计" scheme="xtf615.com/tags/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/"/>
    
      <category term="最大后验估计" scheme="xtf615.com/tags/%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>Learning Theory</title>
    <link href="xtf615.com/2017/03/29/Learning-Theory/"/>
    <id>xtf615.com/2017/03/29/Learning-Theory/</id>
    <published>2017-03-29T04:59:14.000Z</published>
    <updated>2017-03-30T02:11:25.295Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文与前面不同，主要内容不是算法，而是机器学习的另一部分内容——学习理论。主要包括偏差/方差(Bias/Variance)、经验风险最小化(Empirical Risk Minimization,ERM)、联合界(Union bound)、一致收敛(Uniform Convergence)。</p>
<h1 id="偏差-方差权衡"><a href="#偏差-方差权衡" class="headerlink" title="偏差/方差权衡"></a>偏差/方差权衡</h1><p>　　回顾一下，当我们讨论线性回归时，我们尝试过使用简单的线性方法，如\(y=\theta_0 + \theta_1 x\),也尝试使用更复杂的模型，如多项式\(y=\theta_0+\theta_1 x+…+\theta_5 x^5\)。观察下图：<br><img src="/picture/machine-learning/theory1.jpg" alt="theory"><br>　　以上述回归问题为例，机器学习的目标是从训练集中得到一个模型，使之能对测试集进行分类。这里训练集和测试集都是分布\(\mathcal{D}\)的样本。机器学习的关注点在于模型在测试集上的分类效果，这也称作泛化能力(generalization ability)。如上图，最左边的图用一个线性模型进行拟合，显然即使拥有很多的训练集，该模型在测试集上进行预测的话，仍然存在着很大的误差，这种情况称为欠拟合，对应着高偏差。对于最右边的图，用一个高阶(五阶)去拟合，从数据中得到的模型结构很可能碰巧是该训练集特有的，即尽管五次多项式模型对训练集的拟合不错，但并非是一个好的模型，因为对于训练集以外的数据，该模型不一定能很好得进行预测，即泛化能力不够好，因此仍然存在着很大的泛化误差，这种情况称作过拟合，对应高方差。<br>　　在机器学习中，对偏差和方差的权衡是学习理论重点解决的问题。如果我们的模型太过于简单，只有少量的参数要学习，那么就可能存在高偏差(large bias but small variance)。如果我们的模型太过于复杂，拥有大量的参数，那么就可能存在高方差(large variance but small bias)。在上面的例子中，训练一个二次型的模型(对应中间那幅图)，比训练一个过于简单的一次型模型或过于复杂的五次型模型都好。　　<br><a id="more"></a></p>
<h1 id="经验风险最小化"><a href="#经验风险最小化" class="headerlink" title="经验风险最小化"></a>经验风险最小化</h1><p>　　在这部分我们开始对学习理论进行研究。这部分的研究可以磨练我们的直觉，并学到在不同情况下，更好得应用学习算法的经验法则。我们也会尝试回答一些问题，例如是否可以将偏差/方差的权衡进行形式化表述?这有助于后面对于特征选择方法的学习，也有助于为训练数据选择合适的多项式拟合阶数。其次，在机器学习中，我们对泛化误差格外关注，然而我们的模型是对训练集进行拟合的，训练集拟合表现对泛化误差有什么影响？是否可以将训练集的误差和泛化误差联系在一起。最后一个问题，证明学习算法表现良好是否需要一些条件作为基础？</p>
<h2 id="引理"><a href="#引理" class="headerlink" title="引理"></a>引理</h2><p>　　首先讨论两条引理。<br>　　<strong>联合界定理(The union bound)</strong>:令\(A_1,A_2,…,A_k\)是k个事件，这k个时间可以相互独立也可以不相互独立，我们有:<br>$$P(A_1 \cup A_2 … \cup A_k) \leq P(A_1)+P(A_2)+…+P(A_k)$$<br>　　在概率论中，上述是一个公理。任意事件发生的概率显然小于所有事件各自发生的概率之和。该定理可以使用文氏图(韦恩图)进行非正式的证明。<br>　　<strong>Hoeffding不等式</strong>：令\(Z_1,Z_2,…,Z_m\)为m个独立同分布变量(\(i.i.d\)),它们都服从伯努利分布，即\(P(Z_i=1)=\phi,P(Z_i=0)=1-\phi\),我们使用m个服从\(i.i.d的Z_i\)变量的平均值来估计\(\phi\)，得到:<br>$$\hat{\phi}=\frac{1}{m}\sum_{i=1}^m Z_i$$<br>　　那么Hoeffding不等式的定义即，对于任意的固定数值\(\gamma&gt;0\)，满足：<br>$$P(|\phi-\hat{\phi}|&gt;\gamma) \leq 2exp(-2\gamma^2 m)$$<br>　　这个引理是指,如果我们使用m个满足伯努利分布的随机变量的平均值\(\hat{\phi}\)来估计\(\phi\),那么随着样本数目m的增大，我们对参数的估计\(\hat{\phi}\)会越来越接近真实的\(\phi\)值。上式的概率实际上代表犯错误的概率，即犯错误概率会随样本数目的增大而减小。<br>　　运用上述两条引理，我们可以得出一些重要的学习理论结论。</p>
<h2 id="经验风险"><a href="#经验风险" class="headerlink" title="经验风险"></a>经验风险</h2><p>　　为了简化我们的讨论，我们将注意力集中在二分类问题上，即\(y \in \{0,1\}\)。所有关于二分类问题的讨论同样适用于其它的回归问题或者多分类问题。<br>　　假设给定一个训练集\(S=\{(x^{(i)},y^{(i)});i=1,…,m\}\),样本数量为m，每一个样本都满足独立同分布，且服从分布\(D\),即假设每个样本都是通过该分布生成的。对于一个特定的假设h,我们定义训练误差training error（在学习理论中称作经验风险或经验误差）为：<br>$$\hat{\epsilon}(h)=\frac{1}{m} \sum_{i=1}^m I\{h(x^{(i)}) \not= y^{(i)}\}$$<br>　　\(\hat{\epsilon}(h)\)代表对于<strong>特定</strong>训练集S得到的<strong>估计值</strong>，也可以写作\(\hat{\epsilon}_S(h)\)。我们定义泛化误差generalization error为：<br>$$\epsilon(h)=P(x,y) \sim \mathcal{D}(h(x) \not= y)$$<br>　　泛化误差是针对满足分布的新样本而言，指的是对于满足分布\(\mathcal{D}\)的新样本(x,y),会被h误分类的概率。注意，我们假设训练数据是根据分布\(\mathcal{D}\)得到的，同时，\(\mathcal{D}\)也是测试数据的分布，也就是上式泛化误差中的\(\mathcal{D}\)。这也是PAC假设之一，PAC全称probably approximately correct,是学习理论得以证明所依赖的一个框架和一系列假设，训练集和测试集同分布是其中最重要的一个假设。<br>　　考虑一个线性分类问题，令\(h_\theta(x)=I\{\theta^T x \geq 0\}\),即当\(\theta^T x \geq 0\)时，分类结果为1。一种拟合参数\(\theta\)的方法是最小化训练误差:<br>$$\hat{\theta}=\mathop{argmin}_\limits{\theta} \hat{\epsilon}(h_\theta)$$<br>　　我们称这个过程为经验风险最小化(empirical risk minimization,ERM),根据该学习算法，可以得到假设h的估计，即\(\hat{h}=h_{\hat{\theta}}\)。我们认为ERM是最基本的学习算法，其他算法如逻辑回归等也可以被近似当作ERM。<br>　　在研究学习理论中，我们暂且不考虑假设具体的参数和具体使用的分类器是什么。我们定义一个学习算法的假设空间\(\mathcal{H}\)由所有的决策函数或模型的集合构成。例如对于线性分类问题，有：\(\mathcal{H}=\{h_\theta:h_\theta(x)=I\{\theta^Tx \geq 0\},\theta \in {\mathbb{R}}^{n+1}\}\)。拓展来说，如果我们在学习神经网络，那么\(\mathcal{H}\)就代表一系列可以代表神经网络的决策函数组成。<br>　　在这里，ERM可以认为是在假设空间\(\mathcal{H}\)中寻找使得训练误差最小化的某个假设h.即：<br>$$\hat{h}=\mathop{argmin}_\limits{h \in H} \hat{\epsilon}(h)$$</p>
<h2 id="一致收敛"><a href="#一致收敛" class="headerlink" title="一致收敛"></a>一致收敛</h2><p>　　我们首先考虑有限的假设空间\(\mathcal{H}=\{h_1,…,h_k\}\),假设空间由k个假设组成。因此\(\mathcal{H}\)只是k个由映射函数组成，该映射函数负责从输入空间\(\mathcal{X}\)映射到\(\{0,1\}\)。经验风险最小化就是从这k个函数中选择使得训练误差最小的假设\(\hat{h}\)。<br>　　我们关注的是\(\hat{h}\)在泛化误差上表现,即\(\epsilon(\hat{h})\)。我们的策略包含两个步骤，首先证明，对所有的h，\(\hat{\epsilon}(h)\)都是\(\epsilon(h)\)的可靠估计。接着证明\(\hat{h}\)的泛化误差\(\epsilon(\hat{h})\)存在着一个上界。<br>　　先证明第一个，对所有的h，\(\hat{\epsilon}(h)\)都是\(\epsilon(h)\)的可靠估计。<br>　　从假设空间选取某个特定的\(h_i \in \mathcal{H}\)。考虑伯努利随机变量Z，我们根据分布\(\mathcal{D}\)生成新样本(x,y),即\((x,y) \sim \mathcal{D}\)，再令\(Z=I\{h_i(x) \not= y\}\)，即判断\(h_i\)能否正确分类新样本。同样我们定义\(Z_j=I\{h_i(x^{(j)}) \not= y^{(j)}\}\)，即判断训练集中的样本是否被正确分类。因为训练样本也是根据分布\(\mathcal{D}\)获得的，则Z和\(Z_j\)属于同分布。<br>　　训练误差重写为：<br>$$\hat{\epsilon}(h_i)=\frac{1}{m}\sum_{j=1}^m Z_j$$<br>　　\(\hat{\epsilon}(h_i)\)实际上就是m个服从伯努利分布的随机变量\(Z_j\)的平均值。而\(\epsilon(h_i)\)代表伯努利分布Z的均值。根据Hoeffding不等式，有：<br>$$P(|\epsilon(h_i)-\hat{\epsilon}(h_i)|&gt;\gamma) \leq 2exp(-2\gamma^2 m)$$<br>　　这意味着，对于给定的\(h_i\),当m非常大时，泛化误差和训练误差接近的概率很大，即训练误差\(\hat{\epsilon}(h_i)\)能够很好的估计泛化误差\(\epsilon(h_i)\)。更进一步，我们想证明对于任意的\(h \in \mathcal{H}\),都存在上述结果。为了证明这个结论，我们令\(A_i\)代表\(|\epsilon(h_i)-\hat{\epsilon}(h_i)|&gt;\gamma\)，对于任意给定的\(A_i\),都有：\(P(A_i) \leq 2exp(-2\gamma^2 m)\)。因此使用联合界定义，有：<br>$$P(\exists h \in \mathcal{H}.|\epsilon(h_i)-\hat{\epsilon}(h_i)|&gt;\gamma) = P(A_1 \cup A_2 … \cup A_k) \leq \sum_{i=1}^k P(A_i) \\\\<br>\leq \sum_{i=1}^k 2exp(-2\gamma^2 m) \\\\<br>= 2kexp(-2\gamma^2 m)<br>$$<br>　　同时使用1减去不等式两边有，<br>$$P(\nexists h \in \mathcal{H}.|\epsilon(h_i)-\hat{\epsilon}(h_i)|&gt;\gamma)=P(\forall h \in \mathcal{H}.|\epsilon(h_i)-\hat{\epsilon}(h_i)| \leq \gamma) \geq 1-2kexp(-2\gamma^2m)$$<br>　　上式代表，至少以概率\(1-2kexp(-2\gamma^2m)\)保证,对所有的\(h \in \mathcal{H}\)，都有泛化误差和训练误差的差值不大于\(\gamma\).称作一致收敛定理。<br>　　在一致收敛中，有三个参数,\(m,\gamma\),误差的概率(或称作犯错误的概率),这三个参数是互相关联的，我们可以固定其中两个，来推出第三个，其中固定\(m,\gamma\)求概率上式已经得出。下面依次对另外两种参数关联进行说明。<br>　　第一个，对于给定\(\gamma,\delta &gt; 0\)，需要多少样本，才可以保证至少有\(1-\delta\)的概率，使得泛化误差和训练误差相差在\(\gamma\)的范围内.令\(1-2kexp(-2\gamma^2m) \geq 1-\delta \)可以求出m:<br>$$m \geq \frac{1}{2\gamma^2}log\frac{2k}{\delta}$$<br>　　即当m满足上式时，对任意的\(h \in \mathcal{H}\),都至少有\(1-\delta\)的概率保证\(|\epsilon(h_i)-\hat{\epsilon}(h_i)| \leq \gamma\)，也即犯错误(\(|\epsilon(h_i)-\hat{\epsilon}(h_i)| &gt; \gamma\))的概率至多为\(\delta\)<br>　　这个推论的意义在于，一个模型或算法要达到一个确定的性能时，需要的样本数目为多少。这也称作算法的样本复杂度。上式也表明，达到好的性能，对k的限制只需要对数级别就行，k是假设空间的大小。这个很关键。<br>　　同样的，我们也可以固定m和\(\delta&gt;0\),泛化误差会落在训练误差的什么范围内呢？<br>　　$$|\hat{\epsilon}(h)-\epsilon(h)| \leq \sqrt{\frac{1}{2m} log \frac{2k}{\delta}}$$<br>　　接着证明\(\hat{h}\)的泛化误差\(\epsilon(\hat{h})\)存在着一个上界。也就是考察在一致收敛成立的情况下，我们通过ERM方法得到的假设\(\hat{h}\)的泛化能力到底如何?<br>　　首先定义：<br>$$\hat{h}=\mathop{argmin}_\limits{h \in \mathcal{H}} \hat{\epsilon}(h)$$<br>$$h^{*}=\mathop{argmin}_\limits{h \in \mathcal{H}} \epsilon(h)$$<br>　　\(\hat{h}\)可以理解为在假设空间中，寻找使得训练误差最小的那个假设。\(h^{*}\)可以理解为在假设空间\(\mathcal{H}\)中，寻找使得泛化误差最小的假设。\(h^{*}\)是我们能找到的最好的假设。我们可以将使得训练误差最小的那个假设\(\hat{h}\)和其进行对比,\(\epsilon(\hat{h})\)可以表示训练集上选择使训练误差最小的假设\(\hat{h}\)在泛化误差上的表现。<br>$$\epsilon(\hat{h}) \leq \hat{\epsilon}(\hat{h})+\gamma \\\\<br>\leq \hat{\epsilon}(h^{*}) + \gamma \\\\<br>\leq \epsilon(h^{*}) + 2\gamma<br>$$<br>　　首先是第一个不等式，\(\epsilon(\hat{h})\)是指对于某个特定的假设\(\hat{h}\)的泛化误差,\( \hat{\epsilon}(\hat{h})\)代表对于某个特定的假设\(\hat{h}\)的训练误差。根据一致收敛定理, 在\(1-\delta\)的概率下能保证泛化误差和训练误差相差在\(\gamma\)的范围内时, 即：<br>$$|\epsilon(h_i)-\hat{\epsilon}(h_i)| \leq \gamma$$<br>　　展开不等式：<br>$$-\gamma \leq \epsilon(h_i)-\hat{\epsilon}(h_i) \leq \gamma$$<br>　　根据右半边部分可以得到,\(\epsilon(h_i)\leq \hat{\epsilon}(h_i)+\gamma\),进而推出第一个不等式,这里的\(\hat{h}\)相当于上面的\(h_i\),因为\(h_i\)可以是任意属于假设空间的假设。<br>　　第二个不等式是因为根据上述定义的\(\hat{h}=\mathop{argmin}_\limits{h \in \mathcal{H}} \hat{\epsilon}(h)\),即在训练误差表现上，\(\hat{h}\)是表现最好的，没有任何其他的假设在训练误差上表现会更好，因此\(\hat{\epsilon}(\hat{h}) \leq \hat{\epsilon}(h^{*})\)。<br>　　最后一个不等式，仍然是根据一致收敛定理，根据上述绝对值不等式展开后的左半边部分，有:<br>$$\hat{\epsilon}(h_i) \leq \epsilon(h_i) + \gamma$$<br>　　使用\(h^{*}\)替换\(h_i\),则有：<br>$$\hat{\epsilon}(h^{*}) \leq \epsilon(h^{*}) + \gamma$$<br>　　进而可以推出第三个不等式。<br>　　下面将这些推论综合一下，我们得到一个定理：<br>　　令\(|\mathcal{H}|=k\),给定m和\(\delta&gt;0\),那么至少有\(1-\delta\)的概率能否使下面公式成立:<br>$$\epsilon(\hat{h}) \leq \min_{h \in \mathcal{H}} \epsilon(h) + 2\sqrt{\frac{1}{2m} log \frac{2k}{\delta}}$$<br>　　该定理反映了在训练集上选择使训练误差最小的假设\(\hat{h}\)在泛化误差上的表现(\(\epsilon(\hat{h})\))受模型精确度和复杂度的影响，也就是反映了偏差和方差之间的权衡。可以想象，当选择一个复杂的模型假设时,\(|\mathcal{H}|=k\)会变大 ，导致不等式后的第二项变大，意味着方差变大；但是第一项也会相应的变小，因为使用一个更大的假设空间\(\mathcal{H}\)意味着可供选择的假设变多了，在多的那部分假设中可能存在使误差更小的假设，因此偏差就会变小。故应该选择一个最优值，使得偏差和方差之和最小，才能得到一个好的模型。<br>　　同样，该定理还有另外形式的推论：<br>　　令\(|\mathcal{H}|=k\)，给定\(\gamma,\delta&gt;0\)，那么至少有\(1-\delta\)概率使得\(\epsilon(\hat{h}) \leq \min_\limits{h \in \mathcal{H}} \epsilon(h) + 2\gamma\)成立的前提是：<br>$$m \geq \frac{1}{2\gamma^2} log \frac{2k}{\delta}=O(\frac{1}{\gamma^2}log\frac{k}{\delta})$$</p>
<h1 id="推广无限假设空间"><a href="#推广无限假设空间" class="headerlink" title="推广无限假设空间"></a>推广无限假设空间</h1><p>　　上述讨论的是有限假设空间的情况。我们将其拓展到无限空间。</p>
<h2 id="直观理解"><a href="#直观理解" class="headerlink" title="直观理解"></a>直观理解</h2><p>　　先从一个简单的例子说起。假设我们的假设空间\(\mathcal{H}\)由d个实数参数表示。例如对于逻辑回归，如果有n个特征的话,就有d=n+1(多的一个是截距)个参数。因为计算机通常使用双精度64bit来表示double型数据。因此对于每个参数都有\(2^64\)种不同可能的取值，那么d个参数的话，不同排列组合有，\(2^{64} \times 2^{64} \times …\times 2^{64}\)种，共d个式子，即\(k=2^{64d}\)种不同的假设。为了满足在\(1-\sigma\)概率下，有\(\epsilon(\hat{h}) \leq \epsilon(h^{*})+2\gamma\),则：<br>$$m \geq \frac{1}{2\gamma^2} log \frac{2k}{\delta}=O(\frac{1}{\gamma^2}log\frac{2^{64}}{\delta})=O(\frac{d}{\gamma^2} log \frac{1}{\gamma})=O_{\gamma,\delta}(d)$$<br>　　最后一个O代表对于给定的\(\gamma,\delta\)，即认为为常数的时候，所需要的样本个数应该和参数个数呈线性关系。<br>　　上述证明不够严格，下面进行更正式的表述。(具体证明不给出)</p>
<h2 id="VC维"><a href="#VC维" class="headerlink" title="VC维"></a>VC维</h2><p>　　首先引入VC(Vapnik-Chervonenkis)维的概念。VC维是为了研究学习过程一致收敛的速度和推广性，由统计学理论定义的有关函数集学习性能的一个重要指标。<br>　　具体定义，对一个指示函数集，如果存在H个样本能够被函数集中的函数按所有可能的\(2^H\)种形式分开，则称函数集能够把H个样本打散(分开)；函数集的VC维就是它能打散的最大样本数目H。若对任意数目的样本都有函数能将它们打散,则函数集的VC维是无穷大，它可以将任意多样本的任意标注情况精确分开，即在训练集上达到100%的分类正确率。<br>　　我们可以看一下2维空间，对于3个样本而言：<br><img src="/picture/machine-learning/theory2.jpg" alt="theory"><br>　　共用8种可能(\(2^3\),任意一个样本可以在直线任意一侧)。可以发现都可以很好的分开，只要存在一种放置该8种可能的方式即可(例如如果选择同一直线的方式就不能打散，但是存在其他种不再同一直线上的8种方式可以进行打散)。我们再观察4个样本，都不能同时对\(2^4=16\)种标注进行打散，即不是所有的标注形式，都能找到一个假设来分散，因此VC维在二维线性分类器上等于3。推广至<br>维线性分类器上，VC维d=n+1。<br>　　实际上对于无限假设空间，我们令该假设空间的VC维为d，即\(d=VC(\mathcal{H})\)。我们可以得到如下结论，在\(1-\delta\)概率下,对于所有的\(h \in \mathcal{H}\),都有：<br>$$|\epsilon(h)-\hat{\epsilon}(h)| \leq O\left(\sqrt{\frac{d}{m} log \frac{m}{d} + \frac{1}{m} log \frac{1}{\delta}}\right)$$<br>　　同样，我们可以推出，在\(1-\delta\)概率下：<br>$$\epsilon(\hat{h}) \leq \epsilon(h^{*}) + O\left(\sqrt{\frac{d}{m} log \frac{m}{d} + \frac{1}{m} log \frac{1}{\delta}}\right)$$<br>　　换句话说，如果某个假设空间有有限的VC维，那么当m变大的时候，一致收敛会发生。<br>　　进而得出m大小的推论，对于给定的\(\gamma,\delta&gt;0\),在\(1-\delta\)概率下保证\(\epsilon(\hat{h}) \leq \epsilon(h^{*})+2\gamma\)，则:<br>$$m=O_{\gamma,\delta}(d)$$<br>　　最后得出结论，对于一个目标是使训练误差最小的算法而言，需要的样本数量和假设空间的VC维大小呈线性关系，实际上VC维可以理解为假设空间参数的数目,即对大多数模型而言，VC维和模型参数的数目呈正比关系。</p>
<h2 id="拓展：VC维解释SVM"><a href="#拓展：VC维解释SVM" class="headerlink" title="拓展：VC维解释SVM"></a>拓展：VC维解释SVM</h2><p>　　根据上一篇文章我们知道，SVM通过核函数将数据映射到高维空间，模型复杂度增加，那么相应的，其VC维应该变大，要达到较好的效果所需的数据应该增大才对。但SVM只在原数据上就达到了比其他模型更优的结果，为什么呢？<br>　　虽然SVM将数据映射到高维空间，但是其仍然有最大间隔分类器的假设，而对于最大间隔分类器来说，<strong>其VC维并不依赖X的维度</strong>.对于最小间隔为\(\gamma\)的分类器而言，令\(||x^{(i)}||_2 \leq R\),即采样点在半径为R的圆内。那么:<br>$$VC(H) \leq \left \lceil \frac{R^2}{4\gamma^2} \right\rceil + 1$$<br>　　SVM算法会自动寻找一个具有较小VC维的假设，这样反而降低了VC维，使得原来的数据量就相对足够充分(\(m \propto O(d)\))，因此不影响模型的效果。</p>
<h1 id="ERM的直观意义"><a href="#ERM的直观意义" class="headerlink" title="ERM的直观意义"></a>ERM的直观意义</h1><p>　　ERM即经验风险最小化，有公式：<br>$$\hat{\epsilon}(h)=\frac{1}{m} \sum_{i=1}^m I\{h(x^{(i)}) \not= y^{(i)}\}$$<br>　　我们以单个样本为例，其误差函数为\(I\{h(x^{(i)}) \not= y^{(i)}\}\),很显然，这是一个非凸函数，使用机器学习的方法并不能很好的对其进行优化。因而产生了一些算法对该误差函数进行凸性近似，以期能够更好的优化，以svm和logistic为例，如图2所示：<br><img src="/picture/machine-learning/theory3.jpg" alt="theory"><br>　　如上图，logistic模型采用极大似然估计方法，它尝试令负的对数似然最小，即，\(-log P(y^{(i)}|x^{(i)};\theta)\),因而如图2中的曲线所示。SVM使用的是大间隔概念，即不仅仅考虑\(\theta^T x\)大于0,更严格的跟1或者-1比较。可以根据下图理解：<br><img src="/picture/machine-learning/theory4.jpg" alt="theory"><br>　　上图可以令负样本的\(y^{(i)}=-1\),这样就可以利用函数间隔概念统一化。<br>　　因此虽然logistic和svm都不是直接的ERM算法，但基于对ERM的近似而产生，因而可见，ERM的一致性定理在实际中的威力。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/" target="_blank" rel="external">VC维的来龙去脉</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文与前面不同，主要内容不是算法，而是机器学习的另一部分内容——学习理论。主要包括偏差/方差(Bias/Variance)、经验风险最小化(Empirical Risk Minimization,ERM)、联合界(Union bound)、一致收敛(Uniform Convergence)。&lt;/p&gt;
&lt;h1 id=&quot;偏差-方差权衡&quot;&gt;&lt;a href=&quot;#偏差-方差权衡&quot; class=&quot;headerlink&quot; title=&quot;偏差/方差权衡&quot;&gt;&lt;/a&gt;偏差/方差权衡&lt;/h1&gt;&lt;p&gt;　　回顾一下，当我们讨论线性回归时，我们尝试过使用简单的线性方法，如\(y=\theta_0 + \theta_1 x\),也尝试使用更复杂的模型，如多项式\(y=\theta_0+\theta_1 x+…+\theta_5 x^5\)。观察下图：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/theory1.jpg&quot; alt=&quot;theory&quot;&gt;&lt;br&gt;　　以上述回归问题为例，机器学习的目标是从训练集中得到一个模型，使之能对测试集进行分类。这里训练集和测试集都是分布\(\mathcal{D}\)的样本。机器学习的关注点在于模型在测试集上的分类效果，这也称作泛化能力(generalization ability)。如上图，最左边的图用一个线性模型进行拟合，显然即使拥有很多的训练集，该模型在测试集上进行预测的话，仍然存在着很大的误差，这种情况称为欠拟合，对应着高偏差。对于最右边的图，用一个高阶(五阶)去拟合，从数据中得到的模型结构很可能碰巧是该训练集特有的，即尽管五次多项式模型对训练集的拟合不错，但并非是一个好的模型，因为对于训练集以外的数据，该模型不一定能很好得进行预测，即泛化能力不够好，因此仍然存在着很大的泛化误差，这种情况称作过拟合，对应高方差。&lt;br&gt;　　在机器学习中，对偏差和方差的权衡是学习理论重点解决的问题。如果我们的模型太过于简单，只有少量的参数要学习，那么就可能存在高偏差(large bias but small variance)。如果我们的模型太过于复杂，拥有大量的参数，那么就可能存在高方差(large variance but small bias)。在上面的例子中，训练一个二次型的模型(对应中间那幅图)，比训练一个过于简单的一次型模型或过于复杂的五次型模型都好。　　&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="经验风险最小化" scheme="xtf615.com/tags/%E7%BB%8F%E9%AA%8C%E9%A3%8E%E9%99%A9%E6%9C%80%E5%B0%8F%E5%8C%96/"/>
    
      <category term="方差" scheme="xtf615.com/tags/%E6%96%B9%E5%B7%AE/"/>
    
      <category term="偏差" scheme="xtf615.com/tags/%E5%81%8F%E5%B7%AE/"/>
    
  </entry>
  
  <entry>
    <title>SVM支持向量机</title>
    <link href="xtf615.com/2017/03/28/SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <id>xtf615.com/2017/03/28/SVM支持向量机/</id>
    <published>2017-03-28T00:26:31.000Z</published>
    <updated>2017-07-09T01:55:48.554Z</updated>
    
    <content type="html"><![CDATA[<p>　　本文将介绍SVM(Support Vector Machine)学习算法。SVM是现有的最强大的监督学习算法。我们首先讨论什么是间隔以及使用最大间隔来分类数据的思想。接着讨论最优间隔分类器，这里面会涉及拉格朗日对偶问题。我们也会讨论关于核方法以及如何有效地应用核方法到高维特征空间。最后我们会讨论SMO算法，它是SVM的一种实现方法。</p>
<h1 id="间隔的直观理解"><a href="#间隔的直观理解" class="headerlink" title="间隔的直观理解"></a>间隔的直观理解</h1><p>　　要理解支持向量机，首先必须先了解间隔以及关于预测置信度的概念。考虑一下逻辑回归，模型是\(h_\theta(x)=g(\theta^Tx)\),当且仅当\(h_\theta(x) \geq 0.5\),也即\(\theta^Tx \geq 0\)时，我们预测结果为1。考虑一个正例样本，显然\(\theta^Tx\)的值越大，\(h_\theta(x)=p(y=1|x;w;b)\)的值也越大，则预测样本label为1的置信程度也越高。更正式的，当\(\theta^Tx \gg 0\)时，可以认为我们的预测样本label为1的置信程度很高，同样，当\(\theta^Tx \ll 0\)时,可以认为我们的预测样本label为0的置信程度很高。给定一个训练集，如果我们能够在标签为1的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \gg 0\)，那么这样拟合的效果就很好。同样，在标签为0的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \ll 0\)。这样的拟合效果能够体现出分类器对于样本分类的置信程度很高。后面我们会使用函数间隔来形式化该思想。<br><a id="more"></a><br>　　我们可以换一种方式来理解。考虑下图，X代表正例，O代表反例，判定边界或称作分离超平面(separating hyperplane)将正反例分开，边界上，我们有\(\theta^T X = 0\)。考虑三个点A,B,C。<br><img src="/picture/machine-learning/svm1.jpg" alt="svm"><br>如上图所示，A点离判定边界很远。如果要预测A点的y值,显然可以很自信的预测y=1. 相反，C点离判定边界很近，尽管目前看我们可以判定C点y=1，但是如果我们对判定稍微移动一点，就很容易导致C点跑到另一侧y=0。因此可以说对A点预测的置信程度是高于C点的。B点介于两种情况之间。更通用的，对于离分离超平面远的点，我们可以对我们的预测结果很自信。因此，对于给定的训练集，我们希望找到一个判定边界，能够使得对于所有的样本都分类正确并且置信程度高，这也就意味着样本点要离判定边界远一点。后面我们会使用几何间隔来形式化该思想。</p>
<h1 id="符号变化"><a href="#符号变化" class="headerlink" title="符号变化"></a>符号变化</h1><p>　　为了使SVMs的讨论更加容易，我们需要对以前习惯的符号进行略微修正。我们首先考虑二分类线性分类器。对于标签y，我们现在不使用\(y \in \{0,1\}\),而使用\(y \in \{-1,1\}\)。对于线性分类器的参数，我们不使用向量\(\theta\),而使用参数\(w,b\)来表示：<br>$$h_{w,b}(x)=g(w^T x + b)$$<br>因此当\(z \geq 0\)时，g(z)=1, 当\(z&lt;0\)时，g(z)=-1。新的标志可以使得我们将截距项b和其他参数分开讨论。我们不再使用之前的\(x_0=1\), b相当于之前的\(\theta_0\),\(w\)相当于之前的\([\theta_1,\theta_2,…,\theta_n]^T\)<br>　　根据上文g的定义，我们的分类器会直接预测样本为1或者-1，而不是像逻辑回归那样先预测样本类别如果为1的概率，再根据概率大小确定样本类别。</p>
<h1 id="函数间隔和几何间隔"><a href="#函数间隔和几何间隔" class="headerlink" title="函数间隔和几何间隔"></a>函数间隔和几何间隔</h1><h2 id="函数间隔"><a href="#函数间隔" class="headerlink" title="函数间隔"></a>函数间隔</h2><p>　　对于一个给定的训练样本\((x^{(i)},y^{(i)})\), 我们定义该样本到w,b确定的分离超平面的函数间隔为：<br>$$\hat{\gamma}^{(i)}=y^{(i)}(w^T x + b)$$<br>　　注意为了使得预测更准确并且置信度更高，函数间隔越大越好。当\(y^{(i)}=1\)时,即\(w^T x + b\)在正方向越大越好。当当\(y^{(i)}=-1\)时,即\(w^T x + b\)在负方向越大越好。归纳起来，当\(y^{(i)}(w^T x + b)&gt;0\)时，我们对该样本的预测结果就是正确的。而最大函数间隔可以代表我们的预测结果是正确并且置信度高。<br>　　对于一个线性分类器, 在我们选择的g函数的基础上(取值为-1和1)，函数间隔的问题在于，只要成倍增大\(w,b\)，\(g(w^Tx+b)=g(2w^Tx+2b)\)，这不会改变\(h_{w,b}\)的值，因为\(h_{w,b}\)的值只取决于其符号，即正负性，而不取决于\(w^T x + b\)的数量级。但是我们发现函数间隔却变大了2倍。这意味着，放大\(w,b\),会使得函数间隔任意大，但是却对模型的改进没有任何帮助。我们可以引入正则化条件，例如规定\(||w||_2=1\)，即二阶范式的值。然后将\((w,b)\)替换成，\((\frac{w}{||w||_2},\frac{b}{||w||_2})\).<br>　　对于给定的训练集\(S=\{(x^{(i)},y^{(i)});i=1,…,m\}\),我们定义训练集S相对于\((w,b)\)决定的分离超平面的函数间隔为，每个样本相对于分离超平面函数间隔中的最小的那个值。即：<br>$$\hat{\gamma}=\min_\limits{i=1,…,m} \hat{\gamma}^{(i)}$$</p>
<h2 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a>几何间隔</h2><p><img src="/picture/machine-learning/svm2.jpg" alt="svm"><br>　　如上图，\((w,b)\)决定了分离超平面。可以证明\(w\)就是分离超平面的法向量。证明如下，考虑在分离超平面上取两点，\(x^{\\’}和x^{\\’’}\)<br>，则\(w^Tx^{\\’}+b=0\),\(w^Tx^{\\’’}+b=0\),两式相减有：<br>$$w^T(x^{\\’}-x^{\\’’})=0$$<br>因为\(x^{\\’}-x^{\\’’}\)是超平面上的向量，则根据垂直向量乘积为0，可以得到\(w\)就是分离超平面的法向量。<br>　　考虑点Ａ，Ａ代表了某个输入样本\(x^{(i)}\)且标签\(y^{(i)}=1\),设它到分离超平面的距离为\(\gamma^{(i)}\),就是图中AB代表的线段。<br>　　如何求\(\gamma^{(i)}\)的值呢？因为\(\frac{w}{||w||}\)代表和法向量同方向的单位向量，A点为\(x^{(i)}\),设B点位\(x^{(j)}\),BA和法向量同方向。则:<br>$$x^{(i)}-x^{(j)}=\gamma^{(i)}\frac{w}{||w||}$$<br>得出B点为：<br>$$x^{(j)}=x^{(i)}-\gamma^{(i)}\frac{w}{||w||}$$<br>因为B点位于分离超平面上，则：<br>$$w^T\left(x^{(i)}-\gamma^{(i)}\frac{w}{||w||}\right)+b=0$$<br>解的：<br>$$\gamma^{(i)}=\frac{w^Tx^{(i)}+b}{||w||}=\left(\frac{w}{||w||}\right)^T x^{(i)}+\frac{b}{||w||}$$<br>　　上面的结果是针对正样本，对于负样本，结果是一样的。<br>　　更通用的，我们定义某个训练样本\(x^{(i)},y^{(i)})\)相对于由\((w,b)\)决定的分离超平面的几何间隔为：<br>$$\gamma^{(i)}=y^{(i)}\left(\left(\frac{w}{||w||}\right)^T x^{(i)}+\frac{b}{||w||}\right)$$<br>注意到，如果\(||w||=1\),函数间隔等于几何间隔。这也是两种间隔之间的联系。几何间隔不受参数量级的影响，如果同时成倍放大w和b，几何间隔不会改变。正因为如此，在使用训练集拟合w和b的时候，我们可以施加任意的放大缩小约束条件，例如，可以限制\(||w||=1\)或者\(||w_1||=5\),或者\(||w_1+b||+|w_2|=2\),所有的这些可以通过重新调整w和b来恢复。<br>　　对于给定的训练集\(S=\{(x^{(i)},y^{(i)});i=1,…,m\}\),我们定义训练集S相对于\((w,b)\)决定的分离超平面的几何间隔为，每个样本相对于分离超平面几何间隔中的最小的那个值。即：<br>$$\gamma=\min_\limits{i=1,…,m} \gamma^{(i)}$$</p>
<h1 id="最优间隔分类器"><a href="#最优间隔分类器" class="headerlink" title="最优间隔分类器"></a>最优间隔分类器</h1><p>　　对于给定的训练集，根据前面的讨论，我们很自然的希望能够找到一个分离超平面使得几何间隔最大化，只有这样，对于预测结果我们的置信度才足够高，样本拟合的结果才足够好。<br>　　开始前，我们要强调下，本文所讨论的内容仍然是假设数据集市线性可分的。我们可以写出如下的优化问题：<br>$$\max_{\gamma,w,b} \gamma \\\\<br>使得，y^{(i)}(w^T x^{(i)} + b) \geq \gamma,　　i=1,2,…,m \\\\<br>||w||=1<br>$$<br>　　我们要最大化\(\gamma\)，使得每一个训练样本的函数间隔都至少为\(\gamma\)。\(||w||=1\)约束保证了函数间隔等于几何间隔。也即，我们保证了每一个训练样本的几何间隔都至少为\(\gamma\)。因此，解决该优化问题的方法就是不断调整\((w,b)\)，来最大化几何间隔。<br>　　但是||w||=1的约束条件是非凸性约束，最优解容易陷入局部最优，因此我们无法使用现成的标准优化方法来解该优化问题。我们尝试修改该优化问题，考虑如下：<br>$$\max_{\gamma,w,b} \frac{\hat{\gamma}}{||w||} \\\\<br>使得，y^{(i)}(w^T x^{(i)} + b) \geq \hat{\gamma},　　i=1,…,m<br>$$<br>　　我们尝试最大化几何间隔\(\frac{\hat{\gamma}}{||w||}\),使得每个样本的函数间隔都至少为\(\hat{\gamma}\)。几何间隔和函数间隔通过\(\gamma=\frac{\hat{\gamma}}{||w||}\)来联系。我们去掉了非凸约束||w||。我们通过将非凸约束转移到目标函数上，从而使得问题变成了非凸性问题。该问题目前仍然无法用标准通用方法解决。<br>　　对于上式，我们还可以再做一次变换。我们知道，等比例对\(w,b\)进行缩放，不会改变分离超平面的位置，假设已经得到了\(w,b\)，那么就能求得\(\hat{\gamma}\)的值，那么我们可以通过缩放w,b(同时除以\(\hat{\gamma}\)),使得\(\hat{\gamma}\)变为1.这样得到的分离超平面与最开始就将\(\hat{\gamma}\)设为1是一样的。因此优化问题可以改写成：<br>$$\max_{\gamma,w,b} \frac{1}{||w||}$$<br>也即：（加上1/2系数是为了使结果更漂亮）<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2 \\\\<br>使得, y^{(i)}(w^T x^{(i)} + b) \geq 1, 　　i=1,…,m<br>$$<br>　　上述问题已经转换成凸性问题了，约束条件只有线性约束。该优化问题的结果就是最优间隔分类器。为了更好解决该问题，需要使用它的对偶问题，下面首先介绍拉格朗日对偶性。</p>
<h2 id="拉格朗日对偶性"><a href="#拉格朗日对偶性" class="headerlink" title="拉格朗日对偶性"></a>拉格朗日对偶性</h2><p>　　下面回顾一下线性约束优化问题。如下形式：<br>$$\min_w f(w) \\\\<br>使得， h_i(w)=0,　　i=1,…,l<br>$$<br>　　我们使用拉格朗日乘子(Lagrange multipliers)，拉格朗日方程如下：<br>$$L(w,\beta)=f(w)+\sum_{i=1}^l \beta_i h_i(w)$$<br>　　这里，\(\beta_i\)称作拉格朗日乘子，我们对其求偏导数并设为0.求得的值就是原问题的解了。<br>$$\frac{\partial L}{\partial w_i}=0; \frac{\partial L}{\partial \beta_i}=0$$<br>　　至于为什么引入拉格朗日算子可以求出极值，原因是f(w)的方向导数dw受等式的约束，dw的变化方向与f(w)的梯度度垂直时才能获得极值，而且在极值处，f(w)的梯度与其他等式梯度的线性组合平行，因此他们之间存在线性关系。<br>　　上述问题对应的是等式约束条件，我们需要将其扩展为不等式约束条件。考虑如下原始优化问题(primal optimization problem):<br>$$\min_w f(w) \\\\<br>使得， g_i(w) \leq 0,　　i=1,…,k \\\\<br>h_i(w)=0,　　i=1,…,l<br>$$<br>　　我们定义通用的拉格朗日方程(generalized Lagrangian)：<br>$$L(w,\alpha,\beta)=f(w)+\sum_{i=1}^k \alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w)$$<br>\(\alpha_i和\beta_i\)是拉格朗日乘子。考虑如下等式:<br>$$\theta_p(w)=\max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta)$$<br>  　这里的下标p代表原始Primal。对于某些给定的\(w\)，如果w不符合约束条件，例如当某个\(g_i(w)&gt;0\)时，我们可以使得和该\(g_i(w)&gt;0\)相乘的乘子\(\alpha_i\)趋向于正无穷，则\(\theta_p(w)\)也趋向于正无穷；同样，当\(h_i(w) \neq 0\)时，根据\(h_i(w)\)的正负性，选择相应的\(\beta_i\)趋向于正无穷或负无穷，则\(\theta_p(w)\)也趋向于正无穷。因此对于不满足约束条件时，上述问题结果是：<br>  $$\theta_p(w)=\max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) \\\\<br>  =f(w)+\sum_{i=1}^k \alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w) \\\\<br>  =\infty$$<br>  　　相反，如果约束条件满足的话，对于给定的\(w\)，我们有,\(\theta_p(w)=f(w)\),这里的关键是我们的\(\alpha_i \geq 0且g_i(w) \leq 0\), 则\(\sum_{i=1}^k \alpha_i g_i(w) \leq 0\)，那么为了最大化\(\theta_p(w)\),有\(\sum_{i=1}^k \alpha_i g_i(w)=0\)。<br>  　　因此，我们有：<br>  $$<br>\begin{eqnarray} \theta_p(w)=\begin{cases} f(w),　　if \ w \ satisfies \ primal \ constraints \cr \infty,　　otherwise. \end{cases} \end{eqnarray}<br>  $$<br>　　因而，我们可以认为\(\theta_p(w)\)即使将约束条件与目标函数融合在一起的表达方法，考虑最小化问题，我们得到了如下公式：<br>$$\min_w \theta_p(w) = \min_w \max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) 　　　　　　　　　　　(1)$$<br>　　因为,\(\theta_p(w)\)在满足约束条件下等价于\(f(w)\)问题，则\(\min_w \theta_p(w)\)问题等价于我们最初的原始优化问题(primal problem) \(\min_w f(w)\)。<br>　　我们定义\(p^{*}\)为原始问题取得最优解时的函数值，也即:<br>$$p^{*} = \min_w \theta_p(w)$$<br>　　接着定义：<br>$$\theta_D(\alpha,\beta)=\min_w L(w,\alpha,\beta)$$<br>　　上式中的下标D代表对偶(dual)。注意，\(\theta_p(w)\)优化的参数是\(\alpha,\beta\)，而这里\(\theta_D\)优化的参数是w.<br>　　我们可以得到对偶问题：<br>$$\max_{\alpha,\beta:\alpha_i \geq 0} \theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i \geq 0} \min_w L(w,\alpha,\beta)　　　　　　　　　　(2)$$<br>　　该式就是我们原始问题的对偶形式，我们对比(1)和(2)发现：两个式子很相似，只是max和min位置调换了。<br>　　我们定义对偶问题的最优解为:<br>$$d^{*}=\max_{\alpha,\beta:\alpha_i \geq 0} \theta_D(w)$$<br>　　对偶问题和原始问题的关联如下：<br>$$d^{*}=\max_{\alpha,\beta:\alpha_i \geq 0} \min_w L(w,\alpha,\beta) \leq \min_w \max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) = p^{*}$$<br>　　可以证明,对于任意函数,max min的结果总是小于等于min max。在特定条件下, 我们有：<br>$$d^{*}=p^{*}$$<br>　　这些特定的条件包括，约束不等式\(g_i\)都是凸函数(线性函数都属于凸函数);约束\(h_i\)都是仿射函数(其实就是在线性函数基础上加上截距b);不等式\(g_i(w)\)约束条件严格可行,即对于任意的i,存在w,使得\(g_i(w)&lt;0\)<br>　　在这些假设下，肯定存在\(w^{*},\alpha^{*},\beta^{*}\),使得\(w^{*}\)是原始问题的解，\(\alpha^{*},\beta^{*}\)是对偶问题的解,且\(p^{*}=d^{*}=L(w^{*},\alpha^{*},\beta^{*})\),这样的\(w^{*},\alpha^{*},\beta^{*}\)需要满足KKT(Karush-Kuhn-Tucker)条件，KKT条件如下：<br>$$\frac{\partial}{\partial w_i}L(w^{*},\alpha^{*},\beta^{*})=0,　i=1,…,n \\\\<br>\frac{\partial}{\partial \beta_i}L(w^{*},\alpha^{*},\beta^{*})=0,　i=1,…,l \\\\<br>\alpha_i^{*}g_i(w^{*})=0,　i=1,…,k \\\\<br>g_i(w^{*}) \leq 0,　i=1,…,k \\\\<br>\alpha^{*} \geq 0,　i=1,…,k<br>$$<br>注意第3个式子，特别的:<br>$$当\alpha_i^{*}大于0时,g_i(w^{*})=0$$<br>我们称之为KKT互补条件。也就是说，\(g_i(w^{*})=0\)时，w处于可行域的边界上，这时才是起作用的约束，其他位于可行域内内部(\(g_i(w^{*})小于0\)的点都是不起作用的约束,其\(\alpha_i^{*}=0\))。KKT的总体思想是将极值会在可行域边界上取得，也就是不等式为0或等式约束里取得，而最优下降方向一般是这些等式的线性组合，其中每个元素要么是不等式为0的约束，要么是等式约束。对于在可行域边界内的点，对最优解不起作用，因此前面的系数为0。这个条件比较重要，在后文中，它将展示SVM只有一些支持向量点会起作用，在SMO算法中会给出收敛测试。</p>
<h2 id="最优间隔分类器求解"><a href="#最优间隔分类器求解" class="headerlink" title="最优间隔分类器求解"></a>最优间隔分类器求解</h2><p>　　上面讲述的原始／对偶优化问题(primal/dual optimal problem)，其目的在于对原始问题上不易求解的问题进行转换，使之更易求解。下面介绍通过对最优间隔分类器的对偶问题进行求解，得到的简化后的问题的过程。之前我们的优化问题是：<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2 \\\ 使得, y^{(i)}(w^T x^{(i)} + b) \geq 1, 　　i=1,…,m$$<br>　　我们将约束条件改写成:<br>$$g_i(w)=-y^{(i)}(w^T x^{(i)} + b)+1 \leq 0$$<br>　　该约束条件对每个样本都成立，根据KKT对偶互补条件，对于函数间隔为1(即满足约束g_i(w)=0)的样本点，我们有\(\alpha_i &gt; 0\)<br>　　考虑下图，最大间隔分离超平面是图中的实线。<br><img src="/picture/machine-learning/svm3.jpg" alt="svm"><br>　　最小间隔的点是那些靠近分离超平面的点，这里有3个这样的点，位于图中虚线处，1个负样本，2个正样本，因此只有该3个点对应的\(\alpha_i\)非零。这3个点叫做该问题的支持向量，意味着在求解问题时，使用到的支持向量数比样本大小少的多。<br>　　上述问题对应的拉格朗日方程是：<br>$$L(w,b,\alpha)=\frac{1}{2}{||w||}^2-\sum_{i=1}^m \alpha_i[y^{(i)}(w^T x^{(i)}+b)-1]$$<br>　　我们的问题只有不等式约束，没有等式约束，故拉格朗日乘子只有\(\alpha\)。并且该问题符合\(d^{*}=p^{*}\)的假设，肯定存在\(w^{*},\alpha^{*},\beta^{*}\)使得原始问题和对偶问题共用最优解。<br>　　求解对偶问题时，首先要固定\(\alpha\),以w,b为变量，最小化L；最小化L时，求解L对w和b的偏导，并将导数设为0，可以得到：<br>$$\nabla_w L(w,b,\alpha)=w-\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}=0$$<br>得到:<br>$$w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}$$<br>对b求偏导，得到：<br>$$\frac{\partial}{\partial b}(w,b,\alpha)=\sum_{i=1}^m \alpha_i y^{(i)}=0$$<br>我们将上式代入拉格朗日方程得到：<br>$$L(w,b,\alpha)=\frac{1}{2}{||w||}^2-\sum_{i=1}^m \alpha_i[y^{(i)}(w^T x^{(i)}+b)-1] \\\\<br>= \frac{1}{2}w^T w-\sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)}-\sum_{i=1}^m \alpha_i y^{(i)} b + \sum_{i=1}^m \alpha_i \\\\<br>= \frac{1}{2}w^T \sum_{i=1}^m \alpha_i y^{(i)}x^{(i)} - \sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)} + \sum_{i=1}^m \alpha_i \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)} \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \alpha_i y^{(i)} \left(\sum_{j=1}^m \alpha_j y^{(j)} (x^{(j)})^T \right)x^{(i)} \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j y^{(i)} y^{(j)} (x^{(j)})^T x^{(i)} \\\\<br>=\sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j (x^{(j)})^T x^{(i)}<br>$$<br>得到如下对偶优化问题：<br>$$<br>\max_{\alpha} W(\alpha) = \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j ＜x^{(i)},x^{(j)}＞ \\\\<br>使得， \alpha_i \geq 0,　　i=1,…,m \\\\<br>\sum_{i=1}^m \alpha_i y^{(i)} = 0<br>$$<br>　　\(＜x^{(i)},x^{(j)}＞\)代表向量的内积,该式子可以当作一个整体，在后续核技巧中发挥重要作用。<br>　　上式第一步为原问题，第二部将累加和展开，第三步代入w和b求导并设置为0后的结果，第四步合并系数，第五步代入w求导结果。<br>　　再强调一次，该问题符合\(d^{*}=p^{*}\)的假设和KKT条件。因此我们可以求解对偶优化问题，从而求得原始优化问题。上述对偶优化问题求解的参数只有\(\alpha_i\)。如果我们能够求解使得对偶问题最大化的\(\alpha\), 我们就可以通过\(w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\)推出原始优化问题的\(w\).如果找到了\(w^{*}\),可以得到截距b的值：<br>$$b^{*}=-\frac{\max_{i:y^{(i)}=-1} {w^{*}}^T x^{(i)} + \min_{i:y^{(i)}=1} {w^{*}}^T x^{(i)}}{2}$$<br>　　上式是在确定\(w^{*}\)后，正例和负例的支持向量所对应的截距的平均值，为了更直观的理解，考虑下图：<br><img src="/picture/machine-learning/svm3.jpg" alt="svm"><br>　　上式即是两条虚线与纵轴的截距的平均值。也可以理解为离超平面最近的正的函数间隔要等于离超平面最近的负的函数间隔，可以将分母2乘到b，再整理式子：<br>$$(\max_{i:y^{(i)}=-1} {w^{*}}^T x^{(i)}+b^{*}) + (\min_{i:y^{(i)}=1} {w^{*}}^T x^{(i)}+b^{*})=0$$<br>　　可以理解为二者函数间隔互为相反数，抵消了。<br>　　我们进一步考察一下式子\(w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\)，假设我们已经找到了优化问题的最优解，现在需要对新样本ｘ作出预测,我们可以通过计算\(w^T x+b\)来判断，大于等于0则预测y=1,否则y=0.但是使用上述式子，我们有：<br>$$w^T x+b=\left(\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\right)^T x + b \\\\<br>=\sum_{i=1}^m \alpha_i y^{(i)}＜x^{(i)},x＞+b$$<br>　　根据上式，如果我们求得了\(\alpha_i\)，为了对新样本做出预测，我们可以只计算x和每一个训练样本的内积。更进一步，前面我们讨论过，只有在支持向量处，\(\alpha_i\)才非零，因此我们只需要计算新样本和每一个支持向量之间的内积，这样计算数据量就少了很多。相当于只有这些支持向量为目标函数的计算做出贡献。<br>　　下文将引入核技巧到目标函数中，从而得到完全的支持向量机算法，然后介绍SMO序列最小化算法，该算法是优化问题的一种较快的解决方法。</p>
<h1 id="核Kernels"><a href="#核Kernels" class="headerlink" title="核Kernels"></a>核Kernels</h1><p>　　上文中，我们的对偶最优问题中都会出现内积的形式，本部分将介绍可以使用核来替代内积，一定程度上可以解决非线性可分的问题。</p>
<h2 id="核函数的理解"><a href="#核函数的理解" class="headerlink" title="核函数的理解"></a>核函数的理解</h2><p>　　核函数！＝内积！＝映射！＝相似度，核函数是一种表征映射、实现内积逻辑关系且降低计算复杂度的一类特殊函数。(满足Mercer’s condition)。简单来说，核函数只是用来计算映射到高维空间滞后的内积的一种简便方法。<br>　　一般英文文献中对Kernel有两种提法，意识Kernel Function,二是Kernel Trick。从Trick一词可以看出，这只是一种运算技巧，不涉及高深莫测的东西。具体巧在哪里，我们如果想进行原本线性不可分的数据集的分割，那么一种方法是引入Soft Margin来容忍一些错误；另一种方法是对输入空间(Input Space)做特征扩展(Feature Expansion)，把数据集映射到高维中去，形成了特征空间(Feature Space)。我们几乎可以认为原本在低维中线性不可分的数据集在足够高的维度中存在线性可分的超平面。<br>　　对于第二种方法，我们所做的就是在特征空间中，使用原本在线性可分的情况下的优化方法，来找到最优分离超平面，唯一不同的是代入数据不同，我们需要代入得是\(\phi_(x_i)\),而不是\(x_i\)，\(\phi_(x_i)\)才是真正的从低维空间到高维空间的映射。考虑我们前面的优化式子，存在着一步内积计算。也即必须求出\(\phi_(x_i)^T \phi_(x_j)\),我们定义核函数为\(K(x_i,x_j)=\phi_(x_i)^T \phi_(x_j)\),使得我们不需要显示的计算每一个\(\phi_(x_i)\),甚至不需要知道\(\phi(\dot)\)长什么样，就可以直接求出\(\phi_(x_i)^T \phi_(x_j)\)的值，同时也能够大幅度提高计算速度和效率。<br>　　另外需要强调的一点是，kernel是一个独立的概念，kernel在SVM中的应用只是冰山一角，kernel的应用非常广泛，甚至出现的比SVM还早。</p>
<h2 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h2><p>　　首先让我们回顾一下线性回归中房价预测的例子，我们曾尝试对变量居住面积Ｘ进行处理以获得三次型函数。即使用特征\(x,x^2,x^3\)。为了区别这两种形式的变量，我们称原始输入为输入属性(attributes)，映射之后的输入称为输入特征(features)。我们记\(\phi\)为特征映射(feature mappping)，即从属性到特征的映射。在上面例子中，我们有:<br>$$\phi(x)=\begin{bmatrix}x \\\ x^2 \\\ x^3 \end{bmatrix}$$<br>　　我们现在不使用原始的属性ｘ,而使用映射后的特征\(\phi(x)\).我们将之前的对偶优化问题使用\(\phi(x)\)来替换\(x\)。因为我们的对偶优化问题有内积的形式存在，意味着我们可以使用\(＜\phi(x),\phi(z)＞\)来替换\(＜x,z＞\)。对于给定的映射\(\phi\),我们定义相应的核为：<br>$$K(x,z)=\phi(x)^T \phi(Z)$$<br>　　这样，对于出现\(＜x,z＞\)的地方，我们可以使用\(K(x,z)\)来替换，这样我们的算法就是使用特征\(\phi\)得到的,而不是原始的属性。这样的处理可以使数据线性可分的概率变大，即不能保证在高维上一定是线性可分的，但一般情况下高维空间比低维空间上更倾向于线性可分。<br>　　但通常通过\(\phi\)映射后的向量维度过高，导致映射后向量内积的计算复杂度过高，核函数的引入就是为了解决这个问题，它既可以使得我们不需要显示定义出映射函数就能计算两个向量在高维空间的内积了，又使得时间复杂度降低。<br>　　下面介绍一个核函数的例子，假设\(x,z \in {\mathbb{R}}^n\)，考虑如下核函数：<br>$$K(x,z)=(x^T z)^2$$<br>　　重写为：<br>$$K(x,z)=\left(\sum_{i=1}^n x_i z_i \right) \left(\sum_{j=1}^n x_i z_i \right) \\\ <br>= \sum_{i=1}^n \sum_{j=1}^n x_i x_j z_i z_j \\\\<br>= \sum_{i,j=1}^n (x_i x_j) (z_i z_j)<br>$$　　<br>因为\(K(x,z)=\phi(x)^T \phi(Z)\), 则相应的映射为：<br>$$\phi(x)=\begin{bmatrix} x_1 x_1 \\\ x_1 x_2 \\\ … \\\ x_n x_n\end{bmatrix}<br>$$<br>因此计算\(\phi(x)\)需要\(O(n^2)\)时间复杂度(内外两层循环计算乘积)。而计算\(K(x,z)\)只需要\(O(n)\)时间复杂度(一层循环计算\(\sum_{i=1}^n x_i z_i\),再对结果平方即可)。<br>　　一个相似的核函数如下：<br>$$K(x,z)=(x^T z+c)^2 \\\\<br>=\sum_{i,j=1}^n (x_i x_j)(z_i z_j) + \sum_{i=1}^n (\sqrt{2c}x_i)(\sqrt{2c}z_i) + c^2$$<br>　　对应的映射如下：<br>$$\phi(x)=\begin{bmatrix} x_1 x_1 \\\ x_1 x_2 \\\ … \\\ x_n x_n \\\ \sqrt{2c}x_1 \\\ … \\\  \sqrt{2c}x_n \\\ c \end{bmatrix}$$<br>　　一个更一般化的核函数如下：<br>$$K(x,z)=(x^T z+c)^d$$<br>　　该核函数对应的映射函数结果是一个\(\binom{n+d}{n}\)(组合符号)大小的向量，向量中每个向量都是最高为d阶的变量的组合。<br>　　对于上面的这些核函数，虽然它们对应的映射函数的维度可能是\(n^2,n^4\)等，意味着直接计算映射结果的内积的复杂度为\(O(n^2),O(n^4)\)。但是如果直接计算核函数的值，其复杂度均为\(O(n)\).<br>　　直观上来看，如果\(\phi(x)和\phi(z)\)在其对应的维度空间中位置接近，那么内积值K会很大(可认为同方向比较大)，如果很远则内积很小。这意味着核函数K是一个向量x和向量z接近程度的度量函数，从而引出SVM中使用较广泛的高斯核：<br>$$K(x,z)=exp\left(-\frac{ ||x-z||^2 }{2 \sigma^2}\right)$$<br>　　高斯核函数是一种度量x和z相似度的方法，如果x和y位置很接近，则K值接近1;如果很远，则k值接近0。高斯核函数对应的映射函数\(\phi\)是可以映射到无限维的。</p>
<h2 id="Mercer定理"><a href="#Mercer定理" class="headerlink" title="Mercer定理"></a>Mercer定理</h2><p>　　那么，什么样的核函数才是正确有效的核函数的？即如何判断一个函数是不是能拆分成映射函数乘积的形式？这两种表述是等价的，核函数是由映射函数乘积得到的，因而如果核函数合法，那么必然能写成两个映射函数的乘积。<br>　　我们首先定义核矩阵，对一个数据集\(\{x^{(1)},x^{(2)},…,x^{(m)}\}\),定义一个m*m的矩阵K，K中每个元素定义如下：<br>$$K_{ij}=K(x^{(i)},x^{(j)})$$<br>　　注意K既代表核函数又代表核矩阵。对于核矩阵，有几个性质，首先很显然\(K_{ij}=K_{ji}\),因此核矩阵是一个对称矩阵(symmetric matrix)。其次，对于任意的m维向量z，记\(\phi_k(x)\)为向量\(\phi(x)\)的第k个分量，我们有:<br>$$z^T K z = \sum_i \sum_j z_i K_{ij} z_j = \sum_i \sum_j z_i \phi(x^{(i)})^T \phi(x^{(j)}) z_j \\\\<br>=\sum_i \sum_j z_i \left(\sum_k \phi_k(x^{(i)}) \phi_k(x^{(j)}) \right)z_j \\\\<br>=\sum_k \sum_i \sum_j z_i \phi_k(x^{(i)}) \phi_k(x^{(j)}) z_j  \\\\<br>= \sum_k \left(\sum_i z_i \phi_k(x^{(i)})\right)^2 \geq 0<br>$$<br>　　因为z是任意向量，可以得出K是半正定矩阵，加上对称性，K是对称半正定矩阵。如果K是有效的核，可以推出K是对称半正定矩阵，同样如果K是对称半正定矩阵，可以得出K是有效核。因此我们可以归纳出一个充要条件，该定理称作Mercer定理：<br>　　给定一个K：\({\mathbb{R}}^n \times {\mathbb{R}}^n -&gt; \mathbb{R}\),那么K是有效核的充分必要条件是，对于任意一个有限数据集，对应的核矩阵式对称半正定矩阵。<br>　　对于核来说，不仅仅只存在SVM内，对于任意的算法，只要计算时出现了内积，都可以用核函数替代，从而提高在高维数据上的性能，例如感知机算法，代入后发展为核感知机算法，这也是核函数被称作核技巧的原因。</p>
<h1 id="软间隔分类器"><a href="#软间隔分类器" class="headerlink" title="软间隔分类器"></a>软间隔分类器</h1><p>　　上文提到的最优间隔分类器时，一直强调数据是线性可分的。但是，当数据线性不可分时，或者映射到高维空间后仍然线性不可分，再或者即便是线性可分的但实际应用中不可避免出现噪声时，该如何处理呢？下文使用软间隔的方式进行解决。<br><img src="/picture/machine-learning/svm4.jpg" alt="svm"><br>　　首先观察上图，左边图代表最优间隔分类器，右边图在左上角添加一个负样本，为了实现最优间隔分类器，这导致分离超平面发生了一个急剧的旋转变换，这也导致得到的新的分类器在整体上只拥有一个比原来更小的间隔。<br>　　为了使算法能够适用于非线性分类器，对一些额外的点不那么敏感，我们重新修改优化问题，加入L1正则化项：<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2+C \sum_{i=1}^m \zeta_i \\\\<br>使得, y^{(i)}(w^T x^{(i)} + b) \geq 1-\zeta_i, 　　i=1,…,m \\\\<br>\zeta_i \geq 0,　　i=1,…,m<br>$$<br>　　注意上述的正则化是指第二项\(C \sum_{i=1}^m \zeta_i\)，称作hinge loss。如果是L2正则化则为，\(C\sum_{i=1}^m \zeta_i^2\),称作squared-hinge-loss。可参考<a href="http://www.doc88.com/p-6761653257229.html" target="_blank" rel="external">A study on L2-Loss(Squared Hinge-Loss Multi-Class SVM)</a>。另外对于第一项\(\frac{1}{2}{||w||}^2\)有的时候也叫做正则化，我们上述公式的第一项就是L2正则化。为了区别，对于上式，称第一项为<strong>L2-regularized</strong>，第二项为<strong>L1-loss</strong>。可参考<a href="https://www.quora.com/Support-Vector-Machines/Liblinear-does-not-support-L1-regularized-L1-loss-hinge-loss-support-vector-classification-Why" target="_blank" rel="external">Liblinear does not support L1-regularized L1-loss ( hinge loss ) support vector classification. Why?</a>。在sklearn的LinearSVC中，L2-regularized对应参数penalty=’l2’,L1-loss对应参数loss=’hinge’。如果使用L2-loss，则loss=’squared_hinge’。<br>　　因此现在样本允许函数间隔小于1,如果一个样本的函数间隔为\(1-\zeta_i\),我们在目标函数上增加一个代价项\(C\zeta_i\). 参数C在\(||w||^2\)变大(我们之前希望其越小越好)和保证大多数样本函数间隔至少为1之间进行权衡。相当于现在放宽了约束条件，但是我们也对目标函数进行惩罚，使之更加严格。松弛因子\(\zeta\)使SVM能够容忍异常离群点的存在。惩罚因子\(C\)决定了你有多重视离群点带来的损失，显然当所有离群点的松弛变量(\(\zeta\))的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题，即C越大，你越希望在训练数据上少犯错误，而实际上这是不可能/没有意义的，于是就造成过拟合。<br>　　根据上述软间隔优化问题得到新的拉格朗日方程：<br>$$L(w,b,\zeta,\alpha,r)=\frac{1}{2}w^T w+C \sum_{i=1}^m \zeta_i - \sum_{i=1}^m \alpha_i[y^{(i)}(w^T x^{(i)}+b)-1+\zeta_i]- \sum_{i=1}^m r_i \zeta_i$$<br>　　\(\alpha_i,r_i\)是拉格朗日乘子，并且都\(\geq 0\).我们将上述改写成对偶问题的形式，具体过程不进行推导，和前文类似,得到如下对偶问题：<br>$$ \max_\alpha W(\alpha)= \sum_{i=1}^m \alpha_i - \frac{1}{2} \sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j ＜x^{(i)},x^{(j)}＞ \\\\<br>使得, 0 \leq \alpha_i \leq C,　　　i=1,…,m \\\\<br>\sum_{i=1}^m \alpha_i y^{(i)} = 0<br>$$<br>　　我们惊奇的发现，该式子和之前最优间隔分类器优化问题唯一的区别是对\(\alpha_i\)做了进一步约束。求解得到\(\alpha\)后，w仍然可以按照公式\(w=\sum_{i=1}^m \alpha_i y^{(i)} x^{(i)}\)给出，但是截距b得到方式需要变化。KKT中的互补条件也要有略微变化：<br>$$\alpha_i=0 \Longrightarrow y^{(i)}(w^T x^{(i)} + b) \geq 1 \\\\<br>\alpha_i=C \Longrightarrow y^{(i)}(w^T x^{(i)} + b) \leq 1 \\\\<br>0 &lt; \alpha_i &lt; C \Longrightarrow y^{(i)}(w^T x^{(i)} + b) = 1<br>$$<br>　　这些条件将在下一节中用于判断SMO算法是否收敛。至此，终于已经得到一个可以应用于实际的具体问题了，下面一节将对对偶问题求解进行讨论。</p>
<h1 id="SMO算法"><a href="#SMO算法" class="headerlink" title="SMO算法"></a>SMO算法</h1><p>　　SMO全称序列最小优化(sequential minimal optimization)，给出了一种解决对偶问题的有效方法。</p>
<h2 id="坐标上升法"><a href="#坐标上升法" class="headerlink" title="坐标上升法"></a>坐标上升法</h2><p>　　在介绍SMO算法前，先介绍一个简化的但与SMO使用同一思想的算法，坐标上升法(Coordinate Ascent)。<br>　　考虑如下无约束优化问题:<br>$$\max_\alpha W(\alpha_1,\alpha_2,…,\alpha_m)$$<br>　　我们认为W是关于\(\alpha_i\)参数的函数。暂且先不考虑SVM。我们已经学习过梯度上升和牛顿法，现在介绍一种新方法：<br><strong>Loop Until Convergence: {</strong><br><strong>For　i=1,2,…,m {</strong><br>        $$\alpha_i := \mathop{argmax}\limits_{\hat{\alpha_i}}W(\alpha_1,…,\alpha_{i-1}, \hat{\alpha_i},…,\alpha_n)<br>        $$<br>    　　}<br><strong>}</strong><br>　<br>　　最内层循环,当更新\(\alpha_i\)时，保持其它参数不变。在上述方法中，我们内层循环按照下标顺序遍历，在其他情况下，我们也可能根据一些规则，例如使得\(W(\alpha)\)增幅最大来选择相应的\(\alpha_i\)。如果argmax方法能够有效的执行，那么坐标上升法会是一个效率不错的算法。下图是只有二次型函数的坐标上升法：<br><img src="/picture/machine-learning/svm5.jpg" alt="svm"><br>　　上图的椭圆代表二次型函数的等高线。坐标上升法初始\(\alpha\)为(2,-2)。图中线条代表了从起始点到全局最大值经过的路径，每一步坐标上升法的收敛方法都与一个坐标轴平行，因为我们一次优化只更新一个变量，固定其余的变量。这张图只有2个参数，所以才能在二维图中展示出来。</p>
<h2 id="SMO算法-1"><a href="#SMO算法-1" class="headerlink" title="SMO算法"></a>SMO算法</h2><p>　　我们的优化问题是：<br>$$ \max_\alpha W(\alpha)= \sum_{i=1}^m \alpha_i - \frac{1}{2} \sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j ＜x^{(i)},x^{(j)}＞ \\\\<br>使得, 0 \leq \alpha_i \leq C,　　　i=1,…,m<br>\sum_{i=1}^m \alpha_i y^{(i)} = 0<br>$$<br>　　SMO算法与坐标上升法的不同地方在于，我们的对偶优化问题存在着约束\(\sum_{i=1}^m \alpha_i y^{(i)} = 0\),使得当固定其他参数而只改变一个参数的时候，发现该参数实际上是固定不变的，这样就无法进行更新。例如第一次更新\(\alpha_1\),则：<br>$$\alpha_1 y^{(1)} = - \sum_{i=2}^m \alpha_i y^{(i)}$$<br>　　两边同乘\(y^{(1)}\),即：<br>$$\alpha_1 = -y^{(1)} \sum_{i=2}^m \alpha_i y^{(i)}$$<br>　　因此，\(\alpha_1\)由其他参数唯一决定，我们就无法在不违反约束的情况下更新\(\alpha_1\).<br>　　因而SMO算法每次选择两个参数进行优化。选择参数时，使用一些启发式规则选择使全局目标函数增长最大的参数，具体：<br><img src="/picture/machine-learning/svm6.jpg" alt="svm"><br>　　假设我们在一次优化中选择\(\alpha_1,\alpha_2\)，根据约束条件，有:<br>$$\alpha_1 y^{(1)} + \alpha_2 y^{(2)} = - \sum_{i=3}^m \alpha_i y^{(i)}$$<br>　　右边式子是固定已知的(因为我们固定了其余的参数,注意这些参数一开始都有初始化的,因此上一次迭代完的参数值是已知的)。我们设右边式子为\(\zeta\):<br>$$\alpha_1 y^{(1)} + \alpha_2 y^{(2)} = \zeta$$<br><img src="/picture/machine-learning/svm7.jpg" alt="svm"><br>　　如上图，画出了该次迭代的约束直线，我们知道\(\alpha_1,\alpha_2\)一定位于\([0,C] \times [0,C]\)决定的边界以内。我们进一步得出,\(L \leq \alpha_2 \leq H\),否则\((\alpha_1,\alpha_2)\)无法同时满足在边界内核约束直线上。在这个例子中，L=0。实际上，两个参数中可以将一个当作变量，另外一个当作该变量的函数。我们重写为:<br>$$\alpha_1 = (\zeta-\alpha_2 y^{(2)})y^{(1)}$$<br>　　因此，目标函数W可以重写为：<br>$$W(\alpha_1,\alpha_2,…,\alpha_m)=W((\zeta-\alpha_2 y^{(2)})y^{(1)}, \alpha_2,…,\alpha_m)$$<br>　　将\(\alpha_3,…,\alpha_m\)当作常量，我们不难证明W是关于\(\alpha_2\)的二次函数，可以表达为\(a\alpha_2^2+b\alpha_2+c\)。加上[L,H]的约束条件，我们不难求出该二次函数最大时的\(\alpha_2\)取值。记二次函数无约束时的最优解为,\(\alpha_2^{new,unclipped}\),则有:<br><img src="/picture/machine-learning/svm8.jpg" alt="svm"><br>　　得到\(\alpha_2^{new}\)后，再使用\(\alpha_1,\alpha_2\)的关系求得\(\alpha_1^{new}\),最后在循环中进行更新。<br>　　关于选择更新参数的规则以及截距b如何求解，可以参考SMO作者Platt的论文。</p>
<h1 id="SVM的应用"><a href="#SVM的应用" class="headerlink" title="SVM的应用"></a>SVM的应用</h1><p>　　SVM作为一种分类器，在分类问题上表现惊人。比如文本分类、图像分类等。下面列举几个SVM的实际应用。<br>　　第一个例子是关于手写数字识别的问题。给定一张16*16的图片，上面写着0-9的10个数字，使用SVM判断。这本来是NN(Neural Network)比较擅长的问题，但初次用在SVM上时效果就好的惊人，因为SVM没有图片识别的先验知识，它只依据像素就能达到很好的效果。SVM上使用高斯核和多项式核都能在该问题上达到和NN相当的效果。<br>　　再比如通过氨基酸序列对蛋白质种类进行判别，假设有20种氨基酸，它们按照不同的序列组成不同的蛋白质，但是这些氨基酸序列的长度差异很大，那么该如何表示特征呢？有一种方式是使用连续4个氨基酸序列出现次数作为向量。首先求出氨基酸序列所有的排列组合\(20^4\)种，每个排列组合作为特征向量的一个特征，值是出现的次数，例如对于AABAABACDEF，可以得到AABA：2，ABAA：1，…，CDEF：1。因为特征向量的长度为\(20^4\)种,难以载入内存，但有一种高效的动态规划算法可以解决该问题。最后，再使用SVM进行建模。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/24627666/answer/28460490" target="_blank" rel="external">知乎: 核函数理解</a><br><a href="http://www.svms.org/mercer/" target="_blank" rel="external">Mercer’s Condition</a><br><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-98-14.pdf" target="_blank" rel="external">Platt, John (1998), Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　本文将介绍SVM(Support Vector Machine)学习算法。SVM是现有的最强大的监督学习算法。我们首先讨论什么是间隔以及使用最大间隔来分类数据的思想。接着讨论最优间隔分类器，这里面会涉及拉格朗日对偶问题。我们也会讨论关于核方法以及如何有效地应用核方法到高维特征空间。最后我们会讨论SMO算法，它是SVM的一种实现方法。&lt;/p&gt;
&lt;h1 id=&quot;间隔的直观理解&quot;&gt;&lt;a href=&quot;#间隔的直观理解&quot; class=&quot;headerlink&quot; title=&quot;间隔的直观理解&quot;&gt;&lt;/a&gt;间隔的直观理解&lt;/h1&gt;&lt;p&gt;　　要理解支持向量机，首先必须先了解间隔以及关于预测置信度的概念。考虑一下逻辑回归，模型是\(h_\theta(x)=g(\theta^Tx)\),当且仅当\(h_\theta(x) \geq 0.5\),也即\(\theta^Tx \geq 0\)时，我们预测结果为1。考虑一个正例样本，显然\(\theta^Tx\)的值越大，\(h_\theta(x)=p(y=1|x;w;b)\)的值也越大，则预测样本label为1的置信程度也越高。更正式的，当\(\theta^Tx \gg 0\)时，可以认为我们的预测样本label为1的置信程度很高，同样，当\(\theta^Tx \ll 0\)时,可以认为我们的预测样本label为0的置信程度很高。给定一个训练集，如果我们能够在标签为1的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \gg 0\)，那么这样拟合的效果就很好。同样，在标签为0的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \ll 0\)。这样的拟合效果能够体现出分类器对于样本分类的置信程度很高。后面我们会使用函数间隔来形式化该思想。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="支持向量机" scheme="xtf615.com/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    
      <category term="SVM" scheme="xtf615.com/tags/SVM/"/>
    
      <category term="线性分类器" scheme="xtf615.com/tags/%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    
      <category term="非线性分类器" scheme="xtf615.com/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>生成算法</title>
    <link href="xtf615.com/2017/03/25/%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95/"/>
    <id>xtf615.com/2017/03/25/生成算法/</id>
    <published>2017-03-25T02:09:22.000Z</published>
    <updated>2017-03-27T15:54:15.135Z</updated>
    
    <content type="html"><![CDATA[<p>　　这篇笔记主要针对斯坦福ML公开课的第五个视频，主要内容包括生成学习算法(generate learning algorithm)、高斯判别分析(Gaussian Discriminant Analysis)、朴素贝叶斯(Navie Bayes)、拉普拉斯平滑(Laplace Smoothing)。</p>
<h1 id="生成学习算法概述"><a href="#生成学习算法概述" class="headerlink" title="生成学习算法概述"></a>生成学习算法概述</h1><p>　　到目前为止，我们学习的方法主要是直接对问题进行求解，比如二分类问题中的感知机算法和逻辑回归算法，都是在解空间中寻找一条直线从而把两种类别的样例分开，对于新的样例只要判断在直线的哪一侧即可，这种截至对问题求解的方法可以称作判别学习方法(discriminative learning algorithm)。判别学习方法的任务是训练如下模型：<br>$$p(y|x;\theta)$$<br><a id="more"></a><br>即在给定特征x的情况下，我们直接求出y的条件概率作为模型的输出。例如逻辑回归中，我们将\(h_\theta(x)=g(\theta^Tx)\)作为模型\(p(y|x;\theta)\)的结果。也就是说，判别方法并不关心数据长什么样子，它直接面向分类任务，只关心数据之间的区别或者差异，然后利用学习到的区别来对样本做出预测。<br>　　而生成学习算法则是试图弄清楚数据是怎样产生的，每种数据的分布规律是怎样的，例如二分类问题中，生成学习算法对两个类别分别进行建模，用新的样例去匹配两个模型，<strong>匹配度较高的作为新样例的类别</strong>。比如良性肿瘤与恶性肿瘤分类，首先对两个类别分别建模，比如分别计算两类肿瘤是否扩散的概率，计算肿瘤大小大于某个值的概率；再比如狗与大象的分类，分别对狗与大象建模，比如计算两种类别体重大于某个值的概率，鼻子长度大于某个值的概率等等。即，每种特征都计算在不同类别下的概率，后面我们会讲到，可以利用朴素贝叶斯假设，每种特征在不同类别下的概率的累积可以作为\(P(x|y)\)的结果，即\(P(x|y)=\prod_{j=1}^n p(x_j|y)\), n是特征的数量，j是特征的下标。<br>　　形式化的说，判别学习方法是直接对\(p(y|x)\)进行建模，或者直接学习输入空间到输出空间的映射关系，其中x是类样本的特征，y是某类样本的分类标记。而生成学习方法是对\(p(x|y)\)(条件概率)和\(p(y)\)(先验概率)进行建模，然后依照贝叶斯法则求出后验概率\(p(y|x)\):<br>$$p(y|x)=\frac{p(x|y)p(y)}{p(x)}$$<br>使得后验概率最大的类别y即是新样本的预测值：<br>$$\mathop{argmax}\limits_y p(y|x)=\mathop{argmax}\limits_y \frac{p(x|y)p(y)}{p(x)}=\mathop{argmax}\limits_y p(x|y)p(y)$$<br>　　这个式子直观上也很好理解：比如我们在马路边远远地望到一个小动物，你想要判断它是一只狗还是一只鹿。首先，你肯定是要观察它的特征，然后根据你之前已经建立的经验，把它分别与狗和鹿的特征相对比，看更像哪个，也就是利用条件概率p(x|y)。然而距离太远了，根据你现在能够观察到的来看，可能和两者的特征都很符合。这个时候如果要让你作出判断的话，我想大多数人都会认为这个在马路边出现的动物是狗。为什么呢？因为狗在城市中更为常见，先验概率p(y=dog)的值更大。在这个过程中，我们便是同时利用了条件概率和先验概率来作出判断的。<br>　　注意，虽然在这个公式中也出现了\(p(y|x)\)，但它和判别模型中要预测的\(p(y|x;θ)\)是不同的。判别模型中我们直接计算出了\(p(y|x;θ)\)的大小，并把它作为预测结果的概率。而在生成模型中，我们是通过选取不同的y，来得到一个最大的\(p(y|x)\)，也就是看哪种类别会令测试样本出现的概率最大，把这种类别对应的y值作为预测结果。</p>
<h1 id="高斯判别分析"><a href="#高斯判别分析" class="headerlink" title="高斯判别分析"></a>高斯判别分析</h1><p>　　高斯判别分析（GDA）是其中一种生成学习算法。虽然它的名字里有判别两字，但却是生成学习算法。<br>　　在GDA中，假设\(p(x|y)\)属于多变量正态分布(multivariate normal distribution)。</p>
<h2 id="多变量正态分布"><a href="#多变量正态分布" class="headerlink" title="多变量正态分布"></a>多变量正态分布</h2><p>　　多变量正态分布是正态分布在多维变量下的扩展，它的参数是一个均值向量(mean vector) \(\mu\)和协方差矩阵(covariance matrix) \(\Sigma \sim \mathbb{R}^{n*n}\),其中n是多维变量的向量长度，\(\Sigma\)是对称正定矩阵。也写作，\(N(\mu,\Sigma)\),多变量正态分布的概率密度函数为：<br>$$p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp\left(-\frac{1}{2}(x-\mu)^T \Sigma^{-1}(x-\mu) \right)$$<br>　　其中，\(|\Sigma|\)是行列式的值。<br>　　对于服从多变量正态分布的随机变量x，均值由下面的公式给出：<br>$$E[X] = \int_x xp(x;\mu,\Sigma)dx = \mu$$<br>　　协方差矩阵由协方差函数Cov得到,如果 \(X \sim N(\mu,\Sigma)\),则：<br>$$Cov(X)=\Sigma$$<br>　　其中，Cov的计算过程为：<br>$$Cov(Z)=E[(Z-E[Z])(Z-E[Z])^T]=E[ZZ^T]-(E[Z])(E[Z])^T$$<br>　　下图是部分多元正态分布概率密度函数图：<br>    <img src="/picture/machine-learning/gda1.jpg" alt="gda"><br>　　最左边代表\(\mu\)为0(\(\mu\)是2*1规格的零向量)，并且协方差矩阵\(\Sigma=I\)(\(\Sigma\)为2*2的单位矩阵)。这也称作标准正态分布。中间那幅密度函数图代表零均值，\(\Sigma=0.6I\),最右边代表零均值，\(\Sigma=2I\).我们可以看出随着\(\Sigma\)对角元素变大,密度函数变得更扁平分散(spread-out)，随着其变小，则变得更瘦高集中(compressed)。<br>    下图是当协方差矩阵不是单位矩阵倍数时的情况：<br>    <img src="/picture/machine-learning/gda2.jpg" alt="gda"><br>    两幅图的\(\Sigma\)分别为：<br>    $$\Sigma_1=\begin{bmatrix} 1　0.5 \\\ 0.5　1\end{bmatrix} \\\\<br>    \Sigma_2=\begin{bmatrix} 1　0.8 \\\ 0.8　1\end{bmatrix}<br>    $$<br>可以看出随着反对角元素的增大，密度函数往45°方向变得更加的瘦高集中(compressed)。我们可以通过观察下图的等高线图来对比：<br>    <img src="/picture/machine-learning/gda3.jpg" alt="gda"><br>　　实际上，对于一个二维向量，\(\Sigma\)的非对角元素表示了两个分量之间的相关性，而主对角元素则是各分量本身的方差，即：<br>    $$\Sigma=\begin{bmatrix} E[(X_1-\mu_1)^2]　E[(X_1-\mu_1)(X_2-\mu_2)] \\\ E[(X_2-\mu_2)(X_1-\mu_1)]　E[(X_2-\mu_2)^2] \end{bmatrix} =  \begin{bmatrix} \sigma_1^2　\sigma_{12}^2 \\\ \sigma_{21}^2　\sigma_2^2 \end{bmatrix}$$<br>　　显然对于上图，右边的图因为反对角数字更大，即相关性更强。则横轴变量变大时，右图的纵轴变量变化比左图大，即右图相关性更强。实际上可以体现出数据更集中，故右图在图形上体现出更加瘦高。</p>
<h2 id="GDA模型"><a href="#GDA模型" class="headerlink" title="GDA模型"></a>GDA模型</h2><p>　　GDA模型针对的是输入特征为连续值时的分类问题。这个模型的基本假设是目标值y服从伯努利分布，条件概率\(p(x|y)\)服从多元正态分布。即:<br>$$y \sim Bernoulli(\phi) \\\\<br>x|y=0 \sim N(\mu_0, \Sigma) \\\\<br>x|y=1 \sim N(\mu_1, \Sigma)<br>$$<br>于是它们的概率密度为：<br>$$p(y)=\phi_y(1-y)^{1-y} \\\\<br>p(x|y=0)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp\left(-\frac{1}{2}(x-\mu_0)^T \Sigma^{-1}(x-\mu_0) \right) \\\\<br>p(x|y=1)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp\left(-\frac{1}{2}(x-\mu_1)^T \Sigma^{-1}(x-\mu_1) \right)<br>$$<br>我们模型的参数包括，\(\phi, \Sigma, \mu_0, \mu_1 \).注意到，我们使用了两种不同的均值向量\(\mu_0和\mu_1\)，但是使用了同一种协方差矩阵\(\Sigma\), 则我们的极大似然函数的对数如下所示：<br>$$L(\phi,\mu_0,\mu_1,\Sigma)=log \prod_{i=1}^m p(x^{(i)},y^{(i)};\phi,\mu_0,\mu_1,\Sigma) \\\ =log \prod_{i=1}^m p(x^{(i)}|y^{(i)};\phi,\mu_0,\mu_1,\Sigma)p(y^{(i)};\phi)$$<br>对极大似然函数对数最大化，我们就得到了GDA模型各参数的极大虽然估计，即得到了如何使用GDA算法的方法，各参数极大似然估计如下：<br>$$\phi = \frac{1}{m}\sum_{i=1}^m I\{y^{(i)}=1\} \\\ \\\\<br>\mu_0 = \frac{\sum_{i=1}^m I\{y^{(i)}=0\} x^{(i)}}{\sum_{i=1}^m I\{y^{(i)}=0\}} \\\ \\\\<br>\mu_1 = \frac{\sum_{i=1}^m I\{y^{(i)}=1\} x^{(i)}}{\sum_{i=1}^m I\{y^{(i)}=1\}} \\\ \\\\<br>\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T<br>$$<br>上述\(\mu_0\)代表类别为0的样本中，所有变量组成的均值向量。\(\mu_1\)代表类别为1的样本中，所有变量组成的均值向量，\(x^{(i)}\)实际上就是一个样本向量，\(\mu_{y^{(i)}}\)是指每个样本需要根据其类别来选择均值向量。<br>上述第一个式子可以由伯努利的最大似然估计得到，后面的三个式子在后一节里将进行详细推导。<br>一个二维GDA模型的例子如下图所示：<br><img src="/picture/machine-learning/gda4.jpg" alt="gda"><br>注意到两个二维高斯分布分别对两类数据进行拟合，它们使用相同的协方差矩阵，但却有不同的均值，在直线所示的部分,\(p(y=1|x)=(y=0|x)=0.5\)</p>
<h2 id="多元正态分布参数估计推导"><a href="#多元正态分布参数估计推导" class="headerlink" title="多元正态分布参数估计推导"></a>多元正态分布参数估计推导</h2><p>　　我们想证明：多元正态分布的参数\(\mu,\Sigma\)可由最大似然法求出，即：<br>$$\hat{\mu}=\overline{X}, \hat{\Sigma}=\frac{1}{m}S$$<br>其中，S为样本协方差矩阵，\(\overline{X}为样本均值向量\)<br>设，\(X_{(1)},X_{(2)},…,X_{(m)}\)来自正态总体\(N_n(\mu,\Sigma)\)容量为m的样本，每个样本\(X_{(a)}=(X_{a1},X_{a2},…,X_{an})^T,a=1,2,…,m\),<br>其中，m为样本容量，n为变量个数。构造似然函数：<br>$$<br>L(\mu,\Sigma)=\prod_{i=1}^m f(X_i, \mu, \Sigma)=\frac{1}{(2\pi)^{nm/2}|\Sigma|^{m/2}}exp\left(-\frac{1}{2}\sum_{i=1}^m(X_i-\mu)^T \Sigma^{-1}(X_i-\mu) \right)<br>$$<br>两边取对数，得到:<br>$$log(\mu,\Sigma)=-\frac{1}{2}nm log(2\pi)-\frac{m}{2}log|\Sigma| \\\\<br>        -\frac{1}{2}\sum_{i=1}^m(X_i-\mu)^T\Sigma^{-1}(X_i-\mu)<br>$$<br>因为对数函数为严格单调递增函数，所以可以通过极大值求参数估计量。<br>根据矩阵代数理论：对于实对称矩阵A，我们有：<br>$$\frac{\partial(X^TAX)}{\partial X} = 2AX \\\\<br>\frac{\partial(X^TAX)}{\partial A} = XX^T \\\\<br>\frac{\partial log(|A|)}{\partial A} = A^{-1}<br>$$<br>这里的\(\Sigma\)就是实对称矩阵，分别对\(\mu,\Sigma\)求偏导，则有：<br>$$<br>\frac{\partial log L(\mu,\Sigma)}{\partial \mu} = \sum_{i=1}^m \Sigma^{-1}(X_i-\mu)=0 \\\\<br>\frac{\partial log L(\mu,\Sigma)}{\partial \Sigma} = -\frac{m}{2}\Sigma^{-1}+\frac{1}{2}\sum_{i=1}^m(X_i-\mu)(X_i-\mu)^T(\Sigma^{-1})^2=0<br>$$<br>则：<br>$$<br>\hat{\mu} = \frac{1}{m}\sum_{i=1}^m X_i = \overline{X} \\\\<br>\hat{\Sigma} = \frac{1}{m}\sum_{i=1}^m (X_i-\overline{X})(X_i-\overline{X})^T=\frac{1}{m}S<br>$$</p>
<h2 id="GDA模型与logistic模型的关系"><a href="#GDA模型与logistic模型的关系" class="headerlink" title="GDA模型与logistic模型的关系"></a>GDA模型与logistic模型的关系</h2><p>前面我们提到：<br>$$\mathop{argmax}\limits_y p(y|x)=\mathop{argmax}\limits_y \frac{p(x|y)p(y)}{p(x)}=\mathop{argmax}\limits_y p(x|y)p(y)$$<br>我们有：<br>$$p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1)+p(x|y=0)p(y=0)}$$<br>上式实际上可以表示成logistic函数的形式：<br>$$p(y=1|x;\phi,\mu_0,\mu_1,\Sigma)=\frac{1}{1+exp(-\theta^T X)}$$<br>　　其中，\(\theta是参数\phi,\mu_0,\mu_1,\Sigma\)某种形式的函数。GDA的后验分布可以表示logistic函数的形式。<br>　　实际上，可以证明，不仅仅当先验概率分布服从多变量正态分布时可以推导出逻辑回归的模型，当先验分布属于指数分布簇中的任何一个分布，如泊松分布时，都可以推导出逻辑回归模型。而反之不成立，逻辑回归的先验概率分布不一定必须得是指数分布簇中的成员，因此也可以说明logistic在建模上的鲁棒性。<br>　　因此推导逻辑回归模型有两种方法。第一种是之前提到的通过指数分布簇来推导，第二种则是通过生成学习假设先验概率分布的方式进行推导。<br>　　那么如何选择GDA与logistic回归模型呢？由上面的分析可以知道，GDA与logistic回归是泛化与特化的关系.GDA比logistic回归有更强的前置假设。当数服从或大致服从正态分布时，使用GDA会达到更好的效果，因为利用了更多的信息构建模型。但当数据不服从正态分布时，那么logistic回归更有效，因为它做出了更弱的假设，构建的模型更加鲁棒性。生成学习还有另外一个好处，就是可以使用比判别模型更少的数据构建出更鲁棒的模型。</p>
<h1 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h1><p>　　GDA针对的是特征向量X为连续值时的问题。而朴素贝叶斯Navie Bayes则针对的是特征向量为离散值时的问题。<br>　　NB算法的常见的应用是文本分类问题，例如邮件是否为垃圾邮件的分类问题。<br>　　对于文本分类问题来说，使用向量空间模型VSM来表示文本。何为VSM？首先，我们需要有一个词典，词典可以是现有词典，也可以从数据中统计出来的词典，对于每个文本，我们用长度等于词典大小的向量表示，如果文本包含某个词，则该词在词典中的索引为index，则表示文本向量的index出设为1，否则设为0。该方法对应多元伯努利分布。<br>　　如果按直接对p(x|y)进行建模，那么会遇到参数过多的问题，我们假设词典有50000个词，则向量长度为50000，向量中每个分量的取值为{0,1}，那么可能有\(2^50000\)个可能的结果，如果我们使用多项式分布对这\(2^50000\)个可能的结果进行建模，则对其建模需要\(2^50000-1\)个参数。<strong>这里仍然存在着一点疑问？为什么参数个数不是50000，而是\(2^50000-1\)呢？个人理解是，这里所说的是指对X建模, 暂时没有考虑y的因素。那么相当于我们需要计算每种X组合出现的概率。</strong><br>原话如下图所示：<br><img src="/picture/machine-learning/gda5.jpg" alt="gda"><br>　　朴素贝叶斯假设是在给定分类y后，假设特征向量中各个分量是条件独立的。例如对于垃圾邮件，即y=1，”购买”是第2087个词，“价格”是第39831个词，假设已经告诉了我们某个邮件是垃圾邮件，即y=1, 那么\(x_{2087}\)不会对\(x_{39831}\)的值产生任何影响。更正式的，这可以写作：\(p(x_{2087}|y)=p(x_{2087}|y,x_{39831})\)。注意我们不是说\(x_{2087}和x_{39831}\)是相互独立的，即不是指\(p(x_{2087})=p(x_{2087}|x_{39831})\),而只是假设在给定y的情况下，\(x_{2087}和x_{39831}\)是条件独立的。现在我们有：<br>$$p(x_1,…,x_{50000}|y)=p(x_1|y)p(x_2|y,x_1)p(x_3|y,x_1,x_2)…p(x_{50000}|y,x_1,x_2,…,x_{49999}) \\\\<br>= p(x_1|y)p(x_2|y)p(x_3|y)…p(x_{50000}|y) \\\\<br>= \prod_{i=1}^n p(x_i|y)<br>$$<br>第一个等式是根据通常的概率论得到的，第二个等式是根据贝叶斯假设得到的。虽然贝叶斯假设是个很强的假设，但是实践证明在许多问题上都表现得很好。<br>我们得到了NB方法的参数：<br>$$\phi_y=p(y=1) \\\\<br>\phi_{j|y=1} = p(x_j=1|y=1) \\\\<br>\phi_{j|y=0} = p(x_j=1|y=0)<br>$$<br>这里的\(\phi\)是向量，向量的分量代表每个特征项伯努利分布的参数值，实际上就是每个特征项出现的概率组成的向量。我们需要求出每个特征项在类别为0下出现的概率值和类别为1下出现的概率值。<br>于是，我们就得到NB方法的极大似然估计的对数函数：<br>$$L(\phi_y,\phi_{j|y=1},\phi_{j|y=0})=\prod_{i=1}^m p(x^{(i)},y^{(i)})=\prod_{i=1}^m p(x^{(i)}|y^{(i)})p(y^{(i)}) \\\\<br>=\prod_{i=1}^m \left(\prod_{j=1}^n p(x_j^{(i)}|y^{(i)})\right)p(y^{(i)})<br>$$<br>其中，n为词典的大小，也就是特征项的数目。m为样本的数量，也就是邮件数。第一个式子是根据极大似然估计方法得到的，第二个式子中\(p(x^{(i)}|y^{(i)})=\left(\prod_{j=1}^n p(x_j^{(i)}|y^{(i)})\right)\)是根据朴素贝叶斯假设得到的。j是特征项的下标。我们假设\(p(x_j|y)\)满足伯努利分布，因为特征项只取0和1，那么根据伯努利分布的最大似然估计：<br>我们得到如下参数的极大似然估计：<br>$$\phi_y = \frac{\sum_{i=1}^m I\{y^{(i)}=1\}}{m} \\\ \\\ \phi_{j|y=1} = \frac{\sum_{i=1}^m I\{x_j^{(i)}=1 \wedge y^{(i)}=1\}}{\sum_{i=1}^m I\{y^{(i)}=1\}} \\\ \\\ \phi_{j|y=0} = \frac{\sum_{i=1}^m I\{x_j^{(i)}=1 \wedge y^{(i)}=0\}}{\sum_{i=1}^m I\{y^{(i)}=0\}}$$<br>　　其中，\(\wedge\)代表并且，\(\phi_y\)是类别y的先验概率，二分类问题就是2*1的向量。\(\phi_{j|y=1}\)是类别为1的情况下，各个特征项参数组成的向量，也即各个特征项出现的概率组成的向量。\(\phi_{j|y=0}\)是类别为0的情况下，各个特征项参数组成的向量，也即各个特征项出现的概率组成的向量。\(x_j^{(i)}\)代表第i个样本的第j个特征项的值。<br>　　对于新样本，按照如下公式计算其后验概率值：<br>$$p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}=\frac{p(x|y=1)p(y=1)}{p(x|y=1)p(y=1)+p(x|y=0)p(y=0)}=\frac{(\prod_{j=1}^n p(x_j|y=1))p(y=1)}{(\prod_{j=1}^n p(x_j|y=1))p(y=1)+(\prod_{j=1}^n p(x_j|y=0))p(y=0)}$$<br>我们可以将上述特征项的取值扩展到{0,1,2…,k}，而\(p(x_j|y)\)的概率分布由伯努利分布变为多项式分布，对于一些连续的变量，我们可以将其离散化后使其可以用NB方法解决，例如离散化方法可以是通过将连续变量按值分段实现。</p>
<h1 id="拉普拉斯平滑"><a href="#拉普拉斯平滑" class="headerlink" title="拉普拉斯平滑"></a>拉普拉斯平滑</h1><p>　　拉普拉斯平滑(Laplace Smoothing)又称为加1平滑。平滑方法的存在是为了解决零概率问题。<br>　　所谓的零概率问题，就是在计算新实例的概率时，如果某个分量在训练集中从没出现过，会导致整个实例的概率计算结果为０，针对文本分类问题就是当一个词语在训练集中没有出现过，那么该词语的概率为０，使用连乘计算文本出现的概率时，整个文本出现的概率也为０，这显然不合理，因为不能因为一个事件没有观测到就判断该事件的概率为０.<br>　　对于一个随机变量ｚ，它的取值范围为｛1,2,3,…,k｝，对于m次试验后的观测结果\({z^{(1)},z^{(2)},z^{(3)},…,z^{(m)}} \),极大似然估计按照下式计算：<br>$$\phi_j=\frac{\sum_{i=1}^m I(z^{(i)}=j)}{m}$$<br>使用Laplace平滑后，计算公式变为：<br>$$\phi_j=\frac{\sum_{i=1}^m I(z^{(i)}=j)+1}{m+k}$$<br>即在分母上加上随机变量Z取值范围的大小，在分子加1。<strong>注意不是y的取值范围！！</strong><br>可以发现，\(\sum_{j=1}^k \phi_j=1\)仍然满足。<br>回到NB算法，我们可以修正各分量的计算公式：<br>$$\phi_{j|y=1} = \frac{\sum_{i=1}^m I\{x_j^{(i)}=1 \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m I\{y^{(i)}=1\}+2} \\\ \\\ \phi_{j|y=0} = \frac{\sum_{i=1}^m I\{x_j^{(i)}=1 \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m I\{y^{(i)}=0\}+2}$$</p>
<p>　　另外，上文我们假设特征项是服从伯努利分布，对应于，词集型模型–根据分类中某词是否出现计算概率，不考虑权重。我们可以假设特征项服从多项式分布，对应于词频型模型–根据分类中某词出现的次数计算概率。这部分是下一个视频的内容，这里我们提前讲下这部分内容。</p>
<h1 id="拓展：朴素贝叶斯多项式事件模型"><a href="#拓展：朴素贝叶斯多项式事件模型" class="headerlink" title="拓展：朴素贝叶斯多项式事件模型"></a>拓展：朴素贝叶斯多项式事件模型</h1><p>　　前面我们提到的NB模型也被称作多元伯努利事件模型(Multivariate Bernoulli Event Model, 简称NB-MBEM)。这部分将介绍一种与多元伯努利事件模型有较大区别的NB模型，即多项式事件模型（Multinomial Event Model，简称NB-MEM）。<br>　　首先，NB-MEM改变了特征向量的表示方法。在NB-MBEM中，特征向量的每个分量代表词典中该index上的词语是否在文本中出现过，其取值范围为{0,1}，特征向量的长度为词典的大小。而在NB-MEM中，特征向量中的每个分量是文本中处于该分量位置的词语在词典中的索引，其取值范围是{1,2,…,|V|},|V|是词典的大小，特征向量的长度为相应样例文本中词语的数目，它会因为样本的不同而不同。<br>　　在NB-MEM中，假设文本的生成过程如下：</p>
<ul>
<li>随机确定文本的类别，比如是否为垃圾文本、教育类文本、财经类文本。</li>
<li>遍历词典的每个位置，以相同的多项式分布决定是否将该词包含在该文本中。</li>
</ul>
<p>由上面的生成过程可以知道，NB-MEM假设文本类别服从多项式分布或伯努利分布，即根据p(y)的先验概率分布得到的；而词典中所有的词语则服从多项式分布。生成过程还可以如下解释，即先在类别服从的先验分布p(y)下选取类别，然后遍历整个词典，在词典所服从的多项式分布\(p(x_i=1|y)=\phi_{i|y}\)中选择词语，确定是否放在文本中相应的位置上。因此根据朴素贝叶斯假设，某个文本整体出现的概率是：\(p(y)\prod_{i=1}^n p(x_i|y)\)<br>　　因此，NB-MEM的参数如下所示：<br>$$\phi_y=p(y) \\\\<br>\phi_{k|y=1}=p(x_j=k|y=1) \\\\<br>\phi_{k|y=0}=p(x_j=k|y=0) \\\\<br>其中，\phi_{k|y=1}可以代表字典中每个词语在类别为1的文本中出现的概率组成的向量<br>$$<br>　　得到参数在训练集上的极大似然估计：<br>$$\ell(\phi_y,\phi_{k|y=1},\phi_{k|y=0})=\prod_{i=1}^m p(x^{(i)},y^{(i)})<br>= \prod_{i=1}^m \left(\prod_{j=1}^{n_i} p(x_j^{(i)}|y);\phi_{k|y=1},\phi_{k|y=0}) \right) p(y^{(i)};\phi_y)<br>$$<br>注意上式的\(n_i\)是每个文本的单词量；m是文本数量。<br>可以根据多项式分布的极大似然估计方法(查查资料)，得到各个参数的极大似然估计：<br>$$<br>\phi_{k|y=1} = \frac{\sum_{i=1}^m \sum_{j=1}^{n_i} I\{x_j^{(i)}=k \wedge y^{(i)}=1\}}{\sum_{i=1}^m I\{y^{(i)}=1)\}n_i} \\\\<br>\phi_{k|y=0} = \frac{\sum_{i=1}^m \sum_{j=1}^{n_i} I\{x_j^{(i)}=k \wedge y^{(i)}=0\}}{\sum_{i=1}^m I\{y^{(i)}=0)\}n_i} \\\\<br>\phi_y = \frac{\sum_{i=1}^m I\{y^{(i)}=1\}}{m}<br>$$<br>实际上，\(\phi_{k|y=1}\)分子代表：对所有的m个文本样本进行外层遍历，再对每个文本的\(n_i\)个单词进行内层遍历，如果该文本类别为1，统计该文本中该单词出现的次数，最后将所有文本中该单词出现的次数进行累加作为分子。分母则代表，对所有类别为1的文本，累加其所有的单词量。<br>使用拉普拉斯平滑得到：<br>$$<br>\phi_{k|y=1} = \frac{\sum_{i=1}^m \sum_{j=1}^{n_i} I\{x_j^{(i)}=k \wedge y^{(i)}=1\}+1}{\sum_{i=1}^m I\{y^{(i)}=1)\}n_i+|V|} \\\\<br>\phi_{k|y=0} = \frac{\sum_{i=1}^m \sum_{j=1}^{n_i} I\{x_j^{(i)}=k \wedge y^{(i)}=0\}+1}{\sum_{i=1}^m I\{y^{(i)}=0)\}n_i+|V|}<br>$$<br>其中，|V|为词典的大写，也就是变量\(X\)的每个特征分量的取值范围。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="http://blog.csdn.net/win_in_action/article/details/51260486" target="_blank" rel="external">Naive Bayes Spam detection</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　这篇笔记主要针对斯坦福ML公开课的第五个视频，主要内容包括生成学习算法(generate learning algorithm)、高斯判别分析(Gaussian Discriminant Analysis)、朴素贝叶斯(Navie Bayes)、拉普拉斯平滑(Laplace Smoothing)。&lt;/p&gt;
&lt;h1 id=&quot;生成学习算法概述&quot;&gt;&lt;a href=&quot;#生成学习算法概述&quot; class=&quot;headerlink&quot; title=&quot;生成学习算法概述&quot;&gt;&lt;/a&gt;生成学习算法概述&lt;/h1&gt;&lt;p&gt;　　到目前为止，我们学习的方法主要是直接对问题进行求解，比如二分类问题中的感知机算法和逻辑回归算法，都是在解空间中寻找一条直线从而把两种类别的样例分开，对于新的样例只要判断在直线的哪一侧即可，这种截至对问题求解的方法可以称作判别学习方法(discriminative learning algorithm)。判别学习方法的任务是训练如下模型：&lt;br&gt;$$p(y|x;\theta)$$&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="生成算法" scheme="xtf615.com/tags/%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95/"/>
    
      <category term="朴素贝叶斯" scheme="xtf615.com/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    
      <category term="文本挖掘" scheme="xtf615.com/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>Python实现时间序列分析</title>
    <link href="xtf615.com/2017/03/08/Python%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"/>
    <id>xtf615.com/2017/03/08/Python实现时间序列分析/</id>
    <published>2017-03-08T01:54:58.000Z</published>
    <updated>2017-03-10T12:30:52.244Z</updated>
    
    <content type="html"><![CDATA[<p>前面花了两章篇幅介绍了时间序列模型的数学基础。 <a href="/2017/03/07/ARIMA时间序列模型/">ARIMA时间序列模型(一)</a>和<a href="/2017/03/07/ARIMA时间序列模型-二/">ARIMA时间序列模型(二)</a> 。本文重点介绍使用python开源库进行时间序列模型实践。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>回顾一下自回归移动平均模型ARMA，它主要由两部分组成：AR代表p阶自回归过程，MA代表q阶移动平均过程，形式如下：<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\<br>+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>为了方便，我们重写以上等式为：<br>$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\<br>其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$<br>根据前两篇的分析，我们总结ARMA模型的性质如下：<br><img src="/picture/machine-learning/arima5.jpg" alt="arima"><br><a id="more"></a></p>
<h1 id="p值检验"><a href="#p值检验" class="headerlink" title="p值检验"></a>p值检验</h1><p>　　在开始之前，我们首先回顾一下p值检验。<br>　　一般地，用X表示检验的统计量，当H0为真时，可由样本数据计算出该统计量的值C，根据检验统计量X的具体分布，可求出P值。具体地说：</p>
<ul>
<li>左侧检验的P值为检验统计量X小于样本统计值C的概率，即：P = P{ X &lt; C}</li>
<li>右侧检验的P值为检验统计量X大于样本统计值C的概率：P = P{ X &gt; C}</li>
<li>双侧检验的P值为检验统计量X落在样本统计值C为端点的尾部区域内的概率的2倍：P = 2P{ X &gt; C} (当C位于分布曲线的右端时) 或P = 2P{ X&lt; C}(当C位于分布曲线的左端时) 。若X服从正态分布和t分布，其分布曲线是关于纵轴对称的，故其P值可表示为P=P{|X|&gt;C}。<br>计算出P值后，将给定的显著性水平α与P值比较，就可作出检验的结论：<br>如果\(p &lt; α\)值，则在显著性水平α下拒绝原假设。<br>如果\(P \geq α\)值，则在显著性水平α下接受原假设。</li>
</ul>
<h1 id="pandas数据操作"><a href="#pandas数据操作" class="headerlink" title="pandas数据操作"></a>pandas数据操作</h1><p>使用pandas来加载数据，并对数据索引进行转换，使用日期作为索引。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">dateparse = <span class="keyword">lambda</span> dates:pd.datetime.strptime(dates,<span class="string">'%Y-%m'</span>)</div><div class="line">data=pd.read_csv(<span class="string">'AirPassengers.csv'</span>,parse_dates=<span class="string">'Month'</span>,index_col=<span class="string">'Month'</span>,date_parser=dateparse);</div><div class="line"><span class="keyword">print</span> data.head()</div><div class="line"><span class="comment"># 数据如下所示：</span></div><div class="line">Month                  </div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-01</span><span class="number">-01</span>          <span class="number">112</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-02</span><span class="number">-01</span>          <span class="number">118</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-03</span><span class="number">-01</span>          <span class="number">132</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-04</span><span class="number">-01</span>          <span class="number">129</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-05</span><span class="number">-01</span>          <span class="number">121</span></div></pre></td></tr></table></figure>
<p>接着绘制数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ts = data[<span class="string">'#Passengers'</span>]</div><div class="line">plt.plot(ts)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima6.jpg" alt="arma"></p>
<p>非常清晰的看到，随着季节性的变动，飞机乘客的数量总体上是在不断增长的。但是，不是经常都可以获得这样清晰的视觉体验。我们可以通过下面的方法测试稳定性。</p>
<h1 id="稳定性检测"><a href="#稳定性检测" class="headerlink" title="稳定性检测"></a>稳定性检测</h1><ul>
<li><strong>绘制滚动统计</strong>：我们可以绘制移动平均数和移动方差，观察它是否随着时间变化。</li>
<li><strong>ADF检验：</strong>这是一种检查数据稳定性的统计测试。无效假设：时间序列是不稳定的。测试结果由测试统计量和一些置信区间的临界值组成。如果“测试统计量”少于“临界值”，我们可以拒绝无效假设，并认为序列是稳定的。或者根据前面提高的p值检验，如果p值小于显著性水平，我们可以拒绝无效假设，认为序列稳定。</li>
</ul>
<h2 id="滚动统计"><a href="#滚动统计" class="headerlink" title="滚动统计"></a>滚动统计</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rolling_statistics</span><span class="params">(timeseries)</span>:</span></div><div class="line">    <span class="comment">#Determing rolling statistics</span></div><div class="line">    rolmean = pd.rolling_mean(timeseries, window=<span class="number">12</span>)</div><div class="line">    rolstd = pd.rolling_std(timeseries, window=<span class="number">12</span>)</div><div class="line"></div><div class="line">    <span class="comment">#Plot rolling statistics:</span></div><div class="line">    orig = plt.plot(timeseries, color=<span class="string">'blue'</span>,label=<span class="string">'Original'</span>)</div><div class="line">    mean = plt.plot(rolmean, color=<span class="string">'red'</span>, label=<span class="string">'Rolling Mean'</span>)</div><div class="line">    std = plt.plot(rolstd, color=<span class="string">'black'</span>, label = <span class="string">'Rolling Std'</span>)</div><div class="line">    plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">    plt.title(<span class="string">'Rolling Mean &amp; Standard Deviation'</span>)</div><div class="line">    plt.show(block=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>pd.rolling_mean有两个参数，第一个是输入数据，第二个是窗口大小。假设有个序列是，1  2  3  3  5  8  6  9，如果窗口大小为3，那么移动平均数计算过程如下： 第一步: (1+2+3)/3 =2;    第二步:往右移动一个数据，(2+3+3)/3=2.667;  第三步, (3+3+5)/3=3.667;  第四步：(3+5+8)/3=5.333; 第四步: (5+8+6)/3=6.333; 第五步;(8+6+9)/3=7.667;  因此移动平均数序列为： NA NA 2  2.667  3.667  5.3333   6.333  7.667.  共用n-windows+1个数。</p>
<p><img src="/picture/machine-learning/arima7.jpg" alt="arma"></p>
<p>移动标准差类似，只不过把求平均变成了求标准差。</p>
<p>绘图如下：可以看出移动平均数仍然是上升趋势，而移动标准差相对比较平稳。</p>
<p><img src="/picture/machine-learning/arima8.jpg" alt="arma"></p>
<h2 id="ADF检验"><a href="#ADF检验" class="headerlink" title="ADF检验"></a>ADF检验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statsmodels.tsa.stattools <span class="keyword">import</span> adfuller</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adf_test</span><span class="params">(timeseries)</span>:</span></div><div class="line">    rolling_statistics(timeseries)<span class="comment">#绘图</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Results of Augment Dickey-Fuller Test:'</span></div><div class="line">    dftest = adfuller(timeseries, autolag=<span class="string">'AIC'</span>)</div><div class="line">    dfoutput = pd.Series(dftest[<span class="number">0</span>:<span class="number">4</span>], index=[<span class="string">'Test Statistic'</span>,<span class="string">'p-value'</span>,<span class="string">'#Lags Used'</span>,<span class="string">'Number of Observations Used'</span>])</div><div class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> dftest[<span class="number">4</span>].items():</div><div class="line">        dfoutput[<span class="string">'Critical Value (%s)'</span>%key] = value</div><div class="line">    <span class="keyword">print</span> dfoutput</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima9.jpg" alt="arma"></p>
<p>上述输出如何解读?</p>
<ul>
<li>Test statistic：代表检验统计量</li>
<li>p-value：代表p值检验的概率</li>
<li>Lags used：使用的滞后k，autolag=AIC时会自动选择滞后</li>
<li>Number of Observations Used：样本数量</li>
<li>Critical Value(5%) : 显著性水平为5%的临界值。</li>
</ul>
<p>ADF检验</p>
<ul>
<li>假设是存在单位根，即不平稳； </li>
<li>显著性水平，1%：严格拒绝原假设；5%：拒绝原假设，10%类推。</li>
<li>看P值和显著性水平a的大小，p值越小，小于显著性水平的话，就拒绝原假设，认为序列是平稳的；大于的话，不能拒绝，认为是不平稳的</li>
<li>看检验统计量和临界值，检验统计量小于临界值的话，就拒绝原假设，认为序列是平稳的；大于的话，不能拒绝，认为是不平稳的</li>
</ul>
<p>根据上文提到的p值检验以及上面的结果，我们可以发现p=0.99&gt;10%&gt;5%&gt;1%, 并且检验统计量0.815&gt;&gt;-2.58&gt;-2.88&gt;-3.48，因此可以认定原序列不平稳。</p>
<p>先让我们弄明白是什么导致时间序列不稳定。两个主要原因。</p>
<ul>
<li><strong>趋势-随着时间产生不同的平均值。</strong>举例：在飞机乘客这个案例中，我们看到总体上，飞机乘客的数量是在不断增长的。</li>
<li><strong>季节性-特定时间框架内的变化。</strong>举例：在特定的月份购买汽车的人数会有增加的趋势，因为车价上涨或者节假日到来。</li>
</ul>
<p>我们的基本原理是，通过建模并估计趋势和季节性这些因素，并从时间序列中移除，来获得一个稳定的时间序列，然后再使用统计预测技术来处理时间序列，最后将预测得到的数据，通过加入趋势和季节性等约束，来回退到原始时间序列数据。</p>
<h1 id="平稳性处理"><a href="#平稳性处理" class="headerlink" title="平稳性处理"></a>平稳性处理</h1><p>　　消除趋势的第一个方法是转换。例如,在本例中,我们可以清楚地看到该时间序列有显著趋势。所以我们可以通过变换，惩罚较高值而不是较小值。这可以采用对数,  平方根,立方跟等等。</p>
<h2 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ts_log = np.log(ts)</div><div class="line">plt.plot(ts_log)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima10.jpg" alt="arma"></p>
<p>在这个例子中,很容易看到一个向前的趋势。但是它表现的不是很直观。我们可以使用一些技术来对这个趋势建模, 然后将它从序列中删除。最常用的方法有:</p>
<ul>
<li><strong>平滑-取滚动平均数</strong></li>
<li><strong>差分</strong></li>
<li><strong>分解</strong></li>
</ul>
<h2 id="移动平均数"><a href="#移动平均数" class="headerlink" title="移动平均数"></a>移动平均数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">moving_avg = pd.rolling_mean(ts_log,<span class="number">12</span>)</div><div class="line">plt.plot(ts_log)</div><div class="line">plt.plot(moving_avg,color=<span class="string">'red'</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima11.jpg" alt="arma"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#做差</span></div><div class="line">ts_log_moving_avg_diff = ts_log - moving_avg</div><div class="line">ts_log_moving_avg_diff.head(<span class="number">12</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima12.jpg" alt="arma"></p>
<p>前11个数是NA</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adf_test(ts_log_moving_avg_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima13.jpg" alt="arma"></p>
<p>可以发现通过了5%和10%的显著性检验，即在该水平下，拒绝原假设，认为序列是平稳的，但是没有通过1%的检验。</p>
<p><strong>指数加权移动平均</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">expwighted_avg=pd.ewma(ts_log,halflife=<span class="number">12</span>)</div><div class="line">plt.plot(ts_log)</div><div class="line">plt.plot(expwighted_avg, color=<span class="string">'red'</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima14.jpg" alt="arma"></p>
<p>前面移动平均数需要指定window,并且对所有的数一视同仁；这里采用指数加权移动平均方法，会对当前的数据加大权重，对过去的数据减小权重。halflife半衰期，用来定义衰减量。其他参数,如跨度span和质心com也可以用来定义衰减。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#做差</span></div><div class="line">ts_log_ewma_diff = ts_log - expwighted_avg</div><div class="line">adf_test(ts_log_ewma_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima15.jpg" alt="arma"></p>
<p>可以发现，经过指数移动平均后，再做差的结果，已经能够通过1%显著性水平检验了。</p>
<h2 id="差分"><a href="#差分" class="headerlink" title="差分"></a>差分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#步长为1的一阶差分</span></div><div class="line">ts_log_diff = ts_log - ts_log.shift(periods=<span class="number">1</span>)</div><div class="line">plt.plot(ts_log_diff)</div></pre></td></tr></table></figure>
<p>我们首先使用步长为1的一阶差分，得到如下图：</p>
<p><img src="/picture/machine-learning/arima16.jpg" alt="arma"></p>
<p>接着进行adf检验，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#只通过了10%的检验</div><div class="line">ts_log_diff.dropna(inplace=True)</div><div class="line">test_stationarity(ts_log_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima17.jpg" alt="arma"></p>
<p>可以发现只通过了10%的显著性水平检验。</p>
<p><strong>二阶差分</strong></p>
<p>我们继续进行二阶差分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#一阶差分：Y(k)=X(k+1)-X(k)</span></div><div class="line"><span class="comment">#二阶差分：Y(k)的一阶差分Z(k)=Y(k+1)-Y(k)=X(k+2)-2*X(k+1)+X(k)为此函数的二阶差分</span></div><div class="line">ts_log_diff = ts_log - ts_log.shift(periods=<span class="number">1</span>)</div><div class="line">ts_log_diff2 = ts_log_diff - ts_log_diff.shift(periods=<span class="number">1</span>)</div><div class="line">plt.plot(ts_log_diff2)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima18.jpg" alt="arma"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#二阶差分检验</div><div class="line">#可以看到，二阶差分，p值非常小，小于1%，检验统计量也明显小于%1的临界值。因此认定为很平稳</div><div class="line">ts_log_diff2.dropna(inplace=True)</div><div class="line">adf_test(ts_log_diff2)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima19.jpg" alt="arma"></p>
<p>对二阶差分进行adf检验,可以看到，二阶差分，p值非常小，小于1%，检验统计量也明显小于%1的临界值。因此认定为很平稳.</p>
<h2 id="分解"><a href="#分解" class="headerlink" title="分解"></a>分解</h2><p>建立有关趋势和季节性的模型，并从模型中删除它们。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#时间序列分解</div><div class="line">from statsmodels.tsa.seasonal import seasonal_decompose</div><div class="line">decomposition = seasonal_decompose(ts_log)</div><div class="line">trend = decomposition.trend</div><div class="line">seasonal = decomposition.seasonal</div><div class="line">residual = decomposition.resid</div><div class="line"></div><div class="line">plt.subplot(411)</div><div class="line">plt.plot(ts_log,label=&apos;Original&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(412)</div><div class="line">plt.plot(trend, label=&apos;Trend&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(413);</div><div class="line">plt.plot(seasonal,label=&apos;Seasonality&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(414)</div><div class="line">plt.plot(residual, label=&apos;Residuals&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.tight_layout()</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima20.jpg" alt="arma"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#对残差进行ADF检验</div><div class="line">#可以发现序列非常平稳</div><div class="line">ts_log_decompose = residual</div><div class="line">ts_log_decompose.dropna(inplace=True)</div><div class="line">adf_test(ts_log_decompose)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima21.jpg" alt="arma"></p>
<p>对残差进行ADF检验，可以发现序列非常平稳。</p>
<h1 id="时间序列建模"><a href="#时间序列建模" class="headerlink" title="时间序列建模"></a>时间序列建模</h1><h2 id="平稳性检验"><a href="#平稳性检验" class="headerlink" title="平稳性检验"></a>平稳性检验</h2><p>平稳性检验的目的是为了判断序列是否平稳，如果不平稳，需要采取一定的措施进行平稳性处理，常见的方法是差分，我们需要选择合适的差分阶数。只要能够通过1%显著性检测，差分阶数就是合理的，我们希望阶数越小越好。</p>
<h3 id="ADF检验-1"><a href="#ADF检验-1" class="headerlink" title="ADF检验"></a>ADF检验</h3><p>ADF检验前文已经说过，用于判断序列是否平稳。</p>
<h3 id="自相关图和偏自相关图"><a href="#自相关图和偏自相关图" class="headerlink" title="自相关图和偏自相关图"></a>自相关图和偏自相关图</h3><p>前面我们对数据进行ADF检验，判断序列是否平稳，这里我们使用自相关图和偏自相关图对数据平稳性再次进行验证，一阶差分如下图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">acf_pacf_plot</span><span class="params">(ts_log_diff)</span>:</span></div><div class="line">    sm.graphics.tsa.plot_acf(ts_log_diff,lags=<span class="number">40</span>) <span class="comment">#ARIMA,q</span></div><div class="line">    sm.graphics.tsa.plot_pacf(ts_log_diff,lags=<span class="number">40</span>) <span class="comment">#ARIMA,p</span></div><div class="line">acf_pacf_plot(ts_log_diff) <span class="comment">#调用一阶差分</span></div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima22.jpg" alt="arma"></p>
<p>可以看出，一阶差分自相关和偏相系数拖尾特点明显。p=1,q=1</p>
<h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><h3 id="差分阶数选择"><a href="#差分阶数选择" class="headerlink" title="差分阶数选择"></a>差分阶数选择</h3><p>我们发现，ARIMA该开源库，不支持3阶以上的差分。我们唯一的办法是先数据差分好，再传入模型进行建模。但是这样也带来了回退数据到原始序列数据的难度。</p>
<p><img src="/picture/machine-learning/arima26.jpg" alt="arma"></p>
<p>这里开发了差分和回退的方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 差分操作,d代表差分序列，比如[1,1,1]可以代表3阶差分。  [12,1]可以代表第一次差分偏移量是12，第二次差分偏移量是1</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">diff_ts</span><span class="params">(ts, d)</span>:</span></div><div class="line">    <span class="keyword">global</span> shift_ts_list</div><div class="line">    <span class="comment">#  动态预测第二日的值时所需要的差分序列</span></div><div class="line">    <span class="keyword">global</span> last_data_shift_list <span class="comment">#这个序列在恢复过程中需要用到</span></div><div class="line">    shift_ts_list = []</div><div class="line">    last_data_shift_list = []</div><div class="line">    tmp_ts = ts</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> d:</div><div class="line">        last_data_shift_list.append(tmp_ts[-i])</div><div class="line">        <span class="keyword">print</span> last_data_shift_list</div><div class="line">        shift_ts = tmp_ts.shift(i)</div><div class="line">        shift_ts_list.append(shift_ts)</div><div class="line">        tmp_ts = tmp_ts - shift_ts</div><div class="line">    tmp_ts.dropna(inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> tmp_ts</div><div class="line"></div><div class="line"><span class="comment"># 还原操作</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_diff_recover</span><span class="params">(predict_value, d)</span>:</span></div><div class="line">    <span class="keyword">if</span> isinstance(predict_value, float):</div><div class="line">        tmp_data = predict_value</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            tmp_data = tmp_data + last_data_shift_list[-i<span class="number">-1</span>]</div><div class="line">    <span class="keyword">elif</span> isinstance(predict_value, np.ndarray):</div><div class="line">        tmp_data = predict_value[<span class="number">0</span>]</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            tmp_data = tmp_data + last_data_shift_list[-i<span class="number">-1</span>]</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        tmp_data = predict_value</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                tmp_data = tmp_data.add(shift_ts_list[-i<span class="number">-1</span>])</div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'What you input is not pd.Series type!'</span>)</div><div class="line">        tmp_data.dropna(inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> tmp_data <span class="comment"># return np.exp(tmp_data)也可以return到最原始，tmp_data是对原始数据取对数的结果</span></div></pre></td></tr></table></figure>
<p>使用的时候，必须先调用diff_ts进行差分处理，然后进行建模，将预测数据传入predict_diff_recover方法进行还原。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">d=[<span class="number">1</span>, <span class="number">1</span>] <span class="comment"># 定义差分序列</span></div><div class="line">ts_log = np.log(ts)</div><div class="line">diffed_ts = diff_ts(ts_log, d) </div><div class="line"><span class="comment"># model = arima_model(diffed_ts)构建模型</span></div><div class="line">predict_ts = model.properModel.predict() <span class="comment">#预测，这是对训练数据的预测</span></div><div class="line">diff_recover_ts = predict_diff_recover(predict_ts, d)</div><div class="line">log_recover = np.exp(diff_recover_ts) <span class="comment">#恢复对数前数据，该数据可以和原始数据ts进行作图对比</span></div></pre></td></tr></table></figure>
<p>差分阶数的选择通常越小越好，只要能够使得序列稳定就行。我们可以通过选择不同的阶数，然后进行平稳性检测，选择平稳性表现良好的阶数就行，一般一阶和二阶用的比较多。</p>
<h3 id="p和q选择"><a href="#p和q选择" class="headerlink" title="p和q选择"></a>p和q选择</h3><p>　　差分阶数确定后，我们需要确定p和q. 对于个数不多的时序数据，我们可以通过观察自相关图和偏相关图来进行模型识别，倘若我们要分析的时序数据量较多，例如要预测每只股票的走势，我们就不可能逐个去调参了。这时我们可以依据BIC准则识别模型的p, q值，通常认为BIC值越小的模型相对更优。这里我简单介绍一下BIC准则，它综合考虑了残差大小和自变量的个数，残差越小BIC值越小，自变量个数越多BIC值越大。个人觉得BIC准则就是对模型过拟合设定了一个标准。当然，我们也可以使用AIC指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#注意这里面使用的ts_log_diff是经过合适阶数的差分之后的数据，上文中提到ARIMA该开源库，不支持3阶以上的#差分。所以我们需要提前将数据差分好再传入</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARMA</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_proper_model</span><span class="params">(ts_log_diff, maxLag)</span>:</span></div><div class="line">    best_p = <span class="number">0</span> </div><div class="line">    best_q = <span class="number">0</span></div><div class="line">    best_bic = sys.maxint</div><div class="line">    best_model=<span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> np.arange(maxLag):</div><div class="line">        <span class="keyword">for</span> q <span class="keyword">in</span> np.arange(maxLag):</div><div class="line">            model = ARMA(ts_log_diff, order=(p, q))</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                results_ARMA = model.fit(disp=<span class="number">-1</span>)</div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            bic = results_ARMA.bic</div><div class="line">            <span class="keyword">print</span> bic, best_bic</div><div class="line">            <span class="keyword">if</span> bic &lt; best_bic:</div><div class="line">                best_p = p</div><div class="line">                best_q = q</div><div class="line">                best_bic = bic</div><div class="line">                best_model = results_ARMA</div><div class="line">    <span class="keyword">return</span> best_p,best_q,best_model</div><div class="line">_proper_model(ts_log_diff, <span class="number">10</span>) <span class="comment">#对一阶差分求最优p和q</span></div></pre></td></tr></table></figure>
<p>通过上述方法可以得到最优的p和q。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>我们使用一阶差分进行构建。</p>
<h3 id="AR-p-模型"><a href="#AR-p-模型" class="headerlink" title="AR(p)模型"></a>AR(p)模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># AR模型，q=0</span></div><div class="line"><span class="comment">#RSS是残差平方和</span></div><div class="line"><span class="comment"># disp为-1代表不输出收敛过程的信息，True代表输出</span></div><div class="line">model = ARIMA(ts_log,order=(<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>)) <span class="comment">#第二个参数代表使用了一阶差分</span></div><div class="line">results_AR = model.fit(disp=<span class="number">-1</span>)</div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_AR.fittedvalues, color=<span class="string">'red'</span>) <span class="comment">#红色线代表预测值</span></div><div class="line">plt.title(<span class="string">'RSS:%.4f'</span> % sum((results_AR.fittedvalues-ts_log_diff)**<span class="number">2</span>))<span class="comment">#残差平方和</span></div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima23.jpg" alt="arma"></p>
<h3 id="MA-q-模型"><a href="#MA-q-模型" class="headerlink" title="MA(q)模型"></a>MA(q)模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#MA模型 p=0</div><div class="line">model = ARIMA(ts_log,order=(0,1,1))</div><div class="line">results_MA = model.fit(disp=-1)</div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_MA.fittedvalues, color=&apos;red&apos;)</div><div class="line">plt.title(&apos;RSS: %.4f&apos;% sum((results_MA.fittedvalues-ts_log_diff)**2))</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima24.jpg" alt="arma"></p>
<h3 id="ARIMA-p-q-模型"><a href="#ARIMA-p-q-模型" class="headerlink" title="ARIMA(p,q)模型"></a>ARIMA(p,q)模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#ARIMA</span></div><div class="line">model = ARIMA(ts_log, order=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))  </div><div class="line">results_ARIMA = model.fit(disp=<span class="number">-1</span>)  <span class="comment">#不展示信息</span></div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_ARIMA.fittedvalues, color=<span class="string">'red'</span>)<span class="comment">#和下面这句结果一样</span></div><div class="line">plt.plot(results_ARIMA.predict(), color=<span class="string">'black'</span>)<span class="comment">#predict得到的就是fittedvalues，只是差分的结果而已。还需要继续回退</span></div><div class="line">plt.title(<span class="string">'RSS: %.4f'</span>% sum((results_ARIMA.fittedvalues-ts_log_diff)**<span class="number">2</span>))</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima25.jpg" alt="arma"></p>
<p>可以发现，ARIMA在AR和MA基础上，RSS有所减少，故模型有所提高。</p>
<p>我们使用上文中提高的p和q选择方法，对一阶差分结果进行p和q选择。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">_proper_model(ts_log_diff, <span class="number">9</span>)</div><div class="line"><span class="comment"># 输出最优结果如下：</span></div><div class="line">(<span class="number">8</span>, <span class="number">7</span>, &lt;statsmodels.tsa.arima_model.ARMAResultsWrapper at <span class="number">0xb4e2898</span>&gt;)</div></pre></td></tr></table></figure>
<p>故可以使用p=8,q=7再次进行测试。得到如下结果：</p>
<p><img src="/picture/machine-learning/arima27.jpg" alt="arma"></p>
<p>可以发现，残差平方和RSS已经优化到0.40了。</p>
<h2 id="数据还原"><a href="#数据还原" class="headerlink" title="数据还原"></a>数据还原</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">ts_log_diff = diff_ts(ts_log, d=[1])#调用差分方法，方便后续还原</div><div class="line">model = ARIMA(ts_log, order=(8, 1, 7))  #建模</div><div class="line">results_ARIMA = model.fit(disp=-1)  #fit</div><div class="line">predict_ts = model.predict() #对训练数据进行预测</div><div class="line"></div><div class="line">#还原</div><div class="line">diff_recover_ts = predict_diff_recover(predict_ts, d=[1])#恢复数据</div><div class="line">log_recover = np.exp(diff_recover_ts)#还原对数前数据</div><div class="line"></div><div class="line">#绘图</div><div class="line">#ts = ts[log_recover.index]#排除空的数据</div><div class="line">plt.plot(ts,color=&quot;blue&quot;,label=&apos;Original&apos;)</div><div class="line">plt.plot(log_recover,color=&apos;red&apos;,label=&apos;Predicted&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.title(&apos;RMSE: %.4f&apos;% np.sqrt(sum((log_recover-ts)**2)/len(ts)))#RMSE,残差平方和开根号，即标准差</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima28.jpg" alt="arma"></p>
<h2 id="预测未来走势"><a href="#预测未来走势" class="headerlink" title="预测未来走势"></a>预测未来走势</h2><p>使用forecast进行预测，参数为预测值个数。这个得到的就是进行自动差分还原后的数据，因为我们建立模型的时候ARIMA(p,1,q), 第二个参数就是差分阶数，forecast会将结果恢复回差分前的数据，因此我们直接将结果通过np.exp来恢复到最原始数据即可。但是ARIMA只支持最多2阶差分，因此我们可以使用ARMA模型，将我们手动差分完的数据传入。最后预测的时候，使用我们自定义的差分还原方法，对预测得到的值进行差分还原。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># forecast方法会自动进行差分还原，当然仅限于支持的1阶和2阶差分</div><div class="line">forecast_n = 12 #预测未来12个月走势</div><div class="line">forecast_ARIMA_log = results_ARIMA.forecast(forecast_n)</div><div class="line">forecast_ARIMA_log = forecast_ARIMA_log[0]</div><div class="line">print forecast_ARIMA_log</div><div class="line"></div><div class="line">##如下是差分还原后的数据：</div><div class="line">[6.15487901  6.12150398  6.13788758  6.19511156  6.27419885  6.40259838</div><div class="line">  6.57706431  6.49128697  6.35429917  6.2679321   6.13597822  6.18507789</div><div class="line">  6.26245365  6.24740859  6.24775066  6.29778253  6.3935587   6.54015482</div><div class="line">  6.67409705  6.62124844]</div></pre></td></tr></table></figure>
<p>我们希望能够将预测的数据和原来的数据绘制在一起，为了实现这一目的，我们需要增加数据索引，使用开源库arrow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#定义获取连续时间，start是起始时间，limit是连续的天数,level可以是day,month,year</span></div><div class="line"><span class="keyword">import</span> arrow</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_date_range</span><span class="params">(start, limit, level=<span class="string">'month'</span>,format=<span class="string">'YYYY-MM-DD'</span>)</span>:</span></div><div class="line">    start = arrow.get(start, format)  </div><div class="line">    result=(list(map(<span class="keyword">lambda</span> dt: dt.format(format) , arrow.Arrow.range(level, start, 		   limit=limit))))</div><div class="line">    dateparse2 = <span class="keyword">lambda</span> dates:pd.datetime.strptime(dates,<span class="string">'%Y-%m-%d'</span>)</div><div class="line">    <span class="keyword">return</span> map(dateparse2, result)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 预测从1961-01-01开始，也就是我们训练数据最后一个数据的后一个日期</div><div class="line">new_index = get_date_range(&apos;1961-01-01&apos;, forecast_n)</div><div class="line">forecast_ARIMA_log = pd.Series(forecast_ARIMA_log, copy=True, index=new_index)</div><div class="line">print forecast_ARIMA_log.head()</div><div class="line"></div><div class="line"># 直接取指数，即可恢复至原数据</div><div class="line">forecast_ARIMA = np.exp(forecast_ARIMA_log)</div><div class="line">print forecast_ARIMA</div><div class="line">plt.plot(ts,label=&apos;Original&apos;,color=&apos;blue&apos;)</div><div class="line">plt.plot(forecast_ARIMA, label=&apos;Forcast&apos;,color=&apos;red&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.title(&apos;forecast&apos;)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima29.jpg" alt="arma"></p>
<p><strong>遗留问题：</strong></p>
<p>如果直接将差分处理的结果传入ARMA模型，再进行forecast预测，如何对预测的结果进行还原至原始序列？</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/" target="_blank" rel="external">Complete guide to create a Time Series Forecast (with Codes in Python)</a></p>
<p><a href="http://www.cnblogs.com/foley/p/5582358.html" target="_blank" rel="external">时间序列分析</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面花了两章篇幅介绍了时间序列模型的数学基础。 &lt;a href=&quot;/2017/03/07/ARIMA时间序列模型/&quot;&gt;ARIMA时间序列模型(一)&lt;/a&gt;和&lt;a href=&quot;/2017/03/07/ARIMA时间序列模型-二/&quot;&gt;ARIMA时间序列模型(二)&lt;/a&gt; 。本文重点介绍使用python开源库进行时间序列模型实践。&lt;/p&gt;
&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;回顾一下自回归移动平均模型ARMA，它主要由两部分组成：AR代表p阶自回归过程，MA代表q阶移动平均过程，形式如下：&lt;br&gt;$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\&lt;br&gt;+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$&lt;br&gt;为了方便，我们重写以上等式为：&lt;br&gt;$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\&lt;br&gt;其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$&lt;br&gt;$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$&lt;br&gt;$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$&lt;br&gt;根据前两篇的分析，我们总结ARMA模型的性质如下：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/arima5.jpg&quot; alt=&quot;arima&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
  </entry>
  
  <entry>
    <title>ARIMA时间序列模型(二)</title>
    <link href="xtf615.com/2017/03/07/ARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B-%E4%BA%8C/"/>
    <id>xtf615.com/2017/03/07/ARIMA时间序列模型-二/</id>
    <published>2017-03-07T05:49:28.000Z</published>
    <updated>2017-03-11T05:05:41.860Z</updated>
    
    <content type="html"><![CDATA[<p>　　前面我们介绍了时间序列模型的概念、数学基础等。本文将接着介绍时间序列模型的更多理论性质，包括一般线性过程(general linear process)，自回归模型AR(the autoregressive model),移动平均模型MA(the moving average)以及ARMA模型。</p>
<h1 id="一般线性过程"><a href="#一般线性过程" class="headerlink" title="一般线性过程"></a>一般线性过程</h1><h2 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h2><ul>
<li>时间序列\({Z_t}\)是线性(linear)的，当且仅当\(Z_t\)的值是白噪声系列的线性函数。</li>
<li>时间序列\({Z_t}\)是有因果的(causal),当且仅当\(Z_t\)的值只受到目前为止的信息影响，换句话说\(Z_t\)是独立于未来信息\(a_s\)的，s&gt;t</li>
<li>时间序列模型通常是由白噪声驱动的，即\({a_t}\), 时间序列是\({a_t}\)的函数。随机变量\(a_t\)可以被时刻t的信息所解释。白噪声通常叫做新息序列（innovation sequence）或信息序列(information sequence).</li>
</ul>
<p>因此，一个线性的、有因果的、平稳的时间序列也被称作一般线性过程(a general linear process)。</p>
<p>一般线性过程具有如下形式：<br>$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2} \\\\<br>其中，{a_t} \sim WN(0,\sigma_a^2) \ and \  \sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&lt;\infty$$<br>不失一般性，我们可以设\(\psi_0=1\)<br><a id="more"></a>  </p>
<h2 id="均值，自协方差，自相关系数"><a href="#均值，自协方差，自相关系数" class="headerlink" title="均值，自协方差，自相关系数"></a>均值，自协方差，自相关系数</h2><p>一般线性过程：<br>$$E(Z_t)=\mu$$<br>$$\gamma_0=var(Z_t)=\sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&lt;\infty$$<br>$$\gamma_k=cov(Z_t,Z_{t-k})=\sigma_a^2\sum_{j=0}^{\infty}\psi_j\psi_{j+k},k \geq 0$$<br>$$\rho_k=\frac{cov(Z_t,Z_{t-k})}{var(Z_t)}=\frac{\sum_{j=0}^{\infty}\psi_j\psi_{j+k}}{\sum_{j=0}^{\infty}\psi_j^2},k &gt; 0$$</p>
<h1 id="移动平均MA过程"><a href="#移动平均MA过程" class="headerlink" title="移动平均MA过程"></a>移动平均MA过程</h1><p>定义：q阶移动平均过程，简记为：<br>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q} \\\\<br>其中，q \in \mathbb{N}, 并且 {a_t} \sim WN(0,\sigma_a^2)$$</p>
<ul>
<li>如果\(\theta_0=0\)，则0阶移动平均过程实际上就是白噪声序列，此时\(Z_t=a_t\)</li>
<li>移动平均过程是一种特殊的一般线性过程。因为它是线性，因果和平稳的</li>
</ul>
<h2 id="一阶移动平均过程MA（1）"><a href="#一阶移动平均过程MA（1）" class="headerlink" title="一阶移动平均过程MA（1）"></a>一阶移动平均过程MA（1）</h2><p>$$Z_t=\theta_0+a_t-\theta a_{t-1}$$</p>
<ul>
<li>显然，\(E(Z_t)=\theta_0\)</li>
<li>\(\gamma_0=var(Z_t)=\sigma_a^2(1+\theta^2)\)</li>
<li>\(\gamma_1=cov(Z_t,Z_{t-1})=cov(a_t-\theta a_{t-1},a_{t-1}-\theta a_{t-2}) = cov(-\theta a_{t-1},-\theta a_{t-2})=-\theta \sigma_a^2\)</li>
<li>\(\rho_1 = \frac{-\theta}{1+\theta^2}\)</li>
<li>\(\rho_2=cov(Z_t,Z_{t-2})=cov(a_t-\theta a_{t-1},a_{t-2}-\theta a_{t-3})=0\)</li>
<li>同理，因为\(Z_t和Z_{t-2}\)之间不存在共同的下标,故\(\rho_2=0\)</li>
<li>故当\(k \geq 2\)时，\(\gamma_k=cov(Z_t,Z_{t-k})=0, 并且 \rho_k=0\)，即这一过程在超过滞后1,就不存在相关性。这一事实在我们后续为实际数据选择合适的模型时会起到很重要作用。</li>
</ul>
<h2 id="二阶移动平均过程MA（2）"><a href="#二阶移动平均过程MA（2）" class="headerlink" title="二阶移动平均过程MA（2）"></a>二阶移动平均过程MA（2）</h2><p>$$Z_t=\theta_0+a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2}$$</p>
<ul>
<li>显然，\(E(Z_t)=\theta_0\)</li>
<li>方差\(\gamma_0=var(Z_t)=(1+\theta_1^2+\theta_2^2)\sigma_a^2\)</li>
<li>滞后k=1的自协方差:<br>$$\gamma_1=cov(Z_t,Z_{t-1})=cov(a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2},a_{t-1}-\theta_1 a_{t-2}-\theta_2 a_{t-3})=cov(-\theta_1 a_{t-1},a_{t-1}) + cov(-\theta_2 a_{t-2},-\theta_1 a_{t-2})=[-\theta_1+(-\theta_1)(-\theta_2)]\sigma_a^2=(-\theta_1+\theta_1 \theta_2)\sigma_a^2$$</li>
<li>滞后k=2的自协方差为：<br>$$\gamma_2=cov(Z_t,Z_{t-2})=cov(a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2},a_{t-2}-\theta_1 a_{t-3}-\theta_2 a_{t-4})=cov(-\theta_2 a_{t-2}, a_{t-2})=-\theta_2 \sigma_a^2$$</li>
<li>同理相关系数，\(\rho_k=0, \forall k \geq 3\)</li>
</ul>
<p>$$ \begin{eqnarray} \rho=\begin{cases} \rho_1=\frac{-\theta_1+\theta_1 \theta_2}{1+\theta_1^2+\theta_2^2} \cr \rho_2=\frac{-\theta_2}{1+\theta_1^2+\theta_2^2} \cr \rho_k=0, \forall k \geq 3 \end{cases} \end{eqnarray}$$</p>
<h2 id="q阶移动平均过程MA（q）"><a href="#q阶移动平均过程MA（q）" class="headerlink" title="q阶移动平均过程MA（q）"></a>q阶移动平均过程MA（q）</h2><p>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$</p>
<ul>
<li>均值\(\mu=\theta_0\)</li>
<li>方差\(\gamma_0=(1+\theta_1^2+\theta_2^2+…+\theta_q^2)\sigma_a^2\)</li>
<li>自协方差：<br>$$ \begin{eqnarray} \rho_k=\begin{cases} \frac{-\theta_k+\theta_1 \theta_{k+1}+\theta_2 \theta_{k+2}+…+\theta_{q-k} \theta_{q}}{1+\theta_1^2+\theta_2^2+…+\theta_q^2},k=1,2,…,q \cr 0, \forall k \geq q+1 \end{cases} \end{eqnarray}$$</li>
<li>自相关：<br>当k=q时,\(\rho_k \neq 0\); 当k&gt;q时，\(\rho_k=0\)<br><strong>我们通常说，q阶移动平均过程的自相关函数在q滞后截尾，即ACF会在lag=q时截尾(cuts off).</strong></li>
</ul>
<h2 id="后向移位算子"><a href="#后向移位算子" class="headerlink" title="后向移位算子"></a>后向移位算子</h2><p>任意时间序列上的后向移位算子B定义为：<br>\(BZ_t=Z_{t-1}\), \(B^kZ_t=B^{k-1}(BZ_t)=…=Z_{t-k}, \forall k \in \mathbb{Z}\)<br>因此，B(Z)是原始序列Z的滞后为1的序列。\(B^k(Z)是原始序列滞后为k的序列\)<br>特别的，\(B^0是单位算子，B^0Z=Z\)<br>因此：<br>移动平均过程：<br>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>可以被重写为：<br>$$Z_t=(1-\theta_1B-\theta_2B^2-…-\theta_qB^q)a_t=\theta(B)a_t$$<br>其中，\(\theta(x)=1-\theta_1x-…-\theta_qx^q\)是MA移动平均的特征多项式</p>
<h1 id="自回归过程AR"><a href="#自回归过程AR" class="headerlink" title="自回归过程AR"></a>自回归过程AR</h1><p>p阶自回归模型AR(p)定义为：<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t \\\\<br>其中，p \geq 0,且p为整数。 \phi是参数。{a_t} \sim WN(0,\sigma_a^2)<br>$$<br>模型可以被重写为：<br>$$\phi(B)Z_t=\theta_0+a_t \\\\<br>其中，\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p是AR的特征多项式$$</p>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>AR(p)模型有一个唯一的平稳性解，只有当下面AR特征方程的所有根都在单位圆外时。<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p=0$$</p>
<ul>
<li>求解唯一平稳性解叫做AR(p)自回归过程</li>
<li>上述条件称作平稳性条件</li>
<li>对于一个复杂的z值，如果\(\vert z \vert &gt; 1\),我们称它是在单位圆外。 </li>
<li>例子：找出AR(1)模型的平稳性条件：<br>  \(Z_t=\phi Z_{t-1}+a_t\)<br>  由上可得，\(1-\phi x=0\),则\(x=1/\phi\),因为需要满足|x|&gt;1，则我们有\(|\phi| &lt; 1\)</li>
<li>例子，找出AR(1),\(Z_t=0.5Z_{t-1}+a_t\)的一般线性过程形式：<br>由前面AR的特征多项式可得，<br>$$(1-0.5B)Z_t=a_t$$<br>因此可以根据等比数列求和性质得到如下式子<br>$$Z_t=\frac{1}{1-0.5B}a_t=(1+0.5B+0.5^2B^2+…)a_t$$<br>进一步得到，即一般线性过程形式：<br>$$Z_t=a_t+0.5a_{t-1}+0.5^2a_{t-2}+…$$<h2 id="一般平稳性条件"><a href="#一般平稳性条件" class="headerlink" title="一般平稳性条件"></a>一般平稳性条件</h2>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t \ (1)$$<br>必须满足如下条件：<br>$$ \begin{eqnarray} \begin{cases} \mu=\frac{1}{1-\phi_1-…-\phi_p} \cr \psi_1=\phi_1, \cr \psi_2=\phi_1\psi_1+\phi_2, \cr … \cr \psi_k=\phi_1\psi_{k-1}+\phi_2\psi_{k-2}+…+\phi_p\psi_{k-p} \end{cases} \end{eqnarray}$$<br>其中，\(\psi是一般线性过程的参数\)<br>一般线性过程是：<br>$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2}  \ (2)$$<br>要想满足平稳性，要求AR模型能够转换成一般线性过程的形式，因此通过比较(1),(2)式子，展开运算，可以得到上述一般平稳性条件</li>
</ul>
<h2 id="均值，自协方差，方差，自相关"><a href="#均值，自协方差，方差，自相关" class="headerlink" title="均值，自协方差，方差，自相关"></a>均值，自协方差，方差，自相关</h2><p>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t $$</p>
<ul>
<li>均值<br>我们对等式两边同时求均值：<br>$$\mu=\theta_0+\phi_1 \mu+\phi_2 \mu + …+ \phi_p \mu + 0$$<br>得到：<br>$$\mu = \frac{\theta_0}{1-\phi_1-\phi_2-…-\phi_p}$$<br>可以证明分母不为0.</li>
<li>自相关<br><img src="/picture/machine-learning/arima1.jpg" alt="arima"><br>将两个式子等式两边对应相乘，然后再等式两边同时求自相关，根据定义，可以得到上述3.3的式子。<br><img src="/picture/machine-learning/arima2.jpg" alt="arima"></li>
<li>方差<br><img src="/picture/machine-learning/arima4.jpg" alt="arima"><br><img src="/picture/machine-learning/arima3.jpg" alt="arima"><br>上述3.2式子和\(Z_t\)相乘后，再等式两边同时取方差，根据定义以及\(E(a_tZ_t)\)的推导，可以得到上述式子。</li>
</ul>
<h1 id="ARMA模型"><a href="#ARMA模型" class="headerlink" title="ARMA模型"></a>ARMA模型</h1><p>英文全称为，the mixed autoregressive-moving average model<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\<br>+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>我们称\({Z_t}\)是(p,q)阶混合自回归移动平均模型，简记为ARMA(p,q)<br>如果q=0，则模型退化为AR模型；如果p=0,则模型退化为MA模型。二者都是ARMA模型的特例。<br>为了方便，我们重写以上等式为：<br>$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\<br>其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$</p>
<p>定理：如果AR多项式等式\(\phi(x)=0\)所有根都在单位圆之外，那么ARMA(p,q)模型存在唯一的平稳性解。<br>当存在平稳性解时，ARMA模型具备如下形式:<br>$$Z_t=\mu+\sum_{j=0}^\infty \psi_j a_{t-j}$$</p>
<h2 id="如何求解ARMA模型平稳性条件？"><a href="#如何求解ARMA模型平稳性条件？" class="headerlink" title="如何求解ARMA模型平稳性条件？"></a>如何求解ARMA模型平稳性条件？</h2><p>考虑ARMA(1,1)，则：<br>$$Z_t=\phi Z_{t-1}+a_t-\theta a_{t-1}$$<br>比较上述式子的系数可以得到：<br>$$\psi_0 a_t+\psi_1 a_{t-1}+ \psi_2 a_{t-2}+ … \\\\<br>  = \phi \psi_0 a_{t-1} + \phi \psi_1 a_{t-2} + \phi \psi_2 a_{t-3} +…+a_t-\theta a_{t-1}$$<br>可以得出：<br>$$\psi_0=1$$<br>$$\psi_1=\phi \psi_0 - \theta = \phi - \theta$$<br>$$\psi_0=\phi \psi_1 = \phi^2-\phi \theta$$<br>$$…$$<br>$$\psi_k=\phi \psi_k = \phi^k - \phi^{k-1} \theta$$<br>一般的，对于ARMA(p,q),我们可以得到:<br>$$ \begin{eqnarray} \begin{cases} \psi_0=1 \cr \psi_1=-\theta_1+\phi_1, \cr \psi_2=-\theta_2+\phi_2+\phi_1 \psi_1, \cr … \cr \psi_j=\theta_j+ \phi_p \psi_{j-p}+ … + \phi_1 \psi_{j-1} \end{cases} \end{eqnarray}$$<br>而，<br>$$\mu=\frac{\theta_0}{1-\phi_1-\phi_2-…-\phi_p}$$<br>所以有：<br>$$Z_t=\mu+\sum_{j=0}^\infty \psi_j a_{t-j}$$</p>
<h2 id="可逆性"><a href="#可逆性" class="headerlink" title="可逆性"></a>可逆性</h2><ul>
<li><p>为什么需要可逆性？<br>  假设我们获取了100个观察值：<br>  $$z_1,z_2,…,z_{100}$$<br>  经过复杂的过程，我们得到了一个AR(1)模型:<br>  $$Z_t=0.6Z_{t-1}+a_t$$<br>  那么该如何解释结果呢？<br>  如果模型变成：<br>  $$Z_t=a_t-0.5a_{t-1}或者Z_t=0.3Z_{t-1}+a_t+0.2a_{t-1}$$<br>  又该如何解释呢？</p>
<ul>
<li>定义：如果时间序列\({Z_t}\)是可逆的，则：<br>$$a_t=\pi_0 Z_t+\pi_1 Z_{t-1}+\pi_2 Z_{t-2}+…$$<br>这个性质使得我们能够基于过去观察序列获取信息序列<br>不失一般性，我们令\(\pi_0=1\)<br>AR过程总是可逆的。</li>
<li>定理：ARMA或MA模型是可逆的，当且仅当MA特征方程的根都在单位圆外。<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_qx^q=0$$</li>
<li>定义：如果时间序列\({Z_t}\)是可逆的，则定义：<br>$$Z_t=a_t-\pi_1Z_{t-1}-\pi_2Z_{t-2}-…$$<br>为该时间序列的AR表示（autoregressive representation）。</li>
</ul>
</li>
</ul>
<p>注意：可以发现求解AR表示和求解AR或ARMA模型的唯一平稳性解方法是一样的，同样是需要比较方程两边的系数。<br>相反，求解AR或ARMA模型的唯一平稳性解也叫做AR或ARMA模型的MA表示。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　前面我们介绍了时间序列模型的概念、数学基础等。本文将接着介绍时间序列模型的更多理论性质，包括一般线性过程(general linear process)，自回归模型AR(the autoregressive model),移动平均模型MA(the moving average)以及ARMA模型。&lt;/p&gt;
&lt;h1 id=&quot;一般线性过程&quot;&gt;&lt;a href=&quot;#一般线性过程&quot; class=&quot;headerlink&quot; title=&quot;一般线性过程&quot;&gt;&lt;/a&gt;一般线性过程&lt;/h1&gt;&lt;h2 id=&quot;定义：&quot;&gt;&lt;a href=&quot;#定义：&quot; class=&quot;headerlink&quot; title=&quot;定义：&quot;&gt;&lt;/a&gt;定义：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;时间序列\({Z_t}\)是线性(linear)的，当且仅当\(Z_t\)的值是白噪声系列的线性函数。&lt;/li&gt;
&lt;li&gt;时间序列\({Z_t}\)是有因果的(causal),当且仅当\(Z_t\)的值只受到目前为止的信息影响，换句话说\(Z_t\)是独立于未来信息\(a_s\)的，s&amp;gt;t&lt;/li&gt;
&lt;li&gt;时间序列模型通常是由白噪声驱动的，即\({a_t}\), 时间序列是\({a_t}\)的函数。随机变量\(a_t\)可以被时刻t的信息所解释。白噪声通常叫做新息序列（innovation sequence）或信息序列(information sequence).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，一个线性的、有因果的、平稳的时间序列也被称作一般线性过程(a general linear process)。&lt;/p&gt;
&lt;p&gt;一般线性过程具有如下形式：&lt;br&gt;$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2} \\\\&lt;br&gt;其中，{a_t} \sim WN(0,\sigma_a^2) \ and \  \sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&amp;lt;\infty$$&lt;br&gt;不失一般性，我们可以设\(\psi_0=1\)&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
  </entry>
  
  <entry>
    <title>ARIMA时间序列模型(一)</title>
    <link href="xtf615.com/2017/03/07/ARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>xtf615.com/2017/03/07/ARIMA时间序列模型/</id>
    <published>2017-03-07T01:33:02.000Z</published>
    <updated>2017-03-10T09:27:51.452Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="时间序列是什么？"><a href="#时间序列是什么？" class="headerlink" title="时间序列是什么？"></a>时间序列是什么？</h2><p>定义：时间序列数据是按时间排序的观察序列，是目标在不同时间点下的一系列观察值。</p>
<p>所有的时间观察序列数据可以被标记为：\(z_1,z_2,…,z_T\) , 可以当作T个随机变量的一个实例：$$(Z_1,Z_2,..,Z_T)$$</p>
<p>进一步定义：时间序列是一系列按照时间排序的随机变量。通常定义为双无穷随机变量序列。标记为：\({Z_t,t \in \mathbb{Z}}\), 或者简记为：\({Z_t}\) 。时间序列是离散时间下的随机过程。</p>
<p>回顾线性模型，响应变量Y和多个因变量X，线性模型表示为：$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$</p>
<p>因变量X的信息是已知的，我们希望对响应变量Y做出推断。</p>
<p>在时间序列分析中，我们提出如下模型：$$Y_t=\beta_o+\beta_1Y_{t-1}+\varepsilon_t$$</p>
<p>在时间序列中，已知的信息包括：</p>
<ul>
<li>时间下标t</li>
<li>过去的信息</li>
</ul>
<p>两个典型的时间序列模型如下：</p>
<p>$$Z_t=a+bt+\varepsilon_t$$</p>
<p>and</p>
<p>$$Z_t=\theta_0+\phi Z_{t-1}+\varepsilon_t$$</p>
<p>它们分别对应于确定性模型和随机模型，本文将讨论后者。<br><a id="more"></a>  </p>
<h1 id="时间序列的均值，方差，协方差"><a href="#时间序列的均值，方差，协方差" class="headerlink" title="时间序列的均值，方差，协方差"></a>时间序列的均值，方差，协方差</h1><ul>
<li><p><strong>均值函数（The mean function）</strong>：对于一个时间序列\({Z_t,t \in Z}\), 均值函数或平均序列被定义为：</p>
<p>$$\mu_t = E(Z_t), \ t \in \mathbb{Z} $$</p>
<p>\(\mu_t\)是在t时刻的期望值，\(\mu_t\) 在不同时刻可以是不同的值。</p>
</li>
<li><p><strong>自协方差函数（The auto-covariance function）</strong>：简记为ACVF，定义为：</p>
<p>$$\gamma(t,s)=cov(Z_t,Z_s) \ t,s \in \mathbb{Z}$$</p>
<p>其中，</p>
<p>$$cov(Z_t,Z_s)=E[(Z_t-\mu_t)(Z_s-\mu_s)]=E(Z_tZ_s)-\mu_t\mu_s$$</p>
</li>
<li><p><strong>方差函数（The variance function）</strong>：特别是在s=t时，我们有：</p>
<p>$$\gamma(t,t)=cov(Z_t,Z_t)=var(Z_t)$$</p>
<p>这就是\({Z_t}\)的方差函数</p>
</li>
<li><p><strong>自相关函数（The auto-correlation function）</strong>：简记为ACF，定义为：</p>
<p>$$\rho(t,s)=corr(Z_t,Z_s),  \ t,s \in \gamma(t,s)=cov(Z_t,Z_s) \ t,s \in \mathbb{Z} $$</p>
<p>其中，</p>
<p>$$corr(Z_t,Z_s)=\frac{cov(Z_t,Z_s)}{\sqrt{var(Z_t)var(Z_s)}}=\frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}}$$</p>
<p><strong>ACVF和ACF有如下性质：</strong></p>
<p> ACVF:</p>
</li>
<li><p>\(\gamma(t,t)=var(Z_t)\)</p>
</li>
<li>\(\gamma(t,s)=\gamma(s,t)\)</li>
<li><p>\(\vert{\gamma(t,s)} \vert \leq \sqrt{\gamma(t,t)\gamma(s,s)} \)</p>
<p> ACF:</p>
</li>
<li><p>\(\rho(t,t)=1\)</p>
</li>
<li>\(\rho(t,s)=\rho(s,t)\)</li>
<li><p>\(\vert{\rho(t,s)}\vert \leq 1\)</p>
<p><strong>一些重要的性质：</strong></p>
</li>
</ul>
<p>$$cov(aX,Y)=acov(X,Y)$$</p>
<p>$$cov(X,aY+bZ)=acov(X,Y)+bcov(X,Z)$$</p>
<p>$$cov(c_1Y_1+c_2Y_2, d_1Z_1+d_2Z_2)=c_1d_1cov(Y_1,Z_1)+c_2d_1cov(Y_2,Z_1)+c_1d_2cov(Y_1,Z_2)+c_2d_2cov(Y_2,Z_2)$$</p>
<p>$$cov\left[\sum_{i=1}^m c_iY_i, \sum_{j=1}^n d_jZ_j\right]=\sum_{i=1}^m\sum_{j=1}^n c_id_jcov(Y_i,Z_j)$$</p>
<p>最后一条性质经常用到。</p>
<h2 id="随机游走"><a href="#随机游走" class="headerlink" title="随机游走"></a>随机游走</h2><p><strong>随机游走（The random walk）</strong>：令序列\({a_t, t \in \mathbb{N}}\) 是服从 \(i.i.d\)独立同分布的随机变量。每个变量都是零均值，方差为\(\sigma_a^2\), 随机游走过程\({Z_t, t \in \mathbb{N}}\)定义为：</p>
<p>$$Z_t = \sum_{j=1}^t a_j, \ t \in \mathbb{N}$$</p>
<p>另外，我们可以写作：</p>
<p>$$Z_t=Z_{t-1}+a_t, \ t \in \mathbb{N}, Z_0=0$$</p>
<ul>
<li>\({Z_t}\)均值函数为:</li>
</ul>
<p>$$\mu_t=E(Z_t)=E\left(\sum_{j=1}^t a_j\right)=\sum_{j=1}^tE(a_j)=0$$</p>
<ul>
<li>\({Z_t}\)方差函数为:</li>
</ul>
<p>$$\gamma(t,t)=var(Z_t)=var\left(\sum_{j=1}^t a_j\right)=\sum_{j=1}^t var(a_j)=t \cdot \sigma_a^2$$</p>
<p>注意到，这一过程，方差会随着时间线性增长。</p>
<ul>
<li><p>ACVF自协方差函数：对于一切\(t \leq s\),</p>
<p>$$\gamma(t,s)=cov(Z_t,Z_s) \\\\=cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^s a_j\right) \\\ =cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^t a_j + \sum_{j=t+1}^s a_j\right) \\\ =cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^t a_j\right) \\\\=var\left(\sum_{j=1}^t a_j\right) = t \cdot \sigma_a^2$$</p>
</li>
<li><p>ACF自相关函数，根据定义有：</p>
<p>$$\rho(t,s)=\frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}} \\\ = \frac{\sigma_at}{\sqrt{\sigma_a^2t \cdot \sigma_a^2s}} \\\ = \sqrt{t/s}, \ 1 \leq t \leq s$$</p>
<p>当s=t+1时，</p>
<p>$$\rho(t,t+1)=corr(Z_t,Z_{t+1})=\sqrt{t/(t+1)} \approx 1, \ 当t无穷大$$</p>
<p>​</p>
<p><strong>理解：随机游走可以看作，在时间轴上任意行走一步（大步或小步），是若干时刻的和。</strong></p>
</li>
</ul>
<h2 id="移动平均"><a href="#移动平均" class="headerlink" title="移动平均"></a>移动平均</h2><p><strong>移动平均（a moving average）</strong>：假设\({Z_t, t \in \mathbb{Z}}\) 定义为：</p>
<p>$$Z_t=a_t-0.5a_{t-1}, \ t \in \mathbb{Z}$$</p>
<p>同样，a满足独立同分布，零均值，方差为\(\sigma_a^2\)</p>
<ul>
<li><p>\({Z_t}\)均值函数为:</p>
<p>$$\mu_t=E(Z_t)=E(a_t)-0.5E(a_{t-1})=0, \ t \in \mathbb{Z}$$</p>
</li>
<li><p>\({Z_t}\)f方差函数为:</p>
<p>$$var(Z_t)=var(a_t-0.5a_{t-1})=\sigma_a^2+0.5^2\sigma_a^2=1.25\sigma_a^2$$</p>
</li>
<li><p>ACVF自协方差函数：</p>
<p>$$cov(Z_t,Z_{t-1})=cov(a_t-0.5a_{t-1},a_{t-1}-0.5a_{t-2})=cov(a_t,a_{t-1})-0.5cov(a_t,a_{t-2})-0.5cov(a_{t-1},a_{t-1})-0.5cov(a_{t-1},a_{t-1})+0.5^2cov(a_{t-1},a_{t-2})=-0.5cov(a_{t-1},a_{t-1})$$</p>
<p>或者表示为：</p>
<p>$$\gamma(t,t-1)=-0.5\sigma_a^2,   \forall t \in \mathbb{Z}$$</p>
<p>对任意\(k \geq 2\),</p>
<p>$$cov(Z_t, Z_{t-k})=0$$</p>
<p>或者表示为，$$\gamma(t,t-k)=0, \ \forall  k \geq 2,t \in \mathbb{Z}$$</p>
</li>
<li><p>ACF自相关函数：</p>
<p>$$\rho(t,s)=-0.4,   if  \ \vert{t-s}\vert = 1 \\\ \rho(t,s)=0, if \ \vert{t-s}\vert \geq 2$$</p>
<p><strong>理解：移动平均可以看作，若干时刻的线性组合。</strong></p>
</li>
</ul>
<h1 id="平稳性"><a href="#平稳性" class="headerlink" title="平稳性"></a>平稳性</h1><p><strong>强平稳性（strict stationarity）要求：</strong>时间序列\({Z_t}\)为强平稳，只有当对任意的自然数n, 任意的时间点\(t_1\),\(t_2\),..,\(t_n\)以及任意的滞后k, 都满足\(Z_{t_1}\),\(Z_{t_2}\),…,\(Z_{t_n}\)的联合分布 和\(Z_{t_1-k}\),\(Z_{t_2-k}\),…,\(Z_{t_n-k}\)相同。</p>
<p><strong>弱平稳性(weak stationarity)要求</strong>：时间序列为弱平稳性，只有当均值函数\(\mu_t\)不随时间变化，并且对于任意的时间t和任意的滞后k，都有\(\gamma(t,t-k)=\gamma(0,k)\)</p>
<p>对于弱平稳性，有如下标志：</p>
<p>$$\mu = E(Z_t)$$</p>
<p>$$\gamma_k=cov(Z_t, Z_{t-k}), \ (\gamma_{-k}=\gamma_k)$$</p>
<p>$$\rho_k=Corr(Z_t,Z_{t-k}); \ (\rho_{-k}=\rho_k)$$</p>
<p>强平稳性和弱平稳性关系如下：</p>
<ol>
<li>强平稳性+有限的秒时刻 =&gt; 弱平稳性</li>
<li>时间序列的联合分布为多元正太分布，那么这两种定义是一致的</li>
</ol>
<h2 id="白噪声"><a href="#白噪声" class="headerlink" title="白噪声"></a>白噪声</h2><p><strong>白噪声（White noise）</strong>：一个很重要的关于平稳性处理的例子就是所谓的白噪声处理。它被定义为满足独立同分布的随机变量\({a_t}\), 零均值并且方差为\(\sigma_a^2&gt;0\), 简记为：\(WN(0,\sigma_a^2)\)</p>
<p>显然，\({a_t}\)满足强平稳性要求。</p>
<p>对于弱平稳性，注意到\(\mu_t=E(a_t)=0\)是一个常数，并且，</p>
<p>$$ \begin{eqnarray} \gamma(t;t-k)=\begin{cases} \sigma_a^2, k=0 \cr 0, k \neq 0 \end{cases} \end{eqnarray} :=\gamma_k$$,</p>
<p>$$\begin{eqnarray} \rho_k=\begin{cases} 1, k=0 \cr 0, k \neq 0 \end{cases} \end{eqnarray} $$</p>
<p>有些书中定义白噪声为一系列不相关的随机变量。</p>
<p>前面我们提高的随机游走，由于\({Z_t}\)的方差受时间影响线性变化\(var(Z_t)=t\sigma_a^2\)，并且协方差\(\gamma(t,s)=t\sigma_a^2\), 因此不仅仅受滞后k的影响，故不是平稳的时间序列。</p>
<p>令，$$X_t=\nabla Z_t=Z_t-Z_{t-1}$$</p>
<p>则\(X_t=a_t\), \({\nabla Z_t}\)是平稳的。</p>
<p>前面我们还提到移动平均。是由白噪声构成的一个非平凡平稳时间序列。在前面那个例子里，我们有：</p>
<p>$$\begin{eqnarray} \rho_k=\begin{cases} 1, k=0 \cr -0.4, k \pm 1 \cr 0, \vert k \vert \geq 2  \end{cases} \end{eqnarray}$$</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;时间序列是什么？&quot;&gt;&lt;a href=&quot;#时间序列是什么？&quot; class=&quot;headerlink&quot; title=&quot;时间序列是什么？&quot;&gt;&lt;/a&gt;时间序列是什么？&lt;/h2&gt;&lt;p&gt;定义：时间序列数据是按时间排序的观察序列，是目标在不同时间点下的一系列观察值。&lt;/p&gt;
&lt;p&gt;所有的时间观察序列数据可以被标记为：\(z_1,z_2,…,z_T\) , 可以当作T个随机变量的一个实例：$$(Z_1,Z_2,..,Z_T)$$&lt;/p&gt;
&lt;p&gt;进一步定义：时间序列是一系列按照时间排序的随机变量。通常定义为双无穷随机变量序列。标记为：\({Z_t,t \in \mathbb{Z}}\), 或者简记为：\({Z_t}\) 。时间序列是离散时间下的随机过程。&lt;/p&gt;
&lt;p&gt;回顾线性模型，响应变量Y和多个因变量X，线性模型表示为：$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$&lt;/p&gt;
&lt;p&gt;因变量X的信息是已知的，我们希望对响应变量Y做出推断。&lt;/p&gt;
&lt;p&gt;在时间序列分析中，我们提出如下模型：$$Y_t=\beta_o+\beta_1Y_{t-1}+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;在时间序列中，已知的信息包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时间下标t&lt;/li&gt;
&lt;li&gt;过去的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两个典型的时间序列模型如下：&lt;/p&gt;
&lt;p&gt;$$Z_t=a+bt+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$Z_t=\theta_0+\phi Z_{t-1}+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;它们分别对应于确定性模型和随机模型，本文将讨论后者。&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
      <category term="ARMA" scheme="xtf615.com/tags/ARMA/"/>
    
  </entry>
  
  <entry>
    <title>神经网络(系列2)</title>
    <link href="xtf615.com/2017/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%B3%BB%E5%88%972/"/>
    <id>xtf615.com/2017/02/17/神经网络-系列2/</id>
    <published>2017-02-17T08:28:37.000Z</published>
    <updated>2017-02-18T07:50:10.027Z</updated>
    
    <content type="html"><![CDATA[<p>神经网络的入门知识参见<a href="/2017/02/13/神经网络/">神经网络(系列1)</a><br>本文主要对神经网络进行深入，探讨神经网络模型的学习。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>首先引入一些便于稍后讨论的新标记方法：<br>假设神经网络的训练样本有m个，每个包含一组输入x和一组输出信号y，L表示神经网络层数，\(S_l\)表示每层的neuron个数(\(S_L\)表示输出层神经元个数),(\(S_L\)代表最后一层中处理单元的个数。<br>将神经网络的分类定义为两种情况：二类分类和多类分类:<br>二类分类：\(S_L=1\), y=0 or 1表示哪一类；<br>K类分类：\(S_L=K\),  \(y_i = 1\)表示分到第i类；（K&gt;2）<br><img src="/picture/machine-learning/network_learn1.jpg" alt="network_learn"><br>我们回顾逻辑回归问题中我们的代价函数为：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$<br>在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，我们可以有很多输出变量，我们的\(h_θ(x)\)是一个维度为K的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：<br>$$J(\Theta)=-\frac{1}{m}\Big[\sum_{i=1}^m\sum_{k=1}^K\left(y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)\right)\Big] \\\ + \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2$$<br><img src="/picture/machine-learning/network_learn2.jpg" alt="network_learn"><br>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个。<br>注意：j循环所有的行（由\(s_{l+1}\)层的激活单元数决定,l+1整体是下标），循环i则循环所有的列，由该层（\(s_l\)层）的激活单元数所决定。<br><a id="more"></a></p>
<h1 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h1><p>之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的\(h_θ(x)\)。<br>现在，为了计算代价函数的偏导数\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\),我们需要采用新的方法。</p>
<h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><p>机器学习可以看做是数理统计的一个应用，在数理统计中一个常见的任务就是拟合，也就是给定一些样本点，用合适的曲线揭示这些样本点随着自变量的变化关系。<br>深度学习同样也是为了这个目的，只不过此时，样本点不再限定为(x, y)点对，而可以是由向量、矩阵等等组成的广义点对(X,Y)。而此时，(X,Y)之间的关系也变得十分复杂，不太可能用一个简单函数表示。然而，人们发现可以用多层神经网络来表示这样的关系，而多层神经网络的本质就是一个多层复合的函数。<br><img src="/picture/machine-learning/network11.jpg" alt="network_learn"><br>对应的表达式如下：<br>$$a_1^{(2)}=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3) \\\\<br>a_2^{(2)}=g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3) \\\\<br>a_3^{(2)}=g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3)$$<br>$$h_{\Theta}(x)=a_1^{(3)}=g(\Theta_{10}^{(2)}a_0^{(2)}+\Theta_{11}^{(2)}a_1^{(2)}+\Theta_{12}^{(2)}a_2^{(2)}+\Theta_{13}^{(2)}a_3^{(2)})$$<br>和直线拟合一样，深度学习的训练也有一个目标函数，这个目标函数定义了什么样的参数才算一组“好参数”，不过在机器学习中，一般是采用成本函数（cost function），然后，训练目标就是通过调整每一个权值\(\Theta_{ij}\)来使得cost达到最小。cost函数也可以看成是由所有待求权值\(\Theta_{ij}\)为自变量的复合函数，而且基本上是非凸的，即含有许多局部最小值。但实际中发现，采用我们常用的梯度下降法就可以有效的求解最小化cost函数的问题。<br>梯度下降法需要给定一个初始点，并求出该点的梯度向量，然后以负梯度方向为搜索方向，以一定的步长进行搜索，从而确定下一个迭代点，再计算该新的梯度方向，如此重复直到cost收敛。那么如何计算梯度呢？<br>假设我们把cost函数表示为\(J(\Theta_{11},\Theta_{12},\Theta_{13},\Theta_{ij},…,\Theta_{mn})\), 那么它的梯度向量就等于\(\nabla J = \frac{\partial J}{\partial \Theta_{11}}e_{11}+…+\frac{\partial J}{\partial \Theta_{mn}}e_{mn}\), 其中\(e_{ij}\)表示正交单位向量。为此，我们需求出cost函数J对每一个权值\(\Theta_{ij}\)的偏导数。<strong>而BP算法正是用来求解这种多层复合函数的所有变量的偏导数的利器。</strong><br>我们以求e=(a+b)*(b+1)的偏导为例。</p>
<p>它的复合关系画出图可以表示如下：<br><img src="/picture/machine-learning/network_learn4.png" alt="network_learn"><br>为了求出a=2,b=1时，e的梯度，我们可以先利用偏导数求出不同层之间的邻节点的偏导关系，如下图所示：<br><img src="/picture/machine-learning/network_learn5.png" alt="network_learn"><br>利用链式法则我们知道：<br>$$\frac{\partial e}{\partial a}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial a}$$<br>$$\frac{\partial e}{\partial b}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial b}+\frac{\partial e}{\partial d}\frac{\partial d}{\partial b}$$<br>链式法则在上图中的意义是什么呢？其实不难发现，\(\frac{\partial e}{\partial a}\)的值等于从a到e的路径上的偏导值的乘积，而\(\frac{\partial e}{\partial b}\)的值等于从b到e的路径1(b-c-e)上的偏导值的乘积加上路径2(b-d-e)上的偏导值的乘积。也就是说，对于上层节点p和下层节点q，要求得，需要找到从q节点到p节点的所有路径，并且对每条路径，求得该路径上的所有偏导数之乘积，然后将所有路径的 “乘积” 累加起来才能得到的值。<br>大家也许已经注意到，这样做是<strong>十分冗余</strong>的，因为很多路径被重复访问了。比如上图中，a-c-e和b-c-e就都走了路径c-e。<strong>对于权值动则数万的深度模型中的神经网络，这样的冗余所导致的计算量是相当大的。</strong><br>同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于<strong>每一个路径只访问一次</strong>就能求顶点对所有下层节点的偏导值。<br>正如反向传播(BP)算法的名字说的那样，BP算法是反向(自上往下)来寻找路径的。</p>
<p>从最上层的节点e开始，初始值为1，以层为单位进行处理。对于e的下一层的所有子节点，将1乘以e到某个节点路径上的偏导值，并将结果“堆放”在该子节点中。等e所在的层按照这样传播完毕后，第二层的每一个节点都“堆放”些值，然后我们针对每个节点，把它里面所有“堆放”的值求和，就得到了顶点e对该节点的偏导。然后将这些第二层的节点各自作为起始顶点，初始值设为顶点e对它们的偏导值，以”层”为单位重复上述传播过程，即可求出顶点e对每一层节点的偏导数。</p>
<p>以上图为例，节点c接受e发送的1*2并堆放起来，节点d接受e发送的1*3并堆放起来，至此第二层完毕，求出各节点总堆放量并继续向下一层发送。节点c向a发送2*1并对堆放起来，节点c向b发送2*1并堆放起来，节点d向b发送3*1并堆放起来，至此第三层完毕，节点a堆放起来的量为2，节点b堆放起来的量为2*1+3*1=5, 即顶点e对b的偏导数为5.</p>
<p>举个不太恰当的例子，如果把上图中的箭头表示欠钱的关系，即c→e表示e欠c的钱。以a, b为例，直接计算e对它们俩的偏导相当于a, b各自去讨薪。a向c讨薪，c说e欠我钱，你向他要。于是a又跨过c去找e。b先向c讨薪，同样又转向e，b又向d讨薪，再次转向e。可以看到，追款之路，充满艰辛，而且还有重复，即a, b 都从c转向e。</p>
<p>而BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜。</p>
<h2 id="路径合并"><a href="#路径合并" class="headerlink" title="路径合并"></a>路径合并</h2><p>将所有路径累加的问题在于，在可能的路径数中，很容易陷入爆炸式组合增长。<br><img src="/picture/machine-learning/network_learn10.png" alt="network_learn"><br>在上图中，从X到Y有3条路径，从Y到Z也有3条路径。如果要求\(\frac{\partial Z}{\partial X}\),我们需要把所有路径累加起来，也就是共9条路径。<br>$$\frac{\partial Z}{\partial X} = \alpha\delta + \alpha\epsilon + \alpha\zeta + \beta\delta + \beta\epsilon + \beta\zeta + \gamma\delta + \gamma\epsilon + \gamma\zeta$$<br>上图只有9条路径，但是随着图复杂程度的增加，路径数很容易呈现爆炸式增长。<br>和直接将所有路径累加相反，更好的方法是合并路径：<br>$$\frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)(\delta + \epsilon + \zeta)$$<br>这就是前向传播(forward-mode differentiation)和后向传播(reverse-mode differentiation)。它们都是通过合并路径的方法来更有效的计算路径和。和直接显示地把所有路径加起来不同，它们通过在每个节点上，向后合并路径的方式来更有效的计算路径和。实际上，两个方法每条边都只计算了一次。<br>前向传播起始于图的输入节点，一直向前直到最后一个节点。在每个节点上，它将传入(feed in)的每一条路径累加。每一条路径都代表了输入对该节点的影响。通过将它们累加起来，我们获得了不同输入对该节点总的影响。这就是导数的定义。<br><img src="/picture/machine-learning/network_learn11.png" alt="network_learn"><br>前向传播就像你刚刚入门微积分课程时学到的方法。而后向传播，起始于图的输出节点，一直向后直到第一个节点。在每一个节点上，将起源于(originated at)该节点的所有路径合并。<br><img src="/picture/machine-learning/network_learn12.png" alt="network_learn"><br>前向传播跟踪一个输入如何影响每一个节点。反向传播跟踪每一个节点如何影响一个输出节点。即，前向传播将\(\frac{\partial}{\partial X}\)应用到每一个节点(每个节点对输入求导)，而后向传播将\(\frac{\partial Z}{\partial}\)应用到每一个节点（输出对每个节点求导）。</p>
<h2 id="反向传播优势"><a href="#反向传播优势" class="headerlink" title="反向传播优势"></a>反向传播优势</h2><p>现在，我们可能会疑问，为什么人们更关心后向传播，它看起来似乎和前向传播差不多，那它的优势在哪?<br>让我们回到前面的那个例子中：<br><img src="/picture/machine-learning/network_learn5.png" alt="network_learn"><br>我们可以使用前向传播算法从b自底向上。我们需要求每个节点对b的导数。（即b如何影响每一个节点）<br><img src="/picture/machine-learning/network_learn13.png" alt="network_learn"><br>如果我们使用后向传播从e自顶向下，我们需要求e对每个节点的导数(即每个节点如何影响e)。<br><img src="/picture/machine-learning/network_learn14.png" alt="network_learn"><br>需要强调的是： 当我说反向传播给了我们e对每个节点的导数，需要强调的是确实是<strong>每个节点</strong>，我们得到了\(\frac{\partial e}{\partial a}\)和\(\frac{\partial e}{\partial b}\)，即e对每一个输入的导数。前向传播只给了我们单独的一个b的导数，但是后向传播给了我们所有的输入的导数。<br>对这幅图而言，只得到了2倍的加速比，想象一下如果有<strong>上百万的输入节点和1个输出节点</strong>,前向传播需要我们遍历这个图上百万次才能得到导数，而后向传播只需要遍历1次即可，这就得到了上百万的加速比。<br>在神经网络中，我们的代价函数经常拥有上百万个参数，因此反向传播能够让我们训练的速度大大提高。<br><strong>那前向传播什么时候适用呢？如果只有少量的输入，而拥有大量的输出，此时前向传播速度更快。</strong><br>补充：对信息的处理，分为前向和反向两种，即从因到果和从果到因。前者适合人类的思考模式，但对机器而言，它需要的是运算，显然，反向运算更便捷（如上中所说，这是有前提的，即输入因子多于输出因子，这也符合逻辑，当我们要做出一个判断、得出一个结论，总会从方方面面进行思考，然后在提取、凝练，即归纳、总结），就像梳理头发时，我们都是从发根向发梢梳理——头皮为一个质点，向发梢逐渐发散，从一到多、从总到分的梳理、计算过程。所以反向运算比较普及，是因为运算成本更低。</p>
<h2 id="反向传播算法-1"><a href="#反向传播算法-1" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p>我们的目标是为了计算代价函数的偏导数：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)$$<br>我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。<br>以一个例子来说明反向传播算法。<br>假设我们的训练集只有一个实例\((x^{(1)},y^{(1)})\),我们的神经网络是一个四层的神经网络，其中 K=4，SL=4，L=4：<br><img src="/picture/machine-learning/network_learn6.jpg" alt="network_learn"><br>前向传播算法：<br>$$a^{(1)}=x \\\\<br>z^{(2)}=\Theta^{(1)}a^{(1)} \\\\<br>a^{(2)}=g(z^{(2)}) (add \ a_0^{(2)}) \\\\<br>z^{(3)}=\Theta^{(2)}a^{(2)} \\\\<br>a^{(3)}=g(z^{3}) (add \ a_0^{(3)}) \\\\<br>z^{(4)}=\Theta^{(3)}a^{(3)} \\\\<br>a^{(4)}=h_\Theta(x)=g(z^{(4)})<br>$$<br>我们从最后一层的误差开始计算，误差是激活单元的预测值（\(a_k^{(4)}\)）与实际值（\(y^{k}\)）之间的误差.（k=1:K）<br>我们用\(\delta\)来表示误差，则：<br>$$\delta^{(4)}=a^{(4)}-y$$<br>我们利用这个误差值来计算前一层的误差:<br>$$\delta^{(3)}=(\Theta^{(3)})^T\delta^{(4)}.*g’(z^{(3)})$$<br>其中,\(g’(z^{(3)})\)为sigmoid函数的导数，\(g’(z^{(3)})=a^{(3)}*(1-a^{(3)})\)。而\((\Theta^{(3)})^T\delta^{(4)}\)则是权重导致的误差的和。<br>注意到：\((\Theta^{(3)})^T\)取了转置，正常\(\Theta\)例如：<br>$$\Theta=\begin{bmatrix} \Theta_{10} \ \Theta_{11} \ \Theta_{12} \ \Theta_{13}\\\ \Theta_{20} \ \Theta_{21} \ \Theta_{22} \ \Theta_{23}\\\ \Theta_{30} \ \Theta_{31} \ \Theta_{32} \ \Theta_{33}\end{bmatrix}$$<br>每一行都代表第j层的所有神经元到第j+1层某一个神经元的连线（权重）。例如第一行就代表第j层的所有神经元到第j+1层的第一个神经元的连线。而转置\(\Theta\)后，每一行代表第j层某一个神经元到第j+1层的所有神经元的连线，可以理解成j层某一个神经元导致的j+1层总误差的情况。<br>另外，.*即点乘，代表矩阵对应位置的数字相乘。<br>下一步是继续计算第二层的误差：<br>$$\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}.*g’(z^{(2)})$$<br>因为第一层为输入变量，不存在误差，我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设\(\lambda=0\)，即我们不做任何归一化处理的话：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}$$<br>重要的是清楚地知道上面式子中上下标的含义：<br>l代表目前所计算的是第几层<br>j代表目前计算层中的激活单元的下标，也将是下一层的第j个输入变量的下标。<br>i代表下一层中误差单元的下标，是受到权重矩阵中第i行影响的下一层中的误差单元的下标。<br>即：\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}\)是对第l层的第j个神经元到第l+1层的第i个神经元的连线（权重）求偏导。<br>\(a_j^{(l)}\)是第l层第j个神经元经过sigmoid函数计算后的值。<br>\(\delta_i^{l+1}\)是第l+1层第i个神经元的误差。<br>例如：<br><img src="/picture/machine-learning/network_learn7.jpg" alt="network_learn"><br>对图中红色的这条线求偏导：<br>$$\frac{\partial}{\partial \Theta_{41}^{(1)}}=a_1^{(1)}*\delta_4^{(2)}$$<br>如果我们考虑归一化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为<strong>整个训练集</strong>计算误差单元，此时的误差单元也是一个矩阵，我们用\(\Delta_{ij}\)来表示这个误差矩阵。第l层的第i个激活单元受到第j个参数影响而导致的误差。<br>我们的算法：<br><img src="/picture/machine-learning/network_learn8.jpg" alt="network_learn"><br>即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。<br>在求出\(\Delta_{ij}^{(l)}\)后，我们便可以计算代价函数的偏导数了，计算方法如下：<br><img src="/picture/machine-learning/network_learn9.jpg" alt="network_learn"></p>
<h2 id="反向传播理解"><a href="#反向传播理解" class="headerlink" title="反向传播理解"></a>反向传播理解</h2><h3 id="疑问1：为什么输出层的-delta-为-delta-L-a-L-y"><a href="#疑问1：为什么输出层的-delta-为-delta-L-a-L-y" class="headerlink" title="疑问1：为什么输出层的\(\delta\)为\(\delta^{(L)}=a^{(L)}-y\)?"></a>疑问1：为什么输出层的\(\delta\)为\(\delta^{(L)}=a^{(L)}-y\)?</h3><p>很多人认为输出层的偏差量就是计算值减实际值这么简单，又或者认为是线性回归代价函数求导的结果，即\(J(\Theta)=\frac{1}{2}(h_\Theta(x)-y)^2\),求导得到：\(\frac{\partial}{\partial a^{(L)}}J(\Theta)=a^{(L)}-y\)。其实不然，要知道我们的代价函数是逻辑回归的代价函数。详细见下面分析。</p>
<h3 id="疑问2：-Theta-l-T-delta-l-1-怎么理解？"><a href="#疑问2：-Theta-l-T-delta-l-1-怎么理解？" class="headerlink" title="疑问2：\((\Theta^{(l)})^T\delta^{(l+1)}\)怎么理解？"></a>疑问2：\((\Theta^{(l)})^T\delta^{(l+1)}\)怎么理解？</h3><p>所谓“偏差”应该这么理解：对于后一层某一个结点上出现的偏差，前一层的每一个结点都要承担一部分责任，所以我们可以把后一层结点的偏差量按照系数比例分配给前一层的结点。同时，前一层的某一个结点，对后一层的每一个节点都承担着责任，那么它的“总责任”就是这些所有的小责任之和。因此这里面矩阵的转置，我们前面也有提到，转置后的每一行实际上代表l层的某一个神经元到l+1层的每一个神经元的连线(权重)。和后一层的\(\delta^{(l+1)}\)进行矩阵乘后，实际上相当于l层的这个神经元分担掉l+1层所有神经元的这些小的误差，将这些小的误差之和作为自己的责任承担下来。如果你仔细想想这个矩阵乘法的计算过程，会发现正好就是上面说的这个责任分配与求和的过程。这就是【疑问2】的答案。</p>
<h3 id="疑问3：为什么前一层的-delta-l-和后一层的-delta-l-1-的关系是-delta-l-Theta-l-T-delta-l-1-g’-z-l-？"><a href="#疑问3：为什么前一层的-delta-l-和后一层的-delta-l-1-的关系是-delta-l-Theta-l-T-delta-l-1-g’-z-l-？" class="headerlink" title="疑问3：为什么前一层的\(\delta^{(l)}\)和后一层的\(\delta^{(l+1)}\)的关系是\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)？"></a>疑问3：为什么前一层的\(\delta^{(l)}\)和后一层的\(\delta^{(l+1)}\)的关系是\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)？</h3><p>可以发现，在疑问2的基础上，该式子还多了个因子\(.*g’(z^{(l)})\)。为什么呢？详细见下面分析。</p>
<h3 id="疑问4：为什么-delta-i-l-1-计算完后，还要乘以前一层的-a-j-l-后，才是偏导-frac-partial-partial-Theta-ij-l-J-Theta-的结果？"><a href="#疑问4：为什么-delta-i-l-1-计算完后，还要乘以前一层的-a-j-l-后，才是偏导-frac-partial-partial-Theta-ij-l-J-Theta-的结果？" class="headerlink" title="疑问4：为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果？"></a>疑问4：为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果？</h3><p>即，\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}\)详见下面。</p>
<h3 id="详细推导"><a href="#详细推导" class="headerlink" title="详细推导"></a>详细推导</h3><p>我们的目标是证明：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1} \\\\<br>其中,\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)}), \\\\可以取l=l+1,求得\delta^{(l+1)},\delta_i^{l+1}为\delta^{(l+1)}的第i个元素，即l+1层误差向量的第i个元素。<br>$$<br><strong>是对第\(l\)层的第\(j\)个神经元到第\(l+1\)层的第\(i\)个神经元的连线（权重）求偏导</strong>。<br>首先回顾一下前面的一些定义：<br>$$a^{(l+1)}=g(z^{(l+1)}) \\\\<br>g(z)=\frac{1}{1+e^{-z}} \\\\<br>z^{(l+1)}=\Theta^{(l)}a^{(l)} \\\\<br>其中,g(z)为sigmoid函数 \\\\<br>z^{(l+1)}代表l+1层经过l层权重加权后的结果 \\\\<br>a^{(l+1)}代表z^{(l+1)}经过sigmoid函数后的输出值 \\\\<br>$$<br>为了使用这些定义，我们可以将上面的偏微分式子使用链式法则展开：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}$$</p>
<ul>
<li>首先看最后一项：<br>$$z_i^{(l+1)}=\Theta_{1,i}^{(l)}a_1^{(l)}+\Theta_{2,i}^{(l)}a_2^{(l)}+…$$<br>所以：<br>$$\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}=a_j^{(l)}$$<br>顺便说一下，<strong>右边前两项的乘积，就是课程中引入的\(\delta\)的值</strong>。这就解释了【疑问4】中，为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果，即\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}\)</li>
<li><p>接下来第二项<br>这就是sigmoid函数的求导：<br>$$g’(z)=\frac{e^{-z}}{(1+e^{-z})^2}=\frac{1}{1+e^{-z}}*\frac{e^{-z}}{(1+e^{-z})}=g(z)(1-g(z))$$<br>根据定义:\(g(z^{(l)})=a^{(l)}\)<br>因此，我们\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)改写成：<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*a^{(l)}.*(1-a^{(l)})$$<br>这个式子留在下面【疑问1】的证明。</p>
</li>
<li><p>第一项<br>首先回顾下代价函数:<br>$$J(\Theta)=-ylog(h_\Theta(x))-(1-y)log(1-h_\Theta(x))$$<br>对输出层\(a^{(L)}\)求导：<br>$$\frac{\partial}{\partial a^{(L)}}J(\Theta)=\frac{a^{(L)}-y}{a^{(L)}-(a^{(L)})^2} \\\\<br>注意对于输出层，h_\Theta(x)=a^{(L)}$$<br>因此根据前面定义:\(\delta\)为前两项偏导的乘积，即<br>$$\delta^{(L)}=\frac{a^{(L)}-y}{a^{(L)}-(a^{(L)})^2}a^{(L)}(1-a^{(L)})=a^{(L)}-y$$<br>这就解决了【疑问1】中的疑惑。实际上并不是简单的相减，而只是凑巧结果是这样。<br>对于【疑问1】【疑问2】的推导，即<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})$$<br>根据前面定义:\(\delta\)为前两项偏导的乘积，<br>我们来看下面式子的前两项偏导，<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}$$<br>实际上前两项偏导结果就是：<br>$$\frac{\partial}{\partial z_{i}^{(l+1)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}$$<br>令\(l=l-1\),得到：<br>$$\frac{\partial}{\partial z_{i}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l)}}\frac{\partial a_i^{(l)}}{\partial z_i^{(l)}}$$<br>利用链式法则得到:<br>$$\delta_{j}^{(l)}=\frac{\partial}{\partial z_{j}^{(l)}}J(\Theta)=\sum_k \frac{\partial J(\Theta)}{\partial z_k^{(l+1)}}\frac{\partial z_k^{(l+1)}}{\partial a_j^{(l)}}\frac{\partial a_j^{(l)}}{\partial z_{j}^{(l)}} \\\\<br>=\sum_k \delta_k^{(l+1)} \frac{\partial (\Theta_{kj}^{(l)}a_j^{(l)})}{\partial a_j^{(l)}}g’(z_j^{(l)}) \\\\<br>=\sum_k \delta_k^{(l+1)}\Theta_{kj}^{(l)}g’(z_j^{(l)})$$</p>
</li>
</ul>
<p>1）上式是针对\(l\)层<strong>某一个神经元</strong>的求导，\(i\)(在这里k实际上就是l+1层神经元)代表\(l+1\)层神经元，\(j\)代表\(l\)层神经元。<br>2）求和相当于不同路径累加。<br>所以有：<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})$$<br>1）上式是求\(l\)层所有神经元误差的矩阵形式。<br>2）仔细看\(\Theta_{kj}^{(l)}\)的下标变换，从1开始\(\Theta_{1j}^{(l)}\)，\(\Theta_{2j}^{(l)}\)，\(\Theta_{3j}^{(l)}\)…,实际上就代表\(l\)层的第\(j\)个神经元到\(l+1\)层的所有神经元的连线（权重）。因为\(l+1\)层的神经元代表的是行，即下标中的第一个数字。实际上和\((\Theta^{(l)})^T\delta^{(l+1)}\)矩阵形式是一样的。<br>这就解决了【疑问2】【疑问3】<br><strong>结论</strong>：<br>还有很多人说为什么这个值和很多别的网站，包括维基百科上说的不一样啊？因为很多别的网站包括维基百科，cost函数用的是线性回归的那种，它的偏微分就和逻辑回归的cost函数有差别了。具体地说，就差在分母的那一项上\(a^{(L)}-(a^{(L)})^2\)</p>
<h2 id="反向传播演示"><a href="#反向传播演示" class="headerlink" title="反向传播演示"></a>反向传播演示</h2><p>说明：图片摘自网上，存在一定的偏差，实际上是一样的，只不过是写法的不同，重点在于<strong>整个过程以及箭头</strong>。首先进行前向传播计算，这里的\(w\)对应\(\Theta\),\(f\)对应\(g\)，即sigmoid函数，\(y\)对应\(a\),即sigmod的输出，\(e\)对应\(z\),即权重的线性组合结果。 \(\delta\)的计算式里的\(g’(z)\)项，图片中是放在最后梯度下降的时候求得导，即\(\frac{d_f}{d_e}\)。最后梯度下降公式中，不要忘记\(\delta\)还要乘以\(y\)，即我们上文讲到的\(a\)。<br><img src="/picture/machine-learning/network_learn_demo1.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo2.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo3.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo4.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo5.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo6.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo7.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo8.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo9.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo10.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo11.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo12.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo13.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo14.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo15.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo16.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo17.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo18.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo19.jpg" alt="demo"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://colah.github.io/posts/2015-08-Backprop/#fnref1" target="_blank" rel="external">Calculus on Computational Graphs: Backpropagation</a><br><a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="external">Principles of training multi-layer neural network using backpropagation</a><br><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="external">A Step by Step Backpropagation Example</a><br><a href="http://www.cs.toronto.edu/~fritz/absps/naturebp.pdf" target="_blank" rel="external">Learning representation by back-propagating errors</a><br><a href="http://blog.csdn.net/u014313009/article/details/51039334" target="_blank" rel="external">反向传播算法（过程及公式推导）</a><br><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">斯坦福机器学习</a><br><a href="http://mooc.guokr.com/note/16702/" target="_blank" rel="external">反向传播算法的一些争论与思考</a><br><a href="https://www.zhihu.com/question/27239198" target="_blank" rel="external">知乎：如何直观的解释back propagation算法？</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;神经网络的入门知识参见&lt;a href=&quot;/2017/02/13/神经网络/&quot;&gt;神经网络(系列1)&lt;/a&gt;&lt;br&gt;本文主要对神经网络进行深入，探讨神经网络模型的学习。&lt;/p&gt;
&lt;h1 id=&quot;代价函数&quot;&gt;&lt;a href=&quot;#代价函数&quot; class=&quot;headerlink&quot; title=&quot;代价函数&quot;&gt;&lt;/a&gt;代价函数&lt;/h1&gt;&lt;p&gt;首先引入一些便于稍后讨论的新标记方法：&lt;br&gt;假设神经网络的训练样本有m个，每个包含一组输入x和一组输出信号y，L表示神经网络层数，\(S_l\)表示每层的neuron个数(\(S_L\)表示输出层神经元个数),(\(S_L\)代表最后一层中处理单元的个数。&lt;br&gt;将神经网络的分类定义为两种情况：二类分类和多类分类:&lt;br&gt;二类分类：\(S_L=1\), y=0 or 1表示哪一类；&lt;br&gt;K类分类：\(S_L=K\),  \(y_i = 1\)表示分到第i类；（K&amp;gt;2）&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network_learn1.jpg&quot; alt=&quot;network_learn&quot;&gt;&lt;br&gt;我们回顾逻辑回归问题中我们的代价函数为：&lt;br&gt;$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$&lt;br&gt;在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，我们可以有很多输出变量，我们的\(h_θ(x)\)是一个维度为K的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：&lt;br&gt;$$J(\Theta)=-\frac{1}{m}\Big[\sum_{i=1}^m\sum_{k=1}^K\left(y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)\right)\Big] \\\ + \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2$$&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network_learn2.jpg&quot; alt=&quot;network_learn&quot;&gt;&lt;br&gt;这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个。&lt;br&gt;注意：j循环所有的行（由\(s_{l+1}\)层的激活单元数决定,l+1整体是下标），循环i则循环所有的列，由该层（\(s_l\)层）的激活单元数所决定。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="xtf615.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络(系列1)</title>
    <link href="xtf615.com/2017/02/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>xtf615.com/2017/02/13/神经网络/</id>
    <published>2017-02-13T10:23:23.000Z</published>
    <updated>2017-02-17T08:25:39.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h1><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。<br>下面是一个例子：<br><img src="/picture/machine-learning/network1.jpg" alt="network"><br>当我们使用\(x_1,x_2\)的多次项式进行预测时，我们可以应用得很好。<br>之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合\(x_1x_2+x_1x_3+x_1x_4+…+x_2x_3+x_2x_4+…+x_{99}x_{100}\),我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。<br>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车）。<br>我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。<br>假如我们只选用灰度图片，每个像素则只有一个值（而非RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：<br><img src="/picture/machine-learning/network2.jpg" alt="network"><br>假使我们采用的都是  50x50像素的小图片，并且我们将所有的像素视为特征，则会有2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约\(\frac{2500^2}{2}\)个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们就需要神经网络。</p>
<h1 id="神经元和大脑"><a href="#神经元和大脑" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h1><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。<br>接下来我将介绍神经网络。它能很好地解决不同的机器学习问题。首先介绍一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的，神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？<br><a id="more"></a></p>
<h2 id="起源"><a href="#起源" class="headerlink" title="起源"></a>起源</h2><p>神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><ul>
<li><p>如图，大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层.<br><img src="/picture/machine-learning/network3.jpg" alt="network"></p>
</li>
<li><p>神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。</p>
</li>
<li>下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。</li>
<li>这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为BrainPort的系统，它现在正在FDA(美国食品和药物管理局的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头<br>的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。<br><img src="/picture/machine-learning/network4.jpg" alt="network"></li>
<li>这是关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索 YouTube之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。<br><img src="/picture/machine-learning/network5.jpg" alt="network"></li>
<li>这是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。<br><img src="/picture/machine-learning/network6.jpg" alt="network"></li>
<li>还有一些离奇的例子。如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。<br><img src="/picture/machine-learning/network7.jpg" alt="network"><br>神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户。</li>
</ul>
<h1 id="模型表示（1）"><a href="#模型表示（1）" class="headerlink" title="模型表示（1）"></a>模型表示（1）</h1><p>为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元 /神经核（processing unit/Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。<br><img src="/picture/machine-learning/network8.jpg" alt="network"><br>下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。<br>这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。<br><img src="/picture/machine-learning/network9.jpg" alt="network"><br>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被称为权重（weight）。<br><img src="/picture/machine-learning/network10.jpg" alt="network"><br>我们设计出了类似于神经元的神经网络，效果如下：<br><img src="/picture/machine-learning/network11.jpg" alt="network"><br>其中\(x_1,x_2,x_3\)是输入单元（input units），我们将原始数据输入给它们。\(a_1,a_2,a_3\)是中间单元，它们负责将数据进行处理，然后呈递到下一层。最后是输出单元，它负责计算\(h_θ(x)\)。<br>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个 3层的神经网络，第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）：<br><img src="/picture/machine-learning/network12.jpg" alt="network"><br>下面引入一些标记法来帮助描述模型：<br>\(a_i^{(j)}\)代表第j层的第i个激活单元。\(\Theta^{(j)}\)代表从第j层映射到第j+1层时的权重的矩阵。例如\(\Theta^{(1)}\)代表从第一层映射到第二层的权重矩阵。其尺寸为：以第<strong>j+1</strong>层的激活单元数量为<strong>行数</strong>，以第<strong>j</strong>层的激活单元数加1为<strong>列数</strong>的矩阵。<br>例如：上图所示的神经网络中\(\Theta^{(1)}\)的尺寸为3*4。<br>对于上图所示的模型，激活单元和输出分别表达为：</p>
<p>$$a_1^{(2)}=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3) \\\\<br>a_2^{(2)}=g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3) \\\\<br>a_3^{(2)}=g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3)$$<br>上面进行的讨论中只是将特征矩阵中的一行(一个训练实例)喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。<br>注意：<strong>\(\Theta\)的下标和上标需要注意一下！下标的第一个数字：代表第j+1层神经元的编号，第二个数字代表第j层神经元的编号。上标则代表神经元层数的编号。</strong><br>我们可以知道：每一个a都是由上一层所有的x和每一个x所对应的参数决定的。<br>（我们把这样从左到右的算法称为前向传播算法(FORWARD PROPAGATION)）<br>把X，a分别用矩阵表示：<br>$$X=\begin{bmatrix} x_0 \\\ x_1 \\\ x_2 \\\ x_3\end{bmatrix}\\\\<br>\Theta=\begin{bmatrix} \Theta_{10} \ \Theta_{11} \ \Theta_{12} \ \Theta_{13}\\\ \Theta_{20} \ \Theta_{21} \ \Theta_{22} \ \Theta_{23}\\\ \Theta_{30} \ \Theta_{31} \ \Theta_{32} \ \Theta_{33}\end{bmatrix} \\\\<br>a=\begin{bmatrix} a_1 \\\ a_2 \\\ a_3\end{bmatrix} \\\\<br>我们可以得到\Theta X=a。<br>$$</p>
<h1 id="模型表示（2）"><a href="#模型表示（2）" class="headerlink" title="模型表示（2）"></a>模型表示（2）</h1><p>( FORWARD PROPAGATION  )相对与使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值：</p>
<p>$$x=\begin{bmatrix} x_0 \\\ x_1 \\\ x_2 \\\ x_3\end{bmatrix}\\\\<br>z^{(2)}=\begin{bmatrix} z_1^{(2)} \\\ z_2^{(2)} \\\ z_3^{(2)}\end{bmatrix}$$<br><img src="/picture/machine-learning/network13.jpg" alt="network"><br>我们令：\(z^{(2)}=\Theta^{(1)}x\),则\(a^{(2)}=g(z^{(2)})\),计算后添加\(a_0^{(2)}=1\)。计算输出值为：<br><img src="/picture/machine-learning/network14.jpg" alt="network"><br>令：\(z^{(3)}=\Theta^{(2)}a^{(2)}\),则\(h_\theta(x)=a^{(3)}=g(z^{(3)})\)<br>这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即：<br>\(z^{(2)}=\Theta^{(1)}*X^T\) , \(a^{(2)}=g(z^{(2)})\)<br>为了更好地了解Neuron Networks的工作原理，我们先把左半部分遮住：<br><img src="/picture/machine-learning/network15.jpg" alt="network"><br>右半部分其实就是以\(a_0,a_1,a_2,a_3\)按照Logistic Regression的方式输出h(x)：<br><img src="/picture/machine-learning/network16.jpg" alt="network"><br>其实神经网络就像是logistic  regression，只不过我们把logistic regression中的输入向量\([x1 \sim x3]\)变成了中间层的\([a_1^{(2)} \sim a_3^{(2)}]\)<br>即：<br>$$h(x)=g(\theta_0^{(2)}a_0^{(2)}+\theta_1^{(2)}a_1^{(2)}+\theta_2^{(2)}a_2^{(2)}+\theta_3^{(2)}a_3^{(2)})$$<br>我们可以把\(a_0,a_1,a_2,a_3\)看成更为高级的特征值，也就是\(x_0,x_1,x_2,x_3\)的进化体，并且它们是由x决定的，因为是梯度下降的，所以a是变化的，并且变得越来越厉害，所以<strong>这些更高级的特征值远比仅仅将x次方厉害</strong>，也能更好的预测新数据。<br>这就是神经网络相比于逻辑回归和线性回归的优势。</p>
<h1 id="例子和直观理解（1）"><a href="#例子和直观理解（1）" class="headerlink" title="例子和直观理解（1）"></a>例子和直观理解（1）</h1><p>从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征\(x_1,x_2,…,x_n\)，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。<br>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑AND、逻辑或OR。</p>
<h2 id="举例说明：逻辑与AND"><a href="#举例说明：逻辑与AND" class="headerlink" title="举例说明：逻辑与AND"></a>举例说明：逻辑与AND</h2><p>下图是神经网络的设计与Output层的表达式：<br><img src="/picture/machine-learning/network17.jpg" alt="network"><br>其中，\(\theta_0=-30,\theta_1=20,\theta_2=20\)<br>输出函数h(x)为：<br>$$h_\Theta(x)=g(-30+20x_1+20x_2)$$<br>我们知道g(x)的图像是：<br><img src="/picture/machine-learning/network18.jpg" alt="network"><br>真值表如下：<br><img src="/picture/machine-learning/network19.jpg" alt="network"><br>所以我们有:<br>$$h_\Theta(x) \approx x_1 AND x_2$$</p>
<h2 id="举例说明：逻辑或OR"><a href="#举例说明：逻辑或OR" class="headerlink" title="举例说明：逻辑或OR"></a>举例说明：逻辑或OR</h2><p><img src="/picture/machine-learning/network20.jpg" alt="network"><br>OR与AND整体一样，区别只在于\(\Theta\)的取值不同。</p>
<h1 id="例子和直观理解（2）"><a href="#例子和直观理解（2）" class="headerlink" title="例子和直观理解（2）"></a>例子和直观理解（2）</h1><p>们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。</p>
<h2 id="XNOR"><a href="#XNOR" class="headerlink" title="XNOR"></a>XNOR</h2><p>XNOR代表：输入的两个值必须一样，均为1或均为0），<br>即：\(XNOR=(x_1 \ AND \ x_2) \ OR \ ((NOT \ x_1) \ AND \ (NOT \ x_2))\)<br>首先构造一个能表达\((NOT x_1) AND (NOT x_2)\)部分的神经元，都取0表达式才真：<br><img src="/picture/machine-learning/network21.jpg" alt="network"><br>然后将表示AND的神经元和表示\((NOT x_1)AND(NOT x_2)\)的神经元以及表示OR的神经元进行组合。<br>下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（AND）：<br><img src="/picture/machine-learning/network22.jpg" alt="network"><br>下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（OR）：<br><img src="/picture/machine-learning/network23.jpg" alt="network"><br>组合：<br><img src="/picture/machine-learning/network24.jpg" alt="network"><br>\(x_1或x_2其中1个为1，1个为0的话，则a_1和a_2都为0，结果为0。\)<br>我们就得到了一个能实现XNOR运算符功能的神经网络。按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。这就是神经网络的厉害之处。</p>
<h1 id="多类问题"><a href="#多类问题" class="headerlink" title="多类问题"></a>多类问题</h1><p>当我们有不止两种分类时（也就是y=1,2,3….），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。<br>输入向量x有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现\([a b c d]^T\)，且a,b,c,d中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例：<br><img src="/picture/machine-learning/network25.jpg" alt="network"><br><img src="/picture/machine-learning/network26.jpg" alt="network"><br>神经网络算法的输出结果为四种可能情形之一：<br><img src="/picture/machine-learning/network27.jpg" alt="network"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;非线性假设&quot;&gt;&lt;a href=&quot;#非线性假设&quot; class=&quot;headerlink&quot; title=&quot;非线性假设&quot;&gt;&lt;/a&gt;非线性假设&lt;/h1&gt;&lt;p&gt;我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。&lt;br&gt;下面是一个例子：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network1.jpg&quot; alt=&quot;network&quot;&gt;&lt;br&gt;当我们使用\(x_1,x_2\)的多次项式进行预测时，我们可以应用得很好。&lt;br&gt;之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合\(x_1x_2+x_1x_3+x_1x_4+…+x_2x_3+x_2x_4+…+x_{99}x_{100}\),我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。&lt;br&gt;假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车）。&lt;br&gt;我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。&lt;br&gt;假如我们只选用灰度图片，每个像素则只有一个值（而非RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network2.jpg&quot; alt=&quot;network&quot;&gt;&lt;br&gt;假使我们采用的都是  50x50像素的小图片，并且我们将所有的像素视为特征，则会有2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约\(\frac{2500^2}{2}\)个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们就需要神经网络。&lt;/p&gt;
&lt;h1 id=&quot;神经元和大脑&quot;&gt;&lt;a href=&quot;#神经元和大脑&quot; class=&quot;headerlink&quot; title=&quot;神经元和大脑&quot;&gt;&lt;/a&gt;神经元和大脑&lt;/h1&gt;&lt;p&gt;神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。&lt;br&gt;接下来我将介绍神经网络。它能很好地解决不同的机器学习问题。首先介绍一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的，神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="xtf615.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="xtf615.com/2017/02/11/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>xtf615.com/2017/02/11/逻辑回归/</id>
    <published>2017-02-11T07:30:53.000Z</published>
    <updated>2017-03-18T02:08:15.781Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>在分类问题中，你要预测的变量  y是离散的值，我们将学习一种叫做逻辑回归(Logistic Regression)的算法，这是目前最流行使用最广泛的一种学习算法。</p>
<p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。</p>
<p>我们从二元的分类问题开始讨论。我们将因变量(dependant variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量 \(y\in{0,1}\) 其中0表示负向类，1表示正向类。<br><img src="/picture/machine-learning/logistic_regression1.jpg" alt="logistic_regression"><br><img src="/picture/machine-learning/logistic_regression2.jpg" alt="logistic_regression2"><br>如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为     0或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于  1，或者远小于0，即使所有训练样本的标签y都等于0或1。尽管我们知道标签应该取值0或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到1之间。</p>
<p>顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法.<br><a id="more"></a></p>
<h1 id="假设表示"><a href="#假设表示" class="headerlink" title="假设表示"></a>假设表示</h1><p>在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。<br>回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线：<br><img src="/picture/machine-learning/logistic_regression3.jpg" alt="logistic_regression3"><br>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：<br>当\(h_θ&gt;=0.5\)时，预测y=1。<br>当\(h_θ&lt;0.5\)时，预测y=0。<br>对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。<br><img src="/picture/machine-learning/logistic_regression4.jpg" alt="logistic_regression4"><br>这时，再使用 0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。<br>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和 1之间。逻辑回归模型的假设是：<br>$$h_\theta(x)=g(\theta^TX) \\\\<br>其中，X代表特征向量 \\\\<br>g代表逻辑函数(logistic function), 也叫S形函数（Sigmoid \ function), \\\\<br>公式为：g(z)=\frac{1}{1+e^{-z}}<br>$$<br>该函数的图像：<br><img src="/picture/machine-learning/logistic_regression5.jpg" alt="logistic_regression5"><br>合起来，我们得到逻辑回归模型的假设：<br>$$h_\theta(x)=\frac{1}{1+e^{-\theta^TX}}$$<br>\(h_\theta(x)\)的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性(estimated probablity)，即:<br>$$h_\theta(x)=P(y=1|x;\theta)$$<br>例如，如果对于给定的 x，通过已经确定的参数计算得出\(h_θ(x)=0.7\)，则表示有70%的几率y为正向类，相应地y为负向类的几率为1-0.7=0.3。</p>
<h1 id="判定边界"><a href="#判定边界" class="headerlink" title="判定边界"></a>判定边界</h1><p>现在讲下决策边界(decision  boundary)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。<br><img src="/picture/machine-learning/logistic_regression6.jpg" alt="logistic_regression6"><br>在逻辑回归中，我们预测：</p>
<ul>
<li>当\(h_θ\)大于等于0.5时，预测y=1;</li>
<li>当\(h_θ\)小于0.5时，预测y=0;<br>根据上面绘制出的S形函数图像，我们知道:</li>
<li>当z=0时, g(z)=0.5;</li>
<li>当z&gt;0时, g(z)&gt;0.5;</li>
<li>当z&lt;0时, g(z)&lt;0.5.</li>
</ul>
<p>又\(z=\theta^TX\),即：<br>\(\theta^TX \ge 0\),预测y=1;<br>\(\theta^TX &lt; 0\),预测y=0;<br>现在假设我们有一个模型：<br><img src="/picture/machine-learning/logistic_regression7.jpg" alt="logistic_regression7"><br>并且参数θ是向量[-3 1 1]。则当\( (-3+x_1+x_2)\ge 0\)，即 \(x_1+x_2 \ge 3\)时,模型将预测y=1。<br>我们可以绘制直线\(x_1+x_2=3\)，这条线便是我们模型的分界线，将预测为1的区域和预测为0的区域分隔开。<br><img src="/picture/machine-learning/logistic_regression8.jpg" alt="logistic_regression8"><br>假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？<br><img src="/picture/machine-learning/logistic_regression9.jpg" alt="logistic_regression9"><br>因为需要用曲线才能分隔y=0的区域和y=1的区域，我们需要二次方特征：假设参数：\(h_θ(x)=g(θ_0+θ_1x_1+θ_2x_2+θ_3x_1^2+θ_4x_2^2)\)是[-1 0 0 1 1],则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。<br>我们可以用非常复杂的模型来适应非常复杂形状的判定边界。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>接下来我们要介绍如何拟合逻辑回归模型的参数\(θ\)。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。<br><img src="/picture/machine-learning/logistic_regression10.jpg" alt="logistic_regression10"><br>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于:当我们将\(h_θ(x)=\frac{1}{1+e^{-θ^TX}}\)代入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（no-convex function).<br><img src="/picture/machine-learning/logistic_regression11.jpg" alt="logistic_regression11"><br>这意味着我们的代价函数有许多局部最小值，<strong>这将影响梯度下降算法寻找全局最小值。</strong><br>线性回归的代价函数为：<br>$$J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>我们重新定义逻辑回归的代价函数为:<br>$$J(\theta)=\frac{1}{m}\sum_{i=1}^mCost\left(h_{\theta}(x^{(i)}),y^{(i)}\right)$$<br>其中：<br>$$<br>\begin{eqnarray}<br>Cost(h_\theta(x),y)=<br>\begin{cases}<br>-log(h_\theta(x)), y=1 \cr -log(1-h_\theta(x)), y=0<br>\end{cases}<br>\end{eqnarray}<br>$$<br>\(h_θ(x)\)与\(Cost(h_θ(x),y)\)之间的关系如下图所示：<br><img src="/picture/machine-learning/logistic_regression12.jpg" alt="logistic_regression12"><br>这样构建的\(Cost(h_θ(x),y)\)函数的特点是：当实际的y=1且\(h_θ\)也为1时误差为 0，当y=1但\(h_θ\)不为1时误差随着\(h_θ\)的变小而变大；当实际的y=0且\(h_θ\)也为0时,代价为0，当y=0但\(h_θ\)不为0时误差随着\(h_θ\)的变大而变大。<br>将构建的Cost(hθ(x),y)简化如下:<br>$$Cost(h_θ(x),y)=-y*log(h_θ(x))-(1-y)*log(1-h_θ(x))$$</p>
<p>代入代价函数得到：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta) $$<br>}<br>求导后得到：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\sum_{i=1}^m\left((h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\right) $$<br>}</p>
<h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p>所给的代价函数：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>其中：<br>\(h_θ(x^{(i)})=\frac{1}{1+e^{-θ^TX}}\)<br>令\(z=θ^Tx=θ_0+θ_1x_1+θ_2x_2+…+θ_nx_n\)<br>则\(\frac{\partial z}{\partial(θ_j)}=x_j^{(i)}\)<br>\(h_θ(x^{(i)})=\frac{1}{1+e^{-z}}=\frac{e^z}{1+e^z}\) </p>
<p>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)\\\\<br>=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))-y^{(i)}log(1-h_θ(x^{(i)}))+log(1-h_θ(x^{(i)}))\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log\left(\frac{h_θ(x^{(i)})}{1-h_θ(x^{(i)})}\right)+log(1-h_θ(x^{(i)}))\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log\left(\frac{\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}}{1-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}}\right)+log(1-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}})\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}z^{(i)}-log(1+e^{z^{(i)}})\right)<br>$$<br>$$<br>J’(θ)= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}\frac{\partial z^{(i)}}{\partialθ_j}-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}\frac{\partial z^{(i)}}{\partialθ_j}\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}-h_θ(x^{(i)})\right)\frac{\partial z^{(i)}}{\partialθ_j} \\\\<br>= \frac{1}{m}\sum_{i=1}^m\left((h_θ(x^{(i)})-y^{(i)})x_j^{(i)}\right)<br>$$</p>
<p>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的\(h_θ(x)=g(θ^TX)\)与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之T前，进行特征缩放依旧是非常必要的。<br>一些梯度下降算法之外的选择：除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS)。</p>
<h1 id="多类别分类-1对多"><a href="#多类别分类-1对多" class="headerlink" title="多类别分类 1对多"></a>多类别分类 1对多</h1><p>我们将谈到如何使用逻辑回归(logistic  regression)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (one-vs-all)的分类算法。<br>先看这样一些例子。</p>
<ul>
<li>第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成<br>这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用y=1、y=2、y=3、y=4来代表。</li>
<li>第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用y=1这个类别来代表；或者患了感冒，用y=2来代表；或者得了流感用y=3来代表。</li>
<li>第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，y可以取一个很小的数值，一个相对”谨慎”的数值，比如1到3、1到4或者其它数值。<br>以上说的都是多类分类问题。<br>然而对于之前的一个二元分类问题，我们的数据看起来可能是像这样：<br><img src="/picture/machine-learning/logistic_regression13.jpg" alt="logistic"><br>对于一个多类分类问题，我们的数据集或许看起来像这样：<br><img src="/picture/machine-learning/logistic_regression14.jpg" alt="logistic"><br>我用三种不同的符号来代表三个类别，问题就是给出三个类型的数据集，我们如何得到一个学习算法来进行分类呢？<br>我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。<br>下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。<br>现在我们有一个训练集，好比上图表示的有三个类别，我们用三角形表示y=1，方框表示  y=2，叉叉表示y=3。我们下面要做的就是使用一个训练集，将其分成三个二元分类问题。我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。<br><img src="/picture/machine-learning/logistic_regression15.jpg" alt="logistic_regression15"></li>
</ul>
<p>这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。<br>为了能实现这样的转变，我们将多个类中的一个类标记为正向类（y=1），然后将其他所有类都标记为负向类，这个模型记作\(h_\theta^{(1)}(x)\)。<br>接着，类似地第我们选择另一个类标记为正向类（y=2），再将其它类都标记为负向类，将这个模型记作\(h_\theta^{(2)}(x)\),依此类推。<br>最后我们得到一系列的模型简记为：\(h_\theta^{(i)}(x)=p(y=i|x;\theta)\)<br><img src="/picture/machine-learning/logistic_regression16.jpg" alt="logistic_regression16"><br>最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。<br>总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：\(h_\theta^{(i)}(x)\)其中i对应每一个可能的y=i，最后,为了做出预测，我们给出输入一个新的x值，用这个做预测。我们要做的就是在我们三个分类器里面输入x，然后我们选择一个让\(h_\theta^{(i)}(x)\)最大的i,即\(\max_{i}h_\theta^{(i)}(x)\)<br>现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的,那么就可认为得到一个正确的分类，无论i值是多少，我们都有最高的概率值，我们预测y就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，现在也可以将逻辑回归分类器用在多类分类的问题上。</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过度拟合 (over-fitting)的问题，可能会导致它们效果很差。<br>接下来，我们将谈论一种称为正则化(regularization)的技术，它可以改善或者减少过度拟合问题。<br>下图是一个回归问题的例子：<br><img src="/picture/machine-learning/logistic_regression17.jpg" alt="logistic_regression17"><br>第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。<br>分类问题中也存在这样的问题：<br><img src="/picture/machine-learning/logistic_regression18.jpg" alt="logistic_regression18"><br>就以多项式理解，x的次数越高，拟合的越好，但相应的预测的能力就可能变差。<br>问题是，如果我们发现了过拟合问题，应该如何处理？</p>
<ul>
<li>丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA）</li>
<li>正则化。保留所有的特征，但是减少参数的大小（magnitude）。<h2 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h2>上面的回归问题中如果我们的模型是：<br>$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2^2+\theta_3x_3^3+\theta_4x_4^4$$<br>我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。<br>所以我们要做的就是在一定程度上减小这些参数θ的值，这就是正则化的基本方法。我们决定要减少\(θ_3\)和\(θ_4\)的大小，我们要做的便是修改代价函数，在其中\(θ_3\)和\(θ_4\)设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的\(θ_3\)和\(θ_4\)。修改后的代价函数如下：<br>$$\min_θ\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+1000θ_3^2+10000θ_4^2$$<br>通过这样的代价函数选择出的\(θ_3\)和\(θ_4\)对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：<br>$$J(θ)=\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^nθ_j^2$$<br>其中λ又称为正则化参数（Regularization Parameter）。注：根据惯例，我们不对\(θ_0\)进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示：<br><img src="/picture/machine-learning/logistic_regression19.jpg" alt="regularization"><br>如果选择的正则化参数λ过大，则会把所有的参数都最小化了，导致模型变成\(h_θ(x)=θ_0\).也就是上图中红色直线所示的情况，造成欠拟合。<br>那为什么增加的一项\(\lambda\sum_{j=1}^nθ_j^2\),可以使θ的值减小呢？<br>因为如果我们令λ的值很大的话,为了使Cost Function尽可能的小，所有的θ的值（不包括 \(θ_0\)）都会在一定程度上减小。<br>但若λ的值太大了,那么θ（不包括\(θ_0\)）都会趋近于0，这样我们所得到的只能是一条平行于x轴的直线。<br>所以对于正则化，我们要取一个合理的λ的值，这样才能更好的应用正则化。<br>回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。<h2 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h2>对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。<br>正则化线性回归的代价函数为：<br>$$J(θ)=\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^nθ_j^2$$<br>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对\(θ_0\)进行正则化，所以梯度下降算法将分两种情形：<br><strong>repeat until convergence</strong>{<br> $$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)}).x_0^{(i)}) \\\ <br> \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}+\frac{\lambda}{m}\theta_j) \\\\<br> for j=1,2,…,n$$<br>}<br>对上面j=1,2…n时的更新式子进行调整可得：<br>$$\theta_j:=\theta_j(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$<br>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令θ值减少了一个额外的值。<br>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：<br>$$θ=\left(X^TX+\lambda I\right)^{-1}X^Ty \\\\<br>其中I为对角矩阵,并且第一个元素为0,其余对角元素都为1$$<h2 id="正则化的逻辑回归模型"><a href="#正则化的逻辑回归模型" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h2><img src="/picture/machine-learning/logistic_regression20.jpg" alt="regularization"><br>同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$<br>要最小化该代价函数，通过求导，得出梯度下降算法为：<br><strong>repeat until convergence</strong>{<br> $$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)}).x_0^{(i)}) \\\ <br> \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}+\frac{\lambda}{m}\theta_j) \\\\<br> for j=1,2,…,n$$<br>}</li>
</ul>
<p><strong>注：看上去同线性回归一样，但是逻辑回归\(h_θ(x)=g(θ^TX)\)，而线性回归\(h_θ(x)=θ^TX\),所以二者不同。</strong></p>
<h1 id="广义线性模型与逻辑回归"><a href="#广义线性模型与逻辑回归" class="headerlink" title="广义线性模型与逻辑回归"></a>广义线性模型与逻辑回归</h1><p>广义线性模型的介绍见：<a href="/2017/02/09/线性回归/">线性回归-拓展 广义线性模型与线性回归</a><br>实际上，逻辑回归中：我们有如下假设：<br>$$y|x;θ \sim Bernoulli(\phi)$$<br>即，假设y的条件概率服从伯努利分布，伯努利分布也是广义线性模型的一种特例。</p>
<h2 id="Bernoulli分布的指数分布簇形式"><a href="#Bernoulli分布的指数分布簇形式" class="headerlink" title="Bernoulli分布的指数分布簇形式"></a>Bernoulli分布的指数分布簇形式</h2><p>广义线性模型的指数分布簇形式：<br>$$p(y;\eta)=b(y)exp(\eta^{T}T(y)-a(\eta))$$<br>伯努利分布：<br>$$p(y=1;\phi)=\phi; \ p(y=0;\phi)=1-\phi$$<br>=&gt;<br>$$p(y;\phi)=\phi^y(1-\phi)^{1-y} \\\\<br>=exp(ylog\phi+(1-y)log(1-\phi)) \\\\<br>=exp\left(  \left(log\left(\frac{\phi}{1-\phi}\right)\right)y+log(1-\phi)\right)<br>$$<br>即：在如下参数下，广义线性模型是伯努利分布<br>$$\eta=log(\frac{\phi}{1-\phi}) =&gt; \phi = \frac{1}{1+e^{-\eta}} \\\\<br>T(y)=y \\\\<br>a(\eta)=-log(1-\eta)=log(1+e^\eta) \\\\<br>b(y)=1<br>$$</p>
<h2 id="广义线性模型推导逻辑回归"><a href="#广义线性模型推导逻辑回归" class="headerlink" title="广义线性模型推导逻辑回归"></a>广义线性模型推导逻辑回归</h2><p>让我们重新审视一下逻辑回归，我们定义:<br>$$h_\theta(x)=P(y=1|x;\theta)$$<br>即，模型的输出就是y=1的概率，后面我们会发现\(P(y=1|x;\theta)\)实际上就是伯努利分布的参数\(\phi\)。由上式有：<br>$$P(y=0|x;\theta)=1-h_\theta(x)$$<br>我们将两个式子合并成一个式子：有：<br>$$P(y|x;\theta)=h_\theta(x)^y+(1-h_\theta(x))^{1-y}$$<br>显然,y=1时，上式变为\(P(y=1|x;\theta)=h_\theta(x)\); y=0时，上式变为\(P(y=0|x;\theta)=1-h_\theta(x)\)<br>使用极大似然估计，得到：<br>$$L(\theta)=P(y|X;\theta)=\prod_{i=1}^mP(y^{(i)}|x^{(i)};\theta) \\\\=\prod_{i=1}^m\left(h_\theta(x^{(i)})^{y^{(i)}}+(1-h_\theta(x^{(i)}))^{1-y^{(i)}}\right)$$<br>两边取对数得到：<br>$$\ell(\theta)=log(L(\theta))=\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>这就是上文的代价函数。<br>下面是推导：</p>
<ul>
<li>step1: \(y|x;\theta \sim Bernoulli(\phi)\)</li>
<li>step2: 由假设2: \(h(x)=E[y|x]\) 得到：<br>$$h_\theta(x)=E[y|x;\Theta]=p(y=1|x;\theta)\\\\<br> =\phi \\\\<br> =\frac{1}{1+e^{-\eta}}  \\\\<br> =\frac{1}{1+e^{-\Theta^Tx}}  \\\\<br> 其中, E[y|x;\Theta]=\phi由假设1得到；\\\\<br>\phi=\frac{1}{1+e^{-\eta}}由伯努利分布对应的广义线性模型参数得到；\\\\<br>\eta = \Theta^Tx由假设3得到。<br>$$</li>
</ul>
<p><strong>注：可以看出Sigmoid function得到的实际上就是\(\phi\)的值，也就是预测y=1的概率。</strong></p>
<h1 id="拓展——softmax回归"><a href="#拓展——softmax回归" class="headerlink" title="拓展——softmax回归"></a>拓展——softmax回归</h1><h2 id="多项式分布"><a href="#多项式分布" class="headerlink" title="多项式分布"></a>多项式分布</h2><p>首先，y的取值有多个，\(y \in {1,2…,k}\)，参数也相应的有k个，即\({\phi_1,\phi_2,…,\phi_k}\),则：<br>$$P(y=i)=\phi_i$$<br>我们将\(\phi_k\)改写成：<br>$$\phi_k=1-(\phi_1+\phi_2+…+\phi_{k-1})$$<br>因此可以视作只有k-1个参数，\(\phi_1,\phi_2,…,\phi_{k-1}\)</p>
<h2 id="指数分布簇形式推导"><a href="#指数分布簇形式推导" class="headerlink" title="指数分布簇形式推导"></a>指数分布簇形式推导</h2><p>首先定义T(y):<br>$$T(1)=[1 \ 0 \ … \ 0]^T$$<br>$$T(2)=[0 \ 1 \ … \ 0]^T$$<br>$$T(k-1)=[0 \ 0 \ … \ 1]^T$$<br>$$T(k)=[0 \ 0 \ … \ 0]^T$$<br>定义指示函数：<br>\(I\{True\}=1, I\{False\}=0\)<br>我们使用标志：<br>\(T(y)_i\)表示向量\(T(y)\)的第\(i\)个元素，则：<br>$$T(y)_i=I\{y=i\}$$<br>根据多项式分布：<br>$$P(y)=\phi_1^{I\{y=1\}}\phi_2^{I\{y=2\}}…\phi_k^{I\{y=k\}} \\\\<br>=\phi_1^{(T(y))_1}\phi_2^{(T(y))_2}…\phi_{k=1}^{(T(y))_{k-1}}\phi_k^{1-\sum_{j=1}^{k-1}(T(y))_j} \\\\<br>=exp\left((T(y))_1 log(\phi_1) + (T(y))_2 log(\phi_2))+…+\left(1-\sum_{j=1}^{k-1}(T(y))_j\right)log(\phi_k)\right) \\\\<br>=exp\left((T(y))_1 log(\frac{\phi_1}{\phi_k}) + (T(y))_2 log(\frac{\phi_2}{\phi_k}) + … + (T(y))_{k-1} log(\frac{\phi_{k-1}}{\phi_k})+log(\phi_k) \right)<br>=b(y)exp(\eta^T T(y)-a(\eta)) \\\\<br>$$<br>其中，<br>$$<br>\eta=\begin{bmatrix} log(\frac{\phi_i}{\phi_k}) \\\ … \\\ log(\frac{\phi_{k-1}}{\phi_k}) \end{bmatrix} \\\\<br>a(\eta)=-log(\phi_k) \\\\<br>b(y)=1<br>$$<br>根据上面这些式子，可以将多项式分布转化成指数分布簇形式。<br>我们有：for(i=1,…,k):<br>$$\eta_i=log\frac{\phi_i}{\phi_k}$$<br>为了方便，我们定义\(\eta_k=log\frac{\phi_k}{\phi_k}=0\)<br>我们有：<br>$$e^{\eta_i}=\frac{\phi_i}{\phi_k}$$<br>则：<br>$$\phi_ke^{\eta_i}=\phi_i \ \ \ \ \ \ \ \ (1)$$<br>$$\phi_k\sum_{i=1}^ke^{\eta_i}=\sum_{i=1}^k \phi_i=1$$<br>$$\phi_k=\frac{1}{\sum_{i=1}^k e^{\eta_i}}$$<br>代回到(1)式，得到：<br>$$\phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}$$</p>
<p>我们将\(\phi\)和\(\eta\)关系倒过来，可以得到：<br>$$p(y=i|x;\theta)=\phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^{k}e^{\eta_j}} \\\\<br>=\frac{e^{\theta_i^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}}<br>$$<br>前面提到，\(\eta_k=0\),故上式也可以写作：<br>$$p(y=i|x;\theta)=\phi_i=\frac{e^{\eta_i}}{1+\sum_{j=1}^{k-1}e^{\eta_j}} \\\ =\frac{e^{\theta_i^T X}}{1+\sum_{j=1}^{k-1}e^{\theta_j^T X}}<br>$$<br>这和逻辑回归的样子非常像：<br>$$\phi_1=\frac{1}{1+e^{-\theta^T X}}=\frac{e^{\theta^T X}}{1+e^{\theta^T X}}$$<br>注意，softmax回归中的\(\theta_i,…,\theta_{k-1} \in \mathbb{R^{n+1}}\),即n+1维向量。 </p>
<p>所以我们的学习算法：<br>$$h_\theta(x)=E[T(y)|x;\theta] \\\\<br>=E\left[\begin{bmatrix} I\{y=1\} \\\ … \\\ I\{y=k-1\} \end{bmatrix} | x;\theta\right] = \begin{bmatrix} \phi_1 \\\ … \\\ \phi_{k-1} \end{bmatrix} \\\\<br>= \begin{bmatrix} \frac{e^{\theta_i^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}} \\\ … \\\ \frac{e^{\theta_{k-1}^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}} \end{bmatrix}<br>$$<br>最后只需要使用极大似然法拟合参数即可：<br>$$\ell(\theta)=\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)};\theta) \\\\<br>=\sum_{i=1}^m log \prod_{l=1}^k \left(\frac{e^{\theta_{l}^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}}\right)^{I\{y_i=l\}}$$</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/47637500?sort=created" target="_blank" rel="external">知乎：为什么广义线性模型GLM要求被解释变量属于指数分布簇</a><br><a href="https://zhuanlan.zhihu.com/p/22876460" target="_blank" rel="external">知乎：广义线性模型</a>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分类问题&quot;&gt;&lt;a href=&quot;#分类问题&quot; class=&quot;headerlink&quot; title=&quot;分类问题&quot;&gt;&lt;/a&gt;分类问题&lt;/h1&gt;&lt;p&gt;在分类问题中，你要预测的变量  y是离散的值，我们将学习一种叫做逻辑回归(Logistic Regression)的算法，这是目前最流行使用最广泛的一种学习算法。&lt;/p&gt;
&lt;p&gt;在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。&lt;/p&gt;
&lt;p&gt;我们从二元的分类问题开始讨论。我们将因变量(dependant variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量 \(y\in{0,1}\) 其中0表示负向类，1表示正向类。&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/logistic_regression1.jpg&quot; alt=&quot;logistic_regression&quot;&gt;&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/logistic_regression2.jpg&quot; alt=&quot;logistic_regression2&quot;&gt;&lt;br&gt;如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为     0或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于  1，或者远小于0，即使所有训练样本的标签y都等于0或1。尽管我们知道标签应该取值0或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到1之间。&lt;/p&gt;
&lt;p&gt;顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法.&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="广义线性模型" scheme="xtf615.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="逻辑回归" scheme="xtf615.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>基于jieba分词和nltk的情感分析</title>
    <link href="xtf615.com/2017/02/10/%E5%9F%BA%E4%BA%8Ejieba%E5%88%86%E8%AF%8D%E5%92%8Cnltk%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    <id>xtf615.com/2017/02/10/基于jieba分词和nltk的情感分析/</id>
    <published>2017-02-10T10:45:56.000Z</published>
    <updated>2017-02-11T07:33:21.302Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自然语言处理NLP"><a href="#自然语言处理NLP" class="headerlink" title="自然语言处理NLP"></a>自然语言处理NLP</h1><p>情感分析作为自然语言处理的一个部分，让我们首先看一下自然语言处理。</p>
<h2 id="相关技术及运用"><a href="#相关技术及运用" class="headerlink" title="相关技术及运用"></a>相关技术及运用</h2><p>自动问答（Question Answering，QA）：它是一套可以理解复杂问题，并以充分的准确度、可信度和速度给出答案的计算系统，以IBM‘s Waston为代表；<br>信息抽取（Information Extraction，IE）：其目的是将非结构化或半结构化的自然语言描述文本转化结构化的数据，如自动根据邮件内容生成Calendar；<br>情感分析（Sentiment Analysis，SA）：又称倾向性分析和意见挖掘，它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从大量网页文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向；<br>机器翻译（Machine Translation，MT）：将文本从一种语言转成另一种语言，如中英机器翻译。</p>
<h2 id="发展现状"><a href="#发展现状" class="headerlink" title="发展现状"></a>发展现状</h2><p>基本解决：词性标注、命名实体识别、Spam识别<br>取得长足进展：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取<br>挑战：自动问答、复述、文摘、会话机器人<br><img src="/picture/machine-learning/nlp_process.png" alt="nlp_process"><br><a id="more"></a>  </p>
<h2 id="NLP主要难点——歧义问题"><a href="#NLP主要难点——歧义问题" class="headerlink" title="NLP主要难点——歧义问题"></a>NLP主要难点——歧义问题</h2><ul>
<li>词法分析歧义：<br>1）分词， 如“严守一把手机关了”，可能的分词结果“严守一/ 把/ 手机/ 关/ 了” 和“严守/ 一把手/ 机关/ 了”。2）词性标注， 如“计划”在不同上下文中有不同的词性：“我/ 计划/v 考/ 研/”和“我/ 完成/ 了/ 计划/n”</li>
<li>语法分析歧义：<br>“那只狼咬死了猎人的狗”。 ”咬死了猎人的狗失踪了”。</li>
<li>语义分析歧义：<br>计算机会像你的母亲那样很好的理解你（的语言）： 1）计算机理解你喜欢你的母亲。2）计算机会像很好的理解你的母亲那样理解你</li>
<li>NLP应用中的歧义：<br>音字转换：拼音串“ji qi fan yi ji qi ying yong ji qi le ren men ji qi nong hou de xing qu”中的“ji qi”如何转换成正确的词条<h2 id="为什么自然语言理解如此困难？"><a href="#为什么自然语言理解如此困难？" class="headerlink" title="为什么自然语言理解如此困难？"></a>为什么自然语言理解如此困难？</h2></li>
<li>用户生成内容中存在大量口语化、成语、方言等非标准的语言描述</li>
<li>分词问题</li>
<li>新词不断产生</li>
<li>基本常识与上下文知识</li>
<li>各式各样的实体词</li>
</ul>
<p>为了解决以上难题，我们需要掌握较多的语言学知识，构建知识库资源，并找到一种融合各种知识、资源的方法，目前使用较多是概率模型 （probabilistic model）或称为统计模型（statistical model），或者称为“经验主义模型”，其建模过程基于大规模真实语料库，从中各级语言单位上的统计信息，并且，依据较低级语言单位上的统计信息，运行 相关的统计、推理等技术计算较高级语言单位上的统计信息。与其相对的“理想主义模型”，即基于Chomsky形式语言的确定性语言模型，它建立在人脑中先 天存在语法规则这一假设基础上，认为语言是人脑语言能力推导出来的，建立语言模型就是通过建立人工编辑的语言规则集来模拟这种先天的语言能力。</p>
<h1 id="情感分析概念"><a href="#情感分析概念" class="headerlink" title="情感分析概念"></a>情感分析概念</h1><p>情感分析（Sentiment analysis），又称倾向性分析，意见抽取（Opinion extraction），意见挖掘（Opinion mining），情感挖掘（Sentiment mining），主观分析（Subjectivity analysis），它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从评论文本中分析用户对“数码相机”的“变焦、价格、大小、重 量、闪光、易用性”等属性的情感倾向。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><ul>
<li><p><strong>从电影评论中识别用户对电影的褒贬评价</strong><br><img src="/picture/machine-learning/movie_comment.png" alt="movie_comment"></p>
</li>
<li><p>Google Product Search识别用户对产品各种属性的评价，并从评论中选择代表性评论展示给用户<br><img src="/picture/machine-learning/product_comment.png" alt="product_comment"></p>
</li>
<li><p>微信新闻识别用户对新闻的各种评价，并从评论中选择代表性评论展示给用户</p>
</li>
<li><p>Twitter sentiment versus Gallup Poll of Consumer Confidence：挖掘Twitter中的用户情感发现，其与传统的调查、投票等方法结果有高度的一致性。<br>下图中2008年到2009年初，网民情绪低谷是金融危机导致，从2009年5月份开始慢慢恢复。<br><img src="/picture/machine-learning/mental.png" alt="mental"></p>
</li>
<li><p>Twitter sentiment: 通过Twitter用户情感预测股票走势。<br>2012年5月，世界首家基于社交媒体的对冲基金 Derwent Capital Markets 在屡次跳票后终于上线。它会即时关注Twitter 中的公众情绪指导投资。正如基金创始人保罗•郝汀（Paul Hawtin）表示：“长期以来，投资者已经广泛地认可金融市场由恐惧和贪婪驱使，但我们从未拥有一种技术或数据来量化人们的情感。”一直为金融市场非理性举动所困惑的投资者，终于有了一扇可以了解心灵世界的窗户——那便是 Twitter 每天浩如烟海的推文，在一份八月份的报道中显示，利用 Twitter 的对冲基金 Derwent Capital Markets 在首月的交易中已经盈利，它以1.85%的收益率，让平均数只有0.76%的其他对冲基金相形见绌。类似的工作还有预测电影票房、选举结果等，均是将公众 情绪与社会事件对比，发现一致性，并用于预测，如将“冷静CLAM”情绪指数后移3天后和道琼斯工业平均指数DIJA惊人一致。<br><img src="/picture/machine-learning/stock_predict.png" alt="stock"></p>
</li>
<li><p>Target Sentiment on Twitter（Twitter Sentiment App）：对Twitter中包含给定query的tweets进行情感分类。对于公司了解用户对公司、产品的喜好，用于指导改善产品和服务，公司还可以 据此发现竞争对手的优劣势，用户也可以根据网友甚至亲友评价决定是否购买特定产品。详细见论文：Alec Go, Richa Bhayani, Lei Huang. 2009. Twitter Sentiment Classification using Distant Supervision.<br><img src="/picture/machine-learning/search_sentiment.png" alt="search"></p>
</li>
</ul>
<h2 id="情感分析内容"><a href="#情感分析内容" class="headerlink" title="情感分析内容"></a>情感分析内容</h2><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>情感分析主要目的就是识别用户对事物或人的看法、态度。<br>参与主体主要包括：</p>
<ul>
<li>Holder (source) of attitude：观点持有者</li>
<li>Target (aspect) of attitude：评价对象</li>
<li>Type of attitude：评价观点</li>
<li>From a set of types：观点类型：Like, love, hate, value, desire, etc.<br>Or (more commonly) simple weighted polarity: positive, negative, neutral,together with strength</li>
<li>Text containing the attitude：评价文本，一般是句子或整篇文档。</li>
<li>更细更深入的还包括评价属性，情感词/极性词，评价搭配等。</li>
</ul>
<p>通常，我们面临的情感分析任务包括如下几类：</p>
<ul>
<li>是正面还是反面情绪？<br>Simplest task: Is the attitude of this text positive or negative?</li>
<li>排序态度：<br>More complex: Rank the attitude of this text from 1 to 5</li>
<li>检测目的、观点等：<br>Advanced: Detect the target, source, or complex attitude types</li>
</ul>
<h2 id="词典匹配VS机器学习"><a href="#词典匹配VS机器学习" class="headerlink" title="词典匹配VS机器学习"></a>词典匹配VS机器学习</h2><p>不是有词典匹配的方法了吗？怎么还搞多个机器学习方法。因为词典方法和机器学习方法各有千秋。<br>机器学习的方法精确度更高，因为词典匹配会由于语义表达的丰富性而出现很大误差，而机器学习方法不会。而且它可使用的场景更多样。无论是主客观分类还是正负面情感分类，机器学习都可以完成任务。而无需像词典匹配那样要深入到词语、句子、语法这些层面。<br>而词典方法适用的语料范围更广，无论是手机、电脑这些商品，还是书评、影评这些语料，都可以适用。但机器学习则极度依赖语料，把手机语料训练出来的的分类器拿去给书评分类，那是注定要失败的。<br>使用机器学习进行情感分析，可以换一个相同意思的说法，就是用有监督的（需要人工标注类别）机器学习方法来对文本进行分类。<br>这点与词典匹配有着本质的区别。<strong>词典匹配是直接计算文本中的情感词，得出它们的情感倾向分值</strong>。而<strong>机器学习方法的思路是先选出一部分表达积极情感的文本和一部分表达消极情感的文本，用机器学习方法进行训练，获得一个情感分类器。再通过这个情感分类器对所有文本进行积极和消极的二分分类</strong>。最终的分类可以为文本给出0或1这样的类别，也可以给出一个概率值，比如”这个文本的积极概率是90%，消极概率是10%“。</p>
<h2 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h2><p>Python 有良好的程序包可以进行情感分类，那就是Python 自然语言处理包，Natural Language Toolkit ，简称NLTK 。NLTK 当然不只是处理情感分析，NLTK 有着整套自然语言处理的工具，从分词到实体识别，从情感分类到句法分析，完整而丰富，功能强大。实乃居家旅行，越货杀人之必备良药。<br>另外，<strong>NLTK 新增的scikit-learn 的接口</strong>，使得它的分类功能更为强大好用了，可以用很多高端冷艳的分类算法了。<br>有了scikit-learn 的接口，NLTK 做分类变得比之前更简单快捷，但是相关的结合NLTK 和 sciki-learn 的文章实在少。</p>
<h1 id="构建情感分析工具流程"><a href="#构建情感分析工具流程" class="headerlink" title="构建情感分析工具流程"></a>构建情感分析工具流程</h1><h2 id="人工标注"><a href="#人工标注" class="headerlink" title="人工标注"></a>人工标注</h2><p>有监督意味着需要人工标注，需要人为的给文本一个类标签。比如我有5000条商品评论，如果我要把这些评论分成积极和消极两类。那我就可以先从里面选2000条评论，然后对这2000条数据进行人工标注，把这2000条评论标为“积极”或“消极”。这“积极”和“消极”就是类标签。 假设有1000条评论被标为“积极”，有1000条评论被标为“消极”。（两者数量相同对训练分类器是有用的，如果实际中数量不相同，应该减少和增加数据以使得它们数量相同）</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征就是分类对象所展现的部分特点，是实现分类的依据。我们经常会做出分类的行为，那我们依据些什么进行分类呢？ 举个例子，如果我看到一个年轻人，穿着新的正装，提着崭新的公文包，快步行走，那我就会觉得他是一个刚入职的职场新人。在这里面，“崭新”，“正装”，“公文包”，“快步行走”都是这个人所展现出的特点，也是我用来判断这个人属于哪一类的依据。这些特点和依据就是特征。可能有些特征对我判断更有用，有些对我判断没什么用，有些可能会让我判断错误，但这些都是我分类的依据。<br>我们没办法发现一个人的所有特点，所以我们没办法客观的选择所有特点，我们只能主观的选择一部分特点来作为我分类的依据。这也是特征选择的特点，需要人为的进行一定选择。<br><strong>而在情感分类中，一般从“词”这个层次来选择特征。</strong><br>比如这句话“手机非常好用！”，我给了它一个类标签“Positive”。里面有四个词（把感叹号也算上），“手机”，“非常”，“好用”，“！”。我可以认为这4个词都对分类产生了影响，都是分类的依据。也就是无论什么地方出现了这四个词的其中之一，文本都可以被分类为“积极”。这个是把所有词都作为分类特征。<br>同样的，对这句话，我也可以选择它的双词搭配（Bigrams）作为特征。比如“手机 非常”，“非常 好用”，“好用 ！”这三个搭配作为分类的特征。以此类推，三词搭配（Trigrams），四词搭配都是可以被作为特征的。</p>
<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p>特征降维说白了就是减少特征的数量。这有两个意义，一个是特征数量减少了之后可以加快算法计算的速度（数量少了当然计算就快了），另一个是如果用一定的方法选择信息量丰富的特征，可以减少噪音，有效提高分类的准确率。<br>所谓信息量丰富，可以看回上面这个例子“手机非常好用！”，很明显，其实不需要把“手机”，“非常”，“好用”，“！”这4个都当做特征，因为“好用”这么一个词，或者“非常 好用”这么一个双词搭配就已经决定了这个句子是“积极”的。这就是说，“好用”这个词的信息量非常丰富。<br><strong>那要用什么方法来减少特征数量呢？</strong><br>答案是通过一定的统计方法找到信息量丰富的特征。<br>统计方法包括：词频（Term Frequency）、文档频率（Document Frequency）、互信息（Pointwise Mutual Information）、信息熵（Information Entropy）、卡方统计（Chi-Square）等等。<br>在情感分类中，用词频选择特征，也就是选在语料库中出现频率高的词。比如我可以选择语料库中词频最高的2000个词作为特征。用文档频率选特征，是选在语料库的不同文档中出现频率最高的词。其他类似，都是要通过某个统计方法选择信息量丰富的特征。特征可以是词，可以是词组合。</p>
<h2 id="文本特征化"><a href="#文本特征化" class="headerlink" title="文本特征化"></a>文本特征化</h2><p>在使用分类算法进行分类之前，第一步是要把所有原始的语料文本转化为特征表示的形式。<br>还是以上面那句话做例子，“手机非常好用！”<br>如果在NLTK 中，如果选择所有词作为特征，其形式是这样的：[ {“手机”: True, “非常”: True, “好用”: True, “！”: True} , positive]<br>如果选择双词作为特征，其形式是这样的：[ {“手机 非常”: True, “非常 好用”: True, “好用 ！”: True} , positive ]<br>如果选择信息量丰富的词作为特征，其形式是这样的：[ {“好用”: True} , positive ]<br>无论使用什么特征选择方法，其形式都是一样的。都是[ {“特征1”: True, “特征2”: True, “特征N”: True, }, 类标签 ]</p>
<h2 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h2><p>把用特征表示之后的文本分成开发集和测试集，把开发集分成训练集和验证集。机器学习分类必须有数据给分类算法训练，这样才能得到一个（基于训练数据的）分类器。有了分类器之后，就需要检测这个分类器的准确度。</p>
<h2 id="分类算法学习"><a href="#分类算法学习" class="headerlink" title="分类算法学习"></a>分类算法学习</h2><p>这个时候终于可以使用各种高端冷艳的机器学习算法啦！<br>我们的目标是：找到最佳的机器学习算法。<br>可以使用朴素贝叶斯（NaiveBayes），决策树（Decision Tree）等NLTK 自带的机器学习方法。也可以更进一步，使用NLTK 的scikit-learn 接口，这样就可以调用scikit-learn 里面的所有。</p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>在终于得到最佳分类算法和特征维度（数量）之后，就可以动用测试集。<br>直接用最优的分类算法对测试集进行分类，得出分类结果。对比分类器的分类结果和人工标注的正确结果，给出分类器的最终准确度。</p>
<h1 id="开发实践"><a href="#开发实践" class="headerlink" title="开发实践"></a>开发实践</h1><p>本次实践只是简单的进行文本评论正反面的预测。选取的材料是京东商城酒类商品的评论。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>准备人工标注好的好评和差评文本. good.txt  bad.txt</p>
<ul>
<li>好评<br><img src="/picture/machine-learning/good.jpg" alt="good"></li>
<li>差评<br><img src="/picture/machine-learning/bad.jpg" alt="bad"></li>
<li>停用词（上网查找的）<br><img src="/picture/machine-learning/stop.jpg" alt="stop"><h2 id="特征提取和选择"><a href="#特征提取和选择" class="headerlink" title="特征提取和选择"></a>特征提取和选择</h2></li>
<li>使用jieba分词对文本进行分词<br><img src="/picture/machine-learning/jieba_cut.jpg" alt="jieba"></li>
<li>构建特征<br><img src="/picture/machine-learning/feature_selection_nlp.jpg" alt="feature_selection_nlp"></li>
<li>选择特征<br><img src="/picture/machine-learning/feature_selection_nlp2.jpg" alt="feature_selection_nlp"><br><img src="/picture/machine-learning/feature_selection_nlp3.jpg" alt="feature_selection_nlp"><h2 id="划分数据集-1"><a href="#划分数据集-1" class="headerlink" title="划分数据集"></a>划分数据集</h2><img src="/picture/machine-learning/split_data.jpg" alt="split_data"><h2 id="构建分类器"><a href="#构建分类器" class="headerlink" title="构建分类器"></a>构建分类器</h2><img src="/picture/machine-learning/classifier_sentiment.jpg" alt="classifier_sentiment"><br><img src="/picture/machine-learning/classifier_sentiment2.jpg" alt="classifier_sentiment"><h2 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h2><img src="/picture/machine-learning/predict_sentiment.jpg" alt="predict_sentiment"><br>下图是朴素贝叶斯得到的结果：可以看到正确率达到了90%<br><img src="/picture/machine-learning/predict_sentiment2.jpg" alt="predict_sentiment"><br>下图是其他算法得到的结果：可以看到逻辑回归和线性SVM正确率都在96%以上，效果不错。<br><img src="/picture/machine-learning/predict_sentiment3.jpg" alt="predict_sentiment"></li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.open-open.com/lib/view/open1421114964515.html" target="_blank" rel="external">大数据文摘：斯坦福大学怎样讲“情感分析”</a><br><a href="http://www.nltk.org/" target="_blank" rel="external">NLTK官网</a><br><a href="http://streamhacker.com/" target="_blank" rel="external">StreamHacker</a><br><a href="http://andybromberg.com/sentiment-analysis-python/" target="_blank" rel="external">Andybromberg</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;自然语言处理NLP&quot;&gt;&lt;a href=&quot;#自然语言处理NLP&quot; class=&quot;headerlink&quot; title=&quot;自然语言处理NLP&quot;&gt;&lt;/a&gt;自然语言处理NLP&lt;/h1&gt;&lt;p&gt;情感分析作为自然语言处理的一个部分，让我们首先看一下自然语言处理。&lt;/p&gt;
&lt;h2 id=&quot;相关技术及运用&quot;&gt;&lt;a href=&quot;#相关技术及运用&quot; class=&quot;headerlink&quot; title=&quot;相关技术及运用&quot;&gt;&lt;/a&gt;相关技术及运用&lt;/h2&gt;&lt;p&gt;自动问答（Question Answering，QA）：它是一套可以理解复杂问题，并以充分的准确度、可信度和速度给出答案的计算系统，以IBM‘s Waston为代表；&lt;br&gt;信息抽取（Information Extraction，IE）：其目的是将非结构化或半结构化的自然语言描述文本转化结构化的数据，如自动根据邮件内容生成Calendar；&lt;br&gt;情感分析（Sentiment Analysis，SA）：又称倾向性分析和意见挖掘，它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从大量网页文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向；&lt;br&gt;机器翻译（Machine Translation，MT）：将文本从一种语言转成另一种语言，如中英机器翻译。&lt;/p&gt;
&lt;h2 id=&quot;发展现状&quot;&gt;&lt;a href=&quot;#发展现状&quot; class=&quot;headerlink&quot; title=&quot;发展现状&quot;&gt;&lt;/a&gt;发展现状&lt;/h2&gt;&lt;p&gt;基本解决：词性标注、命名实体识别、Spam识别&lt;br&gt;取得长足进展：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取&lt;br&gt;挑战：自动问答、复述、文摘、会话机器人&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/nlp_process.png&quot; alt=&quot;nlp_process&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="情感分析" scheme="xtf615.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
      <category term="自然语言处理" scheme="xtf615.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="分词" scheme="xtf615.com/tags/%E5%88%86%E8%AF%8D/"/>
    
      <category term="NLTK" scheme="xtf615.com/tags/NLTK/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="xtf615.com/2017/02/09/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>xtf615.com/2017/02/09/线性回归/</id>
    <published>2017-02-09T14:27:47.000Z</published>
    <updated>2017-03-15T04:14:33.637Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><h2 id="房价预测例子"><a href="#房价预测例子" class="headerlink" title="房价预测例子"></a>房价预测例子</h2><p>  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子<br><img src="/picture/machine-learning/house_price.jpg" alt="house_price"><br>   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。下图是房价预测数据格式：<br>  <img src="/picture/machine-learning/train_set_representation.jpg" alt="train_set_representation"><br><a id="more"></a>  </p>
<h2 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h2><p>我们将要用来描述这个回归问题的标记如下:<br>    m代表训练集中实例的数量<br>    x代表特征/输入变量<br>    y代表目标变量/输出变量<br>    (x,y)代表训练集中的实例<br>    \((x^{(i)},y^{(i)})\) 代表第i个观察实例<br>    h代表学习算法的解决方案或函数也称为假设(hypothesis)<br><img src="/picture/machine-learning/supervised_learning.jpg" alt="supervised_learning"><br>  这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写h表示。h代表   hypothesis(假设)，h表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此h根据输入的x值来得出y值，y值对应房子的价格因此，h是一个从x到y的函数映射。<br>   我将选择最初的使用规则h代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设 h，然后将我们要预测的房屋的尺寸作为输入变量输入给h，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达h？<br>   一种可能的表达方式为：\(h_θ(x)=θ_0+θ_1x\)，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>我们将定义代价函数的概念，这有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合。如图：<br><img src="/picture/machine-learning/cost_function.jpg" alt="cost_function"><br>在线性回归中我们有一个像这样的训练集，m代表了训练样本的数量，比如m=47.而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：\(h_θ(x)=θ_0+θ_1x\)。接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数（parameters）θ0和θ1，在房价问题这个例子中便是直线的斜率和在  y轴上的截距。我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。<br><img src="/picture/machine-learning/modeling_error.jpg" alt="modeling_error"><br>我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。即使得代价函数最小：<br>$$J(\theta_{0},\theta_{1})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>我们绘制一个等高线图，三个坐标分别为 \(θ_0\) 和\(θ_1\) 和 \(J(θ_0,θ_1)\) ：<br><img src="/picture/machine-learning/contour.jpg" alt="contour"><br>可以看出在三维空间中存在一个使得 \(J(θ_0,θ_1)\) 最小的点.<br>代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出<br>误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合<br>理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回<br>归问题最常用的手段了。</p>
<h2 id="代价函数的理解（1）"><a href="#代价函数的理解（1）" class="headerlink" title="代价函数的理解（1）"></a>代价函数的理解（1）</h2><h3 id="Hypothesis"><a href="#Hypothesis" class="headerlink" title="Hypothesis:"></a>Hypothesis:</h3><p>$$h_\theta(x)=\theta_0+\theta_1x$$</p>
<h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters:"></a>Parameters:</h3><p>$$\theta_0,  \theta_1$$</p>
<h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function:"></a>Cost Function:</h3><p>$$J(\theta_{0},\theta_{1})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$</p>
<h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal:"></a>Goal:</h3><p>$$\min_{\theta_0,\theta_1}J(\theta_0,\theta_1)$$<br><img src="/picture/machine-learning/mini_.jpg" alt="mini"><br>如上图所示，左图为 \(\theta_0=0,\theta_1=0\) 时的代价,右图为 \(\theta_0=0\),代价函数随 \(\theta_1\) 变化的情况。可以看出当 \(\theta_1=1\) 时，代价损失最低。</p>
<h2 id="代价函数的理解（2）"><a href="#代价函数的理解（2）" class="headerlink" title="代价函数的理解（2）"></a>代价函数的理解（2）</h2><p><img src="/picture/machine-learning/contour2.jpg" alt="contour2"><br>如图是代价函数的样子，等高线图，可以看出在三维空间中存在一个使得 \(J(θ_0,θ_1)\) 最小的点。<br><img src="/picture/machine-learning/contour3.jpg" alt="contour3"><br>上图右边图形为三维图的二维等高线图。<br>通过这些图形，能更好地理解这些代价函数J所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数J的最小值。<br>当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数J取最小值的参数\(θ_0\)和 \(θ_1\)来。<br>我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的 \(θ_0\)和 \(θ_1\)的值.</p>
<h1 id="梯度下降Gradient-Descent"><a href="#梯度下降Gradient-Descent" class="headerlink" title="梯度下降Gradient Descent"></a>梯度下降Gradient Descent</h1><p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数\(J(θ_0,θ_1)\)的最小值。<br>梯度下降背后的思想是：开始时我们随机选择一个参数的组合 \((θ_0,θ_1,…,θ_n)\) ，计算代价<br>函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到到到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。<br><img src="/picture/machine-learning/hill.jpg" alt="hill"><br>想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转 360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。<br>批量梯度下降（batch gradient descent）算法的公式为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) \quad(for \ j = 0\ and\ j = 1)$$<br>}<br>其中 \(\alpha\)是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速<br>率乘以代价函数的导数。<br><img src="/picture/machine-learning/gradient_descent.jpg" alt="gradient"><br>在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新\(θ_0\)和 \(θ_1\)，当j=0和j=1时，会产生更新，所以你将更新 \(J_{θ_0}\)和\(J_{θ_0}\)。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新\(θ_0\)和 \(θ_1\).<br>让我进一步阐述这个过程：<br>$$temp_0:=\theta_0-\alpha\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)\\\\temp_1:=\theta_1-\alpha\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1) \\\ \theta_0:=temp_0 \\\ \theta_1:=temp_1$$<br>在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。</p>
<h2 id="梯度下降理解"><a href="#梯度下降理解" class="headerlink" title="梯度下降理解"></a>梯度下降理解</h2><p>$$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)$$<br>描述：对θ赋值，使得J(θ)按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中 α是学习率（learning  rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。<br><img src="/picture/machine-learning/gradient_descent2.jpg" alt="gradient"><br>对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的\(θ_1\)，\(θ_1\)更新后等于\(θ_1\)减去一个正数乘以 α。这就是我梯度下降法的更新规则：\(\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\)<br>让我们来看看如果 α太小或α太大会出现什么情况：</p>
<ul>
<li>如果α太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果 α太小的话，可能会很慢因为它会一点点挪动，它会需要很多步才能到达全局最低点。</li>
<li>如果 α太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果 α太大，它会导致无法收敛，甚至发散。</li>
</ul>
<p>现在，还有一个问题，<strong>如果我们预先把\(θ_1\)放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？</strong><br>假设你将\(θ_1\)初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。<br>结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得\(θ_1\)不再改变，也就是新的\(θ_1\)等于原来的\(θ_1\)，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率α保持不变时，梯度下降也可以收敛到局部最低点。<br>我们来看一个例子，这是代价函数 J(θ)。<br><img src="/picture/machine-learning/gradient_descent3.jpg" alt="gradient"><br>我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，\(θ_1\)更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。<br>回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小 α。这就是梯度下降算法，你可以用它来最小化任何代价函数 J，不只是线性回归中的代价函数J。</p>
<h2 id="梯度下降的线性回归"><a href="#梯度下降的线性回归" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h2><p>梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。接下来我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。<br>梯度下降算法和线性回归算法比较如图：<br><img src="/picture/machine-learning/gradient_descent_line.jpg" alt="gradient"><br>对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：<br>$$\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)=\frac{\partial}{\partial\theta_j}\left(\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\right)$$ </p>
<ul>
<li>j = 0时,<br>$$\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})$$</li>
<li>j = 1时，<br>$$\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)})$$<br>则算法改写成：<br><strong>repeat until convergence</strong>{<br>$$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)}) \\\ \theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)})$$<br>}<br>我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有m个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。<br>有一种计算代价函数J最小值的数值解法，不需要梯度下降这种迭代算法。它可以在不需要多步梯度下降的情况下，也能解出代价函数J的最小值，这是另一种称为正规方程(normal equations)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。</li>
</ul>
<h1 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h1><h2 id="多维特征"><a href="#多维特征" class="headerlink" title="多维特征"></a>多维特征</h2><p>目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，<br>例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为\((x_1,x_2,…,x_n)\)<br><img src="/picture/machine-learning/multple_feature.jpg" alt="multiple feature"><br>增添更多特征后，我们引入一系列新的注释：<br>n代表特征的数量<br>\(x^{(i)}\) 代表第i个训练实例，是特征矩阵中的第i行，是一个向量（vector）。例如上图中：$$x^{(2)}=\begin{bmatrix} 1416 \\\ 3 \\\ 2 \\\ 40\end{bmatrix}$$</p>
<p>\(x_j^{(i)}\) 代表特征矩阵中第i行的第j个特征，也就是第i个训练实例的第j个特征。例如上图中， \(x_3^{(2)}=2\)<br>支持多变量的假设h表示为：<br>$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$$<br>这个公式中有 n+1个参数和n个变量，为了使得公式能够简化一些，引入 \(x_0=1\)， 此时模型中的参数是一个n+1维的向量，任何一个训练实例也都是n+1维的向量，特征矩阵\(X\)的维度是m*(n+1)。因此公式可以简化为：<br>$$h_{\theta}(x)=\theta^TX$$ </p>
<h2 id="多变量梯度下降"><a href="#多变量梯度下降" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h2><p>与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价<br>函数是所有建模误差的平方和，即：<br>$$J(\theta_{0},\theta_{1}…,\theta_{n})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>其中 \(h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n\)<br>我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。<br>多变量线性回归的批量梯度下降算法为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,…,\theta_n)$$<br>}<br>即：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}\left(\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\right)$$<br>}<br>求导后得到：</p>
<p><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}) \\\ (simultaneously \ update \ \theta_j \ for \ j=0,1,2,…,n)$$<br>}<br>我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p>
<h2 id="梯度下降实践——特征缩放"><a href="#梯度下降实践——特征缩放" class="headerlink" title="梯度下降实践——特征缩放"></a>梯度下降实践——特征缩放</h2><p>在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。<br>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为   0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。<br><img src="/picture/machine-learning/feature_scale.jpg" alt="feature_scale"><br>解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：<br><img src="/picture/machine-learning/feature_scale2.jpg" alt="feature_scale"><br>最简单的方法是令：<br>$$x_n = \frac{x_n-\mu_n}{S_n} \\\ 其中, \mu_n是平均值，S_n是标准差$$</p>
<h2 id="梯度下降实践——学习率"><a href="#梯度下降实践——学习率" class="headerlink" title="梯度下降实践——学习率"></a>梯度下降实践——学习率</h2><p>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。<br><img src="/picture/machine-learning/learn_rate.jpg" alt="learn_rate"><br>梯度下降算法的每次迭代受到学习率的影响，如果学习率 α过小，则达到收敛所需的迭代次数会非常高；如果学习率 α过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。通常可以考虑尝试些学习率：\(α=0.01，0.03，0.1，0.3，1，3，10\)</p>
<h2 id="特征与多项式回归"><a href="#特征与多项式回归" class="headerlink" title="特征与多项式回归"></a>特征与多项式回归</h2><p>如房价预测问题，<br>$$h_\theta(x)=\theta_0+\theta_1*frontage+\theta_2*depth\\\ x_1=frontage(临街宽度),x_2=depth(纵向深度) \\\ x=frontage*depth=area(面积) ， 则：h_\theta(x)=\theta_0+\theta_1x$$<br>线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：<br>$$h_\theta(x)=\theta_0+\theta_1x+\theta_2x_2^2$$<br>或者三次方模型：<br>$$h_\theta(x)=\theta_0+\theta_1x+\theta_2x_2^2+\theta_3x_3^3$$<br><img src="/picture/machine-learning/polynomial_regression.jpg" alt="polynomial_regression"><br>通常我们需要先观察数据然后再决定准备尝试怎样的模型。另外，我们可以令：<br>$$x_2=x_2^2 \\\ x_3=x_3^2$$<br>从而将模型转化为线性回归模型。<br>根据函数图形特性，我们还可以使：<br>$$h_\theta(x)=\theta_0+\theta_1(size)+\theta_2(size)^2<br>\\\ 或者 \\\\<br>h_\theta(x)=\theta_0+\theta_1(size)+\theta_2\sqrt{(size)}$$<br>注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。</p>
<h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法正规方程是通过求解下面的方程来找出使得代价函数最小的参数的是更好的解决方案。<br>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：<br>$$\frac{\partial}{\partial\theta_j}J(\theta_j)=0$$<br>假设我们的训练集特征矩阵为:\(X\)（包含 \(x_0=1\) ）,并且我们的训练集结果为向量   y，则利用正规方程解出向量:<br>$$\theta=\left(X^TX\right)^{-1}X^Ty \\\\<br>设矩阵A=X^TX，则：(X^TX)^{-1}=A^{-1} \\\\<br>上标T代表矩阵转置，-1代表矩阵的逆。$$</p>
<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><p><img src="/picture/machine-learning/normal_example.jpg" alt="normal_example"></p>
<p><table><br>    <tr><br>        <td>X(0)</td> <td>X(1)</td> <td>X(2)</td> <td>X(3)</td> <td>X(4)</td><td>y</td><br>    </tr><br>    <tr><br>        <td>1</td><td>2104</td> <td>5</td> <td>1</td> <td>45</td> <td>460</td><br>    </tr><br>    <tr><br>        <td>1</td><td>1416</td> <td>3</td> <td>2</td> <td>40</td> <td>232</td><br>    </tr><br>    <tr><br>        <td>1</td><td>1534</td> <td>3</td> <td>2</td> <td>30</td> <td>315</td><br>    </tr><br>    <tr><br>        <td>1</td><td>852</td> <td>2</td> <td>1</td> <td>36</td> <td>178</td><br>    </tr><br></table><br>再运用正规方程求解参数：<br><img src="/picture/machine-learning/normal_example2.jpg" alt="normal_example"><br>注：<strong>对于那些不可逆的矩阵</strong>（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。<br> |编号|说明|国外|   </p>
<h3 id="梯度下降和正规方程比较："><a href="#梯度下降和正规方程比较：" class="headerlink" title="梯度下降和正规方程比较："></a>梯度下降和正规方程比较：</h3><p><table><br>    <tr><br>        <td><strong>梯度下降</strong></td> <td><strong>正规方程</strong></td><br>    </tr><br>    <tr><br>        <td>需要选择学习率</td><td>不需要</td><br>    </tr><br>    <tr><br>        <td>需要多次迭代</td><td>一次运算得出</td><br>    </tr><br>    <tr><br>        <td>当特征数量 n大时也能较好适用</td> <td>需要计算 \((X^TX)^{-1}\) 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为 \(O(n^3)\)，通常来说当n小于10000时还是可以接受的</td><br>    </tr><br>    <tr><br>        <td>适用于各种类型的模型</td><td>只适用于线性模型，不适合逻辑回归模型等其他模型</td><br>    </tr><br></table><br>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数  θ的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。随着学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。</p>
<h3 id="正规方程之不可逆性"><a href="#正规方程之不可逆性" class="headerlink" title="正规方程之不可逆性"></a>正规方程之不可逆性</h3><p>我们要讲的问题如下：<br>$$\theta=\left(X^TX\right)^{-1}X^Ty$$<br>对于矩阵，\(X^TX\) 不可逆的情况怎么解决？<br>如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。问题的重点在于 X’X的不可逆的问题很少发生。</p>
<ul>
<li>特征值存在线性关联。<br>例如，在预测住房价格时，如果x1是以英尺为尺寸规格计算的房子，x2是以平方米为尺寸规格计算的房子，同时，你也知道 1米等于3.28英尺(四舍五入到两位小数)，这样，你的这两个特征值将始终满足约束：\(x_1=x_2*(3.28)\)。</li>
<li>大量的特征<br>第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵 \(X^TX\)的结果是不可逆的。<br>具体地说，在 m小于或等于n的时候，例如，有m等于10个的训练样本,n等于100的特征数量。要找到适合的(n+1)维参数矢量\(θ\)，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵.<br>稍后我们将看到，如何使用小数据样本以得到这 100或  101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当m比n小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。</li>
</ul>
<p><strong>总之当你发现的矩阵 X’X的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，要怎么做？</strong><br>首先，看特征值里是否有一些多余的特征，像这些 x1和x2是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。如果特征数量实在太多，我会删除些用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。</p>
<h1 id="拓展-广义线性模型与线性回归"><a href="#拓展-广义线性模型与线性回归" class="headerlink" title="拓展 广义线性模型与线性回归"></a>拓展 广义线性模型与线性回归</h1><p>线性回归是广义线性模型的一种特殊形式。</p>
<h2 id="广义线性模型GLM"><a href="#广义线性模型GLM" class="headerlink" title="广义线性模型GLM"></a>广义线性模型GLM</h2><p>三个假设：</p>
<ul>
<li>\(y|x;\sim ExponentialFamily(\eta) \)，即y的条件概率属于指数分布簇（The exponential Family）</li>
<li>给定x广义线性模型的目标是求解\(T(y)|x\),不过由于很多情况下\(T(y)=y\),所以我们的目标就变成\(y|x\),也即我们希望拟合函数为\(h(x)=E[y|x]\) (备注：这个条件在线性回归中满足)</li>
<li>自然参数\(\eta\)与\(x\)是线性关系：\(\eta=\theta^Tx\) (\(\eta为向量时,\eta_i=\theta_i^Tx\))</li>
</ul>
<h2 id="指数分布簇-The-exponential-Family）"><a href="#指数分布簇-The-exponential-Family）" class="headerlink" title="指数分布簇(The exponential Family）"></a>指数分布簇(The exponential Family）</h2><p>首先定义一下指数分布，它有如下形式:<br>$$p(y;\eta)=b(y)exp(\eta^{T}T(y)-a(\eta)) \\\\<br>其中，\eta是自然参数(natural \ parameter), \\\ <br>T(y)是充分统计量(sufficient \ statistic,一般T(y)=y),\\\\<br>a(\eta)是log \ partition \ function(e^{-a(\eta)}充当正规化常量的角色，保证\sum p(y;\eta)=1)<br>$$<br>也就是说，T,a,b确定了一种分布，\(\eta\)是该分布的参数。选择合适的T,a,b我们可以得到高斯分布Gaussian和伯努利分布Bernoulli等。</p>
<p>即，有了广义线性模型，我们只需要把符合指数分布的一般模型的参数转换为它对应的广义线性模型参数，然后按照广义线性模型的求解步骤，即可轻松求解问题。</p>
<h2 id="Gaussian高斯分布的指数分布簇形式"><a href="#Gaussian高斯分布的指数分布簇形式" class="headerlink" title="Gaussian高斯分布的指数分布簇形式"></a>Gaussian高斯分布的指数分布簇形式</h2><p>在线性回归中，\(\sigma对于模型参数\theta的选择没有影响，为了推导方便我们将其设为1：\)<br>$$p(y;\mu)=\frac{1}{\sqrt{2\pi}}exp\left(-\frac{1}{2}(y-\mu)^2\right) \\\\<br>    = \frac{1}{\sqrt{2\pi}}exp\left(-\frac{1}{2}y^2\right)*exp\left(\mu y-\frac{1}{2}\mu^2\right)<br>$$<br>得到对应参数：<br>$$T(y)=y \\\\<br>\eta=\mu \\\\<br>a(\eta)=\mu^2/2=\eta^2/2 \\\\<br>b(y)=(1/\sqrt{2\pi})exp(-y^2/2)<br>$$</p>
<h2 id="广义线性模型推导线性回归"><a href="#广义线性模型推导线性回归" class="headerlink" title="广义线性模型推导线性回归"></a>广义线性模型推导线性回归</h2><p>我们重新审视一下线性回归,线性回归的表达如下：<br>$$y=\theta^TX+\epsilon$$<br>最重要的假设是，我们认为\(\epsilon\)满足均值为0，方差为\(\sigma^2\)的高斯分布，且满足\(iid\),即独立同分布,  $$\\\epsilon \sim N(0,\sigma^2)$$<br>因此有\(E(\epsilon)=0\),根据上述线性回归表达式我们实际上有，\(E(y)=E(\theta^TX+\epsilon)\), 可以得出y实际上是满足均值为\(\theta^TX\),方差为\(\sigma^2\)的高斯分布，这里的y可以写做\(y|x;\theta\),即：<br>$$y|x;\theta \sim N(\theta^TX,\sigma^2)$$</p>
<p>下面从广义线性模型角度进行推导：</p>
<ul>
<li>step1: \(y|x; \sim N(\mu,\theta)\)</li>
<li>step2: 由假设2: \(h(x)=E[y|x]\) 得到：<br>$$h_\theta(x)=E[y|x;\Theta]\\\\<br>=\mu \\\\<br>=\eta  \\\\<br>=\Theta^Tx  \\\\<br>其中, E[y|x;\Theta]=\mu由假设1得到；\\\\<br>\mu=\eta由高斯分布对应的广义线性模型参数得到；\\\\<br>\eta = \Theta^Tx由假设3得到。<br>$$<br>可以看出\(h_\theta(x)=E[y|x;\Theta]=\Theta^Tx\), \(h_\theta(x)\)实际上就是\(y|x;\theta\)的期望，跟最初的假设是一致的。最后注意一下，\(\theta\)不是随机变量，我们把它看作是某个固定的值，我们要找到这个固定的值。</li>
</ul>
<h2 id="代价函数推导"><a href="#代价函数推导" class="headerlink" title="代价函数推导"></a>代价函数推导</h2><p>根据前面的假设，我们知道\(\epsilon\)满足独立同分布。<br>根据最大似然估计法，我们定义：<br>$$L(\theta)=P(y|X;\theta)$$<br>我们希望每个样本出现的概率最大。再根据独立同分布假设以及高斯分布概率密度函数，我们有：<br>$$L(\theta)=P(y|X;\theta)=\prod_{i=1}^mP(y^{(i)}|x^{(i)};\theta) \\\\<br>=\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)<br>$$<br>两边取对数，有:<br>$$l(\theta)=log(L(\theta))=mlog(\frac{1}{\sqrt{2\pi}\sigma})+\sum_{i=1}^m\left(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)$$</p>
<p>为了使\(l(\theta)\)最大化，我们需要最小化：<br>$$\frac{1}{2}\sum_{i=1}^m(y^{(i)}-\theta^Tx^{(i)})^2$$<br>再调整系数，我们取样本平均，得到：<br>$$J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以看出，广义线性模型要求被解释变量属于指数分布簇。为什么呢？<br>逆推：被解释变量属于指数分布簇-&gt;被解释变可以写成指数分布的形式-&gt;其指数分布形式的参数\(\eta\)与原分布参数会发生联系-&gt;联系的方式是\(\eta=f(原分布中的参数,比如\mu等，则f(\mu)即连接函数)\)</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/47637500?sort=created" target="_blank" rel="external">知乎：为什么广义线性模型GLM要求被解释变量属于指数分布簇</a><br><a href="https://zhuanlan.zhihu.com/p/22876460" target="_blank" rel="external">知乎：广义线性模型</a>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;模型表示&quot;&gt;&lt;a href=&quot;#模型表示&quot; class=&quot;headerlink&quot; title=&quot;模型表示&quot;&gt;&lt;/a&gt;模型表示&lt;/h1&gt;&lt;h2 id=&quot;房价预测例子&quot;&gt;&lt;a href=&quot;#房价预测例子&quot; class=&quot;headerlink&quot; title=&quot;房价预测例子&quot;&gt;&lt;/a&gt;房价预测例子&lt;/h2&gt;&lt;p&gt;  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/house_price.jpg&quot; alt=&quot;house_price&quot;&gt;&lt;br&gt;   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。下图是房价预测数据格式：&lt;br&gt;  &lt;img src=&quot;/picture/machine-learning/train_set_representation.jpg&quot; alt=&quot;train_set_representation&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="xtf615.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="xtf615.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="梯度下降" scheme="xtf615.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
  </entry>
  
</feed>
