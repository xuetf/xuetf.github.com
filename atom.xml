<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蘑菇先生学习记</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="xtf615.com/"/>
  <updated>2017-02-09T15:53:18.556Z</updated>
  <id>xtf615.com/</id>
  
  <author>
    <name>xuetf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>线性回归</title>
    <link href="xtf615.com/2017/02/09/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>xtf615.com/2017/02/09/线性回归/</id>
    <published>2017-02-09T14:27:47.000Z</published>
    <updated>2017-02-09T15:53:18.556Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><h2 id="房价预测例子"><a href="#房价预测例子" class="headerlink" title="房价预测例子"></a>房价预测例子</h2><p>  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子<br><img src="/picture/machine-learning/house_price.jpg" alt="house_price"><br>   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。<br>  <img src="/picture/machine-learning/train_set_representation.jpg" alt="train_set_representation"> </p>
<h2 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h2><p>我们将要用来描述这个回归问题的标记如下:<br>    m代表训练集中实例的数量<br>    x代表特征/输入变量<br>    y代表目标变量/输出变量<br>    (x,y)代表训练集中的实例<br>    \((x^{(i)},y^{(i)})\) 代表第i个观察实例<br>    h代表学习算法的解决方案或函数也称为假设(hypothesis)<br><img src="/picture/machine-learning/supervised_learning.jpg" alt="supervised_learning"><br>  这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写h表示。h代表   hypothesis(假设)，h表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此h根据输入的x值来得出y值，y值对应房子的价格因此，h是一个从x到y的函数映射。<br>   我将选择最初的使用规则h代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设 h，然后将我们要预测的房屋的尺寸作为输入变量输入给h，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达h？<br>   一种可能的表达方式为：\(h_θ(x)=θ_1+θ_2x\)，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>我们将定义代价函数的概念，这有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合。如图：<br><img src="/picture/machine-learning/cost_function.jpg" alt="cost_function"><br>在线性回归中我们有一个像这样的训练集，m代表了训练样本的数量，比如m=47.而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：\(h_θ(x)=θ_1+θ_2x\)。接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数（parameters）θ0和θ1，在房价问题这个例子中便是直线的斜率和在  y轴上的截距。我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。<br><img src="/picture/machine-learning/modeling_error.jpg" alt="modeling_error"><br>我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。即使得代价函数：<br>$$J(\theta_0,\theta_1)=\frac{1}{2m}\sum_i=1^m\left(h_θ(x^{(i)})-y^{(i)}\right)^2$$</p>
<p>$$J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^m$$</p>
<p>$$J(\theta_0,\theta_1)=\frac{1}{2m}$$</p>
<p>$$\sum_{i=1}^m$$</p>
<p>$$\left(h_\theta(x^{(i)})-y^{(i)}\right)^2$$</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;模型表示&quot;&gt;&lt;a href=&quot;#模型表示&quot; class=&quot;headerlink&quot; title=&quot;模型表示&quot;&gt;&lt;/a&gt;模型表示&lt;/h1&gt;&lt;h2 id=&quot;房价预测例子&quot;&gt;&lt;a href=&quot;#房价预测例子&quot; class=&quot;headerlink&quot; title=&quot;房价预测例
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="xtf615.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="xtf615.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>机器学习概念</title>
    <link href="xtf615.com/2017/01/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5/"/>
    <id>xtf615.com/2017/01/18/机器学习概念/</id>
    <published>2017-01-18T01:25:34.000Z</published>
    <updated>2017-01-18T03:56:17.623Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>机器学习是目前信息技术中最激动人心的方向之一。你或许每天都在不知不觉中使用了机器学习的算法。</p>
<ul>
<li>你打开谷歌、必应搜索到你需要的内容，正是因为他们有良好的学习算法，谷歌和微软实现了学习算法来排行网页。</li>
<li>你用Facebook或苹果的图片分类程序他能认出你朋友的照片，这也是机器学习。</li>
<li>每次您阅读您的电子邮件垃圾邮件筛选器，可以帮你过滤大量的垃圾邮件这也是一种学习算法。</li>
</ul>
<p><strong>那么，为什么机器学习如此受欢迎呢？</strong><br>机器学习不只是用于人工智能领域。我们创造智能的机器，有很多基础的知识。比如，我们可以让机器找到A与B之间的最短路径，但我们仍然不知道怎么让机器做更有趣的事情，如web搜索、照片标记、反垃圾邮件。我们发现，<strong>唯一方法是让机器自己学习怎么来解决问题</strong>。所以，机器学习已经成为计算机的一个能力，现在它涉及到各个行业和基础科学中。</p>
<p><strong>这里有一些机器学习的案例。</strong></p>
<ul>
<li><strong>数据挖掘</strong>。机器学习被用于数据挖掘的原因之一是网络和自动化技术的增长，这意味着，我们有史上最大的数据集比如说，大量的硅谷公司正在收集  web上的单击数据，也称为点击流数据，并尝试使用机器学习算法来分析数据，更好的了解用户，并为用户提供更好的服务。这在硅谷有巨大的市场。</li>
<li><strong>医疗记录</strong>。随着自动化的出现，我们现在有了电子医疗记录。如果我们可以把医疗记录变成医学知识，我们就可以更好地理解疾病。</li>
<li><strong>计算生物学</strong>。还是因为自动化技术，生物学家们收集的大量基因数据序列、DNA序列和等等，机器运行算法让我们更好地了解人类基因组，大家都知道这对人类意味着什么。</li>
<li><strong>工程方面</strong>。在工程的所有领域，我们有越来越大、越来越大的数据集，我们试图使用学习算法，来理解这些数据。另外，在机械应用中，有些人不能直接操作。例如，我已经在无人直升机领域工作了许多年。我们不知道如何写一段程序让直升机自己飞。我们唯一能做的就是让计算机自己学习如何驾驶直升机。</li>
<li><p><strong>手写识别</strong>。现在我们能够非常便宜地把信寄到这个美国甚至全世界的原因之一就是当你<br>写一个像这样的信封，一种学习算法已经学会如何读你信封，它可以自动选择路径，所以我们只需要花几个美分把这封信寄到数千英里外。</p>
</li>
<li><p><strong>自然语言处理或计算机视觉</strong>。这些语言理解或图像理解都是属于AI领域。大部分的自然语言处理和大部分的计算机视觉，都应用了机器学习。学习算法还广泛用于自定制程序。每次你去亚马逊或 Netflix或  iTunes Genius，它都会给出其他电影或产品或音乐的建议，这是一种学习算法。仔细想一想，他们有百万的用户；但他们没有办法为百万用户，编写百万个不同程序。软件能给这些自定制的建议的唯一方法是通过学习你的行为，来为你定制服务。</p>
<a id="more"></a>
</li>
</ul>
<h1 id="机器学习概念"><a href="#机器学习概念" class="headerlink" title="机器学习概念"></a>机器学习概念</h1><ul>
<li><strong>Arthur Samuel</strong>： 他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。<br>   <code>Samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。然后就牛逼大发了，程序通过学习后，玩西洋棋的水平超过了Samuel。这绝对是令人注目的成果。</code></li>
<li><strong>Tom Mitchell</strong>: 一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。<br>   <code>e就是程序上万次的自我练习的经验, 而任务t就是下棋。性能度量值p呢，就是它在与一些新的对手比赛时，赢得比赛的概率。</code></li>
</ul>
<h1 id="监督学习概念"><a href="#监督学习概念" class="headerlink" title="监督学习概念"></a>监督学习概念</h1><ul>
<li><strong>回归问题</strong>（房价预测）：<br><img src="/picture/machine-learning/house_price_prediction.jpg" alt="house_price_prediction"><br>我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150, 000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200, 000。<br>可以看出，<strong>监督学习指的就是我们给学习算法一个数据集，这个数据集由“正确答案”组成。</strong>在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。</li>
<li><strong>分类问题</strong>（乳腺癌良性与否）：<br><img src="/picture/machine-learning/breast_cancer.jpg" alt="breast_cancer"><br> 假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出 1和  0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为 1，不是恶性，或者说良性记为 0。我有 5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个分类问题。分类指的是，我们试着推测出离散的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出  0、1、2、3。0代表良性，1表示第一类乳腺癌，2表示第二类癌症，3表示第三类，但这也是分类问题。因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画 X，良性的肿瘤改成用 O表示，恶性的继续用  X表示。来预测肿瘤的恶性与否。在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。</li>
<li><strong>总结</strong><br>现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，<strong>我们数据集中的每个样本都有相应的“正确答案”。</strong>再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。</li>
</ul>
<h1 id="无监督学习概念"><a href="#无监督学习概念" class="headerlink" title="无监督学习概念"></a>无监督学习概念</h1><p>   &emsp;在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即<strong>无监督学习中没有任何的标签或者是有相同的标签或者就是没标签</strong>。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。</p>
<ul>
<li><strong>谷歌新闻</strong>：<br>聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个  URL网址 news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。</li>
<li><strong>基因学</strong>：<br><img src="/picture/machine-learning/DNA.jpg" alt="DNA"><br>一个 DNA微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）……</li>
<li><strong>组织大型计算机集群</strong>:<br>在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。</li>
<li><strong>社交网络</strong>:<br>所以已知你朋友的信息，比如你经常发email的，或是你Facebook的朋友、谷歌+圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？</li>
<li><strong>市场分割</strong>：<br>许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。</li>
<li><strong>天文数据分析</strong>：<br>这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。</li>
<li><strong>语音识别</strong>：<br><img src="/picture/machine-learning/cocktail_party.jpg" alt="party"><br>鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是：1，2，3，4，5，6，7，8，9，10。<br>看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器JAVA库,处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成.就是这里展示的代码：<br><code>[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);</code><br>研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用 Octave编程环境。Octave,是免费的开源软件，使用一个像Octave或Matlab的工具，许多学习算法变得只有几行代码就可实现。</li>
</ul>
<p>所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;机器学习是目前信息技术中最激动人心的方向之一。你或许每天都在不知不觉中使用了机器学习的算法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你打开谷歌、必应搜索到你需要的内容，正是因为他们有良好的学习算法，谷歌和微软实现了学习算法来排行网页。&lt;/li&gt;
&lt;li&gt;你用Facebook或苹果的图片分类程序他能认出你朋友的照片，这也是机器学习。&lt;/li&gt;
&lt;li&gt;每次您阅读您的电子邮件垃圾邮件筛选器，可以帮你过滤大量的垃圾邮件这也是一种学习算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;那么，为什么机器学习如此受欢迎呢？&lt;/strong&gt;&lt;br&gt;机器学习不只是用于人工智能领域。我们创造智能的机器，有很多基础的知识。比如，我们可以让机器找到A与B之间的最短路径，但我们仍然不知道怎么让机器做更有趣的事情，如web搜索、照片标记、反垃圾邮件。我们发现，&lt;strong&gt;唯一方法是让机器自己学习怎么来解决问题&lt;/strong&gt;。所以，机器学习已经成为计算机的一个能力，现在它涉及到各个行业和基础科学中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里有一些机器学习的案例。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据挖掘&lt;/strong&gt;。机器学习被用于数据挖掘的原因之一是网络和自动化技术的增长，这意味着，我们有史上最大的数据集比如说，大量的硅谷公司正在收集  web上的单击数据，也称为点击流数据，并尝试使用机器学习算法来分析数据，更好的了解用户，并为用户提供更好的服务。这在硅谷有巨大的市场。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;医疗记录&lt;/strong&gt;。随着自动化的出现，我们现在有了电子医疗记录。如果我们可以把医疗记录变成医学知识，我们就可以更好地理解疾病。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算生物学&lt;/strong&gt;。还是因为自动化技术，生物学家们收集的大量基因数据序列、DNA序列和等等，机器运行算法让我们更好地了解人类基因组，大家都知道这对人类意味着什么。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工程方面&lt;/strong&gt;。在工程的所有领域，我们有越来越大、越来越大的数据集，我们试图使用学习算法，来理解这些数据。另外，在机械应用中，有些人不能直接操作。例如，我已经在无人直升机领域工作了许多年。我们不知道如何写一段程序让直升机自己飞。我们唯一能做的就是让计算机自己学习如何驾驶直升机。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;手写识别&lt;/strong&gt;。现在我们能够非常便宜地把信寄到这个美国甚至全世界的原因之一就是当你&lt;br&gt;写一个像这样的信封，一种学习算法已经学会如何读你信封，它可以自动选择路径，所以我们只需要花几个美分把这封信寄到数千英里外。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;自然语言处理或计算机视觉&lt;/strong&gt;。这些语言理解或图像理解都是属于AI领域。大部分的自然语言处理和大部分的计算机视觉，都应用了机器学习。学习算法还广泛用于自定制程序。每次你去亚马逊或 Netflix或  iTunes Genius，它都会给出其他电影或产品或音乐的建议，这是一种学习算法。仔细想一想，他们有百万的用户；但他们没有办法为百万用户，编写百万个不同程序。软件能给这些自定制的建议的唯一方法是通过学习你的行为，来为你定制服务。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概念" scheme="xtf615.com/tags/%E6%A6%82%E5%BF%B5/"/>
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
  </entry>
  
  <entry>
    <title>windows下idea编程实现远程发布任务到Spark集群</title>
    <link href="xtf615.com/2016/12/30/windows%E4%B8%8Bidea%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E5%8F%91%E5%B8%83%E4%BB%BB%E5%8A%A1%E5%88%B0Spark%E9%9B%86%E7%BE%A4/"/>
    <id>xtf615.com/2016/12/30/windows下idea编程实现远程发布任务到Spark集群/</id>
    <published>2016-12-30T11:47:13.000Z</published>
    <updated>2017-01-06T01:26:30.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本文的目标是：在windows下，使用idea编写spark任务，并可直接右键运行提交至远程Linux Spark集群上，不需要打包后再拷贝至远程Linux服务器上，再使用命令运行。</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul>
<li>软件<ul>
<li>win10</li>
<li>jdk1.7(windows版本:1.7.0_79)</li>
<li>scala2.11.8(windows版本：scala-2.11.8.zip)</li>
<li>idea 2016.3.2(windows版本：ideaIU-2016.3.2.exe)</li>
<li>hadoop2.7.3(linux版本：hadoop-2.7.3.tar.gz)</li>
<li>spark2.0.2(linux版本：spark-2.0.2-bin-hadoop2.7.tgz)</li>
<li>idea scala插件（scala-intellij-bin-2016.3.4.zip，<a href="https://plugins.jetbrains.com/idea/plugin/1347-scala）" target="_blank" rel="external">https://plugins.jetbrains.com/idea/plugin/1347-scala）</a></li>
<li>winutil.exe等（<a href="https://github.com/xuetf/spark/blob/master/idea/hadoop-common-2.2.0-bin.rar?raw=true" target="_blank" rel="external">winutil下载地址</a>）</li>
<li>maven3.3.9(windows版本：apache-maven-3.3.9-bin.zip)<a id="more"></a></li>
</ul>
</li>
<li>搭建Spark集群<br><a href="/2016/12/29/Spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">分布式Spark集群搭建</a></li>
<li>配置windows环境变量<ul>
<li>jdk(windows版本) JAVA_HOME</li>
<li>scala(windows版本) SCALA_HOME</li>
<li>hadoop(linux版本) HADOOP_HOME</li>
<li>maven(windows版本) MAVEN_HOME<br><strong>注意：以上环境变量均在windows下配置，括号中强调了软件包的平台版本。</strong></li>
</ul>
</li>
<li><p>配置idea</p>
<ul>
<li><p>maven配置：</p>
<ul>
<li><p><strong>修改setting.xml</strong><br>修改%MAVEN_HOME%下的conf/setting.xml为阿里云镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">在mirrors节点添加：</div><div class="line">&lt;mirror&gt; </div><div class="line">    &lt;id&gt;nexus-aliyun&lt;/id&gt;</div><div class="line">    &lt;name&gt;Nexus aliyun&lt;/name&gt;</div><div class="line">    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; </div><div class="line">    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; </div><div class="line">&lt;/mirror&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>修改idea的maven配置</strong><br>主要是为了加快建立maven项目时的速度<br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_setting1.png" alt="maven-idea-setting1"><br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_setting2.png" alt="maven-idea-setting2"> </p>
</li>
</ul>
</li>
<li><p>scala pluin配置<br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/idea_scala_plugin1.png" alt="scala-idea-setting1"><br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/idea_scala_plugin2.png" alt="scala-idea-setting1">     </p>
</li>
</ul>
</li>
</ul>
<h1 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h1><ul>
<li><strong>新建MAVEN+SCALA项目</strong><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala.png" alt="maven-scala1"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala2.png" alt="maven-scala2"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala3.png" alt="maven-scala3"> </li>
<li><p><strong>配置JDK、SCALA</strong><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala4.png" alt="maven-scala4"> </p>
</li>
<li><p><strong>添加POM依赖</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;properties&gt;</div><div class="line">  &lt;spark.version&gt;2.0.2&lt;/spark.version&gt;</div><div class="line">  &lt;scala.version&gt;2.11&lt;/scala.version&gt;</div><div class="line">&lt;/properties&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;2.6.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>编写代码</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</div><div class="line">import scala.math.random</div><div class="line">object SparkPi &#123;</div><div class="line">  def main(args:Array[String]):Unit = &#123;</div><div class="line">    val conf = new SparkConf().setAppName(&quot;Spark Pi&quot;).setMaster(&quot;spark://172.16.21.121:7077&quot;)</div><div class="line">      .setJars(List(&quot;E:\\idea-workspace\\spark-practice\\out\\artifacts\\spark_practice_jar\\spark-practice.jar&quot;));</div><div class="line"></div><div class="line">    val spark = new SparkContext(conf)</div><div class="line">    val slices = if (args.length &gt; 0) args(0).toInt else 2</div><div class="line">    val n = 100000 * slices</div><div class="line">    val count = spark.parallelize(1 to n, slices).map &#123; i =&gt;</div><div class="line">      val x = random * 2 - 1</div><div class="line">      val y = random * 2 - 1</div><div class="line">      if (x * x + y * y &lt; 1) 1 else 0</div><div class="line">    &#125;.reduce(_ + _)</div><div class="line">    println(&quot;Pi is roughly &quot; + 4.0 * count / n)</div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  其中setMaster为：spark主节点的地址。setjars为下面步骤生成的jar包在window路径下的目录</p>
</li>
<li><p>添加输出sparkdemo.jar<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts1.png" alt="artifacts1"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts2.png" alt="artifacts2"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts3.png" alt="artifacts3"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts4.png" alt="artifacts4"> </p>
</li>
<li><p>编译代码<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/build.png" alt="build"> </p>
</li>
<li><p><strong>删除输出的sparkdemo.jar中META-INF中多余文件</strong><br>只保留MANIFEST.MF和MAVEN文件夹<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/sparkdemo_mete_inf_delete.png" alt="delete"> </p>
</li>
<li><p><strong>include in build勾掉</strong><br>防止右键运行的时候，重新输出，导致mete-inf又恢复了<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/build2.png" alt="去掉include in build"> </p>
</li>
<li><p>设置VM参数<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/vm.png" alt="VM参数"> </p>
</li>
<li>右键运行<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/run-result.png" alt="run1"> </li>
<li>运行时可查看web控制台<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/spark-running.png" alt="run2"><br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/spark-finished.png" alt="run3"> </li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;p&gt;本文的目标是：在windows下，使用idea编写spark任务，并可直接右键运行提交至远程Linux Spark集群上，不需要打包后再拷贝至远程Linux服务器上，再使用命令运行。&lt;/p&gt;
&lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;软件&lt;ul&gt;
&lt;li&gt;win10&lt;/li&gt;
&lt;li&gt;jdk1.7(windows版本:1.7.0_79)&lt;/li&gt;
&lt;li&gt;scala2.11.8(windows版本：scala-2.11.8.zip)&lt;/li&gt;
&lt;li&gt;idea 2016.3.2(windows版本：ideaIU-2016.3.2.exe)&lt;/li&gt;
&lt;li&gt;hadoop2.7.3(linux版本：hadoop-2.7.3.tar.gz)&lt;/li&gt;
&lt;li&gt;spark2.0.2(linux版本：spark-2.0.2-bin-hadoop2.7.tgz)&lt;/li&gt;
&lt;li&gt;idea scala插件（scala-intellij-bin-2016.3.4.zip，&lt;a href=&quot;https://plugins.jetbrains.com/idea/plugin/1347-scala）&quot;&gt;https://plugins.jetbrains.com/idea/plugin/1347-scala）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;winutil.exe等（&lt;a href=&quot;https://github.com/xuetf/spark/blob/master/idea/hadoop-common-2.2.0-bin.rar?raw=true&quot;&gt;winutil下载地址&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;maven3.3.9(windows版本：apache-maven-3.3.9-bin.zip)
    
    </summary>
    
      <category term="spark" scheme="xtf615.com/categories/spark/"/>
    
    
      <category term="spark" scheme="xtf615.com/tags/spark/"/>
    
      <category term="idea" scheme="xtf615.com/tags/idea/"/>
    
      <category term="scala" scheme="xtf615.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>spark分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/Spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/Spark分布式环境搭建教程/</id>
    <published>2016-12-29T13:31:00.000Z</published>
    <updated>2016-12-29T15:34:47.954Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>  本文是对spark2.0.2分布式集群搭建的一个详细说明。旨在通过阅读该文章帮助开发人员快速搭建spark分布式集群。</p>
<h1 id="三种集群资源管理概述"><a href="#三种集群资源管理概述" class="headerlink" title="三种集群资源管理概述"></a>三种集群资源管理概述</h1><ul>
<li><p>Spark Standalone<br>作为Spark的一部分,Standalone是一个简单的集群管理器。它具有master的HA，弹性应对WorkerFailures，对每个应用程序的管理资源的能力，并且可以在现有的Hadoop一起运行和访问HDFS的数据。该发行版包括一些脚本，可以很容易地部署在本地或在AmazonEC2云计算。它可以在Linux，Windows或Mac OSX上运行。</p>
</li>
<li><p>Apache Mesos<br>Apache Mesos ,分布式系统内核，具有HA的masters和slaves，可以管理每个应用程序的资源，并对Docker容器有很好的支持。它可以运行Spark工作， Hadoop的MapReduce的，或任何其他服务的应用程序。它有Java， Python和C ++ 的API。它可以在Linux或Mac OSX上运行。</p>
</li>
<li><p>Hadoop YARN<br>Hadoop YARN，作业调度和集群资源管理的分布式计算框架，具有HA为masters和slaves，在非安全模式下支持Docker容器，在安全模式下支持Linux和Windows Container executors，和可插拔的调度器。它可以运行在Linux和Windows上运行。</p>
</li>
</ul>
<p><strong>本文将使用Hadoop YARN方式进行集群搭建。</strong><br><a id="more"></a></p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ul>
<li><p><strong>装有centOS7的3台服务器</strong></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">master 172.16.21.121</div><div class="line">node1  172.16.21.129</div><div class="line">node2  172.16.21.130</div></pre></td></tr></table></figure>
</li>
<li><p><strong>搭建hadoop集群环境</strong><br><a href="/2016/12/29/hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">hadoop分布式环境搭建教程</a></p>
</li>
<li><p><strong>scala: scala-2.12.1.tgz</strong></p>
</li>
<li><strong>spark: sprak-2.0.2-bin-hadoop2.7.tgz</strong></li>
<li><strong>上传sacala和spark到3台服务器</strong><!--more-->
<h1 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h1></li>
<li><strong>解压到/usr/local/scala</strong></li>
<li><p><strong>配置环境变量</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SCALA_HOME=/usr/local/scala/scala-2.12.1</div><div class="line">export PATH=$PATH:$SCALA_HOME/bin</div></pre></td></tr></table></figure>
<p>  scala -version查看版本</p>
</li>
</ul>
<h1 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h1><ul>
<li><strong>解压</strong><br>  tar -zxvf spark-2.0.2-bin-hadoop2.7.tgz到/usr/local/spark</li>
<li><p><strong>配置环境变量</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/usr/local/spark/spark-2.0.2-bin-hadoop2.7</div><div class="line">export PATH=$PATH:$SPARK_HOME/bin</div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置集群</strong></p>
<ul>
<li><p>master上：$SPARK_HOME/conf/slaves 添加:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node1 </div><div class="line">node2</div></pre></td></tr></table></figure>
</li>
<li><p>spark-env.sh： 添加SCALA_HOME和JAVA_HOME</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SCALA_HOME=/usr/local/scala/scala-2.12.1</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div></pre></td></tr></table></figure>
</li>
<li><p>修改spark web 默认端口为8081</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd $SPARK_HOME/sbin</div><div class="line">vim start-master.sh</div><div class="line">if [ &quot;$SPARK_MASTER_WEBUI_PORT&quot; = &quot;&quot; ]; then</div><div class="line">  SPARK_MASTER_WEBUI_PORT=8081</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>启动</strong></p>
<ul>
<li>启动hadoop集群,master上执行<br>  $HADOOP_HOME/sbin/start-all.sh</li>
<li>启动spark集群，master上执行<br>  $SPARK_HOME/sbin/start-all.sh</li>
<li><p>jps查看<br>  master:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-master-jps.png" alt="spark-master-jps"></p>
<p>  node1:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-node1-jps.png" alt="spark-node1-jps"></p>
<p>  node2:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-node2-jps.png" alt="spark-node2-jps"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>验证</strong></p>
<ul>
<li>访问master的8081<br>  <a href="http://172.16.21.121:8081/" target="_blank" rel="external">http://172.16.21.121:8081/</a><br>   <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-8081.png" alt="spark-node2-jps"></li>
<li><p>运行SparkPi例子</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd $SPARK_HOME</div><div class="line">bin/spark-submit --class org.apache.spark.examples.SparkPi --master     spark://master:7077 examples/jars/spark-examples_2.11-2.0.2.jar 100 2&gt;&amp;1 | grep &quot;Pi is roughly&quot;</div></pre></td></tr></table></figure>
<p>   <img src="https://raw.githubusercontent.com/xuetf/spark/master/sparkpi.png" alt="spark-node2-jps"></p>
</li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.voidcn.com/blog/dream_broken/article/p-6319289.html" target="_blank" rel="external">http://www.voidcn.com/blog/dream_broken/article/p-6319289.html</a>    </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;  本文是对spark2.0.2分布式集群搭建的一个详细说明。旨在通过阅读该文章帮助开发人员快速搭建spark分布式集群。&lt;/p&gt;
&lt;h1 id=&quot;三种集群资源管理概述&quot;&gt;&lt;a href=&quot;#三种集群资源管理概述&quot; class=&quot;headerlink&quot; title=&quot;三种集群资源管理概述&quot;&gt;&lt;/a&gt;三种集群资源管理概述&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Spark Standalone&lt;br&gt;作为Spark的一部分,Standalone是一个简单的集群管理器。它具有master的HA，弹性应对WorkerFailures，对每个应用程序的管理资源的能力，并且可以在现有的Hadoop一起运行和访问HDFS的数据。该发行版包括一些脚本，可以很容易地部署在本地或在AmazonEC2云计算。它可以在Linux，Windows或Mac OSX上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apache Mesos&lt;br&gt;Apache Mesos ,分布式系统内核，具有HA的masters和slaves，可以管理每个应用程序的资源，并对Docker容器有很好的支持。它可以运行Spark工作， Hadoop的MapReduce的，或任何其他服务的应用程序。它有Java， Python和C ++ 的API。它可以在Linux或Mac OSX上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hadoop YARN&lt;br&gt;Hadoop YARN，作业调度和集群资源管理的分布式计算框架，具有HA为masters和slaves，在非安全模式下支持Docker容器，在安全模式下支持Linux和Windows Container executors，和可插拔的调度器。它可以运行在Linux和Windows上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;本文将使用Hadoop YARN方式进行集群搭建。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="spark" scheme="xtf615.com/categories/spark/"/>
    
    
      <category term="大数据" scheme="xtf615.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
      <category term="spark" scheme="xtf615.com/tags/spark/"/>
    
      <category term="内存" scheme="xtf615.com/tags/%E5%86%85%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>hadoop分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/hadoop分布式环境搭建教程/</id>
    <published>2016-12-29T10:53:29.000Z</published>
    <updated>2016-12-29T15:44:31.304Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本文是搭建hadoop分布式集群的一个详细说明，旨在通过本文，快速入手hadoop</p>
<h1 id="部署方案"><a href="#部署方案" class="headerlink" title="部署方案"></a>部署方案</h1><p>hadoop部署方案包括：单机模式、伪分布模式、完全分布模式</p>
<p><strong>本文将使用完全分布模式进行集群搭建</strong></p>
<a id="more"></a>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul>
<li><strong>64位centos7服务器3台</strong><ul>
<li>master:172.16.21.121</li>
<li>node1:172.16.21.129</li>
<li>node2:172.16.21.130</li>
</ul>
</li>
<li><strong>hadoop-2.7.3.tar.gz</strong></li>
<li><strong>jdk-8u73-linux-x64.tar.gz</strong></li>
<li><strong>关闭防火墙</strong><br><code>service firewalld stop或systemctl stop firewalld.service</code></li>
<li><p><strong>关闭selinux</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">setenforce 0临时关闭，sestatus查看状态:current mode变成permissive</div></pre></td></tr></table></figure>
</li>
<li><p><strong>纠正系统时间</strong></p>
<ul>
<li><p>设置时区</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">timedatectl查看时区</div><div class="line">timedatactl set-timezone Asia/Shanghai</div></pre></td></tr></table></figure>
</li>
<li><p>安装ntp并启动</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">yum -y install ntp</div><div class="line">systemctl enable ntpd</div><div class="line">start ntpd</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>安装jdk</strong>    </p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">解压tar -zxvf jdk-8u73-linux-x64.tar.gz到/usr/local/java</div><div class="line">vim /etc/profile</div><div class="line">添加：</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div><div class="line">export JRE_HOME=/$JAVA_HOME/jre</div><div class="line">export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</div><div class="line">export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin</div><div class="line"></div><div class="line">source /etc/profile配置生效</div><div class="line">java -version查看</div></pre></td></tr></table></figure>
</code></pre></li>
<li><p><strong>配置主机域名</strong></p>
<ul>
<li><p>配置hostname</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">172.16.21.121(master): </div><div class="line">hostname master</div><div class="line">vim /etc/hostname 输入master</div><div class="line"></div><div class="line">172.16.21.129(node1): </div><div class="line">hostname node1</div><div class="line">vim /etc/hostname 输入node1</div><div class="line"></div><div class="line">172.16.21.130(node2): </div><div class="line">hostname node2</div><div class="line">vim /etc/hostname 输入node2</div></pre></td></tr></table></figure>
</li>
<li><p>配置host(3台服务器同时输入)</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">172.16.21.121 master</div><div class="line">172.16.21.129 node1</div><div class="line">172.16.21.130 node2</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>ssh免密码登录</strong></p>
<ul>
<li><p>master上操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa 一直回车，信息中会看到.ssh/id_rsa.pub的路径</div><div class="line">复制：cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</div></pre></td></tr></table></figure>
</li>
<li><p>node1和node2上操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">创建node1和node2上root/.ssh目录:mkdir /root/.ssh</div></pre></td></tr></table></figure>
</li>
<li><p>master上操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">复制authorized_keys到node1和node2节点：</div><div class="line">scp /root/.ssh/authorized_keys root@172.16.21.129:/root/.ssh/</div><div class="line">scp /root/.ssh/authorized_keys root@172.16.21.130:/root/.ssh/</div></pre></td></tr></table></figure>
</li>
<li><p>master,node1,node2都操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chmod 700 /root/.ssh</div></pre></td></tr></table></figure>
</li>
<li><p>master上验证: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ssh master</div><div class="line">ssh node1</div><div class="line">ssh node2</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="配置Hadoop集群"><a href="#配置Hadoop集群" class="headerlink" title="配置Hadoop集群"></a>配置Hadoop集群</h1><ul>
<li>解压 tar -zxvf hadoop-2.7.3.tar.gz, 到/usr/local/hadoop</li>
<li><p>配置环境变量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">vim /etc/profile</div><div class="line">添加：</div><div class="line">export HADOOP_HOME=/usr/local/hadoop/hadoop-2.7.3</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</div><div class="line">生效：source /etc/profile</div><div class="line">查看版本: hadoop version</div></pre></td></tr></table></figure>
<ul>
<li><p>修改hadoop配置添加JAVA_HOME </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">vim /usr/local/hadoop/hadoop-2.7.3/etc/hadoop hadoop-env.sh</div><div class="line">vim /usr/local/hadoop/hadoop-2.7.3/etc/hadoop yarn-env.sh</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div></pre></td></tr></table></figure>
</li>
<li><p><strong>创建目录</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir -p /usr/local/hadoop/hdfs/data</div><div class="line">mkdir -p /usr/local/hadoop/hdfs/name</div><div class="line">mkdir -p /usr/local/tmp</div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置core-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">            &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">            &lt;value&gt;hdfs://master:9000&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;io.file.buffer.size&lt;/name&gt;</div><div class="line">            &lt;value&gt;4096&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>配置hdfs-site.xml</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">      &lt;value&gt;file:/hadoop/hdfs/name&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">      &lt;value&gt;file:/hadoop/hdfs/data&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">      &lt;value&gt;2&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">      &lt;value&gt;master:9001&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</div><div class="line">      &lt;value&gt;true&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p><strong>复制mapred-site.xml.template为mapred-site.xml,并修改</strong></p>
<pre><code>cp mapred-site.xml.template mapred-site.xml
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">  &lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">            &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">            &lt;final&gt;true&lt;/final&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobtracker.http.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:50030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:10020&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:19888&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapred.job.tracker&lt;/name&gt;</div><div class="line">            &lt;value&gt;http://master:9001&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>修改yarn-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">             &lt;value&gt;master&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8032&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">             &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">             &lt;value&gt;master:8030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">             &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8031&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8033&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8088&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>将以上步骤操作在node1和node2上重复</strong><br>  可将修改的文件拷贝至node1和node2节点</p>
</li>
<li><p><strong>修改master上的slaves文件</strong><br>  $HADOOP_HOME/etc/hadoop/slaves<br>  删除localhost<br>  添加:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node1</div><div class="line">node2</div></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong></p>
<ul>
<li><p><strong>只在master上操作</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">master上格式化：</div><div class="line">cd $HADOOP_HOME/bin/</div><div class="line">./hadoop namenode -format</div><div class="line">master上启动：</div><div class="line">cd $HADOOP_HOME/sbin/</div><div class="line">./start-all.sh</div></pre></td></tr></table></figure>
</li>
<li><p><strong>查看jps：</strong><br>  jps<br>  master: ResourceManager SecondaryNameNode NameNode<br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/master-jps.png" alt="master-jps"></p>
<p>  node1/node2: DataNode NodeManager<br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/node1-jps.png" alt="node1-jps"><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/node2-jps.png" alt="node2-jps"></p>
</li>
<li><p>访问master的50070：<br>  <a href="http://172.16.21.121:50070" target="_blank" rel="external">http://172.16.21.121:50070</a><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/50070.png" alt="master-50070"></p>
</li>
<li>访问master的8088：<br>   <a href="http://172.16.21.121:8088" target="_blank" rel="external">http://172.16.21.121:8088</a><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/8088.png" alt="master-8088"></li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.voidcn.com/blog/dream_broken/article/p-6319288.html" target="_blank" rel="external">http://www.voidcn.com/blog/dream_broken/article/p-6319288.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;本文是搭建hadoop分布式集群的一个详细说明，旨在通过本文，快速入手hadoop&lt;/p&gt;
&lt;h1 id=&quot;部署方案&quot;&gt;&lt;a href=&quot;#部署方案&quot; class=&quot;headerlink&quot; title=&quot;部署方案&quot;&gt;&lt;/a&gt;部署方案&lt;/h1&gt;&lt;p&gt;hadoop部署方案包括：单机模式、伪分布模式、完全分布模式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本文将使用完全分布模式进行集群搭建&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="xtf615.com/categories/hadoop/"/>
    
    
      <category term="hadoop" scheme="xtf615.com/tags/hadoop/"/>
    
      <category term="大数据" scheme="xtf615.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/redis分布式环境搭建教程/</id>
    <published>2016-12-29T07:56:43.000Z</published>
    <updated>2016-12-29T15:42:48.219Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis部署说明"><a href="#redis部署说明" class="headerlink" title="redis部署说明"></a>redis部署说明</h1><ul>
<li><strong>版本</strong><br>使用redis最新版3.2.3进行安装</li>
<li><strong>主从关系</strong><br>使用1个主节点，3个从节点。主节点提供读写操作，从节点只提供读操作。主节点Master安装在dbp模块，提供大量的写操作服务；  3个从节点。</li>
<li><strong>哨兵机制</strong><br>配置3个哨兵，主节点dbp安装1个哨兵，另外3台从服务器选其中两台各安装一个。作为HA高可用方案，防止主节点单点失败，通过重新选举主节点实现故障快速转移。<a id="more"></a>
</li>
</ul>
<h1 id="安装具体步骤"><a href="#安装具体步骤" class="headerlink" title="安装具体步骤"></a>安装具体步骤</h1><ul>
<li>解压</li>
<li>安装gcc</li>
<li>进入redis的bin目录，先执行 make MALLOC=libc； 再执行make install</li>
<li>配置文件：先拷贝redis目录下的配置文件redis.conf和sentinel.conf到/usr/local/etc(或其他任意目录)，再修改<ul>
<li><strong>redis节点配置</strong><br>  <code><strong>bind 主机ip</strong>                        #主机ip<br>  <strong>protected-mode no</strong>                     #保护模式关闭，否则不能通过远程连接，哨兵机制也不起作用，下面使用密码进行安全保证<br>  <strong>port 端口</strong>                          #端口<br>  <strong>daemonize yes</strong>                       #守护进程<br>  <strong>pidfile  /var/run/redis_端口.pid</strong>            #进程号，命名规则redis_端口号.pid<br>  logfile /usr/local/logs/redis/redis_端口.log   #日志文件<br>  <strong>dir  /usr/local/data/redis/端口</strong>          #持久化文件夹，必须是空文件夹<br>  <strong>requirepass 密码</strong>    #认证密码<br>  <strong>masterauth 密码</strong>    #和认证密码一致<br>  <strong>maxmemory 最大内存</strong>  #eg:10g<br>  <strong>maxmemory-policy</strong>        allkeys-lru   #lru算法回收<br>  </code></li>
<li><strong>从节点需要额外配置</strong><br>  <code>slaveof 主机 ip  #例如slaveof  172.16.21.127  6379</code></li>
<li><strong>Sentinel哨兵节点</strong><br><code>port  端口    #命名规则： 本机redis端口前加个2,比如redis:6379: 则sentinel：26379<br>  <strong>sentinel announce-ip</strong>  主机ip<br>  <strong>protected-mode  no</strong>  #需要手动添加这条。<br>  <strong>dir</strong>  /usr/local/data/sentinel_端口    #空文件夹<br>  <strong>logfile</strong>  /usr/local/logs/redis/sentinel_端口.log<br>  <strong>sentinel monitor 主节点名称 主节点ip 主节点端口 仲裁至少需要的哨兵数</strong> #eg：sentinel monitor mymaster  172.16.21.127 6379 2<br>  <strong>sentinel auth-pass 主节点名称 密码</strong>   #认证<br>  </code></li>
</ul>
</li>
<li><strong>进入redis的src目录启动redis和sentinel</strong><br>  <code><strong>reids-server redis配置文件</strong><br>  #eg:redis-server /usr/local/etc/redis_6379.conf<br>  <strong>redis-sentinel sentinel配置文件</strong> &amp;<br>  #eg:redis-sentinel /usr/local/etc/sentinel_26379.conf &amp;<br>  </code></li>
<li><strong>依次启动主节点和从节点后，使用redis-cli连接</strong><br>  <code><strong>reids-cli -h ip地址 -p 端口 -a 密码</strong><br> <strong>sentinel reset mymaster</strong> #重置哨兵状态*<br>  使用命令查看部署情况，info replication可查看集群状态<br>  </code></li>
</ul>
<h1 id="具体配置参见"><a href="#具体配置参见" class="headerlink" title="具体配置参见"></a>具体配置参见</h1><p><a href="https://github.com/xuetf/redis" target="_blank" rel="external">https://github.com/xuetf/redis</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://blog.csdn.net/ownfire/article/details/51546543" target="_blank" rel="external">http://blog.csdn.net/ownfire/article/details/51546543</a><br><a href="http://www.ilanni.com/?p=11838" target="_blank" rel="external">http://www.ilanni.com/?p=11838</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;redis部署说明&quot;&gt;&lt;a href=&quot;#redis部署说明&quot; class=&quot;headerlink&quot; title=&quot;redis部署说明&quot;&gt;&lt;/a&gt;redis部署说明&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;版本&lt;/strong&gt;&lt;br&gt;使用redis最新版3.2.3进行安装&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;主从关系&lt;/strong&gt;&lt;br&gt;使用1个主节点，3个从节点。主节点提供读写操作，从节点只提供读操作。主节点Master安装在dbp模块，提供大量的写操作服务；  3个从节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;哨兵机制&lt;/strong&gt;&lt;br&gt;配置3个哨兵，主节点dbp安装1个哨兵，另外3台从服务器选其中两台各安装一个。作为HA高可用方案，防止主节点单点失败，通过重新选举主节点实现故障快速转移。
    
    </summary>
    
      <category term="redis" scheme="xtf615.com/categories/redis/"/>
    
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
      <category term="redis" scheme="xtf615.com/tags/redis/"/>
    
      <category term="缓存" scheme="xtf615.com/tags/%E7%BC%93%E5%AD%98/"/>
    
      <category term="HA方案" scheme="xtf615.com/tags/HA%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
</feed>
