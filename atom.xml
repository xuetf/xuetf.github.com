<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>蘑菇先生学习记</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="xtf615.com/"/>
  <updated>2017-03-10T12:30:52.244Z</updated>
  <id>xtf615.com/</id>
  
  <author>
    <name>xuetf</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python实现时间序列分析</title>
    <link href="xtf615.com/2017/03/08/Python%E5%AE%9E%E7%8E%B0%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%88%86%E6%9E%90/"/>
    <id>xtf615.com/2017/03/08/Python实现时间序列分析/</id>
    <published>2017-03-08T01:54:58.000Z</published>
    <updated>2017-03-10T12:30:52.244Z</updated>
    
    <content type="html"><![CDATA[<p>前面花了两章篇幅介绍了时间序列模型的数学基础。 <a href="/2017/03/07/ARIMA时间序列模型/">ARIMA时间序列模型(一)</a>和<a href="/2017/03/07/ARIMA时间序列模型-二/">ARIMA时间序列模型(二)</a> 。本文重点介绍使用python开源库进行时间序列模型实践。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>回顾一下自回归移动平均模型ARMA，它主要由两部分组成：AR代表p阶自回归过程，MA代表q阶移动平均过程，形式如下：<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\<br>+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>为了方便，我们重写以上等式为：<br>$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\<br>其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$<br>根据前两篇的分析，我们总结ARMA模型的性质如下：<br><img src="/picture/machine-learning/arima5.jpg" alt="arima"><br><a id="more"></a></p>
<h1 id="p值检验"><a href="#p值检验" class="headerlink" title="p值检验"></a>p值检验</h1><p>　　在开始之前，我们首先回顾一下p值检验。<br>　　一般地，用X表示检验的统计量，当H0为真时，可由样本数据计算出该统计量的值C，根据检验统计量X的具体分布，可求出P值。具体地说：</p>
<ul>
<li>左侧检验的P值为检验统计量X小于样本统计值C的概率，即：P = P{ X &lt; C}</li>
<li>右侧检验的P值为检验统计量X大于样本统计值C的概率：P = P{ X &gt; C}</li>
<li>双侧检验的P值为检验统计量X落在样本统计值C为端点的尾部区域内的概率的2倍：P = 2P{ X &gt; C} (当C位于分布曲线的右端时) 或P = 2P{ X&lt; C}(当C位于分布曲线的左端时) 。若X服从正态分布和t分布，其分布曲线是关于纵轴对称的，故其P值可表示为P=P{|X|&gt;C}。<br>计算出P值后，将给定的显著性水平α与P值比较，就可作出检验的结论：<br>如果\(p &lt; α\)值，则在显著性水平α下拒绝原假设。<br>如果\(P \geq α\)值，则在显著性水平α下接受原假设。</li>
</ul>
<h1 id="pandas数据操作"><a href="#pandas数据操作" class="headerlink" title="pandas数据操作"></a>pandas数据操作</h1><p>使用pandas来加载数据，并对数据索引进行转换，使用日期作为索引。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">dateparse = <span class="keyword">lambda</span> dates:pd.datetime.strptime(dates,<span class="string">'%Y-%m'</span>)</div><div class="line">data=pd.read_csv(<span class="string">'AirPassengers.csv'</span>,parse_dates=<span class="string">'Month'</span>,index_col=<span class="string">'Month'</span>,date_parser=dateparse);</div><div class="line"><span class="keyword">print</span> data.head()</div><div class="line"><span class="comment"># 数据如下所示：</span></div><div class="line">Month                  </div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-01</span><span class="number">-01</span>          <span class="number">112</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-02</span><span class="number">-01</span>          <span class="number">118</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-03</span><span class="number">-01</span>          <span class="number">132</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-04</span><span class="number">-01</span>          <span class="number">129</span></div><div class="line"></div><div class="line"><span class="number">1949</span><span class="number">-05</span><span class="number">-01</span>          <span class="number">121</span></div></pre></td></tr></table></figure>
<p>接着绘制数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ts = data[<span class="string">'#Passengers'</span>]</div><div class="line">plt.plot(ts)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima6.jpg" alt="arma"></p>
<p>非常清晰的看到，随着季节性的变动，飞机乘客的数量总体上是在不断增长的。但是，不是经常都可以获得这样清晰的视觉体验。我们可以通过下面的方法测试稳定性。</p>
<h1 id="稳定性检测"><a href="#稳定性检测" class="headerlink" title="稳定性检测"></a>稳定性检测</h1><ul>
<li><strong>绘制滚动统计</strong>：我们可以绘制移动平均数和移动方差，观察它是否随着时间变化。</li>
<li><strong>ADF检验：</strong>这是一种检查数据稳定性的统计测试。无效假设：时间序列是不稳定的。测试结果由测试统计量和一些置信区间的临界值组成。如果“测试统计量”少于“临界值”，我们可以拒绝无效假设，并认为序列是稳定的。或者根据前面提高的p值检验，如果p值小于显著性水平，我们可以拒绝无效假设，认为序列稳定。</li>
</ul>
<h2 id="滚动统计"><a href="#滚动统计" class="headerlink" title="滚动统计"></a>滚动统计</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rolling_statistics</span><span class="params">(timeseries)</span>:</span></div><div class="line">    <span class="comment">#Determing rolling statistics</span></div><div class="line">    rolmean = pd.rolling_mean(timeseries, window=<span class="number">12</span>)</div><div class="line">    rolstd = pd.rolling_std(timeseries, window=<span class="number">12</span>)</div><div class="line"></div><div class="line">    <span class="comment">#Plot rolling statistics:</span></div><div class="line">    orig = plt.plot(timeseries, color=<span class="string">'blue'</span>,label=<span class="string">'Original'</span>)</div><div class="line">    mean = plt.plot(rolmean, color=<span class="string">'red'</span>, label=<span class="string">'Rolling Mean'</span>)</div><div class="line">    std = plt.plot(rolstd, color=<span class="string">'black'</span>, label = <span class="string">'Rolling Std'</span>)</div><div class="line">    plt.legend(loc=<span class="string">'best'</span>)</div><div class="line">    plt.title(<span class="string">'Rolling Mean &amp; Standard Deviation'</span>)</div><div class="line">    plt.show(block=<span class="keyword">False</span>)</div></pre></td></tr></table></figure>
<p>pd.rolling_mean有两个参数，第一个是输入数据，第二个是窗口大小。假设有个序列是，1  2  3  3  5  8  6  9，如果窗口大小为3，那么移动平均数计算过程如下： 第一步: (1+2+3)/3 =2;    第二步:往右移动一个数据，(2+3+3)/3=2.667;  第三步, (3+3+5)/3=3.667;  第四步：(3+5+8)/3=5.333; 第四步: (5+8+6)/3=6.333; 第五步;(8+6+9)/3=7.667;  因此移动平均数序列为： NA NA 2  2.667  3.667  5.3333   6.333  7.667.  共用n-windows+1个数。</p>
<p><img src="/picture/machine-learning/arima7.jpg" alt="arma"></p>
<p>移动标准差类似，只不过把求平均变成了求标准差。</p>
<p>绘图如下：可以看出移动平均数仍然是上升趋势，而移动标准差相对比较平稳。</p>
<p><img src="/picture/machine-learning/arima8.jpg" alt="arma"></p>
<h2 id="ADF检验"><a href="#ADF检验" class="headerlink" title="ADF检验"></a>ADF检验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> statsmodels.tsa.stattools <span class="keyword">import</span> adfuller</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adf_test</span><span class="params">(timeseries)</span>:</span></div><div class="line">    rolling_statistics(timeseries)<span class="comment">#绘图</span></div><div class="line">    <span class="keyword">print</span> <span class="string">'Results of Augment Dickey-Fuller Test:'</span></div><div class="line">    dftest = adfuller(timeseries, autolag=<span class="string">'AIC'</span>)</div><div class="line">    dfoutput = pd.Series(dftest[<span class="number">0</span>:<span class="number">4</span>], index=[<span class="string">'Test Statistic'</span>,<span class="string">'p-value'</span>,<span class="string">'#Lags Used'</span>,<span class="string">'Number of Observations Used'</span>])</div><div class="line">    <span class="keyword">for</span> key,value <span class="keyword">in</span> dftest[<span class="number">4</span>].items():</div><div class="line">        dfoutput[<span class="string">'Critical Value (%s)'</span>%key] = value</div><div class="line">    <span class="keyword">print</span> dfoutput</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima9.jpg" alt="arma"></p>
<p>上述输出如何解读?</p>
<ul>
<li>Test statistic：代表检验统计量</li>
<li>p-value：代表p值检验的概率</li>
<li>Lags used：使用的滞后k，autolag=AIC时会自动选择滞后</li>
<li>Number of Observations Used：样本数量</li>
<li>Critical Value(5%) : 显著性水平为5%的临界值。</li>
</ul>
<p>ADF检验</p>
<ul>
<li>假设是存在单位根，即不平稳； </li>
<li>显著性水平，1%：严格拒绝原假设；5%：拒绝原假设，10%类推。</li>
<li>看P值和显著性水平a的大小，p值越小，小于显著性水平的话，就拒绝原假设，认为序列是平稳的；大于的话，不能拒绝，认为是不平稳的</li>
<li>看检验统计量和临界值，检验统计量小于临界值的话，就拒绝原假设，认为序列是平稳的；大于的话，不能拒绝，认为是不平稳的</li>
</ul>
<p>根据上文提到的p值检验以及上面的结果，我们可以发现p=0.99&gt;10%&gt;5%&gt;1%, 并且检验统计量0.815&gt;&gt;-2.58&gt;-2.88&gt;-3.48，因此可以认定原序列不平稳。</p>
<p>先让我们弄明白是什么导致时间序列不稳定。两个主要原因。</p>
<ul>
<li><strong>趋势-随着时间产生不同的平均值。</strong>举例：在飞机乘客这个案例中，我们看到总体上，飞机乘客的数量是在不断增长的。</li>
<li><strong>季节性-特定时间框架内的变化。</strong>举例：在特定的月份购买汽车的人数会有增加的趋势，因为车价上涨或者节假日到来。</li>
</ul>
<p>我们的基本原理是，通过建模并估计趋势和季节性这些因素，并从时间序列中移除，来获得一个稳定的时间序列，然后再使用统计预测技术来处理时间序列，最后将预测得到的数据，通过加入趋势和季节性等约束，来回退到原始时间序列数据。</p>
<h1 id="平稳性处理"><a href="#平稳性处理" class="headerlink" title="平稳性处理"></a>平稳性处理</h1><p>　　消除趋势的第一个方法是转换。例如,在本例中,我们可以清楚地看到该时间序列有显著趋势。所以我们可以通过变换，惩罚较高值而不是较小值。这可以采用对数,  平方根,立方跟等等。</p>
<h2 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ts_log = np.log(ts)</div><div class="line">plt.plot(ts_log)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima10.jpg" alt="arma"></p>
<p>在这个例子中,很容易看到一个向前的趋势。但是它表现的不是很直观。我们可以使用一些技术来对这个趋势建模, 然后将它从序列中删除。最常用的方法有:</p>
<ul>
<li><strong>平滑-取滚动平均数</strong></li>
<li><strong>差分</strong></li>
<li><strong>分解</strong></li>
</ul>
<h2 id="移动平均数"><a href="#移动平均数" class="headerlink" title="移动平均数"></a>移动平均数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">moving_avg = pd.rolling_mean(ts_log,<span class="number">12</span>)</div><div class="line">plt.plot(ts_log)</div><div class="line">plt.plot(moving_avg,color=<span class="string">'red'</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima11.jpg" alt="arma"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#做差</span></div><div class="line">ts_log_moving_avg_diff = ts_log - moving_avg</div><div class="line">ts_log_moving_avg_diff.head(<span class="number">12</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima12.jpg" alt="arma"></p>
<p>前11个数是NA</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">adf_test(ts_log_moving_avg_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima13.jpg" alt="arma"></p>
<p>可以发现通过了5%和10%的显著性检验，即在该水平下，拒绝原假设，认为序列是平稳的，但是没有通过1%的检验。</p>
<p><strong>指数加权移动平均</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">expwighted_avg=pd.ewma(ts_log,halflife=<span class="number">12</span>)</div><div class="line">plt.plot(ts_log)</div><div class="line">plt.plot(expwighted_avg, color=<span class="string">'red'</span>)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima14.jpg" alt="arma"></p>
<p>前面移动平均数需要指定window,并且对所有的数一视同仁；这里采用指数加权移动平均方法，会对当前的数据加大权重，对过去的数据减小权重。halflife半衰期，用来定义衰减量。其他参数,如跨度span和质心com也可以用来定义衰减。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#做差</span></div><div class="line">ts_log_ewma_diff = ts_log - expwighted_avg</div><div class="line">adf_test(ts_log_ewma_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima15.jpg" alt="arma"></p>
<p>可以发现，经过指数移动平均后，再做差的结果，已经能够通过1%显著性水平检验了。</p>
<h2 id="差分"><a href="#差分" class="headerlink" title="差分"></a>差分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#步长为1的一阶差分</span></div><div class="line">ts_log_diff = ts_log - ts_log.shift(periods=<span class="number">1</span>)</div><div class="line">plt.plot(ts_log_diff)</div></pre></td></tr></table></figure>
<p>我们首先使用步长为1的一阶差分，得到如下图：</p>
<p><img src="/picture/machine-learning/arima16.jpg" alt="arma"></p>
<p>接着进行adf检验，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#只通过了10%的检验</div><div class="line">ts_log_diff.dropna(inplace=True)</div><div class="line">test_stationarity(ts_log_diff)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima17.jpg" alt="arma"></p>
<p>可以发现只通过了10%的显著性水平检验。</p>
<p><strong>二阶差分</strong></p>
<p>我们继续进行二阶差分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#一阶差分：Y(k)=X(k+1)-X(k)</span></div><div class="line"><span class="comment">#二阶差分：Y(k)的一阶差分Z(k)=Y(k+1)-Y(k)=X(k+2)-2*X(k+1)+X(k)为此函数的二阶差分</span></div><div class="line">ts_log_diff = ts_log - ts_log.shift(periods=<span class="number">1</span>)</div><div class="line">ts_log_diff2 = ts_log_diff - ts_log_diff.shift(periods=<span class="number">1</span>)</div><div class="line">plt.plot(ts_log_diff2)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima18.jpg" alt="arma"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#二阶差分检验</div><div class="line">#可以看到，二阶差分，p值非常小，小于1%，检验统计量也明显小于%1的临界值。因此认定为很平稳</div><div class="line">ts_log_diff2.dropna(inplace=True)</div><div class="line">adf_test(ts_log_diff2)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima19.jpg" alt="arma"></p>
<p>对二阶差分进行adf检验,可以看到，二阶差分，p值非常小，小于1%，检验统计量也明显小于%1的临界值。因此认定为很平稳.</p>
<h2 id="分解"><a href="#分解" class="headerlink" title="分解"></a>分解</h2><p>建立有关趋势和季节性的模型，并从模型中删除它们。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">#时间序列分解</div><div class="line">from statsmodels.tsa.seasonal import seasonal_decompose</div><div class="line">decomposition = seasonal_decompose(ts_log)</div><div class="line">trend = decomposition.trend</div><div class="line">seasonal = decomposition.seasonal</div><div class="line">residual = decomposition.resid</div><div class="line"></div><div class="line">plt.subplot(411)</div><div class="line">plt.plot(ts_log,label=&apos;Original&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(412)</div><div class="line">plt.plot(trend, label=&apos;Trend&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(413);</div><div class="line">plt.plot(seasonal,label=&apos;Seasonality&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.subplot(414)</div><div class="line">plt.plot(residual, label=&apos;Residuals&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.tight_layout()</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima20.jpg" alt="arma"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#对残差进行ADF检验</div><div class="line">#可以发现序列非常平稳</div><div class="line">ts_log_decompose = residual</div><div class="line">ts_log_decompose.dropna(inplace=True)</div><div class="line">adf_test(ts_log_decompose)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima21.jpg" alt="arma"></p>
<p>对残差进行ADF检验，可以发现序列非常平稳。</p>
<h1 id="时间序列建模"><a href="#时间序列建模" class="headerlink" title="时间序列建模"></a>时间序列建模</h1><h2 id="平稳性检验"><a href="#平稳性检验" class="headerlink" title="平稳性检验"></a>平稳性检验</h2><p>平稳性检验的目的是为了判断序列是否平稳，如果不平稳，需要采取一定的措施进行平稳性处理，常见的方法是差分，我们需要选择合适的差分阶数。只要能够通过1%显著性检测，差分阶数就是合理的，我们希望阶数越小越好。</p>
<h3 id="ADF检验-1"><a href="#ADF检验-1" class="headerlink" title="ADF检验"></a>ADF检验</h3><p>ADF检验前文已经说过，用于判断序列是否平稳。</p>
<h3 id="自相关图和偏自相关图"><a href="#自相关图和偏自相关图" class="headerlink" title="自相关图和偏自相关图"></a>自相关图和偏自相关图</h3><p>前面我们对数据进行ADF检验，判断序列是否平稳，这里我们使用自相关图和偏自相关图对数据平稳性再次进行验证，一阶差分如下图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">acf_pacf_plot</span><span class="params">(ts_log_diff)</span>:</span></div><div class="line">    sm.graphics.tsa.plot_acf(ts_log_diff,lags=<span class="number">40</span>) <span class="comment">#ARIMA,q</span></div><div class="line">    sm.graphics.tsa.plot_pacf(ts_log_diff,lags=<span class="number">40</span>) <span class="comment">#ARIMA,p</span></div><div class="line">acf_pacf_plot(ts_log_diff) <span class="comment">#调用一阶差分</span></div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima22.jpg" alt="arma"></p>
<p>可以看出，一阶差分自相关和偏相系数拖尾特点明显。p=1,q=1</p>
<h2 id="参数选择"><a href="#参数选择" class="headerlink" title="参数选择"></a>参数选择</h2><h3 id="差分阶数选择"><a href="#差分阶数选择" class="headerlink" title="差分阶数选择"></a>差分阶数选择</h3><p>我们发现，ARIMA该开源库，不支持3阶以上的差分。我们唯一的办法是先数据差分好，再传入模型进行建模。但是这样也带来了回退数据到原始序列数据的难度。</p>
<p><img src="/picture/machine-learning/arima26.jpg" alt="arma"></p>
<p>这里开发了差分和回退的方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 差分操作,d代表差分序列，比如[1,1,1]可以代表3阶差分。  [12,1]可以代表第一次差分偏移量是12，第二次差分偏移量是1</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">diff_ts</span><span class="params">(ts, d)</span>:</span></div><div class="line">    <span class="keyword">global</span> shift_ts_list</div><div class="line">    <span class="comment">#  动态预测第二日的值时所需要的差分序列</span></div><div class="line">    <span class="keyword">global</span> last_data_shift_list <span class="comment">#这个序列在恢复过程中需要用到</span></div><div class="line">    shift_ts_list = []</div><div class="line">    last_data_shift_list = []</div><div class="line">    tmp_ts = ts</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> d:</div><div class="line">        last_data_shift_list.append(tmp_ts[-i])</div><div class="line">        <span class="keyword">print</span> last_data_shift_list</div><div class="line">        shift_ts = tmp_ts.shift(i)</div><div class="line">        shift_ts_list.append(shift_ts)</div><div class="line">        tmp_ts = tmp_ts - shift_ts</div><div class="line">    tmp_ts.dropna(inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> tmp_ts</div><div class="line"></div><div class="line"><span class="comment"># 还原操作</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_diff_recover</span><span class="params">(predict_value, d)</span>:</span></div><div class="line">    <span class="keyword">if</span> isinstance(predict_value, float):</div><div class="line">        tmp_data = predict_value</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            tmp_data = tmp_data + last_data_shift_list[-i<span class="number">-1</span>]</div><div class="line">    <span class="keyword">elif</span> isinstance(predict_value, np.ndarray):</div><div class="line">        tmp_data = predict_value[<span class="number">0</span>]</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            tmp_data = tmp_data + last_data_shift_list[-i<span class="number">-1</span>]</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        tmp_data = predict_value</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                tmp_data = tmp_data.add(shift_ts_list[-i<span class="number">-1</span>])</div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'What you input is not pd.Series type!'</span>)</div><div class="line">        tmp_data.dropna(inplace=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> tmp_data <span class="comment"># return np.exp(tmp_data)也可以return到最原始，tmp_data是对原始数据取对数的结果</span></div></pre></td></tr></table></figure>
<p>使用的时候，必须先调用diff_ts进行差分处理，然后进行建模，将预测数据传入predict_diff_recover方法进行还原。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">d=[<span class="number">1</span>, <span class="number">1</span>] <span class="comment"># 定义差分序列</span></div><div class="line">ts_log = np.log(ts)</div><div class="line">diffed_ts = diff_ts(ts_log, d) </div><div class="line"><span class="comment"># model = arima_model(diffed_ts)构建模型</span></div><div class="line">predict_ts = model.properModel.predict() <span class="comment">#预测，这是对训练数据的预测</span></div><div class="line">diff_recover_ts = predict_diff_recover(predict_ts, d)</div><div class="line">log_recover = np.exp(diff_recover_ts) <span class="comment">#恢复对数前数据，该数据可以和原始数据ts进行作图对比</span></div></pre></td></tr></table></figure>
<p>差分阶数的选择通常越小越好，只要能够使得序列稳定就行。我们可以通过选择不同的阶数，然后进行平稳性检测，选择平稳性表现良好的阶数就行，一般一阶和二阶用的比较多。</p>
<h3 id="p和q选择"><a href="#p和q选择" class="headerlink" title="p和q选择"></a>p和q选择</h3><p>　　差分阶数确定后，我们需要确定p和q. 对于个数不多的时序数据，我们可以通过观察自相关图和偏相关图来进行模型识别，倘若我们要分析的时序数据量较多，例如要预测每只股票的走势，我们就不可能逐个去调参了。这时我们可以依据BIC准则识别模型的p, q值，通常认为BIC值越小的模型相对更优。这里我简单介绍一下BIC准则，它综合考虑了残差大小和自变量的个数，残差越小BIC值越小，自变量个数越多BIC值越大。个人觉得BIC准则就是对模型过拟合设定了一个标准。当然，我们也可以使用AIC指标。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#注意这里面使用的ts_log_diff是经过合适阶数的差分之后的数据，上文中提到ARIMA该开源库，不支持3阶以上的#差分。所以我们需要提前将数据差分好再传入</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">from</span> statsmodels.tsa.arima_model <span class="keyword">import</span> ARMA</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_proper_model</span><span class="params">(ts_log_diff, maxLag)</span>:</span></div><div class="line">    best_p = <span class="number">0</span> </div><div class="line">    best_q = <span class="number">0</span></div><div class="line">    best_bic = sys.maxint</div><div class="line">    best_model=<span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> np.arange(maxLag):</div><div class="line">        <span class="keyword">for</span> q <span class="keyword">in</span> np.arange(maxLag):</div><div class="line">            model = ARMA(ts_log_diff, order=(p, q))</div><div class="line">            <span class="keyword">try</span>:</div><div class="line">                results_ARMA = model.fit(disp=<span class="number">-1</span>)</div><div class="line">            <span class="keyword">except</span>:</div><div class="line">                <span class="keyword">continue</span></div><div class="line">            bic = results_ARMA.bic</div><div class="line">            <span class="keyword">print</span> bic, best_bic</div><div class="line">            <span class="keyword">if</span> bic &lt; best_bic:</div><div class="line">                best_p = p</div><div class="line">                best_q = q</div><div class="line">                best_bic = bic</div><div class="line">                best_model = results_ARMA</div><div class="line">    <span class="keyword">return</span> best_p,best_q,best_model</div><div class="line">_proper_model(ts_log_diff, <span class="number">10</span>) <span class="comment">#对一阶差分求最优p和q</span></div></pre></td></tr></table></figure>
<p>通过上述方法可以得到最优的p和q。</p>
<h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>我们使用一阶差分进行构建。</p>
<h3 id="AR-p-模型"><a href="#AR-p-模型" class="headerlink" title="AR(p)模型"></a>AR(p)模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># AR模型，q=0</span></div><div class="line"><span class="comment">#RSS是残差平方和</span></div><div class="line"><span class="comment"># disp为-1代表不输出收敛过程的信息，True代表输出</span></div><div class="line">model = ARIMA(ts_log,order=(<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>)) <span class="comment">#第二个参数代表使用了一阶差分</span></div><div class="line">results_AR = model.fit(disp=<span class="number">-1</span>)</div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_AR.fittedvalues, color=<span class="string">'red'</span>) <span class="comment">#红色线代表预测值</span></div><div class="line">plt.title(<span class="string">'RSS:%.4f'</span> % sum((results_AR.fittedvalues-ts_log_diff)**<span class="number">2</span>))<span class="comment">#残差平方和</span></div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima23.jpg" alt="arma"></p>
<h3 id="MA-q-模型"><a href="#MA-q-模型" class="headerlink" title="MA(q)模型"></a>MA(q)模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#MA模型 p=0</div><div class="line">model = ARIMA(ts_log,order=(0,1,1))</div><div class="line">results_MA = model.fit(disp=-1)</div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_MA.fittedvalues, color=&apos;red&apos;)</div><div class="line">plt.title(&apos;RSS: %.4f&apos;% sum((results_MA.fittedvalues-ts_log_diff)**2))</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima24.jpg" alt="arma"></p>
<h3 id="ARIMA-p-q-模型"><a href="#ARIMA-p-q-模型" class="headerlink" title="ARIMA(p,q)模型"></a>ARIMA(p,q)模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#ARIMA</span></div><div class="line">model = ARIMA(ts_log, order=(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))  </div><div class="line">results_ARIMA = model.fit(disp=<span class="number">-1</span>)  <span class="comment">#不展示信息</span></div><div class="line">plt.plot(ts_log_diff)</div><div class="line">plt.plot(results_ARIMA.fittedvalues, color=<span class="string">'red'</span>)<span class="comment">#和下面这句结果一样</span></div><div class="line">plt.plot(results_ARIMA.predict(), color=<span class="string">'black'</span>)<span class="comment">#predict得到的就是fittedvalues，只是差分的结果而已。还需要继续回退</span></div><div class="line">plt.title(<span class="string">'RSS: %.4f'</span>% sum((results_ARIMA.fittedvalues-ts_log_diff)**<span class="number">2</span>))</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima25.jpg" alt="arma"></p>
<p>可以发现，ARIMA在AR和MA基础上，RSS有所减少，故模型有所提高。</p>
<p>我们使用上文中提高的p和q选择方法，对一阶差分结果进行p和q选择。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">_proper_model(ts_log_diff, <span class="number">9</span>)</div><div class="line"><span class="comment"># 输出最优结果如下：</span></div><div class="line">(<span class="number">8</span>, <span class="number">7</span>, &lt;statsmodels.tsa.arima_model.ARMAResultsWrapper at <span class="number">0xb4e2898</span>&gt;)</div></pre></td></tr></table></figure>
<p>故可以使用p=8,q=7再次进行测试。得到如下结果：</p>
<p><img src="/picture/machine-learning/arima27.jpg" alt="arma"></p>
<p>可以发现，残差平方和RSS已经优化到0.40了。</p>
<h2 id="数据还原"><a href="#数据还原" class="headerlink" title="数据还原"></a>数据还原</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">ts_log_diff = diff_ts(ts_log, d=[1])#调用差分方法，方便后续还原</div><div class="line">model = ARIMA(ts_log, order=(8, 1, 7))  #建模</div><div class="line">results_ARIMA = model.fit(disp=-1)  #fit</div><div class="line">predict_ts = model.predict() #对训练数据进行预测</div><div class="line"></div><div class="line">#还原</div><div class="line">diff_recover_ts = predict_diff_recover(predict_ts, d=[1])#恢复数据</div><div class="line">log_recover = np.exp(diff_recover_ts)#还原对数前数据</div><div class="line"></div><div class="line">#绘图</div><div class="line">#ts = ts[log_recover.index]#排除空的数据</div><div class="line">plt.plot(ts,color=&quot;blue&quot;,label=&apos;Original&apos;)</div><div class="line">plt.plot(log_recover,color=&apos;red&apos;,label=&apos;Predicted&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.title(&apos;RMSE: %.4f&apos;% np.sqrt(sum((log_recover-ts)**2)/len(ts)))#RMSE,残差平方和开根号，即标准差</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima28.jpg" alt="arma"></p>
<h2 id="预测未来走势"><a href="#预测未来走势" class="headerlink" title="预测未来走势"></a>预测未来走势</h2><p>使用forecast进行预测，参数为预测值个数。这个得到的就是进行自动差分还原后的数据，因为我们建立模型的时候ARIMA(p,1,q), 第二个参数就是差分阶数，forecast会将结果恢复回差分前的数据，因此我们直接将结果通过np.exp来恢复到最原始数据即可。但是ARIMA只支持最多2阶差分，因此我们可以使用ARMA模型，将我们手动差分完的数据传入。最后预测的时候，使用我们自定义的差分还原方法，对预测得到的值进行差分还原。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># forecast方法会自动进行差分还原，当然仅限于支持的1阶和2阶差分</div><div class="line">forecast_n = 12 #预测未来12个月走势</div><div class="line">forecast_ARIMA_log = results_ARIMA.forecast(forecast_n)</div><div class="line">forecast_ARIMA_log = forecast_ARIMA_log[0]</div><div class="line">print forecast_ARIMA_log</div><div class="line"></div><div class="line">##如下是差分还原后的数据：</div><div class="line">[6.15487901  6.12150398  6.13788758  6.19511156  6.27419885  6.40259838</div><div class="line">  6.57706431  6.49128697  6.35429917  6.2679321   6.13597822  6.18507789</div><div class="line">  6.26245365  6.24740859  6.24775066  6.29778253  6.3935587   6.54015482</div><div class="line">  6.67409705  6.62124844]</div></pre></td></tr></table></figure>
<p>我们希望能够将预测的数据和原来的数据绘制在一起，为了实现这一目的，我们需要增加数据索引，使用开源库arrow:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#定义获取连续时间，start是起始时间，limit是连续的天数,level可以是day,month,year</span></div><div class="line"><span class="keyword">import</span> arrow</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_date_range</span><span class="params">(start, limit, level=<span class="string">'month'</span>,format=<span class="string">'YYYY-MM-DD'</span>)</span>:</span></div><div class="line">    start = arrow.get(start, format)  </div><div class="line">    result=(list(map(<span class="keyword">lambda</span> dt: dt.format(format) , arrow.Arrow.range(level, start, 		   limit=limit))))</div><div class="line">    dateparse2 = <span class="keyword">lambda</span> dates:pd.datetime.strptime(dates,<span class="string">'%Y-%m-%d'</span>)</div><div class="line">    <span class="keyword">return</span> map(dateparse2, result)</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"># 预测从1961-01-01开始，也就是我们训练数据最后一个数据的后一个日期</div><div class="line">new_index = get_date_range(&apos;1961-01-01&apos;, forecast_n)</div><div class="line">forecast_ARIMA_log = pd.Series(forecast_ARIMA_log, copy=True, index=new_index)</div><div class="line">print forecast_ARIMA_log.head()</div><div class="line"></div><div class="line"># 直接取指数，即可恢复至原数据</div><div class="line">forecast_ARIMA = np.exp(forecast_ARIMA_log)</div><div class="line">print forecast_ARIMA</div><div class="line">plt.plot(ts,label=&apos;Original&apos;,color=&apos;blue&apos;)</div><div class="line">plt.plot(forecast_ARIMA, label=&apos;Forcast&apos;,color=&apos;red&apos;)</div><div class="line">plt.legend(loc=&apos;best&apos;)</div><div class="line">plt.title(&apos;forecast&apos;)</div></pre></td></tr></table></figure>
<p><img src="/picture/machine-learning/arima29.jpg" alt="arma"></p>
<p><strong>遗留问题：</strong></p>
<p>如果直接将差分处理的结果传入ARMA模型，再进行forecast预测，如何对预测的结果进行还原至原始序列？</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/" target="_blank" rel="external">Complete guide to create a Time Series Forecast (with Codes in Python)</a></p>
<p><a href="http://www.cnblogs.com/foley/p/5582358.html" target="_blank" rel="external">时间序列分析</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面花了两章篇幅介绍了时间序列模型的数学基础。 &lt;a href=&quot;/2017/03/07/ARIMA时间序列模型/&quot;&gt;ARIMA时间序列模型(一)&lt;/a&gt;和&lt;a href=&quot;/2017/03/07/ARIMA时间序列模型-二/&quot;&gt;ARIMA时间序列模型(二)&lt;/a&gt; 。本文重点介绍使用python开源库进行时间序列模型实践。&lt;/p&gt;
&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;回顾一下自回归移动平均模型ARMA，它主要由两部分组成：AR代表p阶自回归过程，MA代表q阶移动平均过程，形式如下：&lt;br&gt;$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\&lt;br&gt;+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$&lt;br&gt;为了方便，我们重写以上等式为：&lt;br&gt;$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\&lt;br&gt;其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$&lt;br&gt;$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$&lt;br&gt;$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$&lt;br&gt;根据前两篇的分析，我们总结ARMA模型的性质如下：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/arima5.jpg&quot; alt=&quot;arima&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
  </entry>
  
  <entry>
    <title>ARIMA时间序列模型(二)</title>
    <link href="xtf615.com/2017/03/07/ARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B-%E4%BA%8C/"/>
    <id>xtf615.com/2017/03/07/ARIMA时间序列模型-二/</id>
    <published>2017-03-07T05:49:28.000Z</published>
    <updated>2017-03-11T05:05:41.860Z</updated>
    
    <content type="html"><![CDATA[<p>　　前面我们介绍了时间序列模型的概念、数学基础等。本文将接着介绍时间序列模型的更多理论性质，包括一般线性过程(general linear process)，自回归模型AR(the autoregressive model),移动平均模型MA(the moving average)以及ARMA模型。</p>
<h1 id="一般线性过程"><a href="#一般线性过程" class="headerlink" title="一般线性过程"></a>一般线性过程</h1><h2 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h2><ul>
<li>时间序列\({Z_t}\)是线性(linear)的，当且仅当\(Z_t\)的值是白噪声系列的线性函数。</li>
<li>时间序列\({Z_t}\)是有因果的(causal),当且仅当\(Z_t\)的值只受到目前为止的信息影响，换句话说\(Z_t\)是独立于未来信息\(a_s\)的，s&gt;t</li>
<li>时间序列模型通常是由白噪声驱动的，即\({a_t}\), 时间序列是\({a_t}\)的函数。随机变量\(a_t\)可以被时刻t的信息所解释。白噪声通常叫做新息序列（innovation sequence）或信息序列(information sequence).</li>
</ul>
<p>因此，一个线性的、有因果的、平稳的时间序列也被称作一般线性过程(a general linear process)。</p>
<p>一般线性过程具有如下形式：<br>$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2} \\\\<br>其中，{a_t} \sim WN(0,\sigma_a^2) \ and \  \sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&lt;\infty$$<br>不失一般性，我们可以设\(\psi_0=1\)<br><a id="more"></a>  </p>
<h2 id="均值，自协方差，自相关系数"><a href="#均值，自协方差，自相关系数" class="headerlink" title="均值，自协方差，自相关系数"></a>均值，自协方差，自相关系数</h2><p>一般线性过程：<br>$$E(Z_t)=\mu$$<br>$$\gamma_0=var(Z_t)=\sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&lt;\infty$$<br>$$\gamma_k=cov(Z_t,Z_{t-k})=\sigma_a^2\sum_{j=0}^{\infty}\psi_j\psi_{j+k},k \geq 0$$<br>$$\rho_k=\frac{cov(Z_t,Z_{t-k})}{var(Z_t)}=\frac{\sum_{j=0}^{\infty}\psi_j\psi_{j+k}}{\sum_{j=0}^{\infty}\psi_j^2},k &gt; 0$$</p>
<h1 id="移动平均MA过程"><a href="#移动平均MA过程" class="headerlink" title="移动平均MA过程"></a>移动平均MA过程</h1><p>定义：q阶移动平均过程，简记为：<br>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q} \\\\<br>其中，q \in \mathbb{N}, 并且 {a_t} \sim WN(0,\sigma_a^2)$$</p>
<ul>
<li>如果\(\theta_0=0\)，则0阶移动平均过程实际上就是白噪声序列，此时\(Z_t=a_t\)</li>
<li>移动平均过程是一种特殊的一般线性过程。因为它是线性，因果和平稳的</li>
</ul>
<h2 id="一阶移动平均过程MA（1）"><a href="#一阶移动平均过程MA（1）" class="headerlink" title="一阶移动平均过程MA（1）"></a>一阶移动平均过程MA（1）</h2><p>$$Z_t=\theta_0+a_t-\theta a_{t-1}$$</p>
<ul>
<li>显然，\(E(Z_t)=\theta_0\)</li>
<li>\(\gamma_0=var(Z_t)=\sigma_a^2(1+\theta^2)\)</li>
<li>\(\gamma_1=cov(Z_t,Z_{t-1})=cov(a_t-\theta a_{t-1},a_{t-1}-\theta a_{t-2}) = cov(-\theta a_{t-1},-\theta a_{t-2})=-\theta \sigma_a^2\)</li>
<li>\(\rho_1 = \frac{-\theta}{1+\theta^2}\)</li>
<li>\(\rho_2=cov(Z_t,Z_{t-2})=cov(a_t-\theta a_{t-1},a_{t-2}-\theta a_{t-3})=0\)</li>
<li>同理，因为\(Z_t和Z_{t-2}\)之间不存在共同的下标,故\(\rho_2=0\)</li>
<li>故当\(k \geq 2\)时，\(\gamma_k=cov(Z_t,Z_{t-k})=0, 并且 \rho_k=0\)，即这一过程在超过滞后1,就不存在相关性。这一事实在我们后续为实际数据选择合适的模型时会起到很重要作用。</li>
</ul>
<h2 id="二阶移动平均过程MA（2）"><a href="#二阶移动平均过程MA（2）" class="headerlink" title="二阶移动平均过程MA（2）"></a>二阶移动平均过程MA（2）</h2><p>$$Z_t=\theta_0+a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2}$$</p>
<ul>
<li>显然，\(E(Z_t)=\theta_0\)</li>
<li>方差\(\gamma_0=var(Z_t)=(1+\theta_1^2+\theta_2^2)\sigma_a^2\)</li>
<li>滞后k=1的自协方差:<br>$$\gamma_1=cov(Z_t,Z_{t-1})=cov(a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2},a_{t-1}-\theta_1 a_{t-2}-\theta_2 a_{t-3})=cov(-\theta_1 a_{t-1},a_{t-1}) + cov(-\theta_2 a_{t-2},-\theta_1 a_{t-2})=[-\theta_1+(-\theta_1)(-\theta_2)]\sigma_a^2=(-\theta_1+\theta_1 \theta_2)\sigma_a^2$$</li>
<li>滞后k=2的自协方差为：<br>$$\gamma_2=cov(Z_t,Z_{t-2})=cov(a_t-\theta_1 a_{t-1}-\theta_2 a_{t-2},a_{t-2}-\theta_1 a_{t-3}-\theta_2 a_{t-4})=cov(-\theta_2 a_{t-2}, a_{t-2})=-\theta_2 \sigma_a^2$$</li>
<li>同理相关系数，\(\rho_k=0, \forall k \geq 3\)</li>
</ul>
<p>$$ \begin{eqnarray} \rho=\begin{cases} \rho_1=\frac{-\theta_1+\theta_1 \theta_2}{1+\theta_1^2+\theta_2^2} \cr \rho_2=\frac{-\theta_2}{1+\theta_1^2+\theta_2^2} \cr \rho_k=0, \forall k \geq 3 \end{cases} \end{eqnarray}$$</p>
<h2 id="q阶移动平均过程MA（q）"><a href="#q阶移动平均过程MA（q）" class="headerlink" title="q阶移动平均过程MA（q）"></a>q阶移动平均过程MA（q）</h2><p>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$</p>
<ul>
<li>均值\(\mu=\theta_0\)</li>
<li>方差\(\gamma_0=(1+\theta_1^2+\theta_2^2+…+\theta_q^2)\sigma_a^2\)</li>
<li>自协方差：<br>$$ \begin{eqnarray} \rho_k=\begin{cases} \frac{-\theta_k+\theta_1 \theta_{k+1}+\theta_2 \theta_{k+2}+…+\theta_{q-k} \theta_{q}}{1+\theta_1^2+\theta_2^2+…+\theta_q^2},k=1,2,…,q \cr 0, \forall k \geq q+1 \end{cases} \end{eqnarray}$$</li>
<li>自相关：<br>当k=q时,\(\rho_k \neq 0\); 当k&gt;q时，\(\rho_k=0\)<br><strong>我们通常说，q阶移动平均过程的自相关函数在q滞后截尾，即ACF会在lag=q时截尾(cuts off).</strong></li>
</ul>
<h2 id="后向移位算子"><a href="#后向移位算子" class="headerlink" title="后向移位算子"></a>后向移位算子</h2><p>任意时间序列上的后向移位算子B定义为：<br>\(BZ_t=Z_{t-1}\), \(B^kZ_t=B^{k-1}(BZ_t)=…=Z_{t-k}, \forall k \in \mathbb{Z}\)<br>因此，B(Z)是原始序列Z的滞后为1的序列。\(B^k(Z)是原始序列滞后为k的序列\)<br>特别的，\(B^0是单位算子，B^0Z=Z\)<br>因此：<br>移动平均过程：<br>$$Z_t=\theta_0+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>可以被重写为：<br>$$Z_t=(1-\theta_1B-\theta_2B^2-…-\theta_qB^q)a_t=\theta(B)a_t$$<br>其中，\(\theta(x)=1-\theta_1x-…-\theta_qx^q\)是MA移动平均的特征多项式</p>
<h1 id="自回归过程AR"><a href="#自回归过程AR" class="headerlink" title="自回归过程AR"></a>自回归过程AR</h1><p>p阶自回归模型AR(p)定义为：<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t \\\\<br>其中，p \geq 0,且p为整数。 \phi是参数。{a_t} \sim WN(0,\sigma_a^2)<br>$$<br>模型可以被重写为：<br>$$\phi(B)Z_t=\theta_0+a_t \\\\<br>其中，\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p是AR的特征多项式$$</p>
<h2 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h2><p>AR(p)模型有一个唯一的平稳性解，只有当下面AR特征方程的所有根都在单位圆外时。<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p=0$$</p>
<ul>
<li>求解唯一平稳性解叫做AR(p)自回归过程</li>
<li>上述条件称作平稳性条件</li>
<li>对于一个复杂的z值，如果\(\vert z \vert &gt; 1\),我们称它是在单位圆外。 </li>
<li>例子：找出AR(1)模型的平稳性条件：<br>  \(Z_t=\phi Z_{t-1}+a_t\)<br>  由上可得，\(1-\phi x=0\),则\(x=1/\phi\),因为需要满足|x|&gt;1，则我们有\(|\phi| &lt; 1\)</li>
<li>例子，找出AR(1),\(Z_t=0.5Z_{t-1}+a_t\)的一般线性过程形式：<br>由前面AR的特征多项式可得，<br>$$(1-0.5B)Z_t=a_t$$<br>因此可以根据等比数列求和性质得到如下式子<br>$$Z_t=\frac{1}{1-0.5B}a_t=(1+0.5B+0.5^2B^2+…)a_t$$<br>进一步得到，即一般线性过程形式：<br>$$Z_t=a_t+0.5a_{t-1}+0.5^2a_{t-2}+…$$<h2 id="一般平稳性条件"><a href="#一般平稳性条件" class="headerlink" title="一般平稳性条件"></a>一般平稳性条件</h2>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t \ (1)$$<br>必须满足如下条件：<br>$$ \begin{eqnarray} \begin{cases} \mu=\frac{1}{1-\phi_1-…-\phi_p} \cr \psi_1=\phi_1, \cr \psi_2=\phi_1\psi_1+\phi_2, \cr … \cr \psi_k=\phi_1\psi_{k-1}+\phi_2\psi_{k-2}+…+\phi_p\psi_{k-p} \end{cases} \end{eqnarray}$$<br>其中，\(\psi是一般线性过程的参数\)<br>一般线性过程是：<br>$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2}  \ (2)$$<br>要想满足平稳性，要求AR模型能够转换成一般线性过程的形式，因此通过比较(1),(2)式子，展开运算，可以得到上述一般平稳性条件</li>
</ul>
<h2 id="均值，自协方差，方差，自相关"><a href="#均值，自协方差，方差，自相关" class="headerlink" title="均值，自协方差，方差，自相关"></a>均值，自协方差，方差，自相关</h2><p>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} + a_t $$</p>
<ul>
<li>均值<br>我们对等式两边同时求均值：<br>$$\mu=\theta_0+\phi_1 \mu+\phi_2 \mu + …+ \phi_p \mu + 0$$<br>得到：<br>$$\mu = \frac{\theta_0}{1-\phi_1-\phi_2-…-\phi_p}$$<br>可以证明分母不为0.</li>
<li>自相关<br><img src="/picture/machine-learning/arima1.jpg" alt="arima"><br>将两个式子等式两边对应相乘，然后再等式两边同时求自相关，根据定义，可以得到上述3.3的式子。<br><img src="/picture/machine-learning/arima2.jpg" alt="arima"></li>
<li>方差<br><img src="/picture/machine-learning/arima4.jpg" alt="arima"><br><img src="/picture/machine-learning/arima3.jpg" alt="arima"><br>上述3.2式子和\(Z_t\)相乘后，再等式两边同时取方差，根据定义以及\(E(a_tZ_t)\)的推导，可以得到上述式子。</li>
</ul>
<h1 id="ARMA模型"><a href="#ARMA模型" class="headerlink" title="ARMA模型"></a>ARMA模型</h1><p>英文全称为，the mixed autoregressive-moving average model<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\<br>+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>我们称\({Z_t}\)是(p,q)阶混合自回归移动平均模型，简记为ARMA(p,q)<br>如果q=0，则模型退化为AR模型；如果p=0,则模型退化为MA模型。二者都是ARMA模型的特例。<br>为了方便，我们重写以上等式为：<br>$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\<br>其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$</p>
<p>定理：如果AR多项式等式\(\phi(x)=0\)所有根都在单位圆之外，那么ARMA(p,q)模型存在唯一的平稳性解。<br>当存在平稳性解时，ARMA模型具备如下形式:<br>$$Z_t=\mu+\sum_{j=0}^\infty \psi_j a_{t-j}$$</p>
<h2 id="如何求解ARMA模型平稳性条件？"><a href="#如何求解ARMA模型平稳性条件？" class="headerlink" title="如何求解ARMA模型平稳性条件？"></a>如何求解ARMA模型平稳性条件？</h2><p>考虑ARMA(1,1)，则：<br>$$Z_t=\phi Z_{t-1}+a_t-\theta a_{t-1}$$<br>比较上述式子的系数可以得到：<br>$$\psi_0 a_t+\psi_1 a_{t-1}+ \psi_2 a_{t-2}+ … \\\\<br>  = \phi \psi_0 a_{t-1} + \phi \psi_1 a_{t-2} + \phi \psi_2 a_{t-3} +…+a_t-\theta a_{t-1}$$<br>可以得出：<br>$$\psi_0=1$$<br>$$\psi_1=\phi \psi_0 - \theta = \phi - \theta$$<br>$$\psi_0=\phi \psi_1 = \phi^2-\phi \theta$$<br>$$…$$<br>$$\psi_k=\phi \psi_k = \phi^k - \phi^{k-1} \theta$$<br>一般的，对于ARMA(p,q),我们可以得到:<br>$$ \begin{eqnarray} \begin{cases} \psi_0=1 \cr \psi_1=-\theta_1+\phi_1, \cr \psi_2=-\theta_2+\phi_2+\phi_1 \psi_1, \cr … \cr \psi_j=\theta_j+ \phi_p \psi_{j-p}+ … + \phi_1 \psi_{j-1} \end{cases} \end{eqnarray}$$<br>而，<br>$$\mu=\frac{\theta_0}{1-\phi_1-\phi_2-…-\phi_p}$$<br>所以有：<br>$$Z_t=\mu+\sum_{j=0}^\infty \psi_j a_{t-j}$$</p>
<h2 id="可逆性"><a href="#可逆性" class="headerlink" title="可逆性"></a>可逆性</h2><ul>
<li><p>为什么需要可逆性？<br>  假设我们获取了100个观察值：<br>  $$z_1,z_2,…,z_{100}$$<br>  经过复杂的过程，我们得到了一个AR(1)模型:<br>  $$Z_t=0.6Z_{t-1}+a_t$$<br>  那么该如何解释结果呢？<br>  如果模型变成：<br>  $$Z_t=a_t-0.5a_{t-1}或者Z_t=0.3Z_{t-1}+a_t+0.2a_{t-1}$$<br>  又该如何解释呢？</p>
<ul>
<li>定义：如果时间序列\({Z_t}\)是可逆的，则：<br>$$a_t=\pi_0 Z_t+\pi_1 Z_{t-1}+\pi_2 Z_{t-2}+…$$<br>这个性质使得我们能够基于过去观察序列获取信息序列<br>不失一般性，我们令\(\pi_0=1\)<br>AR过程总是可逆的。</li>
<li>定理：ARMA或MA模型是可逆的，当且仅当MA特征方程的根都在单位圆外。<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_qx^q=0$$</li>
<li>定义：如果时间序列\({Z_t}\)是可逆的，则定义：<br>$$Z_t=a_t-\pi_1Z_{t-1}-\pi_2Z_{t-2}-…$$<br>为该时间序列的AR表示（autoregressive representation）。</li>
</ul>
</li>
</ul>
<p>注意：可以发现求解AR表示和求解AR或ARMA模型的唯一平稳性解方法是一样的，同样是需要比较方程两边的系数。<br>相反，求解AR或ARMA模型的唯一平稳性解也叫做AR或ARMA模型的MA表示。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;　　前面我们介绍了时间序列模型的概念、数学基础等。本文将接着介绍时间序列模型的更多理论性质，包括一般线性过程(general linear process)，自回归模型AR(the autoregressive model),移动平均模型MA(the moving average)以及ARMA模型。&lt;/p&gt;
&lt;h1 id=&quot;一般线性过程&quot;&gt;&lt;a href=&quot;#一般线性过程&quot; class=&quot;headerlink&quot; title=&quot;一般线性过程&quot;&gt;&lt;/a&gt;一般线性过程&lt;/h1&gt;&lt;h2 id=&quot;定义：&quot;&gt;&lt;a href=&quot;#定义：&quot; class=&quot;headerlink&quot; title=&quot;定义：&quot;&gt;&lt;/a&gt;定义：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;时间序列\({Z_t}\)是线性(linear)的，当且仅当\(Z_t\)的值是白噪声系列的线性函数。&lt;/li&gt;
&lt;li&gt;时间序列\({Z_t}\)是有因果的(causal),当且仅当\(Z_t\)的值只受到目前为止的信息影响，换句话说\(Z_t\)是独立于未来信息\(a_s\)的，s&amp;gt;t&lt;/li&gt;
&lt;li&gt;时间序列模型通常是由白噪声驱动的，即\({a_t}\), 时间序列是\({a_t}\)的函数。随机变量\(a_t\)可以被时刻t的信息所解释。白噪声通常叫做新息序列（innovation sequence）或信息序列(information sequence).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此，一个线性的、有因果的、平稳的时间序列也被称作一般线性过程(a general linear process)。&lt;/p&gt;
&lt;p&gt;一般线性过程具有如下形式：&lt;br&gt;$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2} \\\\&lt;br&gt;其中，{a_t} \sim WN(0,\sigma_a^2) \ and \  \sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&amp;lt;\infty$$&lt;br&gt;不失一般性，我们可以设\(\psi_0=1\)&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
  </entry>
  
  <entry>
    <title>ARIMA时间序列模型(一)</title>
    <link href="xtf615.com/2017/03/07/ARIMA%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/"/>
    <id>xtf615.com/2017/03/07/ARIMA时间序列模型/</id>
    <published>2017-03-07T01:33:02.000Z</published>
    <updated>2017-03-10T09:27:51.452Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="时间序列是什么？"><a href="#时间序列是什么？" class="headerlink" title="时间序列是什么？"></a>时间序列是什么？</h2><p>定义：时间序列数据是按时间排序的观察序列，是目标在不同时间点下的一系列观察值。</p>
<p>所有的时间观察序列数据可以被标记为：\(z_1,z_2,…,z_T\) , 可以当作T个随机变量的一个实例：$$(Z_1,Z_2,..,Z_T)$$</p>
<p>进一步定义：时间序列是一系列按照时间排序的随机变量。通常定义为双无穷随机变量序列。标记为：\({Z_t,t \in \mathbb{Z}}\), 或者简记为：\({Z_t}\) 。时间序列是离散时间下的随机过程。</p>
<p>回顾线性模型，响应变量Y和多个因变量X，线性模型表示为：$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$</p>
<p>因变量X的信息是已知的，我们希望对响应变量Y做出推断。</p>
<p>在时间序列分析中，我们提出如下模型：$$Y_t=\beta_o+\beta_1Y_{t-1}+\varepsilon_t$$</p>
<p>在时间序列中，已知的信息包括：</p>
<ul>
<li>时间下标t</li>
<li>过去的信息</li>
</ul>
<p>两个典型的时间序列模型如下：</p>
<p>$$Z_t=a+bt+\varepsilon_t$$</p>
<p>and</p>
<p>$$Z_t=\theta_0+\phi Z_{t-1}+\varepsilon_t$$</p>
<p>它们分别对应于确定性模型和随机模型，本文将讨论后者。<br><a id="more"></a>  </p>
<h1 id="时间序列的均值，方差，协方差"><a href="#时间序列的均值，方差，协方差" class="headerlink" title="时间序列的均值，方差，协方差"></a>时间序列的均值，方差，协方差</h1><ul>
<li><p><strong>均值函数（The mean function）</strong>：对于一个时间序列\({Z_t,t \in Z}\), 均值函数或平均序列被定义为：</p>
<p>$$\mu_t = E(Z_t), \ t \in \mathbb{Z} $$</p>
<p>\(\mu_t\)是在t时刻的期望值，\(\mu_t\) 在不同时刻可以是不同的值。</p>
</li>
<li><p><strong>自协方差函数（The auto-covariance function）</strong>：简记为ACVF，定义为：</p>
<p>$$\gamma(t,s)=cov(Z_t,Z_s) \ t,s \in \mathbb{Z}$$</p>
<p>其中，</p>
<p>$$cov(Z_t,Z_s)=E[(Z_t-\mu_t)(Z_s-\mu_s)]=E(Z_tZ_s)-\mu_t\mu_s$$</p>
</li>
<li><p><strong>方差函数（The variance function）</strong>：特别是在s=t时，我们有：</p>
<p>$$\gamma(t,t)=cov(Z_t,Z_t)=var(Z_t)$$</p>
<p>这就是\({Z_t}\)的方差函数</p>
</li>
<li><p><strong>自相关函数（The auto-correlation function）</strong>：简记为ACF，定义为：</p>
<p>$$\rho(t,s)=corr(Z_t,Z_s),  \ t,s \in \gamma(t,s)=cov(Z_t,Z_s) \ t,s \in \mathbb{Z} $$</p>
<p>其中，</p>
<p>$$corr(Z_t,Z_s)=\frac{cov(Z_t,Z_s)}{\sqrt{var(Z_t)var(Z_s)}}=\frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}}$$</p>
<p><strong>ACVF和ACF有如下性质：</strong></p>
<p> ACVF:</p>
</li>
<li><p>\(\gamma(t,t)=var(Z_t)\)</p>
</li>
<li>\(\gamma(t,s)=\gamma(s,t)\)</li>
<li><p>\(\vert{\gamma(t,s)} \vert \leq \sqrt{\gamma(t,t)\gamma(s,s)} \)</p>
<p> ACF:</p>
</li>
<li><p>\(\rho(t,t)=1\)</p>
</li>
<li>\(\rho(t,s)=\rho(s,t)\)</li>
<li><p>\(\vert{\rho(t,s)}\vert \leq 1\)</p>
<p><strong>一些重要的性质：</strong></p>
</li>
</ul>
<p>$$cov(aX,Y)=acov(X,Y)$$</p>
<p>$$cov(X,aY+bZ)=acov(X,Y)+bcov(X,Z)$$</p>
<p>$$cov(c_1Y_1+c_2Y_2, d_1Z_1+d_2Z_2)=c_1d_1cov(Y_1,Z_1)+c_2d_1cov(Y_2,Z_1)+c_1d_2cov(Y_1,Z_2)+c_2d_2cov(Y_2,Z_2)$$</p>
<p>$$cov\left[\sum_{i=1}^m c_iY_i, \sum_{j=1}^n d_jZ_j\right]=\sum_{i=1}^m\sum_{j=1}^n c_id_jcov(Y_i,Z_j)$$</p>
<p>最后一条性质经常用到。</p>
<h2 id="随机游走"><a href="#随机游走" class="headerlink" title="随机游走"></a>随机游走</h2><p><strong>随机游走（The random walk）</strong>：令序列\({a_t, t \in \mathbb{N}}\) 是服从 \(i.i.d\)独立同分布的随机变量。每个变量都是零均值，方差为\(\sigma_a^2\), 随机游走过程\({Z_t, t \in \mathbb{N}}\)定义为：</p>
<p>$$Z_t = \sum_{j=1}^t a_j, \ t \in \mathbb{N}$$</p>
<p>另外，我们可以写作：</p>
<p>$$Z_t=Z_{t-1}+a_t, \ t \in \mathbb{N}, Z_0=0$$</p>
<ul>
<li>\({Z_t}\)均值函数为:</li>
</ul>
<p>$$\mu_t=E(Z_t)=E\left(\sum_{j=1}^t a_j\right)=\sum_{j=1}^tE(a_j)=0$$</p>
<ul>
<li>\({Z_t}\)方差函数为:</li>
</ul>
<p>$$\gamma(t,t)=var(Z_t)=var\left(\sum_{j=1}^t a_j\right)=\sum_{j=1}^t var(a_j)=t \cdot \sigma_a^2$$</p>
<p>注意到，这一过程，方差会随着时间线性增长。</p>
<ul>
<li><p>ACVF自协方差函数：对于一切\(t \leq s\),</p>
<p>$$\gamma(t,s)=cov(Z_t,Z_s) \\\\=cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^s a_j\right) \\\ =cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^t a_j + \sum_{j=t+1}^s a_j\right) \\\ =cov \left(\sum_{j=1}^t a_j, \sum_{j=1}^t a_j\right) \\\\=var\left(\sum_{j=1}^t a_j\right) = t \cdot \sigma_a^2$$</p>
</li>
<li><p>ACF自相关函数，根据定义有：</p>
<p>$$\rho(t,s)=\frac{\gamma(t,s)}{\sqrt{\gamma(t,t)\gamma(s,s)}} \\\ = \frac{\sigma_at}{\sqrt{\sigma_a^2t \cdot \sigma_a^2s}} \\\ = \sqrt{t/s}, \ 1 \leq t \leq s$$</p>
<p>当s=t+1时，</p>
<p>$$\rho(t,t+1)=corr(Z_t,Z_{t+1})=\sqrt{t/(t+1)} \approx 1, \ 当t无穷大$$</p>
<p>​</p>
<p><strong>理解：随机游走可以看作，在时间轴上任意行走一步（大步或小步），是若干时刻的和。</strong></p>
</li>
</ul>
<h2 id="移动平均"><a href="#移动平均" class="headerlink" title="移动平均"></a>移动平均</h2><p><strong>移动平均（a moving average）</strong>：假设\({Z_t, t \in \mathbb{Z}}\) 定义为：</p>
<p>$$Z_t=a_t-0.5a_{t-1}, \ t \in \mathbb{Z}$$</p>
<p>同样，a满足独立同分布，零均值，方差为\(\sigma_a^2\)</p>
<ul>
<li><p>\({Z_t}\)均值函数为:</p>
<p>$$\mu_t=E(Z_t)=E(a_t)-0.5E(a_{t-1})=0, \ t \in \mathbb{Z}$$</p>
</li>
<li><p>\({Z_t}\)f方差函数为:</p>
<p>$$var(Z_t)=var(a_t-0.5a_{t-1})=\sigma_a^2+0.5^2\sigma_a^2=1.25\sigma_a^2$$</p>
</li>
<li><p>ACVF自协方差函数：</p>
<p>$$cov(Z_t,Z_{t-1})=cov(a_t-0.5a_{t-1},a_{t-1}-0.5a_{t-2})=cov(a_t,a_{t-1})-0.5cov(a_t,a_{t-2})-0.5cov(a_{t-1},a_{t-1})-0.5cov(a_{t-1},a_{t-1})+0.5^2cov(a_{t-1},a_{t-2})=-0.5cov(a_{t-1},a_{t-1})$$</p>
<p>或者表示为：</p>
<p>$$\gamma(t,t-1)=-0.5\sigma_a^2,   \forall t \in \mathbb{Z}$$</p>
<p>对任意\(k \geq 2\),</p>
<p>$$cov(Z_t, Z_{t-k})=0$$</p>
<p>或者表示为，$$\gamma(t,t-k)=0, \ \forall  k \geq 2,t \in \mathbb{Z}$$</p>
</li>
<li><p>ACF自相关函数：</p>
<p>$$\rho(t,s)=-0.4,   if  \ \vert{t-s}\vert = 1 \\\ \rho(t,s)=0, if \ \vert{t-s}\vert \geq 2$$</p>
<p><strong>理解：移动平均可以看作，若干时刻的线性组合。</strong></p>
</li>
</ul>
<h1 id="平稳性"><a href="#平稳性" class="headerlink" title="平稳性"></a>平稳性</h1><p><strong>强平稳性（strict stationarity）要求：</strong>时间序列\({Z_t}\)为强平稳，只有当对任意的自然数n, 任意的时间点\(t_1\),\(t_2\),..,\(t_n\)以及任意的滞后k, 都满足\(Z_{t_1}\),\(Z_{t_2}\),…,\(Z_{t_n}\)的联合分布 和\(Z_{t_1-k}\),\(Z_{t_2-k}\),…,\(Z_{t_n-k}\)相同。</p>
<p><strong>弱平稳性(weak stationarity)要求</strong>：时间序列为弱平稳性，只有当均值函数\(\mu_t\)不随时间变化，并且对于任意的时间t和任意的滞后k，都有\(\gamma(t,t-k)=\gamma(0,k)\)</p>
<p>对于弱平稳性，有如下标志：</p>
<p>$$\mu = E(Z_t)$$</p>
<p>$$\gamma_k=cov(Z_t, Z_{t-k}), \ (\gamma_{-k}=\gamma_k)$$</p>
<p>$$\rho_k=Corr(Z_t,Z_{t-k}); \ (\rho_{-k}=\rho_k)$$</p>
<p>强平稳性和弱平稳性关系如下：</p>
<ol>
<li>强平稳性+有限的秒时刻 =&gt; 弱平稳性</li>
<li>时间序列的联合分布为多元正太分布，那么这两种定义是一致的</li>
</ol>
<h2 id="白噪声"><a href="#白噪声" class="headerlink" title="白噪声"></a>白噪声</h2><p><strong>白噪声（White noise）</strong>：一个很重要的关于平稳性处理的例子就是所谓的白噪声处理。它被定义为满足独立同分布的随机变量\({a_t}\), 零均值并且方差为\(\sigma_a^2&gt;0\), 简记为：\(WN(0,\sigma_a^2)\)</p>
<p>显然，\({a_t}\)满足强平稳性要求。</p>
<p>对于弱平稳性，注意到\(\mu_t=E(a_t)=0\)是一个常数，并且，</p>
<p>$$ \begin{eqnarray} \gamma(t;t-k)=\begin{cases} \sigma_a^2, k=0 \cr 0, k \neq 0 \end{cases} \end{eqnarray} :=\gamma_k$$,</p>
<p>$$\begin{eqnarray} \rho_k=\begin{cases} 1, k=0 \cr 0, k \neq 0 \end{cases} \end{eqnarray} $$</p>
<p>有些书中定义白噪声为一系列不相关的随机变量。</p>
<p>前面我们提高的随机游走，由于\({Z_t}\)的方差受时间影响线性变化\(var(Z_t)=t\sigma_a^2\)，并且协方差\(\gamma(t,s)=t\sigma_a^2\), 因此不仅仅受滞后k的影响，故不是平稳的时间序列。</p>
<p>令，$$X_t=\nabla Z_t=Z_t-Z_{t-1}$$</p>
<p>则\(X_t=a_t\), \({\nabla Z_t}\)是平稳的。</p>
<p>前面我们还提到移动平均。是由白噪声构成的一个非平凡平稳时间序列。在前面那个例子里，我们有：</p>
<p>$$\begin{eqnarray} \rho_k=\begin{cases} 1, k=0 \cr -0.4, k \pm 1 \cr 0, \vert k \vert \geq 2  \end{cases} \end{eqnarray}$$</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;时间序列是什么？&quot;&gt;&lt;a href=&quot;#时间序列是什么？&quot; class=&quot;headerlink&quot; title=&quot;时间序列是什么？&quot;&gt;&lt;/a&gt;时间序列是什么？&lt;/h2&gt;&lt;p&gt;定义：时间序列数据是按时间排序的观察序列，是目标在不同时间点下的一系列观察值。&lt;/p&gt;
&lt;p&gt;所有的时间观察序列数据可以被标记为：\(z_1,z_2,…,z_T\) , 可以当作T个随机变量的一个实例：$$(Z_1,Z_2,..,Z_T)$$&lt;/p&gt;
&lt;p&gt;进一步定义：时间序列是一系列按照时间排序的随机变量。通常定义为双无穷随机变量序列。标记为：\({Z_t,t \in \mathbb{Z}}\), 或者简记为：\({Z_t}\) 。时间序列是离散时间下的随机过程。&lt;/p&gt;
&lt;p&gt;回顾线性模型，响应变量Y和多个因变量X，线性模型表示为：$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$&lt;/p&gt;
&lt;p&gt;因变量X的信息是已知的，我们希望对响应变量Y做出推断。&lt;/p&gt;
&lt;p&gt;在时间序列分析中，我们提出如下模型：$$Y_t=\beta_o+\beta_1Y_{t-1}+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;在时间序列中，已知的信息包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时间下标t&lt;/li&gt;
&lt;li&gt;过去的信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两个典型的时间序列模型如下：&lt;/p&gt;
&lt;p&gt;$$Z_t=a+bt+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;p&gt;$$Z_t=\theta_0+\phi Z_{t-1}+\varepsilon_t$$&lt;/p&gt;
&lt;p&gt;它们分别对应于确定性模型和随机模型，本文将讨论后者。&lt;br&gt;
    
    </summary>
    
      <category term="统计学" scheme="xtf615.com/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
    
      <category term="统计学" scheme="xtf615.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/"/>
    
      <category term="时间序列" scheme="xtf615.com/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/"/>
    
      <category term="ARIMA" scheme="xtf615.com/tags/ARIMA/"/>
    
      <category term="ARMA" scheme="xtf615.com/tags/ARMA/"/>
    
  </entry>
  
  <entry>
    <title>SVM支持向量机</title>
    <link href="xtf615.com/2017/02/22/SVM%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    <id>xtf615.com/2017/02/22/SVM支持向量机/</id>
    <published>2017-02-22T00:26:31.000Z</published>
    <updated>2017-03-07T05:47:07.501Z</updated>
    
    <content type="html"><![CDATA[<h1 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h1><p>　　到目前为止,你已经见过一系列不同的学习算法。在监督学习中，许多学习算法的性能都非常类似，因此，重要的不是你该选择使用学习算法 A还是学习算法B，而更重要的是，应用这些算法时，所创建的大量数据在应用这些算法时，表现情况通常依赖于你的水平。比如：你为学习算法所设计的特征量的选择，以及如何选择正则化参数，诸如此类的事。还有一个更加强大的算法广泛的应用于工业界和学术界，它被称为支持向量机(Support Vector<br>Machine)。与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。<br>　　为了描述支持向量机，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。<br><img src="/picture/machine-learning/svm1.jpg" alt="svm"><br>　　在逻辑回归中我们已经熟悉了这里的假设函数形式和右边的S型激励函数。然为了解释一些数学知识.我将用z表示\(\theta^Tx\)。<br>　　现在考虑下我们想要逻辑回归做什么：如果有一个y=1的样本，不管是在训练集中或是在测试集中，又或者在交叉验证集中，总之是y=1，我们希望\(h(x)\)趋近1。因为我们想要正确地将此样本分类，这就意味着当h(x)趋近于1时，\(\theta^Tx\)应当远大于0。这是因为z表示\(\theta^Tx\)，当z远大于0时，即到了该图的右边，不难发现此时逻辑回归的输出将趋近于1。相反地，如果我们有另一个样本，即y=0。我们希望假设函数的输出值将趋近于0，这对应于z远小于0，此时对应的假设函数的输出值趋近 0。<br><a id="more"></a><br><img src="/picture/machine-learning/svm2.jpg" alt="svm"><br>　　如果进一步观察逻辑回归的代价函数，你会发现每个样本(x, y)都会为总代价函数增加这里的一项，因此，对于总代价函数通常会有对所有的训练样本求和，并且这里还有一个1/m项.<br>　　现在，先忽略 1/m这一项。考虑两种情况：一种是y等于1的情况；另一种是y等于0的情况。在第一种情况中，假设y等于1，此时在目标函数中只需有第一项起作用，因为y等于1时，(1-y)项将等于0。因此，当在y等于1的样本中时，我们得到\(-log\frac{1}{1+e^{-z}}\)<br>　　我们用z表示\(\theta^Tx\)。如果画出关于z的函数，你会看到左下角的这条曲线，我们同样可以看到，当z增大时，也就是相当于\(\theta^Tx\)增大时，z对应的值会变的非常小。对整个代价函数而言，影响也非常小。这也就解释了，为什么逻辑回归在观察到正样本y=1时，试图将\(\theta^Tx\)设置得非常大。因为，在代价函数中的这一项会变的非常小。<br>　　现在开始建立SVM。<br>　　我们会从这个代价函数说起，\(-log\frac{1}{1+e^{-z}}\)，取z=1的点，先画出代价函数。<br><img src="/picture/machine-learning/svm3.jpg" alt="svm"></p>
<p>　　目前，我们只是讨论了  y=1的情况，另外一种情况是当y=0时，此时如果你仔细观察代价函数只留下了第二项，因为第一项被消除了。并且，如果你将这一项作为z的函数，那么，这里就会得到横轴z。<br>　　新的代价函数将会水平的从这里到右边，然后我再画一条同逻辑回归非常相似的直线，但是，在这里是一条直线，也就是我用紫红色画的曲线，就是这条紫红色的曲线。那么，到了这里已经非常接近逻辑回归中使用的代价函数了。只是这里是由<strong>两条线段</strong>组成，即位于右边的水平部分和位于左边的直线部分，先别过多的考虑左边直线部分的斜率，这并不是很重要。但是，这里我们将使用的新的代价函数，是在y=1的前提下的。你也许能想到，这应该能做同逻辑回归中类似的事情，但事实上，在之后的的优化问题中，这会为支持向量机带来计算上的优势。例如，更容易计算股票交易的问题等等。<br>　　目前，我们只是讨论了y=1的情况，另外一种情况是当y=0时，此时如果你仔细观察代价函数只留下了第二项，因为第一项被消除了。并且，如果你将这一项作为z的函数，那么，这里就会得到横轴z。同样地，我们要替代这一条蓝色的线，用相似的方法。<br><img src="/picture/machine-learning/svm4.jpg" alt="svm"><br>　　如果我们用一个新的代价函数来代替，即这条从0点开始的水平直线，然后是一条斜线，像上图。那么，现在让我给这两个方程命名，左边的函数，我称之为\(cost_1(z)\)，同时，右边函数我称它为\(cost_<br>0(z)\)。这里的下标是指在代价函数中，对应的y=1和y=0的情况，拥有了这些定义后，现在，我们就开始构建支持向量机。<br><img src="/picture/machine-learning/svm5.jpg" alt="svm"><br>　　这是我们在逻辑回归中使用代价函数J(θ)。也许这个方程看起来不是非常熟悉。这是因为之前有个负号在方程外面，但是，这里我所做的是，将负号移到了表达式的里面，这样做使得方程看起来有些不同。对于支持向量机而言，实质上我们要将这替换为\(cost_1(z)\)，也就是\(cost_1(\theta^Tx)\)，同样地，我也将这一项替换为\(cost_0(z)\)，也就是代价\(cost_0(\theta^Tx)\)。这里的代价函数\(cost_1\)，就是之前所提到的那条线。此外，代价函数\(cost_0\)，也是上面所介绍过的那条线.因此，对于支持向量机，我们得到了这里的最小化问题，即：<br><img src="/picture/machine-learning/svm6.jpg" alt="svm"><br>　　然后，再加上正则化参数。现在，按照支持向量机的惯例，事实上，我们的书写会稍微有些不同，代价函数的参数表示也会稍微有些不同。<br>首先，我们要除去1/m这一项，当然，这仅仅是由于人们使用支持向量机时，对比于逻辑回归而言，不同的习惯所致，但这里我所说的意思是：你知道，我将要做的是仅仅除去1/m这一项，但是，这也会得出同样的 θ最优值，因为1/m仅是个常量，因此，你知道在这个最小化问题中，无论前面是否有 1/m这一项，最终我所得到的最优值θ都是一样的。这里我的意思是，先给你举一个实例，假定有一最小化问题：即要求当  (u-5)^2+1取得最小值时的 u值，这时最小值为：当u=5时取得最小值。<br>　　现在，如果我们想要将这个目标函数乘上常数10，这里我的最小化问题就变成了：求使得 10×(u-5)^2+10最小的值  u，然而，使得这里最小的u值仍为5。因此将一些常数乘以你的最小化项，这并不会改变最小化该方程时得到  u值。因此，这里我所做的是删去常量m。也相同的，我将目标函数乘上一个常量m，并不会改变取得最小值时的θ值。<br>　　第二点概念上的变化，我们只是指在使用支持向量机时，一些如下的标准惯例，而不是逻辑回归。因此，对于逻辑回归，在目标函数中，我们有两项：第一个是训练样本的代价，第二个是我们的正则化项，我们不得不去用这一项来平衡。这就相当于我们想要最小化A加上正则化参数λ，然后乘以其他项B。这里的A表示这里的第一项，同时我用B表示第二项，但不包括λ，我们不是优化这里的 A+λ×B。我们所做的是通过设置不同正则参数λ达到优化目的。这样，我们就能够权衡对应的项，是使得训练样本拟合的更好，即最小化A。还是保证正则参数足够小，也即是对于B项而言。<br>　　但对于支持向量机，按照惯例，我们将使用一个不同的参数替换这里使用的λ来权衡这两项。你知道，就是第一项和第二项我们依照惯例使用一个不同的参数称为C，同时改为优化目标，C×A+B因此，在逻辑回归中，如果给定λ，一个非常大的值，意味着给予B更大的权重。而这里，就对应于将C设定为非常小的值，那么，相应的将会给B比给A更大的权重。因此，这只是一种不同的方式来控制这种权衡或者一种不同的方法，即用参数来决定是更关心第一项的优化，还是更关心第二项的优化。当然你也可以把这里的参数  C考虑成1/λ，同1/ λ所扮演的角色相同，并且这两个方程或这两个表达式并不相同，因为C等于1/λ，但是也并不全是这样，如果C等于1/λ，这两个优化目标应当得到相同的值，相同的最优值θ。那么就用它们来代替。现在删掉这里的λ，并且用常数C来代替。因此，这就得到了在支持向量机中我们的整个优化目标函数。通过最小化这个目标函数，得到SVM学习到的参数C。<br><img src="/picture/machine-learning/svm7.jpg" alt="svm"><br>　　最后有别于逻辑回归输出的概率。在这里，当最小化代价函数，获得参数θ时，支持向量机所做的是它来直接预测y的值等于1，还是等于 0。因此，当\(\theta^Tx\)大于或者等于0时，这个假设函数会预测1。这就是支持向量机数学上的定义。</p>
<h1 id="大边界直观理解"><a href="#大边界直观理解" class="headerlink" title="大边界直观理解"></a>大边界直观理解</h1><p>　　人们有时将支持向量机看作是大间距分类器。在这一部分，我将介绍其中的含义，这有助于我们直观理解SVM模型的假设是什么样的。<br><img src="/picture/machine-learning/svm8.jpg" alt="svm"></p>
<p>未完待续．．．</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;优化目标&quot;&gt;&lt;a href=&quot;#优化目标&quot; class=&quot;headerlink&quot; title=&quot;优化目标&quot;&gt;&lt;/a&gt;优化目标&lt;/h1&gt;&lt;p&gt;　　到目前为止,你已经见过一系列不同的学习算法。在监督学习中，许多学习算法的性能都非常类似，因此，重要的不是你该选择使用学习算法 A还是学习算法B，而更重要的是，应用这些算法时，所创建的大量数据在应用这些算法时，表现情况通常依赖于你的水平。比如：你为学习算法所设计的特征量的选择，以及如何选择正则化参数，诸如此类的事。还有一个更加强大的算法广泛的应用于工业界和学术界，它被称为支持向量机(Support Vector&lt;br&gt;Machine)。与逻辑回归和神经网络相比，支持向量机，或者简称SVM，在学习复杂的非线性方程时提供了一种更为清晰，更加强大的方式。&lt;br&gt;　　为了描述支持向量机，我将会从逻辑回归开始展示我们如何一点一点修改来得到本质上的支持向量机。&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/svm1.jpg&quot; alt=&quot;svm&quot;&gt;&lt;br&gt;　　在逻辑回归中我们已经熟悉了这里的假设函数形式和右边的S型激励函数。然为了解释一些数学知识.我将用z表示\(\theta^Tx\)。&lt;br&gt;　　现在考虑下我们想要逻辑回归做什么：如果有一个y=1的样本，不管是在训练集中或是在测试集中，又或者在交叉验证集中，总之是y=1，我们希望\(h(x)\)趋近1。因为我们想要正确地将此样本分类，这就意味着当h(x)趋近于1时，\(\theta^Tx\)应当远大于0。这是因为z表示\(\theta^Tx\)，当z远大于0时，即到了该图的右边，不难发现此时逻辑回归的输出将趋近于1。相反地，如果我们有另一个样本，即y=0。我们希望假设函数的输出值将趋近于0，这对应于z远小于0，此时对应的假设函数的输出值趋近 0。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="支持向量机" scheme="xtf615.com/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>神经网络(系列2)</title>
    <link href="xtf615.com/2017/02/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E7%B3%BB%E5%88%972/"/>
    <id>xtf615.com/2017/02/17/神经网络-系列2/</id>
    <published>2017-02-17T08:28:37.000Z</published>
    <updated>2017-02-18T07:50:10.027Z</updated>
    
    <content type="html"><![CDATA[<p>神经网络的入门知识参见<a href="/2017/02/13/神经网络/">神经网络(系列1)</a><br>本文主要对神经网络进行深入，探讨神经网络模型的学习。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>首先引入一些便于稍后讨论的新标记方法：<br>假设神经网络的训练样本有m个，每个包含一组输入x和一组输出信号y，L表示神经网络层数，\(S_l\)表示每层的neuron个数(\(S_L\)表示输出层神经元个数),(\(S_L\)代表最后一层中处理单元的个数。<br>将神经网络的分类定义为两种情况：二类分类和多类分类:<br>二类分类：\(S_L=1\), y=0 or 1表示哪一类；<br>K类分类：\(S_L=K\),  \(y_i = 1\)表示分到第i类；（K&gt;2）<br><img src="/picture/machine-learning/network_learn1.jpg" alt="network_learn"><br>我们回顾逻辑回归问题中我们的代价函数为：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$<br>在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，我们可以有很多输出变量，我们的\(h_θ(x)\)是一个维度为K的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：<br>$$J(\Theta)=-\frac{1}{m}\Big[\sum_{i=1}^m\sum_{k=1}^K\left(y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)\right)\Big] \\\ + \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2$$<br><img src="/picture/machine-learning/network_learn2.jpg" alt="network_learn"><br>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个。<br>注意：j循环所有的行（由\(s_{l+1}\)层的激活单元数决定,l+1整体是下标），循环i则循环所有的列，由该层（\(s_l\)层）的激活单元数所决定。<br><a id="more"></a></p>
<h1 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h1><p>之前我们在计算神经网络预测结果的时候我们采用了一种正向传播方法，我们从第一层开始正向一层一层进行计算，直到最后一层的\(h_θ(x)\)。<br>现在，为了计算代价函数的偏导数\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\),我们需要采用新的方法。</p>
<h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><p>机器学习可以看做是数理统计的一个应用，在数理统计中一个常见的任务就是拟合，也就是给定一些样本点，用合适的曲线揭示这些样本点随着自变量的变化关系。<br>深度学习同样也是为了这个目的，只不过此时，样本点不再限定为(x, y)点对，而可以是由向量、矩阵等等组成的广义点对(X,Y)。而此时，(X,Y)之间的关系也变得十分复杂，不太可能用一个简单函数表示。然而，人们发现可以用多层神经网络来表示这样的关系，而多层神经网络的本质就是一个多层复合的函数。<br><img src="/picture/machine-learning/network11.jpg" alt="network_learn"><br>对应的表达式如下：<br>$$a_1^{(2)}=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3) \\\\<br>a_2^{(2)}=g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3) \\\\<br>a_3^{(2)}=g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3)$$<br>$$h_{\Theta}(x)=a_1^{(3)}=g(\Theta_{10}^{(2)}a_0^{(2)}+\Theta_{11}^{(2)}a_1^{(2)}+\Theta_{12}^{(2)}a_2^{(2)}+\Theta_{13}^{(2)}a_3^{(2)})$$<br>和直线拟合一样，深度学习的训练也有一个目标函数，这个目标函数定义了什么样的参数才算一组“好参数”，不过在机器学习中，一般是采用成本函数（cost function），然后，训练目标就是通过调整每一个权值\(\Theta_{ij}\)来使得cost达到最小。cost函数也可以看成是由所有待求权值\(\Theta_{ij}\)为自变量的复合函数，而且基本上是非凸的，即含有许多局部最小值。但实际中发现，采用我们常用的梯度下降法就可以有效的求解最小化cost函数的问题。<br>梯度下降法需要给定一个初始点，并求出该点的梯度向量，然后以负梯度方向为搜索方向，以一定的步长进行搜索，从而确定下一个迭代点，再计算该新的梯度方向，如此重复直到cost收敛。那么如何计算梯度呢？<br>假设我们把cost函数表示为\(J(\Theta_{11},\Theta_{12},\Theta_{13},\Theta_{ij},…,\Theta_{mn})\), 那么它的梯度向量就等于\(\nabla J = \frac{\partial J}{\partial \Theta_{11}}e_{11}+…+\frac{\partial J}{\partial \Theta_{mn}}e_{mn}\), 其中\(e_{ij}\)表示正交单位向量。为此，我们需求出cost函数J对每一个权值\(\Theta_{ij}\)的偏导数。<strong>而BP算法正是用来求解这种多层复合函数的所有变量的偏导数的利器。</strong><br>我们以求e=(a+b)*(b+1)的偏导为例。</p>
<p>它的复合关系画出图可以表示如下：<br><img src="/picture/machine-learning/network_learn4.png" alt="network_learn"><br>为了求出a=2,b=1时，e的梯度，我们可以先利用偏导数求出不同层之间的邻节点的偏导关系，如下图所示：<br><img src="/picture/machine-learning/network_learn5.png" alt="network_learn"><br>利用链式法则我们知道：<br>$$\frac{\partial e}{\partial a}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial a}$$<br>$$\frac{\partial e}{\partial b}=\frac{\partial e}{\partial c}\frac{\partial c}{\partial b}+\frac{\partial e}{\partial d}\frac{\partial d}{\partial b}$$<br>链式法则在上图中的意义是什么呢？其实不难发现，\(\frac{\partial e}{\partial a}\)的值等于从a到e的路径上的偏导值的乘积，而\(\frac{\partial e}{\partial b}\)的值等于从b到e的路径1(b-c-e)上的偏导值的乘积加上路径2(b-d-e)上的偏导值的乘积。也就是说，对于上层节点p和下层节点q，要求得，需要找到从q节点到p节点的所有路径，并且对每条路径，求得该路径上的所有偏导数之乘积，然后将所有路径的 “乘积” 累加起来才能得到的值。<br>大家也许已经注意到，这样做是<strong>十分冗余</strong>的，因为很多路径被重复访问了。比如上图中，a-c-e和b-c-e就都走了路径c-e。<strong>对于权值动则数万的深度模型中的神经网络，这样的冗余所导致的计算量是相当大的。</strong><br>同样是利用链式法则，BP算法则机智地避开了这种冗余，它对于<strong>每一个路径只访问一次</strong>就能求顶点对所有下层节点的偏导值。<br>正如反向传播(BP)算法的名字说的那样，BP算法是反向(自上往下)来寻找路径的。</p>
<p>从最上层的节点e开始，初始值为1，以层为单位进行处理。对于e的下一层的所有子节点，将1乘以e到某个节点路径上的偏导值，并将结果“堆放”在该子节点中。等e所在的层按照这样传播完毕后，第二层的每一个节点都“堆放”些值，然后我们针对每个节点，把它里面所有“堆放”的值求和，就得到了顶点e对该节点的偏导。然后将这些第二层的节点各自作为起始顶点，初始值设为顶点e对它们的偏导值，以”层”为单位重复上述传播过程，即可求出顶点e对每一层节点的偏导数。</p>
<p>以上图为例，节点c接受e发送的1*2并堆放起来，节点d接受e发送的1*3并堆放起来，至此第二层完毕，求出各节点总堆放量并继续向下一层发送。节点c向a发送2*1并对堆放起来，节点c向b发送2*1并堆放起来，节点d向b发送3*1并堆放起来，至此第三层完毕，节点a堆放起来的量为2，节点b堆放起来的量为2*1+3*1=5, 即顶点e对b的偏导数为5.</p>
<p>举个不太恰当的例子，如果把上图中的箭头表示欠钱的关系，即c→e表示e欠c的钱。以a, b为例，直接计算e对它们俩的偏导相当于a, b各自去讨薪。a向c讨薪，c说e欠我钱，你向他要。于是a又跨过c去找e。b先向c讨薪，同样又转向e，b又向d讨薪，再次转向e。可以看到，追款之路，充满艰辛，而且还有重复，即a, b 都从c转向e。</p>
<p>而BP算法就是主动还款。e把所欠之钱还给c，d。c，d收到钱，乐呵地把钱转发给了a，b，皆大欢喜。</p>
<h2 id="路径合并"><a href="#路径合并" class="headerlink" title="路径合并"></a>路径合并</h2><p>将所有路径累加的问题在于，在可能的路径数中，很容易陷入爆炸式组合增长。<br><img src="/picture/machine-learning/network_learn10.png" alt="network_learn"><br>在上图中，从X到Y有3条路径，从Y到Z也有3条路径。如果要求\(\frac{\partial Z}{\partial X}\),我们需要把所有路径累加起来，也就是共9条路径。<br>$$\frac{\partial Z}{\partial X} = \alpha\delta + \alpha\epsilon + \alpha\zeta + \beta\delta + \beta\epsilon + \beta\zeta + \gamma\delta + \gamma\epsilon + \gamma\zeta$$<br>上图只有9条路径，但是随着图复杂程度的增加，路径数很容易呈现爆炸式增长。<br>和直接将所有路径累加相反，更好的方法是合并路径：<br>$$\frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)(\delta + \epsilon + \zeta)$$<br>这就是前向传播(forward-mode differentiation)和后向传播(reverse-mode differentiation)。它们都是通过合并路径的方法来更有效的计算路径和。和直接显示地把所有路径加起来不同，它们通过在每个节点上，向后合并路径的方式来更有效的计算路径和。实际上，两个方法每条边都只计算了一次。<br>前向传播起始于图的输入节点，一直向前直到最后一个节点。在每个节点上，它将传入(feed in)的每一条路径累加。每一条路径都代表了输入对该节点的影响。通过将它们累加起来，我们获得了不同输入对该节点总的影响。这就是导数的定义。<br><img src="/picture/machine-learning/network_learn11.png" alt="network_learn"><br>前向传播就像你刚刚入门微积分课程时学到的方法。而后向传播，起始于图的输出节点，一直向后直到第一个节点。在每一个节点上，将起源于(originated at)该节点的所有路径合并。<br><img src="/picture/machine-learning/network_learn12.png" alt="network_learn"><br>前向传播跟踪一个输入如何影响每一个节点。反向传播跟踪每一个节点如何影响一个输出节点。即，前向传播将\(\frac{\partial}{\partial X}\)应用到每一个节点(每个节点对输入求导)，而后向传播将\(\frac{\partial Z}{\partial}\)应用到每一个节点（输出对每个节点求导）。</p>
<h2 id="反向传播优势"><a href="#反向传播优势" class="headerlink" title="反向传播优势"></a>反向传播优势</h2><p>现在，我们可能会疑问，为什么人们更关心后向传播，它看起来似乎和前向传播差不多，那它的优势在哪?<br>让我们回到前面的那个例子中：<br><img src="/picture/machine-learning/network_learn5.png" alt="network_learn"><br>我们可以使用前向传播算法从b自底向上。我们需要求每个节点对b的导数。（即b如何影响每一个节点）<br><img src="/picture/machine-learning/network_learn13.png" alt="network_learn"><br>如果我们使用后向传播从e自顶向下，我们需要求e对每个节点的导数(即每个节点如何影响e)。<br><img src="/picture/machine-learning/network_learn14.png" alt="network_learn"><br>需要强调的是： 当我说反向传播给了我们e对每个节点的导数，需要强调的是确实是<strong>每个节点</strong>，我们得到了\(\frac{\partial e}{\partial a}\)和\(\frac{\partial e}{\partial b}\)，即e对每一个输入的导数。前向传播只给了我们单独的一个b的导数，但是后向传播给了我们所有的输入的导数。<br>对这幅图而言，只得到了2倍的加速比，想象一下如果有<strong>上百万的输入节点和1个输出节点</strong>,前向传播需要我们遍历这个图上百万次才能得到导数，而后向传播只需要遍历1次即可，这就得到了上百万的加速比。<br>在神经网络中，我们的代价函数经常拥有上百万个参数，因此反向传播能够让我们训练的速度大大提高。<br><strong>那前向传播什么时候适用呢？如果只有少量的输入，而拥有大量的输出，此时前向传播速度更快。</strong><br>补充：对信息的处理，分为前向和反向两种，即从因到果和从果到因。前者适合人类的思考模式，但对机器而言，它需要的是运算，显然，反向运算更便捷（如上中所说，这是有前提的，即输入因子多于输出因子，这也符合逻辑，当我们要做出一个判断、得出一个结论，总会从方方面面进行思考，然后在提取、凝练，即归纳、总结），就像梳理头发时，我们都是从发根向发梢梳理——头皮为一个质点，向发梢逐渐发散，从一到多、从总到分的梳理、计算过程。所以反向运算比较普及，是因为运算成本更低。</p>
<h2 id="反向传播算法-1"><a href="#反向传播算法-1" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p>我们的目标是为了计算代价函数的偏导数：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)$$<br>我们需要采用一种反向传播算法，也就是首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。<br>以一个例子来说明反向传播算法。<br>假设我们的训练集只有一个实例\((x^{(1)},y^{(1)})\),我们的神经网络是一个四层的神经网络，其中 K=4，SL=4，L=4：<br><img src="/picture/machine-learning/network_learn6.jpg" alt="network_learn"><br>前向传播算法：<br>$$a^{(1)}=x \\\\<br>z^{(2)}=\Theta^{(1)}a^{(1)} \\\\<br>a^{(2)}=g(z^{(2)}) (add \ a_0^{(2)}) \\\\<br>z^{(3)}=\Theta^{(2)}a^{(2)} \\\\<br>a^{(3)}=g(z^{3}) (add \ a_0^{(3)}) \\\\<br>z^{(4)}=\Theta^{(3)}a^{(3)} \\\\<br>a^{(4)}=h_\Theta(x)=g(z^{(4)})<br>$$<br>我们从最后一层的误差开始计算，误差是激活单元的预测值（\(a_k^{(4)}\)）与实际值（\(y^{k}\)）之间的误差.（k=1:K）<br>我们用\(\delta\)来表示误差，则：<br>$$\delta^{(4)}=a^{(4)}-y$$<br>我们利用这个误差值来计算前一层的误差:<br>$$\delta^{(3)}=(\Theta^{(3)})^T\delta^{(4)}.*g’(z^{(3)})$$<br>其中,\(g’(z^{(3)})\)为sigmoid函数的导数，\(g’(z^{(3)})=a^{(3)}*(1-a^{(3)})\)。而\((\Theta^{(3)})^T\delta^{(4)}\)则是权重导致的误差的和。<br>注意到：\((\Theta^{(3)})^T\)取了转置，正常\(\Theta\)例如：<br>$$\Theta=\begin{bmatrix} \Theta_{10} \ \Theta_{11} \ \Theta_{12} \ \Theta_{13}\\\ \Theta_{20} \ \Theta_{21} \ \Theta_{22} \ \Theta_{23}\\\ \Theta_{30} \ \Theta_{31} \ \Theta_{32} \ \Theta_{33}\end{bmatrix}$$<br>每一行都代表第j层的所有神经元到第j+1层某一个神经元的连线（权重）。例如第一行就代表第j层的所有神经元到第j+1层的第一个神经元的连线。而转置\(\Theta\)后，每一行代表第j层某一个神经元到第j+1层的所有神经元的连线，可以理解成j层某一个神经元导致的j+1层总误差的情况。<br>另外，.*即点乘，代表矩阵对应位置的数字相乘。<br>下一步是继续计算第二层的误差：<br>$$\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}.*g’(z^{(2)})$$<br>因为第一层为输入变量，不存在误差，我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设\(\lambda=0\)，即我们不做任何归一化处理的话：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}$$<br>重要的是清楚地知道上面式子中上下标的含义：<br>l代表目前所计算的是第几层<br>j代表目前计算层中的激活单元的下标，也将是下一层的第j个输入变量的下标。<br>i代表下一层中误差单元的下标，是受到权重矩阵中第i行影响的下一层中的误差单元的下标。<br>即：\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}\)是对第l层的第j个神经元到第l+1层的第i个神经元的连线（权重）求偏导。<br>\(a_j^{(l)}\)是第l层第j个神经元经过sigmoid函数计算后的值。<br>\(\delta_i^{l+1}\)是第l+1层第i个神经元的误差。<br>例如：<br><img src="/picture/machine-learning/network_learn7.jpg" alt="network_learn"><br>对图中红色的这条线求偏导：<br>$$\frac{\partial}{\partial \Theta_{41}^{(1)}}=a_1^{(1)}*\delta_4^{(2)}$$<br>如果我们考虑归一化处理，并且我们的训练集是一个特征矩阵而非向量。在上面的特殊情况中，我们需要计算每一层的误差单元来计算代价函数的偏导数。在更为一般的情况中，我们同样需要计算每一层的误差单元，但是我们需要为<strong>整个训练集</strong>计算误差单元，此时的误差单元也是一个矩阵，我们用\(\Delta_{ij}\)来表示这个误差矩阵。第l层的第i个激活单元受到第j个参数影响而导致的误差。<br>我们的算法：<br><img src="/picture/machine-learning/network_learn8.jpg" alt="network_learn"><br>即首先用正向传播方法计算出每一层的激活单元，利用训练集的结果与神经网络预测的结果求出最后一层的误差，然后利用该误差运用反向传播法计算出直至第二层的所有误差。<br>在求出\(\Delta_{ij}^{(l)}\)后，我们便可以计算代价函数的偏导数了，计算方法如下：<br><img src="/picture/machine-learning/network_learn9.jpg" alt="network_learn"></p>
<h2 id="反向传播理解"><a href="#反向传播理解" class="headerlink" title="反向传播理解"></a>反向传播理解</h2><h3 id="疑问1：为什么输出层的-delta-为-delta-L-a-L-y"><a href="#疑问1：为什么输出层的-delta-为-delta-L-a-L-y" class="headerlink" title="疑问1：为什么输出层的\(\delta\)为\(\delta^{(L)}=a^{(L)}-y\)?"></a>疑问1：为什么输出层的\(\delta\)为\(\delta^{(L)}=a^{(L)}-y\)?</h3><p>很多人认为输出层的偏差量就是计算值减实际值这么简单，又或者认为是线性回归代价函数求导的结果，即\(J(\Theta)=\frac{1}{2}(h_\Theta(x)-y)^2\),求导得到：\(\frac{\partial}{\partial a^{(L)}}J(\Theta)=a^{(L)}-y\)。其实不然，要知道我们的代价函数是逻辑回归的代价函数。详细见下面分析。</p>
<h3 id="疑问2：-Theta-l-T-delta-l-1-怎么理解？"><a href="#疑问2：-Theta-l-T-delta-l-1-怎么理解？" class="headerlink" title="疑问2：\((\Theta^{(l)})^T\delta^{(l+1)}\)怎么理解？"></a>疑问2：\((\Theta^{(l)})^T\delta^{(l+1)}\)怎么理解？</h3><p>所谓“偏差”应该这么理解：对于后一层某一个结点上出现的偏差，前一层的每一个结点都要承担一部分责任，所以我们可以把后一层结点的偏差量按照系数比例分配给前一层的结点。同时，前一层的某一个结点，对后一层的每一个节点都承担着责任，那么它的“总责任”就是这些所有的小责任之和。因此这里面矩阵的转置，我们前面也有提到，转置后的每一行实际上代表l层的某一个神经元到l+1层的每一个神经元的连线(权重)。和后一层的\(\delta^{(l+1)}\)进行矩阵乘后，实际上相当于l层的这个神经元分担掉l+1层所有神经元的这些小的误差，将这些小的误差之和作为自己的责任承担下来。如果你仔细想想这个矩阵乘法的计算过程，会发现正好就是上面说的这个责任分配与求和的过程。这就是【疑问2】的答案。</p>
<h3 id="疑问3：为什么前一层的-delta-l-和后一层的-delta-l-1-的关系是-delta-l-Theta-l-T-delta-l-1-g’-z-l-？"><a href="#疑问3：为什么前一层的-delta-l-和后一层的-delta-l-1-的关系是-delta-l-Theta-l-T-delta-l-1-g’-z-l-？" class="headerlink" title="疑问3：为什么前一层的\(\delta^{(l)}\)和后一层的\(\delta^{(l+1)}\)的关系是\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)？"></a>疑问3：为什么前一层的\(\delta^{(l)}\)和后一层的\(\delta^{(l+1)}\)的关系是\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)？</h3><p>可以发现，在疑问2的基础上，该式子还多了个因子\(.*g’(z^{(l)})\)。为什么呢？详细见下面分析。</p>
<h3 id="疑问4：为什么-delta-i-l-1-计算完后，还要乘以前一层的-a-j-l-后，才是偏导-frac-partial-partial-Theta-ij-l-J-Theta-的结果？"><a href="#疑问4：为什么-delta-i-l-1-计算完后，还要乘以前一层的-a-j-l-后，才是偏导-frac-partial-partial-Theta-ij-l-J-Theta-的结果？" class="headerlink" title="疑问4：为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果？"></a>疑问4：为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果？</h3><p>即，\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}\)详见下面。</p>
<h3 id="详细推导"><a href="#详细推导" class="headerlink" title="详细推导"></a>详细推导</h3><p>我们的目标是证明：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1} \\\\<br>其中,\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)}), \\\\可以取l=l+1,求得\delta^{(l+1)},\delta_i^{l+1}为\delta^{(l+1)}的第i个元素，即l+1层误差向量的第i个元素。<br>$$<br><strong>是对第\(l\)层的第\(j\)个神经元到第\(l+1\)层的第\(i\)个神经元的连线（权重）求偏导</strong>。<br>首先回顾一下前面的一些定义：<br>$$a^{(l+1)}=g(z^{(l+1)}) \\\\<br>g(z)=\frac{1}{1+e^{-z}} \\\\<br>z^{(l+1)}=\Theta^{(l)}a^{(l)} \\\\<br>其中,g(z)为sigmoid函数 \\\\<br>z^{(l+1)}代表l+1层经过l层权重加权后的结果 \\\\<br>a^{(l+1)}代表z^{(l+1)}经过sigmoid函数后的输出值 \\\\<br>$$<br>为了使用这些定义，我们可以将上面的偏微分式子使用链式法则展开：<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}$$</p>
<ul>
<li>首先看最后一项：<br>$$z_i^{(l+1)}=\Theta_{1,i}^{(l)}a_1^{(l)}+\Theta_{2,i}^{(l)}a_2^{(l)}+…$$<br>所以：<br>$$\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}=a_j^{(l)}$$<br>顺便说一下，<strong>右边前两项的乘积，就是课程中引入的\(\delta\)的值</strong>。这就解释了【疑问4】中，为什么\(\delta_i^{(l+1)}\)计算完后，还要乘以前一层的\(a_j^{(l)}\)后，才是偏导\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)\)的结果，即\(\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=a_j^{(l)}\delta_i^{l+1}\)</li>
<li><p>接下来第二项<br>这就是sigmoid函数的求导：<br>$$g’(z)=\frac{e^{-z}}{(1+e^{-z})^2}=\frac{1}{1+e^{-z}}*\frac{e^{-z}}{(1+e^{-z})}=g(z)(1-g(z))$$<br>根据定义:\(g(z^{(l)})=a^{(l)}\)<br>因此，我们\(\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})\)改写成：<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*a^{(l)}.*(1-a^{(l)})$$<br>这个式子留在下面【疑问1】的证明。</p>
</li>
<li><p>第一项<br>首先回顾下代价函数:<br>$$J(\Theta)=-ylog(h_\Theta(x))-(1-y)log(1-h_\Theta(x))$$<br>对输出层\(a^{(L)}\)求导：<br>$$\frac{\partial}{\partial a^{(L)}}J(\Theta)=\frac{a^{(L)}-y}{a^{(L)}-(a^{(L)})^2} \\\\<br>注意对于输出层，h_\Theta(x)=a^{(L)}$$<br>因此根据前面定义:\(\delta\)为前两项偏导的乘积，即<br>$$\delta^{(L)}=\frac{a^{(L)}-y}{a^{(L)}-(a^{(L)})^2}a^{(L)}(1-a^{(L)})=a^{(L)}-y$$<br>这就解决了【疑问1】中的疑惑。实际上并不是简单的相减，而只是凑巧结果是这样。<br>对于【疑问1】【疑问2】的推导，即<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})$$<br>根据前面定义:\(\delta\)为前两项偏导的乘积，<br>我们来看下面式子的前两项偏导，<br>$$\frac{\partial}{\partial \Theta_{ij}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}\frac{\partial z_i^{(l+1)}}{\partial \Theta_{i,j}^{(l)}}$$<br>实际上前两项偏导结果就是：<br>$$\frac{\partial}{\partial z_{i}^{(l+1)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l+1)}}\frac{\partial a_i^{(l+1)}}{\partial z_i^{(l+1)}}$$<br>令\(l=l-1\),得到：<br>$$\frac{\partial}{\partial z_{i}^{(l)}}J(\Theta)=\frac{\partial J(\Theta)}{\partial a_i^{(l)}}\frac{\partial a_i^{(l)}}{\partial z_i^{(l)}}$$<br>利用链式法则得到:<br>$$\delta_{j}^{(l)}=\frac{\partial}{\partial z_{j}^{(l)}}J(\Theta)=\sum_k \frac{\partial J(\Theta)}{\partial z_k^{(l+1)}}\frac{\partial z_k^{(l+1)}}{\partial a_j^{(l)}}\frac{\partial a_j^{(l)}}{\partial z_{j}^{(l)}} \\\\<br>=\sum_k \delta_k^{(l+1)} \frac{\partial (\Theta_{kj}^{(l)}a_j^{(l)})}{\partial a_j^{(l)}}g’(z_j^{(l)}) \\\\<br>=\sum_k \delta_k^{(l+1)}\Theta_{kj}^{(l)}g’(z_j^{(l)})$$</p>
</li>
</ul>
<p>1）上式是针对\(l\)层<strong>某一个神经元</strong>的求导，\(i\)(在这里k实际上就是l+1层神经元)代表\(l+1\)层神经元，\(j\)代表\(l\)层神经元。<br>2）求和相当于不同路径累加。<br>所以有：<br>$$\delta^{(l)}=(\Theta^{(l)})^T\delta^{(l+1)}.*g’(z^{(l)})$$<br>1）上式是求\(l\)层所有神经元误差的矩阵形式。<br>2）仔细看\(\Theta_{kj}^{(l)}\)的下标变换，从1开始\(\Theta_{1j}^{(l)}\)，\(\Theta_{2j}^{(l)}\)，\(\Theta_{3j}^{(l)}\)…,实际上就代表\(l\)层的第\(j\)个神经元到\(l+1\)层的所有神经元的连线（权重）。因为\(l+1\)层的神经元代表的是行，即下标中的第一个数字。实际上和\((\Theta^{(l)})^T\delta^{(l+1)}\)矩阵形式是一样的。<br>这就解决了【疑问2】【疑问3】<br><strong>结论</strong>：<br>还有很多人说为什么这个值和很多别的网站，包括维基百科上说的不一样啊？因为很多别的网站包括维基百科，cost函数用的是线性回归的那种，它的偏微分就和逻辑回归的cost函数有差别了。具体地说，就差在分母的那一项上\(a^{(L)}-(a^{(L)})^2\)</p>
<h2 id="反向传播演示"><a href="#反向传播演示" class="headerlink" title="反向传播演示"></a>反向传播演示</h2><p>说明：图片摘自网上，存在一定的偏差，实际上是一样的，只不过是写法的不同，重点在于<strong>整个过程以及箭头</strong>。首先进行前向传播计算，这里的\(w\)对应\(\Theta\),\(f\)对应\(g\)，即sigmoid函数，\(y\)对应\(a\),即sigmod的输出，\(e\)对应\(z\),即权重的线性组合结果。 \(\delta\)的计算式里的\(g’(z)\)项，图片中是放在最后梯度下降的时候求得导，即\(\frac{d_f}{d_e}\)。最后梯度下降公式中，不要忘记\(\delta\)还要乘以\(y\)，即我们上文讲到的\(a\)。<br><img src="/picture/machine-learning/network_learn_demo1.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo2.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo3.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo4.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo5.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo6.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo7.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo8.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo9.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo10.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo11.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo12.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo13.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo14.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo15.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo16.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo17.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo18.jpg" alt="demo"><br><img src="/picture/machine-learning/network_learn_demo19.jpg" alt="demo"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://colah.github.io/posts/2015-08-Backprop/#fnref1" target="_blank" rel="external">Calculus on Computational Graphs: Backpropagation</a><br><a href="http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html" target="_blank" rel="external">Principles of training multi-layer neural network using backpropagation</a><br><a href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/" target="_blank" rel="external">A Step by Step Backpropagation Example</a><br><a href="http://www.cs.toronto.edu/~fritz/absps/naturebp.pdf" target="_blank" rel="external">Learning representation by back-propagating errors</a><br><a href="http://blog.csdn.net/u014313009/article/details/51039334" target="_blank" rel="external">反向传播算法（过程及公式推导）</a><br><a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="external">斯坦福机器学习</a><br><a href="http://mooc.guokr.com/note/16702/" target="_blank" rel="external">反向传播算法的一些争论与思考</a><br><a href="https://www.zhihu.com/question/27239198" target="_blank" rel="external">知乎：如何直观的解释back propagation算法？</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;神经网络的入门知识参见&lt;a href=&quot;/2017/02/13/神经网络/&quot;&gt;神经网络(系列1)&lt;/a&gt;&lt;br&gt;本文主要对神经网络进行深入，探讨神经网络模型的学习。&lt;/p&gt;
&lt;h1 id=&quot;代价函数&quot;&gt;&lt;a href=&quot;#代价函数&quot; class=&quot;headerlink&quot; title=&quot;代价函数&quot;&gt;&lt;/a&gt;代价函数&lt;/h1&gt;&lt;p&gt;首先引入一些便于稍后讨论的新标记方法：&lt;br&gt;假设神经网络的训练样本有m个，每个包含一组输入x和一组输出信号y，L表示神经网络层数，\(S_l\)表示每层的neuron个数(\(S_L\)表示输出层神经元个数),(\(S_L\)代表最后一层中处理单元的个数。&lt;br&gt;将神经网络的分类定义为两种情况：二类分类和多类分类:&lt;br&gt;二类分类：\(S_L=1\), y=0 or 1表示哪一类；&lt;br&gt;K类分类：\(S_L=K\),  \(y_i = 1\)表示分到第i类；（K&amp;gt;2）&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network_learn1.jpg&quot; alt=&quot;network_learn&quot;&gt;&lt;br&gt;我们回顾逻辑回归问题中我们的代价函数为：&lt;br&gt;$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$&lt;br&gt;在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，我们可以有很多输出变量，我们的\(h_θ(x)\)是一个维度为K的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：&lt;br&gt;$$J(\Theta)=-\frac{1}{m}\Big[\sum_{i=1}^m\sum_{k=1}^K\left(y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)\right)\Big] \\\ + \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2$$&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network_learn2.jpg&quot; alt=&quot;network_learn&quot;&gt;&lt;br&gt;这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个。&lt;br&gt;注意：j循环所有的行（由\(s_{l+1}\)层的激活单元数决定,l+1整体是下标），循环i则循环所有的列，由该层（\(s_l\)层）的激活单元数所决定。&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="xtf615.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>神经网络(系列1)</title>
    <link href="xtf615.com/2017/02/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>xtf615.com/2017/02/13/神经网络/</id>
    <published>2017-02-13T10:23:23.000Z</published>
    <updated>2017-02-17T08:25:39.073Z</updated>
    
    <content type="html"><![CDATA[<h1 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h1><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。<br>下面是一个例子：<br><img src="/picture/machine-learning/network1.jpg" alt="network"><br>当我们使用\(x_1,x_2\)的多次项式进行预测时，我们可以应用得很好。<br>之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合\(x_1x_2+x_1x_3+x_1x_4+…+x_2x_3+x_2x_4+…+x_{99}x_{100}\),我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。<br>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车）。<br>我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。<br>假如我们只选用灰度图片，每个像素则只有一个值（而非RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：<br><img src="/picture/machine-learning/network2.jpg" alt="network"><br>假使我们采用的都是  50x50像素的小图片，并且我们将所有的像素视为特征，则会有2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约\(\frac{2500^2}{2}\)个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们就需要神经网络。</p>
<h1 id="神经元和大脑"><a href="#神经元和大脑" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h1><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。<br>接下来我将介绍神经网络。它能很好地解决不同的机器学习问题。首先介绍一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的，神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？<br><a id="more"></a></p>
<h2 id="起源"><a href="#起源" class="headerlink" title="起源"></a>起源</h2><p>神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法。近些年计算机的运行速度变快，才足以真正运行起大规模的神经网络。正是由于这个原因和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。当你想模拟大脑时，是指想制造出与人类大脑作用效果相同的机器。大脑可以学会去以看而不是听的方式处理图像，学会处理我们的触觉我们能学习数学，学着做微积分，而且大脑能处理各种不同的令人惊奇的事情。似乎如果你想要模仿它，你得写很多不同的软件来模拟所有这些五花八门的奇妙的事情。不过能不能假设大脑做所有这些，不同事情的方法，不需要用上千个不同的程序去实现。相反的，大脑处理的方法，只需要一个单一的学习算法就可以了？</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><ul>
<li><p>如图，大脑的这一部分这一小片红色区域是你的听觉皮层，你现在正在理解我的话，这靠的是耳朵。耳朵接收到声音信号，并把声音信号传递给你的听觉皮层.<br><img src="/picture/machine-learning/network3.jpg" alt="network"></p>
</li>
<li><p>神经系统科学家做了下面这个有趣的实验，把耳朵到听觉皮层的神经切断。在这种情况下，将其重新接到一个动物的大脑上，这样从眼睛到视神经的信号最终将传到听觉皮层。如果这样做了。那么结果表明听觉皮层将会学会“看”。这里的“看”代表了我们所知道的每层含义。所以，如果你对动物这样做，那么动物就可以完成视觉辨别任务，它们可以看图像，并根据图像做出适当的决定。它们正是通过脑组织中的这个部分完成的。</p>
</li>
<li>下面再举另一个例子，这块红色的脑组织是你的躯体感觉皮层，这是你用来处理触觉的，如果你做一个和刚才类似的重接实验，那么躯体感觉皮层也能学会“看”。这个实验和其它一些类似的实验，被称为神经重接实验，从这个意义上说，如果人体有同一块脑组织可以处理光、声或触觉信号，那么也许存在一种学习算法，可以同时处理视觉、听觉和触觉，而不是需要运行上千个不同的程序，或者上千个不同的算法来做这些大脑所完成的成千上万的美好事情。也许我们需要做的就是找出一些近似的或实际的大脑学习算法，然后实现它大脑通过自学掌握如何处理这些不同类型的数据。在很大的程度上，可以猜想如果我们把几乎任何一种传感器接入到大脑的几乎任何一个部位的话，大脑就会学会处理它。</li>
<li>这张图是用舌头学会“看”的一个例子。它的原理是：这实际上是一个名为BrainPort的系统，它现在正在FDA(美国食品和药物管理局的临床试验阶段，它能帮助失明人士看见事物。它的原理是，你在前额上带一个灰度摄像头，面朝前，它就能获取你面前事物的低分辨率的灰度图像。你连一根线到舌头上安装的电极阵列上，那么每个像素都被映射到你舌头<br>的某个位置上，可能电压值高的点对应一个暗像素电压值低的点。对应于亮像素，即使依靠它现在的功能，使用这种系统就能让你我在几十分钟里就学会用我们的舌头“看”东西。<br><img src="/picture/machine-learning/network4.jpg" alt="network"></li>
<li>这是关于人体回声定位或者说人体声纳。你有两种方法可以实现：你可以弹响指，或者咂舌头。不过现在有失明人士，确实在学校里接受这样的培训，并学会解读从环境反弹回来的声波模式—这就是声纳。如果你搜索 YouTube之后，就会发现有些视频讲述了一个令人称奇的孩子，他因为癌症眼球惨遭移除，虽然失去了眼球，但是通过打响指，他可以四处走动而不撞到任何东西，他能滑滑板，他可以将篮球投入篮框中。注意这是一个没有眼球的孩子。<br><img src="/picture/machine-learning/network5.jpg" alt="network"></li>
<li>这是触觉皮带，如果你把它戴在腰上，蜂鸣器会响，而且总是朝向北时发出嗡嗡声。它可以使人拥有方向感，用类似于鸟类感知方向的方式。<br><img src="/picture/machine-learning/network6.jpg" alt="network"></li>
<li>还有一些离奇的例子。如果你在青蛙身上插入第三只眼，青蛙也能学会使用那只眼睛。因此，这将会非常令人惊奇。如果你能把几乎任何传感器接入到大脑中，大脑的学习算法就能找出学习数据的方法，并处理这些数据。从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。人工智能的梦想就是：有一天能制造出真正的智能机器。<br><img src="/picture/machine-learning/network7.jpg" alt="network"><br>神经网络可能为我们打开一扇进入遥远的人工智能梦的窗户。</li>
</ul>
<h1 id="模型表示（1）"><a href="#模型表示（1）" class="headerlink" title="模型表示（1）"></a>模型表示（1）</h1><p>为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元 /神经核（processing unit/Nucleus），它含有许多输入/树突（input/Dendrite），并且有一个输出/轴突（output/Axon）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。<br><img src="/picture/machine-learning/network8.jpg" alt="network"><br>下面是一组神经元的示意图，神经元利用微弱的电流进行沟通。这些弱电流也称作动作电位，其实就是一些微弱的电流。所以如果神经元想要传递一个消息，它就会就通过它的轴突，发送一段微弱电流给其他神经元，这就是轴突。<br>这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。<br><img src="/picture/machine-learning/network9.jpg" alt="network"><br>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被称为权重（weight）。<br><img src="/picture/machine-learning/network10.jpg" alt="network"><br>我们设计出了类似于神经元的神经网络，效果如下：<br><img src="/picture/machine-learning/network11.jpg" alt="network"><br>其中\(x_1,x_2,x_3\)是输入单元（input units），我们将原始数据输入给它们。\(a_1,a_2,a_3\)是中间单元，它们负责将数据进行处理，然后呈递到下一层。最后是输出单元，它负责计算\(h_θ(x)\)。<br>神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个 3层的神经网络，第一层成为输入层（Input Layer），最后一层称为输出层（Output Layer），中间一层成为隐藏层（Hidden Layers）。我们为每一层都增加一个偏差单位（bias unit）：<br><img src="/picture/machine-learning/network12.jpg" alt="network"><br>下面引入一些标记法来帮助描述模型：<br>\(a_i^{(j)}\)代表第j层的第i个激活单元。\(\Theta^{(j)}\)代表从第j层映射到第j+1层时的权重的矩阵。例如\(\Theta^{(1)}\)代表从第一层映射到第二层的权重矩阵。其尺寸为：以第<strong>j+1</strong>层的激活单元数量为<strong>行数</strong>，以第<strong>j</strong>层的激活单元数加1为<strong>列数</strong>的矩阵。<br>例如：上图所示的神经网络中\(\Theta^{(1)}\)的尺寸为3*4。<br>对于上图所示的模型，激活单元和输出分别表达为：</p>
<p>$$a_1^{(2)}=g(\Theta_{10}^{(1)}x_0+\Theta_{11}^{(1)}x_1+\Theta_{12}^{(1)}x_2+\Theta_{13}^{(1)}x_3) \\\\<br>a_2^{(2)}=g(\Theta_{20}^{(1)}x_0+\Theta_{21}^{(1)}x_1+\Theta_{22}^{(1)}x_2+\Theta_{23}^{(1)}x_3) \\\\<br>a_3^{(2)}=g(\Theta_{30}^{(1)}x_0+\Theta_{31}^{(1)}x_1+\Theta_{32}^{(1)}x_2+\Theta_{33}^{(1)}x_3)$$<br>上面进行的讨论中只是将特征矩阵中的一行(一个训练实例)喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。<br>注意：<strong>\(\Theta\)的下标和上标需要注意一下！下标的第一个数字：代表第j+1层神经元的编号，第二个数字代表第j层神经元的编号。上标则代表神经元层数的编号。</strong><br>我们可以知道：每一个a都是由上一层所有的x和每一个x所对应的参数决定的。<br>（我们把这样从左到右的算法称为前向传播算法(FORWARD PROPAGATION)）<br>把X，a分别用矩阵表示：<br>$$X=\begin{bmatrix} x_0 \\\ x_1 \\\ x_2 \\\ x_3\end{bmatrix}\\\\<br>\Theta=\begin{bmatrix} \Theta_{10} \ \Theta_{11} \ \Theta_{12} \ \Theta_{13}\\\ \Theta_{20} \ \Theta_{21} \ \Theta_{22} \ \Theta_{23}\\\ \Theta_{30} \ \Theta_{31} \ \Theta_{32} \ \Theta_{33}\end{bmatrix} \\\\<br>a=\begin{bmatrix} a_1 \\\ a_2 \\\ a_3\end{bmatrix} \\\\<br>我们可以得到\Theta X=a。<br>$$</p>
<h1 id="模型表示（2）"><a href="#模型表示（2）" class="headerlink" title="模型表示（2）"></a>模型表示（2）</h1><p>( FORWARD PROPAGATION  )相对与使用循环来编码，利用向量化的方法会使得计算更为简便。以上面的神经网络为例，试着计算第二层的值：</p>
<p>$$x=\begin{bmatrix} x_0 \\\ x_1 \\\ x_2 \\\ x_3\end{bmatrix}\\\\<br>z^{(2)}=\begin{bmatrix} z_1^{(2)} \\\ z_2^{(2)} \\\ z_3^{(2)}\end{bmatrix}$$<br><img src="/picture/machine-learning/network13.jpg" alt="network"><br>我们令：\(z^{(2)}=\Theta^{(1)}x\),则\(a^{(2)}=g(z^{(2)})\),计算后添加\(a_0^{(2)}=1\)。计算输出值为：<br><img src="/picture/machine-learning/network14.jpg" alt="network"><br>令：\(z^{(3)}=\Theta^{(2)}a^{(2)}\),则\(h_\theta(x)=a^{(3)}=g(z^{(3)})\)<br>这只是针对训练集中一个训练实例所进行的计算。如果我们要对整个训练集进行计算，我们需要将训练集特征矩阵进行转置，使得同一个实例的特征都在同一列里。即：<br>\(z^{(2)}=\Theta^{(1)}*X^T\) , \(a^{(2)}=g(z^{(2)})\)<br>为了更好地了解Neuron Networks的工作原理，我们先把左半部分遮住：<br><img src="/picture/machine-learning/network15.jpg" alt="network"><br>右半部分其实就是以\(a_0,a_1,a_2,a_3\)按照Logistic Regression的方式输出h(x)：<br><img src="/picture/machine-learning/network16.jpg" alt="network"><br>其实神经网络就像是logistic  regression，只不过我们把logistic regression中的输入向量\([x1 \sim x3]\)变成了中间层的\([a_1^{(2)} \sim a_3^{(2)}]\)<br>即：<br>$$h(x)=g(\theta_0^{(2)}a_0^{(2)}+\theta_1^{(2)}a_1^{(2)}+\theta_2^{(2)}a_2^{(2)}+\theta_3^{(2)}a_3^{(2)})$$<br>我们可以把\(a_0,a_1,a_2,a_3\)看成更为高级的特征值，也就是\(x_0,x_1,x_2,x_3\)的进化体，并且它们是由x决定的，因为是梯度下降的，所以a是变化的，并且变得越来越厉害，所以<strong>这些更高级的特征值远比仅仅将x次方厉害</strong>，也能更好的预测新数据。<br>这就是神经网络相比于逻辑回归和线性回归的优势。</p>
<h1 id="例子和直观理解（1）"><a href="#例子和直观理解（1）" class="headerlink" title="例子和直观理解（1）"></a>例子和直观理解（1）</h1><p>从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征\(x_1,x_2,…,x_n\)，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。<br>神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑AND、逻辑或OR。</p>
<h2 id="举例说明：逻辑与AND"><a href="#举例说明：逻辑与AND" class="headerlink" title="举例说明：逻辑与AND"></a>举例说明：逻辑与AND</h2><p>下图是神经网络的设计与Output层的表达式：<br><img src="/picture/machine-learning/network17.jpg" alt="network"><br>其中，\(\theta_0=-30,\theta_1=20,\theta_2=20\)<br>输出函数h(x)为：<br>$$h_\Theta(x)=g(-30+20x_1+20x_2)$$<br>我们知道g(x)的图像是：<br><img src="/picture/machine-learning/network18.jpg" alt="network"><br>真值表如下：<br><img src="/picture/machine-learning/network19.jpg" alt="network"><br>所以我们有:<br>$$h_\Theta(x) \approx x_1 AND x_2$$</p>
<h2 id="举例说明：逻辑或OR"><a href="#举例说明：逻辑或OR" class="headerlink" title="举例说明：逻辑或OR"></a>举例说明：逻辑或OR</h2><p><img src="/picture/machine-learning/network20.jpg" alt="network"><br>OR与AND整体一样，区别只在于\(\Theta\)的取值不同。</p>
<h1 id="例子和直观理解（2）"><a href="#例子和直观理解（2）" class="headerlink" title="例子和直观理解（2）"></a>例子和直观理解（2）</h1><p>们可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算。</p>
<h2 id="XNOR"><a href="#XNOR" class="headerlink" title="XNOR"></a>XNOR</h2><p>XNOR代表：输入的两个值必须一样，均为1或均为0），<br>即：\(XNOR=(x_1 \ AND \ x_2) \ OR \ ((NOT \ x_1) \ AND \ (NOT \ x_2))\)<br>首先构造一个能表达\((NOT x_1) AND (NOT x_2)\)部分的神经元，都取0表达式才真：<br><img src="/picture/machine-learning/network21.jpg" alt="network"><br>然后将表示AND的神经元和表示\((NOT x_1)AND(NOT x_2)\)的神经元以及表示OR的神经元进行组合。<br>下图的神经元（三个权重分别为-30，20，20）可以被视为作用同于逻辑与（AND）：<br><img src="/picture/machine-learning/network22.jpg" alt="network"><br>下图的神经元（三个权重分别为-10，20，20）可以被视为作用等同于逻辑或（OR）：<br><img src="/picture/machine-learning/network23.jpg" alt="network"><br>组合：<br><img src="/picture/machine-learning/network24.jpg" alt="network"><br>\(x_1或x_2其中1个为1，1个为0的话，则a_1和a_2都为0，结果为0。\)<br>我们就得到了一个能实现XNOR运算符功能的神经网络。按这种方法我们可以逐渐构造出越来越复杂的函数，也能得到更加厉害的特征值。这就是神经网络的厉害之处。</p>
<h1 id="多类问题"><a href="#多类问题" class="headerlink" title="多类问题"></a>多类问题</h1><p>当我们有不止两种分类时（也就是y=1,2,3….），比如以下这种情况，该怎么办？如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。例如，第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车。<br>输入向量x有三个维度，两个中间层，输出层4个神经元分别用来表示4类，也就是每一个数据在输出层都会出现\([a b c d]^T\)，且a,b,c,d中仅有一个为1，表示当前类。下面是该神经网络的可能结构示例：<br><img src="/picture/machine-learning/network25.jpg" alt="network"><br><img src="/picture/machine-learning/network26.jpg" alt="network"><br>神经网络算法的输出结果为四种可能情形之一：<br><img src="/picture/machine-learning/network27.jpg" alt="network"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;非线性假设&quot;&gt;&lt;a href=&quot;#非线性假设&quot; class=&quot;headerlink&quot; title=&quot;非线性假设&quot;&gt;&lt;/a&gt;非线性假设&lt;/h1&gt;&lt;p&gt;我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。&lt;br&gt;下面是一个例子：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network1.jpg&quot; alt=&quot;network&quot;&gt;&lt;br&gt;当我们使用\(x_1,x_2\)的多次项式进行预测时，我们可以应用得很好。&lt;br&gt;之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合\(x_1x_2+x_1x_3+x_1x_4+…+x_2x_3+x_2x_4+…+x_{99}x_{100}\),我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。&lt;br&gt;假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车）。&lt;br&gt;我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。&lt;br&gt;假如我们只选用灰度图片，每个像素则只有一个值（而非RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/network2.jpg&quot; alt=&quot;network&quot;&gt;&lt;br&gt;假使我们采用的都是  50x50像素的小图片，并且我们将所有的像素视为特征，则会有2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约\(\frac{2500^2}{2}\)个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们就需要神经网络。&lt;/p&gt;
&lt;h1 id=&quot;神经元和大脑&quot;&gt;&lt;a href=&quot;#神经元和大脑&quot; class=&quot;headerlink&quot; title=&quot;神经元和大脑&quot;&gt;&lt;/a&gt;神经元和大脑&lt;/h1&gt;&lt;p&gt;神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。&lt;br&gt;接下来我将介绍神经网络。它能很好地解决不同的机器学习问题。首先介绍一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的，神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="神经网络" scheme="xtf615.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>逻辑回归</title>
    <link href="xtf615.com/2017/02/11/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    <id>xtf615.com/2017/02/11/逻辑回归/</id>
    <published>2017-02-11T07:30:53.000Z</published>
    <updated>2017-03-18T02:08:15.781Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>在分类问题中，你要预测的变量  y是离散的值，我们将学习一种叫做逻辑回归(Logistic Regression)的算法，这是目前最流行使用最广泛的一种学习算法。</p>
<p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。</p>
<p>我们从二元的分类问题开始讨论。我们将因变量(dependant variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量 \(y\in{0,1}\) 其中0表示负向类，1表示正向类。<br><img src="/picture/machine-learning/logistic_regression1.jpg" alt="logistic_regression"><br><img src="/picture/machine-learning/logistic_regression2.jpg" alt="logistic_regression2"><br>如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为     0或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于  1，或者远小于0，即使所有训练样本的标签y都等于0或1。尽管我们知道标签应该取值0或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到1之间。</p>
<p>顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法.<br><a id="more"></a></p>
<h1 id="假设表示"><a href="#假设表示" class="headerlink" title="假设表示"></a>假设表示</h1><p>在分类问题中，要用什么样的函数来表示我们的假设。此前我们说过，希望我们的分类器的输出值在0和1之间，因此，我们希望想出一个满足某个性质的假设函数，这个性质是它的预测值要在0和1之间。<br>回顾在一开始提到的乳腺癌分类问题，我们可以用线性回归的方法求出适合数据的一条直线：<br><img src="/picture/machine-learning/logistic_regression3.jpg" alt="logistic_regression3"><br>根据线性回归模型我们只能预测连续的值，然而对于分类问题，我们需要输出0或1，我们可以预测：<br>当\(h_θ&gt;=0.5\)时，预测y=1。<br>当\(h_θ&lt;0.5\)时，预测y=0。<br>对于上图所示的数据，这样的一个线性模型似乎能很好地完成分类任务。假使我们又观测到一个非常大尺寸的恶性肿瘤，将其作为实例加入到我们的训练集中来，这将使得我们获得一条新的直线。<br><img src="/picture/machine-learning/logistic_regression4.jpg" alt="logistic_regression4"><br>这时，再使用 0.5作为阀值来预测肿瘤是良性还是恶性便不合适了。可以看出，线性回归模型，因为其预测的值可以超越[0,1]的范围，并不适合解决这样的问题。<br>我们引入一个新的模型，逻辑回归，该模型的输出变量范围始终在0和 1之间。逻辑回归模型的假设是：<br>$$h_\theta(x)=g(\theta^TX) \\\\<br>其中，X代表特征向量 \\\\<br>g代表逻辑函数(logistic function), 也叫S形函数（Sigmoid \ function), \\\\<br>公式为：g(z)=\frac{1}{1+e^{-z}}<br>$$<br>该函数的图像：<br><img src="/picture/machine-learning/logistic_regression5.jpg" alt="logistic_regression5"><br>合起来，我们得到逻辑回归模型的假设：<br>$$h_\theta(x)=\frac{1}{1+e^{-\theta^TX}}$$<br>\(h_\theta(x)\)的作用是，对于给定的输入变量，根据选择的参数计算输出变量=1的可能性(estimated probablity)，即:<br>$$h_\theta(x)=P(y=1|x;\theta)$$<br>例如，如果对于给定的 x，通过已经确定的参数计算得出\(h_θ(x)=0.7\)，则表示有70%的几率y为正向类，相应地y为负向类的几率为1-0.7=0.3。</p>
<h1 id="判定边界"><a href="#判定边界" class="headerlink" title="判定边界"></a>判定边界</h1><p>现在讲下决策边界(decision  boundary)的概念。这个概念能更好地帮助我们理解逻辑回归的假设函数在计算什么。<br><img src="/picture/machine-learning/logistic_regression6.jpg" alt="logistic_regression6"><br>在逻辑回归中，我们预测：</p>
<ul>
<li>当\(h_θ\)大于等于0.5时，预测y=1;</li>
<li>当\(h_θ\)小于0.5时，预测y=0;<br>根据上面绘制出的S形函数图像，我们知道:</li>
<li>当z=0时, g(z)=0.5;</li>
<li>当z&gt;0时, g(z)&gt;0.5;</li>
<li>当z&lt;0时, g(z)&lt;0.5.</li>
</ul>
<p>又\(z=\theta^TX\),即：<br>\(\theta^TX \ge 0\),预测y=1;<br>\(\theta^TX &lt; 0\),预测y=0;<br>现在假设我们有一个模型：<br><img src="/picture/machine-learning/logistic_regression7.jpg" alt="logistic_regression7"><br>并且参数θ是向量[-3 1 1]。则当\( (-3+x_1+x_2)\ge 0\)，即 \(x_1+x_2 \ge 3\)时,模型将预测y=1。<br>我们可以绘制直线\(x_1+x_2=3\)，这条线便是我们模型的分界线，将预测为1的区域和预测为0的区域分隔开。<br><img src="/picture/machine-learning/logistic_regression8.jpg" alt="logistic_regression8"><br>假使我们的数据呈现这样的分布情况，怎样的模型才能适合呢？<br><img src="/picture/machine-learning/logistic_regression9.jpg" alt="logistic_regression9"><br>因为需要用曲线才能分隔y=0的区域和y=1的区域，我们需要二次方特征：假设参数：\(h_θ(x)=g(θ_0+θ_1x_1+θ_2x_2+θ_3x_1^2+θ_4x_2^2)\)是[-1 0 0 1 1],则我们得到的判定边界恰好是圆点在原点且半径为1的圆形。<br>我们可以用非常复杂的模型来适应非常复杂形状的判定边界。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>接下来我们要介绍如何拟合逻辑回归模型的参数\(θ\)。具体来说，我要定义用来拟合参数的优化目标或者叫代价函数，这便是监督学习问题中的逻辑回归模型的拟合问题。<br><img src="/picture/machine-learning/logistic_regression10.jpg" alt="logistic_regression10"><br>对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于:当我们将\(h_θ(x)=\frac{1}{1+e^{-θ^TX}}\)代入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（no-convex function).<br><img src="/picture/machine-learning/logistic_regression11.jpg" alt="logistic_regression11"><br>这意味着我们的代价函数有许多局部最小值，<strong>这将影响梯度下降算法寻找全局最小值。</strong><br>线性回归的代价函数为：<br>$$J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>我们重新定义逻辑回归的代价函数为:<br>$$J(\theta)=\frac{1}{m}\sum_{i=1}^mCost\left(h_{\theta}(x^{(i)}),y^{(i)}\right)$$<br>其中：<br>$$<br>\begin{eqnarray}<br>Cost(h_\theta(x),y)=<br>\begin{cases}<br>-log(h_\theta(x)), y=1 \cr -log(1-h_\theta(x)), y=0<br>\end{cases}<br>\end{eqnarray}<br>$$<br>\(h_θ(x)\)与\(Cost(h_θ(x),y)\)之间的关系如下图所示：<br><img src="/picture/machine-learning/logistic_regression12.jpg" alt="logistic_regression12"><br>这样构建的\(Cost(h_θ(x),y)\)函数的特点是：当实际的y=1且\(h_θ\)也为1时误差为 0，当y=1但\(h_θ\)不为1时误差随着\(h_θ\)的变小而变大；当实际的y=0且\(h_θ\)也为0时,代价为0，当y=0但\(h_θ\)不为0时误差随着\(h_θ\)的变大而变大。<br>将构建的Cost(hθ(x),y)简化如下:<br>$$Cost(h_θ(x),y)=-y*log(h_θ(x))-(1-y)*log(1-h_θ(x))$$</p>
<p>代入代价函数得到：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>在得到这样一个代价函数以后，我们便可以用梯度下降算法来求得能使代价函数最小的参数了。算法为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta) $$<br>}<br>求导后得到：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\sum_{i=1}^m\left((h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\right) $$<br>}</p>
<h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p>所给的代价函数：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>其中：<br>\(h_θ(x^{(i)})=\frac{1}{1+e^{-θ^TX}}\)<br>令\(z=θ^Tx=θ_0+θ_1x_1+θ_2x_2+…+θ_nx_n\)<br>则\(\frac{\partial z}{\partial(θ_j)}=x_j^{(i)}\)<br>\(h_θ(x^{(i)})=\frac{1}{1+e^{-z}}=\frac{e^z}{1+e^z}\) </p>
<p>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)\\\\<br>=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))-y^{(i)}log(1-h_θ(x^{(i)}))+log(1-h_θ(x^{(i)}))\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log\left(\frac{h_θ(x^{(i)})}{1-h_θ(x^{(i)})}\right)+log(1-h_θ(x^{(i)}))\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log\left(\frac{\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}}{1-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}}\right)+log(1-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}})\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}z^{(i)}-log(1+e^{z^{(i)}})\right)<br>$$<br>$$<br>J’(θ)= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}\frac{\partial z^{(i)}}{\partialθ_j}-\frac{e^{z^{(i)}}}{1+e^{z^{(i)}}}\frac{\partial z^{(i)}}{\partialθ_j}\right) \\\\<br>= -\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}-h_θ(x^{(i)})\right)\frac{\partial z^{(i)}}{\partialθ_j} \\\\<br>= \frac{1}{m}\sum_{i=1}^m\left((h_θ(x^{(i)})-y^{(i)})x_j^{(i)}\right)<br>$$</p>
<p>注：虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的\(h_θ(x)=g(θ^TX)\)与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之T前，进行特征缩放依旧是非常必要的。<br>一些梯度下降算法之外的选择：除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度（Conjugate Gradient），局部优化法(Broyden fletcher goldfarb shann,BFGS)和有限内存局部优化法(LBFGS)。</p>
<h1 id="多类别分类-1对多"><a href="#多类别分类-1对多" class="headerlink" title="多类别分类 1对多"></a>多类别分类 1对多</h1><p>我们将谈到如何使用逻辑回归(logistic  regression)来解决多类别分类问题，具体来说，我想通过一个叫做”一对多” (one-vs-all)的分类算法。<br>先看这样一些例子。</p>
<ul>
<li>第一个例子：假如说你现在需要一个学习算法能自动地将邮件归类到不同的文件夹里，或者说可以自动地加上标签，那么，你也许需要一些不同的文件夹，或者不同的标签来完成<br>这件事，来区分开来自工作的邮件、来自朋友的邮件、来自家人的邮件或者是有关兴趣爱好的邮件，那么，我们就有了这样一个分类问题：其类别有四个，分别用y=1、y=2、y=3、y=4来代表。</li>
<li>第二个例子是有关药物诊断的，如果一个病人因为鼻塞来到你的诊所，他可能并没有生病，用y=1这个类别来代表；或者患了感冒，用y=2来代表；或者得了流感用y=3来代表。</li>
<li>第三个例子：如果你正在做有关天气的机器学习分类问题，那么你可能想要区分哪些天是晴天、多云、雨天、或者下雪天，对上述所有的例子，y可以取一个很小的数值，一个相对”谨慎”的数值，比如1到3、1到4或者其它数值。<br>以上说的都是多类分类问题。<br>然而对于之前的一个二元分类问题，我们的数据看起来可能是像这样：<br><img src="/picture/machine-learning/logistic_regression13.jpg" alt="logistic"><br>对于一个多类分类问题，我们的数据集或许看起来像这样：<br><img src="/picture/machine-learning/logistic_regression14.jpg" alt="logistic"><br>我用三种不同的符号来代表三个类别，问题就是给出三个类型的数据集，我们如何得到一个学习算法来进行分类呢？<br>我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上。<br>下面将介绍如何进行一对多的分类工作，有时这个方法也被称为”一对余”方法。<br>现在我们有一个训练集，好比上图表示的有三个类别，我们用三角形表示y=1，方框表示  y=2，叉叉表示y=3。我们下面要做的就是使用一个训练集，将其分成三个二元分类问题。我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类，我们创建一个新的训练集，如下图所示的那样，我们要拟合出一个合适的分类器。<br><img src="/picture/machine-learning/logistic_regression15.jpg" alt="logistic_regression15"></li>
</ul>
<p>这里的三角形是正样本，而圆形代表负样本。可以这样想，设置三角形的值为1，圆形的值为0，下面我们来训练一个标准的逻辑回归分类器，这样我们就得到一个正边界。<br>为了能实现这样的转变，我们将多个类中的一个类标记为正向类（y=1），然后将其他所有类都标记为负向类，这个模型记作\(h_\theta^{(1)}(x)\)。<br>接着，类似地第我们选择另一个类标记为正向类（y=2），再将其它类都标记为负向类，将这个模型记作\(h_\theta^{(2)}(x)\),依此类推。<br>最后我们得到一系列的模型简记为：\(h_\theta^{(i)}(x)=p(y=i|x;\theta)\)<br><img src="/picture/machine-learning/logistic_regression16.jpg" alt="logistic_regression16"><br>最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。<br>总之，我们已经把要做的做完了，现在要做的就是训练这个逻辑回归分类器：\(h_\theta^{(i)}(x)\)其中i对应每一个可能的y=i，最后,为了做出预测，我们给出输入一个新的x值，用这个做预测。我们要做的就是在我们三个分类器里面输入x，然后我们选择一个让\(h_\theta^{(i)}(x)\)最大的i,即\(\max_{i}h_\theta^{(i)}(x)\)<br>现在知道了基本的挑选分类器的方法，选择出哪一个分类器是可信度最高效果最好的,那么就可认为得到一个正确的分类，无论i值是多少，我们都有最高的概率值，我们预测y就是那个值。这就是多类别分类问题，以及一对多的方法，通过这个小方法，现在也可以将逻辑回归分类器用在多类分类的问题上。</p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><p>到现在为止，我们已经学习了几种不同的学习算法，包括线性回归和逻辑回归，它们能够有效地解决许多问题，但是当将它们应用到某些特定的机器学习应用时，会遇到过度拟合 (over-fitting)的问题，可能会导致它们效果很差。<br>接下来，我们将谈论一种称为正则化(regularization)的技术，它可以改善或者减少过度拟合问题。<br>下图是一个回归问题的例子：<br><img src="/picture/machine-learning/logistic_regression17.jpg" alt="logistic_regression17"><br>第一个模型是一个线性模型，欠拟合，不能很好地适应我们的训练集；第三个模型是一个四次方的模型，过于强调拟合原始数据，而丢失了算法的本质：预测新数据。我们可以看出，若给出一个新的值使之预测，它将表现的很差，是过拟合，虽然能非常好地适应我们的训练集但在新输入变量进行预测时可能会效果不好；而中间的模型似乎最合适。<br>分类问题中也存在这样的问题：<br><img src="/picture/machine-learning/logistic_regression18.jpg" alt="logistic_regression18"><br>就以多项式理解，x的次数越高，拟合的越好，但相应的预测的能力就可能变差。<br>问题是，如果我们发现了过拟合问题，应该如何处理？</p>
<ul>
<li>丢弃一些不能帮助我们正确预测的特征。可以是手工选择保留哪些特征，或者使用一些模型选择的算法来帮忙（例如PCA）</li>
<li>正则化。保留所有的特征，但是减少参数的大小（magnitude）。<h2 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h2>上面的回归问题中如果我们的模型是：<br>$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2^2+\theta_3x_3^3+\theta_4x_4^4$$<br>我们可以从之前的事例中看出，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。<br>所以我们要做的就是在一定程度上减小这些参数θ的值，这就是正则化的基本方法。我们决定要减少\(θ_3\)和\(θ_4\)的大小，我们要做的便是修改代价函数，在其中\(θ_3\)和\(θ_4\)设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的\(θ_3\)和\(θ_4\)。修改后的代价函数如下：<br>$$\min_θ\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+1000θ_3^2+10000θ_4^2$$<br>通过这样的代价函数选择出的\(θ_3\)和\(θ_4\)对预测结果的影响就比之前要小许多。假如我们有非常多的特征，我们并不知道其中哪些特征我们要惩罚，我们将对所有的特征进行惩罚，并且让代价函数最优化的软件来选择这些惩罚的程度。这样的结果是得到了一个较为简单的能防止过拟合问题的假设：<br>$$J(θ)=\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^nθ_j^2$$<br>其中λ又称为正则化参数（Regularization Parameter）。注：根据惯例，我们不对\(θ_0\)进行惩罚。经过正则化处理的模型与原模型的可能对比如下图所示：<br><img src="/picture/machine-learning/logistic_regression19.jpg" alt="regularization"><br>如果选择的正则化参数λ过大，则会把所有的参数都最小化了，导致模型变成\(h_θ(x)=θ_0\).也就是上图中红色直线所示的情况，造成欠拟合。<br>那为什么增加的一项\(\lambda\sum_{j=1}^nθ_j^2\),可以使θ的值减小呢？<br>因为如果我们令λ的值很大的话,为了使Cost Function尽可能的小，所有的θ的值（不包括 \(θ_0\)）都会在一定程度上减小。<br>但若λ的值太大了,那么θ（不包括\(θ_0\)）都会趋近于0，这样我们所得到的只能是一条平行于x轴的直线。<br>所以对于正则化，我们要取一个合理的λ的值，这样才能更好的应用正则化。<br>回顾一下代价函数，为了使用正则化，让我们把这些概念应用到到线性回归和逻辑回归中去，那么我们就可以让他们避免过度拟合了。<h2 id="正则化线性回归"><a href="#正则化线性回归" class="headerlink" title="正则化线性回归"></a>正则化线性回归</h2>对于线性回归的求解，我们之前推导了两种学习算法：一种基于梯度下降，一种基于正规方程。<br>正则化线性回归的代价函数为：<br>$$J(θ)=\frac{1}{2m}\sum_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^nθ_j^2$$<br>如果我们要使用梯度下降法令这个代价函数最小化，因为我们未对\(θ_0\)进行正则化，所以梯度下降算法将分两种情形：<br><strong>repeat until convergence</strong>{<br> $$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)}).x_0^{(i)}) \\\ <br> \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}+\frac{\lambda}{m}\theta_j) \\\\<br> for j=1,2,…,n$$<br>}<br>对上面j=1,2…n时的更新式子进行调整可得：<br>$$\theta_j:=\theta_j(1-\alpha\frac{\lambda}{m})-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$<br>可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令θ值减少了一个额外的值。<br>我们同样也可以利用正规方程来求解正则化线性回归模型，方法如下所示：<br>$$θ=\left(X^TX+\lambda I\right)^{-1}X^Ty \\\\<br>其中I为对角矩阵,并且第一个元素为0,其余对角元素都为1$$<h2 id="正则化的逻辑回归模型"><a href="#正则化的逻辑回归模型" class="headerlink" title="正则化的逻辑回归模型"></a>正则化的逻辑回归模型</h2><img src="/picture/machine-learning/logistic_regression20.jpg" alt="regularization"><br>同样对于逻辑回归，我们也给代价函数增加一个正则化的表达式，得到代价函数：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$<br>要最小化该代价函数，通过求导，得出梯度下降算法为：<br><strong>repeat until convergence</strong>{<br> $$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)}).x_0^{(i)}) \\\ <br> \theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}+\frac{\lambda}{m}\theta_j) \\\\<br> for j=1,2,…,n$$<br>}</li>
</ul>
<p><strong>注：看上去同线性回归一样，但是逻辑回归\(h_θ(x)=g(θ^TX)\)，而线性回归\(h_θ(x)=θ^TX\),所以二者不同。</strong></p>
<h1 id="广义线性模型与逻辑回归"><a href="#广义线性模型与逻辑回归" class="headerlink" title="广义线性模型与逻辑回归"></a>广义线性模型与逻辑回归</h1><p>广义线性模型的介绍见：<a href="/2017/02/09/线性回归/">线性回归-拓展 广义线性模型与线性回归</a><br>实际上，逻辑回归中：我们有如下假设：<br>$$y|x;θ \sim Bernoulli(\phi)$$<br>即，假设y的条件概率服从伯努利分布，伯努利分布也是广义线性模型的一种特例。</p>
<h2 id="Bernoulli分布的指数分布簇形式"><a href="#Bernoulli分布的指数分布簇形式" class="headerlink" title="Bernoulli分布的指数分布簇形式"></a>Bernoulli分布的指数分布簇形式</h2><p>广义线性模型的指数分布簇形式：<br>$$p(y;\eta)=b(y)exp(\eta^{T}T(y)-a(\eta))$$<br>伯努利分布：<br>$$p(y=1;\phi)=\phi; \ p(y=0;\phi)=1-\phi$$<br>=&gt;<br>$$p(y;\phi)=\phi^y(1-\phi)^{1-y} \\\\<br>=exp(ylog\phi+(1-y)log(1-\phi)) \\\\<br>=exp\left(  \left(log\left(\frac{\phi}{1-\phi}\right)\right)y+log(1-\phi)\right)<br>$$<br>即：在如下参数下，广义线性模型是伯努利分布<br>$$\eta=log(\frac{\phi}{1-\phi}) =&gt; \phi = \frac{1}{1+e^{-\eta}} \\\\<br>T(y)=y \\\\<br>a(\eta)=-log(1-\eta)=log(1+e^\eta) \\\\<br>b(y)=1<br>$$</p>
<h2 id="广义线性模型推导逻辑回归"><a href="#广义线性模型推导逻辑回归" class="headerlink" title="广义线性模型推导逻辑回归"></a>广义线性模型推导逻辑回归</h2><p>让我们重新审视一下逻辑回归，我们定义:<br>$$h_\theta(x)=P(y=1|x;\theta)$$<br>即，模型的输出就是y=1的概率，后面我们会发现\(P(y=1|x;\theta)\)实际上就是伯努利分布的参数\(\phi\)。由上式有：<br>$$P(y=0|x;\theta)=1-h_\theta(x)$$<br>我们将两个式子合并成一个式子：有：<br>$$P(y|x;\theta)=h_\theta(x)^y+(1-h_\theta(x))^{1-y}$$<br>显然,y=1时，上式变为\(P(y=1|x;\theta)=h_\theta(x)\); y=0时，上式变为\(P(y=0|x;\theta)=1-h_\theta(x)\)<br>使用极大似然估计，得到：<br>$$L(\theta)=P(y|X;\theta)=\prod_{i=1}^mP(y^{(i)}|x^{(i)};\theta) \\\\=\prod_{i=1}^m\left(h_\theta(x^{(i)})^{y^{(i)}}+(1-h_\theta(x^{(i)}))^{1-y^{(i)}}\right)$$<br>两边取对数得到：<br>$$\ell(\theta)=log(L(\theta))=\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)$$<br>这就是上文的代价函数。<br>下面是推导：</p>
<ul>
<li>step1: \(y|x;\theta \sim Bernoulli(\phi)\)</li>
<li>step2: 由假设2: \(h(x)=E[y|x]\) 得到：<br>$$h_\theta(x)=E[y|x;\Theta]=p(y=1|x;\theta)\\\\<br> =\phi \\\\<br> =\frac{1}{1+e^{-\eta}}  \\\\<br> =\frac{1}{1+e^{-\Theta^Tx}}  \\\\<br> 其中, E[y|x;\Theta]=\phi由假设1得到；\\\\<br>\phi=\frac{1}{1+e^{-\eta}}由伯努利分布对应的广义线性模型参数得到；\\\\<br>\eta = \Theta^Tx由假设3得到。<br>$$</li>
</ul>
<p><strong>注：可以看出Sigmoid function得到的实际上就是\(\phi\)的值，也就是预测y=1的概率。</strong></p>
<h1 id="拓展——softmax回归"><a href="#拓展——softmax回归" class="headerlink" title="拓展——softmax回归"></a>拓展——softmax回归</h1><h2 id="多项式分布"><a href="#多项式分布" class="headerlink" title="多项式分布"></a>多项式分布</h2><p>首先，y的取值有多个，\(y \in {1,2…,k}\)，参数也相应的有k个，即\({\phi_1,\phi_2,…,\phi_k}\),则：<br>$$P(y=i)=\phi_i$$<br>我们将\(\phi_k\)改写成：<br>$$\phi_k=1-(\phi_1+\phi_2+…+\phi_{k-1})$$<br>因此可以视作只有k-1个参数，\(\phi_1,\phi_2,…,\phi_{k-1}\)</p>
<h2 id="指数分布簇形式推导"><a href="#指数分布簇形式推导" class="headerlink" title="指数分布簇形式推导"></a>指数分布簇形式推导</h2><p>首先定义T(y):<br>$$T(1)=[1 \ 0 \ … \ 0]^T$$<br>$$T(2)=[0 \ 1 \ … \ 0]^T$$<br>$$T(k-1)=[0 \ 0 \ … \ 1]^T$$<br>$$T(k)=[0 \ 0 \ … \ 0]^T$$<br>定义指示函数：<br>\(I\{True\}=1, I\{False\}=0\)<br>我们使用标志：<br>\(T(y)_i\)表示向量\(T(y)\)的第\(i\)个元素，则：<br>$$T(y)_i=I\{y=i\}$$<br>根据多项式分布：<br>$$P(y)=\phi_1^{I\{y=1\}}\phi_2^{I\{y=2\}}…\phi_k^{I\{y=k\}} \\\\<br>=\phi_1^{(T(y))_1}\phi_2^{(T(y))_2}…\phi_{k=1}^{(T(y))_{k-1}}\phi_k^{1-\sum_{j=1}^{k-1}(T(y))_j} \\\\<br>=exp\left((T(y))_1 log(\phi_1) + (T(y))_2 log(\phi_2))+…+\left(1-\sum_{j=1}^{k-1}(T(y))_j\right)log(\phi_k)\right) \\\\<br>=exp\left((T(y))_1 log(\frac{\phi_1}{\phi_k}) + (T(y))_2 log(\frac{\phi_2}{\phi_k}) + … + (T(y))_{k-1} log(\frac{\phi_{k-1}}{\phi_k})+log(\phi_k) \right)<br>=b(y)exp(\eta^T T(y)-a(\eta)) \\\\<br>$$<br>其中，<br>$$<br>\eta=\begin{bmatrix} log(\frac{\phi_i}{\phi_k}) \\\ … \\\ log(\frac{\phi_{k-1}}{\phi_k}) \end{bmatrix} \\\\<br>a(\eta)=-log(\phi_k) \\\\<br>b(y)=1<br>$$<br>根据上面这些式子，可以将多项式分布转化成指数分布簇形式。<br>我们有：for(i=1,…,k):<br>$$\eta_i=log\frac{\phi_i}{\phi_k}$$<br>为了方便，我们定义\(\eta_k=log\frac{\phi_k}{\phi_k}=0\)<br>我们有：<br>$$e^{\eta_i}=\frac{\phi_i}{\phi_k}$$<br>则：<br>$$\phi_ke^{\eta_i}=\phi_i \ \ \ \ \ \ \ \ (1)$$<br>$$\phi_k\sum_{i=1}^ke^{\eta_i}=\sum_{i=1}^k \phi_i=1$$<br>$$\phi_k=\frac{1}{\sum_{i=1}^k e^{\eta_i}}$$<br>代回到(1)式，得到：<br>$$\phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}$$</p>
<p>我们将\(\phi\)和\(\eta\)关系倒过来，可以得到：<br>$$p(y=i|x;\theta)=\phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^{k}e^{\eta_j}} \\\\<br>=\frac{e^{\theta_i^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}}<br>$$<br>前面提到，\(\eta_k=0\),故上式也可以写作：<br>$$p(y=i|x;\theta)=\phi_i=\frac{e^{\eta_i}}{1+\sum_{j=1}^{k-1}e^{\eta_j}} \\\ =\frac{e^{\theta_i^T X}}{1+\sum_{j=1}^{k-1}e^{\theta_j^T X}}<br>$$<br>这和逻辑回归的样子非常像：<br>$$\phi_1=\frac{1}{1+e^{-\theta^T X}}=\frac{e^{\theta^T X}}{1+e^{\theta^T X}}$$<br>注意，softmax回归中的\(\theta_i,…,\theta_{k-1} \in \mathbb{R^{n+1}}\),即n+1维向量。 </p>
<p>所以我们的学习算法：<br>$$h_\theta(x)=E[T(y)|x;\theta] \\\\<br>=E\left[\begin{bmatrix} I\{y=1\} \\\ … \\\ I\{y=k-1\} \end{bmatrix} | x;\theta\right] = \begin{bmatrix} \phi_1 \\\ … \\\ \phi_{k-1} \end{bmatrix} \\\\<br>= \begin{bmatrix} \frac{e^{\theta_i^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}} \\\ … \\\ \frac{e^{\theta_{k-1}^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}} \end{bmatrix}<br>$$<br>最后只需要使用极大似然法拟合参数即可：<br>$$\ell(\theta)=\sum_{i=1}^m log \ p(y^{(i)}|x^{(i)};\theta) \\\\<br>=\sum_{i=1}^m log \prod_{l=1}^k \left(\frac{e^{\theta_{l}^T X}}{\sum_{j=1}^{k}e^{\theta_j^T X}}\right)^{I\{y_i=l\}}$$</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/47637500?sort=created" target="_blank" rel="external">知乎：为什么广义线性模型GLM要求被解释变量属于指数分布簇</a><br><a href="https://zhuanlan.zhihu.com/p/22876460" target="_blank" rel="external">知乎：广义线性模型</a>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分类问题&quot;&gt;&lt;a href=&quot;#分类问题&quot; class=&quot;headerlink&quot; title=&quot;分类问题&quot;&gt;&lt;/a&gt;分类问题&lt;/h1&gt;&lt;p&gt;在分类问题中，你要预测的变量  y是离散的值，我们将学习一种叫做逻辑回归(Logistic Regression)的算法，这是目前最流行使用最广泛的一种学习算法。&lt;/p&gt;
&lt;p&gt;在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。&lt;/p&gt;
&lt;p&gt;我们从二元的分类问题开始讨论。我们将因变量(dependant variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量 \(y\in{0,1}\) 其中0表示负向类，1表示正向类。&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/logistic_regression1.jpg&quot; alt=&quot;logistic_regression&quot;&gt;&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/logistic_regression2.jpg&quot; alt=&quot;logistic_regression2&quot;&gt;&lt;br&gt;如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为     0或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于  1，或者远小于0，即使所有训练样本的标签y都等于0或1。尽管我们知道标签应该取值0或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到1之间。&lt;/p&gt;
&lt;p&gt;顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法.&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="广义线性模型" scheme="xtf615.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="逻辑回归" scheme="xtf615.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>基于jieba分词和nltk的情感分析</title>
    <link href="xtf615.com/2017/02/10/%E5%9F%BA%E4%BA%8Ejieba%E5%88%86%E8%AF%8D%E5%92%8Cnltk%E7%9A%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    <id>xtf615.com/2017/02/10/基于jieba分词和nltk的情感分析/</id>
    <published>2017-02-10T10:45:56.000Z</published>
    <updated>2017-02-11T07:33:21.302Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自然语言处理NLP"><a href="#自然语言处理NLP" class="headerlink" title="自然语言处理NLP"></a>自然语言处理NLP</h1><p>情感分析作为自然语言处理的一个部分，让我们首先看一下自然语言处理。</p>
<h2 id="相关技术及运用"><a href="#相关技术及运用" class="headerlink" title="相关技术及运用"></a>相关技术及运用</h2><p>自动问答（Question Answering，QA）：它是一套可以理解复杂问题，并以充分的准确度、可信度和速度给出答案的计算系统，以IBM‘s Waston为代表；<br>信息抽取（Information Extraction，IE）：其目的是将非结构化或半结构化的自然语言描述文本转化结构化的数据，如自动根据邮件内容生成Calendar；<br>情感分析（Sentiment Analysis，SA）：又称倾向性分析和意见挖掘，它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从大量网页文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向；<br>机器翻译（Machine Translation，MT）：将文本从一种语言转成另一种语言，如中英机器翻译。</p>
<h2 id="发展现状"><a href="#发展现状" class="headerlink" title="发展现状"></a>发展现状</h2><p>基本解决：词性标注、命名实体识别、Spam识别<br>取得长足进展：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取<br>挑战：自动问答、复述、文摘、会话机器人<br><img src="/picture/machine-learning/nlp_process.png" alt="nlp_process"><br><a id="more"></a>  </p>
<h2 id="NLP主要难点——歧义问题"><a href="#NLP主要难点——歧义问题" class="headerlink" title="NLP主要难点——歧义问题"></a>NLP主要难点——歧义问题</h2><ul>
<li>词法分析歧义：<br>1）分词， 如“严守一把手机关了”，可能的分词结果“严守一/ 把/ 手机/ 关/ 了” 和“严守/ 一把手/ 机关/ 了”。2）词性标注， 如“计划”在不同上下文中有不同的词性：“我/ 计划/v 考/ 研/”和“我/ 完成/ 了/ 计划/n”</li>
<li>语法分析歧义：<br>“那只狼咬死了猎人的狗”。 ”咬死了猎人的狗失踪了”。</li>
<li>语义分析歧义：<br>计算机会像你的母亲那样很好的理解你（的语言）： 1）计算机理解你喜欢你的母亲。2）计算机会像很好的理解你的母亲那样理解你</li>
<li>NLP应用中的歧义：<br>音字转换：拼音串“ji qi fan yi ji qi ying yong ji qi le ren men ji qi nong hou de xing qu”中的“ji qi”如何转换成正确的词条<h2 id="为什么自然语言理解如此困难？"><a href="#为什么自然语言理解如此困难？" class="headerlink" title="为什么自然语言理解如此困难？"></a>为什么自然语言理解如此困难？</h2></li>
<li>用户生成内容中存在大量口语化、成语、方言等非标准的语言描述</li>
<li>分词问题</li>
<li>新词不断产生</li>
<li>基本常识与上下文知识</li>
<li>各式各样的实体词</li>
</ul>
<p>为了解决以上难题，我们需要掌握较多的语言学知识，构建知识库资源，并找到一种融合各种知识、资源的方法，目前使用较多是概率模型 （probabilistic model）或称为统计模型（statistical model），或者称为“经验主义模型”，其建模过程基于大规模真实语料库，从中各级语言单位上的统计信息，并且，依据较低级语言单位上的统计信息，运行 相关的统计、推理等技术计算较高级语言单位上的统计信息。与其相对的“理想主义模型”，即基于Chomsky形式语言的确定性语言模型，它建立在人脑中先 天存在语法规则这一假设基础上，认为语言是人脑语言能力推导出来的，建立语言模型就是通过建立人工编辑的语言规则集来模拟这种先天的语言能力。</p>
<h1 id="情感分析概念"><a href="#情感分析概念" class="headerlink" title="情感分析概念"></a>情感分析概念</h1><p>情感分析（Sentiment analysis），又称倾向性分析，意见抽取（Opinion extraction），意见挖掘（Opinion mining），情感挖掘（Sentiment mining），主观分析（Subjectivity analysis），它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从评论文本中分析用户对“数码相机”的“变焦、价格、大小、重 量、闪光、易用性”等属性的情感倾向。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><ul>
<li><p><strong>从电影评论中识别用户对电影的褒贬评价</strong><br><img src="/picture/machine-learning/movie_comment.png" alt="movie_comment"></p>
</li>
<li><p>Google Product Search识别用户对产品各种属性的评价，并从评论中选择代表性评论展示给用户<br><img src="/picture/machine-learning/product_comment.png" alt="product_comment"></p>
</li>
<li><p>微信新闻识别用户对新闻的各种评价，并从评论中选择代表性评论展示给用户</p>
</li>
<li><p>Twitter sentiment versus Gallup Poll of Consumer Confidence：挖掘Twitter中的用户情感发现，其与传统的调查、投票等方法结果有高度的一致性。<br>下图中2008年到2009年初，网民情绪低谷是金融危机导致，从2009年5月份开始慢慢恢复。<br><img src="/picture/machine-learning/mental.png" alt="mental"></p>
</li>
<li><p>Twitter sentiment: 通过Twitter用户情感预测股票走势。<br>2012年5月，世界首家基于社交媒体的对冲基金 Derwent Capital Markets 在屡次跳票后终于上线。它会即时关注Twitter 中的公众情绪指导投资。正如基金创始人保罗•郝汀（Paul Hawtin）表示：“长期以来，投资者已经广泛地认可金融市场由恐惧和贪婪驱使，但我们从未拥有一种技术或数据来量化人们的情感。”一直为金融市场非理性举动所困惑的投资者，终于有了一扇可以了解心灵世界的窗户——那便是 Twitter 每天浩如烟海的推文，在一份八月份的报道中显示，利用 Twitter 的对冲基金 Derwent Capital Markets 在首月的交易中已经盈利，它以1.85%的收益率，让平均数只有0.76%的其他对冲基金相形见绌。类似的工作还有预测电影票房、选举结果等，均是将公众 情绪与社会事件对比，发现一致性，并用于预测，如将“冷静CLAM”情绪指数后移3天后和道琼斯工业平均指数DIJA惊人一致。<br><img src="/picture/machine-learning/stock_predict.png" alt="stock"></p>
</li>
<li><p>Target Sentiment on Twitter（Twitter Sentiment App）：对Twitter中包含给定query的tweets进行情感分类。对于公司了解用户对公司、产品的喜好，用于指导改善产品和服务，公司还可以 据此发现竞争对手的优劣势，用户也可以根据网友甚至亲友评价决定是否购买特定产品。详细见论文：Alec Go, Richa Bhayani, Lei Huang. 2009. Twitter Sentiment Classification using Distant Supervision.<br><img src="/picture/machine-learning/search_sentiment.png" alt="search"></p>
</li>
</ul>
<h2 id="情感分析内容"><a href="#情感分析内容" class="headerlink" title="情感分析内容"></a>情感分析内容</h2><h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><p>情感分析主要目的就是识别用户对事物或人的看法、态度。<br>参与主体主要包括：</p>
<ul>
<li>Holder (source) of attitude：观点持有者</li>
<li>Target (aspect) of attitude：评价对象</li>
<li>Type of attitude：评价观点</li>
<li>From a set of types：观点类型：Like, love, hate, value, desire, etc.<br>Or (more commonly) simple weighted polarity: positive, negative, neutral,together with strength</li>
<li>Text containing the attitude：评价文本，一般是句子或整篇文档。</li>
<li>更细更深入的还包括评价属性，情感词/极性词，评价搭配等。</li>
</ul>
<p>通常，我们面临的情感分析任务包括如下几类：</p>
<ul>
<li>是正面还是反面情绪？<br>Simplest task: Is the attitude of this text positive or negative?</li>
<li>排序态度：<br>More complex: Rank the attitude of this text from 1 to 5</li>
<li>检测目的、观点等：<br>Advanced: Detect the target, source, or complex attitude types</li>
</ul>
<h2 id="词典匹配VS机器学习"><a href="#词典匹配VS机器学习" class="headerlink" title="词典匹配VS机器学习"></a>词典匹配VS机器学习</h2><p>不是有词典匹配的方法了吗？怎么还搞多个机器学习方法。因为词典方法和机器学习方法各有千秋。<br>机器学习的方法精确度更高，因为词典匹配会由于语义表达的丰富性而出现很大误差，而机器学习方法不会。而且它可使用的场景更多样。无论是主客观分类还是正负面情感分类，机器学习都可以完成任务。而无需像词典匹配那样要深入到词语、句子、语法这些层面。<br>而词典方法适用的语料范围更广，无论是手机、电脑这些商品，还是书评、影评这些语料，都可以适用。但机器学习则极度依赖语料，把手机语料训练出来的的分类器拿去给书评分类，那是注定要失败的。<br>使用机器学习进行情感分析，可以换一个相同意思的说法，就是用有监督的（需要人工标注类别）机器学习方法来对文本进行分类。<br>这点与词典匹配有着本质的区别。<strong>词典匹配是直接计算文本中的情感词，得出它们的情感倾向分值</strong>。而<strong>机器学习方法的思路是先选出一部分表达积极情感的文本和一部分表达消极情感的文本，用机器学习方法进行训练，获得一个情感分类器。再通过这个情感分类器对所有文本进行积极和消极的二分分类</strong>。最终的分类可以为文本给出0或1这样的类别，也可以给出一个概率值，比如”这个文本的积极概率是90%，消极概率是10%“。</p>
<h2 id="NLTK"><a href="#NLTK" class="headerlink" title="NLTK"></a>NLTK</h2><p>Python 有良好的程序包可以进行情感分类，那就是Python 自然语言处理包，Natural Language Toolkit ，简称NLTK 。NLTK 当然不只是处理情感分析，NLTK 有着整套自然语言处理的工具，从分词到实体识别，从情感分类到句法分析，完整而丰富，功能强大。实乃居家旅行，越货杀人之必备良药。<br>另外，<strong>NLTK 新增的scikit-learn 的接口</strong>，使得它的分类功能更为强大好用了，可以用很多高端冷艳的分类算法了。<br>有了scikit-learn 的接口，NLTK 做分类变得比之前更简单快捷，但是相关的结合NLTK 和 sciki-learn 的文章实在少。</p>
<h1 id="构建情感分析工具流程"><a href="#构建情感分析工具流程" class="headerlink" title="构建情感分析工具流程"></a>构建情感分析工具流程</h1><h2 id="人工标注"><a href="#人工标注" class="headerlink" title="人工标注"></a>人工标注</h2><p>有监督意味着需要人工标注，需要人为的给文本一个类标签。比如我有5000条商品评论，如果我要把这些评论分成积极和消极两类。那我就可以先从里面选2000条评论，然后对这2000条数据进行人工标注，把这2000条评论标为“积极”或“消极”。这“积极”和“消极”就是类标签。 假设有1000条评论被标为“积极”，有1000条评论被标为“消极”。（两者数量相同对训练分类器是有用的，如果实际中数量不相同，应该减少和增加数据以使得它们数量相同）</p>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><p>特征就是分类对象所展现的部分特点，是实现分类的依据。我们经常会做出分类的行为，那我们依据些什么进行分类呢？ 举个例子，如果我看到一个年轻人，穿着新的正装，提着崭新的公文包，快步行走，那我就会觉得他是一个刚入职的职场新人。在这里面，“崭新”，“正装”，“公文包”，“快步行走”都是这个人所展现出的特点，也是我用来判断这个人属于哪一类的依据。这些特点和依据就是特征。可能有些特征对我判断更有用，有些对我判断没什么用，有些可能会让我判断错误，但这些都是我分类的依据。<br>我们没办法发现一个人的所有特点，所以我们没办法客观的选择所有特点，我们只能主观的选择一部分特点来作为我分类的依据。这也是特征选择的特点，需要人为的进行一定选择。<br><strong>而在情感分类中，一般从“词”这个层次来选择特征。</strong><br>比如这句话“手机非常好用！”，我给了它一个类标签“Positive”。里面有四个词（把感叹号也算上），“手机”，“非常”，“好用”，“！”。我可以认为这4个词都对分类产生了影响，都是分类的依据。也就是无论什么地方出现了这四个词的其中之一，文本都可以被分类为“积极”。这个是把所有词都作为分类特征。<br>同样的，对这句话，我也可以选择它的双词搭配（Bigrams）作为特征。比如“手机 非常”，“非常 好用”，“好用 ！”这三个搭配作为分类的特征。以此类推，三词搭配（Trigrams），四词搭配都是可以被作为特征的。</p>
<h2 id="特征降维"><a href="#特征降维" class="headerlink" title="特征降维"></a>特征降维</h2><p>特征降维说白了就是减少特征的数量。这有两个意义，一个是特征数量减少了之后可以加快算法计算的速度（数量少了当然计算就快了），另一个是如果用一定的方法选择信息量丰富的特征，可以减少噪音，有效提高分类的准确率。<br>所谓信息量丰富，可以看回上面这个例子“手机非常好用！”，很明显，其实不需要把“手机”，“非常”，“好用”，“！”这4个都当做特征，因为“好用”这么一个词，或者“非常 好用”这么一个双词搭配就已经决定了这个句子是“积极”的。这就是说，“好用”这个词的信息量非常丰富。<br><strong>那要用什么方法来减少特征数量呢？</strong><br>答案是通过一定的统计方法找到信息量丰富的特征。<br>统计方法包括：词频（Term Frequency）、文档频率（Document Frequency）、互信息（Pointwise Mutual Information）、信息熵（Information Entropy）、卡方统计（Chi-Square）等等。<br>在情感分类中，用词频选择特征，也就是选在语料库中出现频率高的词。比如我可以选择语料库中词频最高的2000个词作为特征。用文档频率选特征，是选在语料库的不同文档中出现频率最高的词。其他类似，都是要通过某个统计方法选择信息量丰富的特征。特征可以是词，可以是词组合。</p>
<h2 id="文本特征化"><a href="#文本特征化" class="headerlink" title="文本特征化"></a>文本特征化</h2><p>在使用分类算法进行分类之前，第一步是要把所有原始的语料文本转化为特征表示的形式。<br>还是以上面那句话做例子，“手机非常好用！”<br>如果在NLTK 中，如果选择所有词作为特征，其形式是这样的：[ {“手机”: True, “非常”: True, “好用”: True, “！”: True} , positive]<br>如果选择双词作为特征，其形式是这样的：[ {“手机 非常”: True, “非常 好用”: True, “好用 ！”: True} , positive ]<br>如果选择信息量丰富的词作为特征，其形式是这样的：[ {“好用”: True} , positive ]<br>无论使用什么特征选择方法，其形式都是一样的。都是[ {“特征1”: True, “特征2”: True, “特征N”: True, }, 类标签 ]</p>
<h2 id="划分数据集"><a href="#划分数据集" class="headerlink" title="划分数据集"></a>划分数据集</h2><p>把用特征表示之后的文本分成开发集和测试集，把开发集分成训练集和验证集。机器学习分类必须有数据给分类算法训练，这样才能得到一个（基于训练数据的）分类器。有了分类器之后，就需要检测这个分类器的准确度。</p>
<h2 id="分类算法学习"><a href="#分类算法学习" class="headerlink" title="分类算法学习"></a>分类算法学习</h2><p>这个时候终于可以使用各种高端冷艳的机器学习算法啦！<br>我们的目标是：找到最佳的机器学习算法。<br>可以使用朴素贝叶斯（NaiveBayes），决策树（Decision Tree）等NLTK 自带的机器学习方法。也可以更进一步，使用NLTK 的scikit-learn 接口，这样就可以调用scikit-learn 里面的所有。</p>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><p>在终于得到最佳分类算法和特征维度（数量）之后，就可以动用测试集。<br>直接用最优的分类算法对测试集进行分类，得出分类结果。对比分类器的分类结果和人工标注的正确结果，给出分类器的最终准确度。</p>
<h1 id="开发实践"><a href="#开发实践" class="headerlink" title="开发实践"></a>开发实践</h1><p>本次实践只是简单的进行文本评论正反面的预测。选取的材料是京东商城酒类商品的评论。</p>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>准备人工标注好的好评和差评文本. good.txt  bad.txt</p>
<ul>
<li>好评<br><img src="/picture/machine-learning/good.jpg" alt="good"></li>
<li>差评<br><img src="/picture/machine-learning/bad.jpg" alt="bad"></li>
<li>停用词（上网查找的）<br><img src="/picture/machine-learning/stop.jpg" alt="stop"><h2 id="特征提取和选择"><a href="#特征提取和选择" class="headerlink" title="特征提取和选择"></a>特征提取和选择</h2></li>
<li>使用jieba分词对文本进行分词<br><img src="/picture/machine-learning/jieba_cut.jpg" alt="jieba"></li>
<li>构建特征<br><img src="/picture/machine-learning/feature_selection_nlp.jpg" alt="feature_selection_nlp"></li>
<li>选择特征<br><img src="/picture/machine-learning/feature_selection_nlp2.jpg" alt="feature_selection_nlp"><br><img src="/picture/machine-learning/feature_selection_nlp3.jpg" alt="feature_selection_nlp"><h2 id="划分数据集-1"><a href="#划分数据集-1" class="headerlink" title="划分数据集"></a>划分数据集</h2><img src="/picture/machine-learning/split_data.jpg" alt="split_data"><h2 id="构建分类器"><a href="#构建分类器" class="headerlink" title="构建分类器"></a>构建分类器</h2><img src="/picture/machine-learning/classifier_sentiment.jpg" alt="classifier_sentiment"><br><img src="/picture/machine-learning/classifier_sentiment2.jpg" alt="classifier_sentiment"><h2 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h2><img src="/picture/machine-learning/predict_sentiment.jpg" alt="predict_sentiment"><br>下图是朴素贝叶斯得到的结果：可以看到正确率达到了90%<br><img src="/picture/machine-learning/predict_sentiment2.jpg" alt="predict_sentiment"><br>下图是其他算法得到的结果：可以看到逻辑回归和线性SVM正确率都在96%以上，效果不错。<br><img src="/picture/machine-learning/predict_sentiment3.jpg" alt="predict_sentiment"></li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.open-open.com/lib/view/open1421114964515.html" target="_blank" rel="external">大数据文摘：斯坦福大学怎样讲“情感分析”</a><br><a href="http://www.nltk.org/" target="_blank" rel="external">NLTK官网</a><br><a href="http://streamhacker.com/" target="_blank" rel="external">StreamHacker</a><br><a href="http://andybromberg.com/sentiment-analysis-python/" target="_blank" rel="external">Andybromberg</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;自然语言处理NLP&quot;&gt;&lt;a href=&quot;#自然语言处理NLP&quot; class=&quot;headerlink&quot; title=&quot;自然语言处理NLP&quot;&gt;&lt;/a&gt;自然语言处理NLP&lt;/h1&gt;&lt;p&gt;情感分析作为自然语言处理的一个部分，让我们首先看一下自然语言处理。&lt;/p&gt;
&lt;h2 id=&quot;相关技术及运用&quot;&gt;&lt;a href=&quot;#相关技术及运用&quot; class=&quot;headerlink&quot; title=&quot;相关技术及运用&quot;&gt;&lt;/a&gt;相关技术及运用&lt;/h2&gt;&lt;p&gt;自动问答（Question Answering，QA）：它是一套可以理解复杂问题，并以充分的准确度、可信度和速度给出答案的计算系统，以IBM‘s Waston为代表；&lt;br&gt;信息抽取（Information Extraction，IE）：其目的是将非结构化或半结构化的自然语言描述文本转化结构化的数据，如自动根据邮件内容生成Calendar；&lt;br&gt;情感分析（Sentiment Analysis，SA）：又称倾向性分析和意见挖掘，它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从大量网页文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向；&lt;br&gt;机器翻译（Machine Translation，MT）：将文本从一种语言转成另一种语言，如中英机器翻译。&lt;/p&gt;
&lt;h2 id=&quot;发展现状&quot;&gt;&lt;a href=&quot;#发展现状&quot; class=&quot;headerlink&quot; title=&quot;发展现状&quot;&gt;&lt;/a&gt;发展现状&lt;/h2&gt;&lt;p&gt;基本解决：词性标注、命名实体识别、Spam识别&lt;br&gt;取得长足进展：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取&lt;br&gt;挑战：自动问答、复述、文摘、会话机器人&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/nlp_process.png&quot; alt=&quot;nlp_process&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="自然语言处理" scheme="xtf615.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"/>
    
      <category term="分词" scheme="xtf615.com/tags/%E5%88%86%E8%AF%8D/"/>
    
      <category term="NLTK" scheme="xtf615.com/tags/NLTK/"/>
    
      <category term="情感分析" scheme="xtf615.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>线性回归</title>
    <link href="xtf615.com/2017/02/09/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>xtf615.com/2017/02/09/线性回归/</id>
    <published>2017-02-09T14:27:47.000Z</published>
    <updated>2017-03-15T04:14:33.637Z</updated>
    
    <content type="html"><![CDATA[<h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><h2 id="房价预测例子"><a href="#房价预测例子" class="headerlink" title="房价预测例子"></a>房价预测例子</h2><p>  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子<br><img src="/picture/machine-learning/house_price.jpg" alt="house_price"><br>   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。下图是房价预测数据格式：<br>  <img src="/picture/machine-learning/train_set_representation.jpg" alt="train_set_representation"><br><a id="more"></a>  </p>
<h2 id="标记"><a href="#标记" class="headerlink" title="标记"></a>标记</h2><p>我们将要用来描述这个回归问题的标记如下:<br>    m代表训练集中实例的数量<br>    x代表特征/输入变量<br>    y代表目标变量/输出变量<br>    (x,y)代表训练集中的实例<br>    \((x^{(i)},y^{(i)})\) 代表第i个观察实例<br>    h代表学习算法的解决方案或函数也称为假设(hypothesis)<br><img src="/picture/machine-learning/supervised_learning.jpg" alt="supervised_learning"><br>  这就是一个监督学习算法的工作方式，我们可以看到这里有我们的训练集里房屋价格我们把它喂给我们的学习算法，学习算法的工作了，然后输出一个函数，通常表示为小写h表示。h代表   hypothesis(假设)，h表示一个函数，输入是房屋尺寸大小，就像你朋友想出售的房屋，因此h根据输入的x值来得出y值，y值对应房子的价格因此，h是一个从x到y的函数映射。<br>   我将选择最初的使用规则h代表hypothesis，因而，要解决房价预测问题，我们实际上是要将训练集“喂”给我们的学习算法，进而学习得到一个假设 h，然后将我们要预测的房屋的尺寸作为输入变量输入给h，预测出该房屋的交易价格作为输出变量输出为结果。那么，对于我们的房价预测问题，我们该如何表达h？<br>   一种可能的表达方式为：\(h_θ(x)=θ_0+θ_1x\)，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>我们将定义代价函数的概念，这有助于我们弄清楚如何把最有可能的直线与我们的数据相拟合。如图：<br><img src="/picture/machine-learning/cost_function.jpg" alt="cost_function"><br>在线性回归中我们有一个像这样的训练集，m代表了训练样本的数量，比如m=47.而我们的假设函数，也就是用来进行预测的函数，是这样的线性函数形式：\(h_θ(x)=θ_0+θ_1x\)。接下来我们会引入一些术语我们现在要做的便是为我们的模型选择合适的参数（parameters）θ0和θ1，在房价问题这个例子中便是直线的斜率和在  y轴上的截距。我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差（modeling error）。<br><img src="/picture/machine-learning/modeling_error.jpg" alt="modeling_error"><br>我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数。即使得代价函数最小：<br>$$J(\theta_{0},\theta_{1})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>我们绘制一个等高线图，三个坐标分别为 \(θ_0\) 和\(θ_1\) 和 \(J(θ_0,θ_1)\) ：<br><img src="/picture/machine-learning/contour.jpg" alt="contour"><br>可以看出在三维空间中存在一个使得 \(J(θ_0,θ_1)\) 最小的点.<br>代价函数也被称作平方误差函数，有时也被称为平方误差代价函数。我们之所以要求出<br>误差的平方和，是因为误差平方代价函数，对于大多数问题，特别是回归问题，都是一个合<br>理的选择。还有其他的代价函数也能很好地发挥作用，但是平方误差代价函数可能是解决回<br>归问题最常用的手段了。</p>
<h2 id="代价函数的理解（1）"><a href="#代价函数的理解（1）" class="headerlink" title="代价函数的理解（1）"></a>代价函数的理解（1）</h2><h3 id="Hypothesis"><a href="#Hypothesis" class="headerlink" title="Hypothesis:"></a>Hypothesis:</h3><p>$$h_\theta(x)=\theta_0+\theta_1x$$</p>
<h3 id="Parameters"><a href="#Parameters" class="headerlink" title="Parameters:"></a>Parameters:</h3><p>$$\theta_0,  \theta_1$$</p>
<h3 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function:"></a>Cost Function:</h3><p>$$J(\theta_{0},\theta_{1})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$</p>
<h3 id="Goal"><a href="#Goal" class="headerlink" title="Goal:"></a>Goal:</h3><p>$$\min_{\theta_0,\theta_1}J(\theta_0,\theta_1)$$<br><img src="/picture/machine-learning/mini_.jpg" alt="mini"><br>如上图所示，左图为 \(\theta_0=0,\theta_1=0\) 时的代价,右图为 \(\theta_0=0\),代价函数随 \(\theta_1\) 变化的情况。可以看出当 \(\theta_1=1\) 时，代价损失最低。</p>
<h2 id="代价函数的理解（2）"><a href="#代价函数的理解（2）" class="headerlink" title="代价函数的理解（2）"></a>代价函数的理解（2）</h2><p><img src="/picture/machine-learning/contour2.jpg" alt="contour2"><br>如图是代价函数的样子，等高线图，可以看出在三维空间中存在一个使得 \(J(θ_0,θ_1)\) 最小的点。<br><img src="/picture/machine-learning/contour3.jpg" alt="contour3"><br>上图右边图形为三维图的二维等高线图。<br>通过这些图形，能更好地理解这些代价函数J所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数J的最小值。<br>当然，我们真正需要的是一种有效的算法，能够自动地找出这些使代价函数J取最小值的参数\(θ_0\)和 \(θ_1\)来。<br>我们也不希望编个程序把这些点画出来，然后人工的方法来读出这些点的数值，这很明显不是一个好办法。我们会遇到更复杂、更高维度、更多参数的情况，而这些情况是很难画出图的，因此更无法将其可视化，因此我们真正需要的是编写程序来找出这些最小化代价函数的 \(θ_0\)和 \(θ_1\)的值.</p>
<h1 id="梯度下降Gradient-Descent"><a href="#梯度下降Gradient-Descent" class="headerlink" title="梯度下降Gradient Descent"></a>梯度下降Gradient Descent</h1><p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数\(J(θ_0,θ_1)\)的最小值。<br>梯度下降背后的思想是：开始时我们随机选择一个参数的组合 \((θ_0,θ_1,…,θ_n)\) ，计算代价<br>函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到到到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。<br><img src="/picture/machine-learning/hill.jpg" alt="hill"><br>想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转 360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。<br>批量梯度下降（batch gradient descent）算法的公式为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) \quad(for \ j = 0\ and\ j = 1)$$<br>}<br>其中 \(\alpha\)是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速<br>率乘以代价函数的导数。<br><img src="/picture/machine-learning/gradient_descent.jpg" alt="gradient"><br>在梯度下降算法中，还有一个更微妙的问题，梯度下降中，我们要更新\(θ_0\)和 \(θ_1\)，当j=0和j=1时，会产生更新，所以你将更新 \(J_{θ_0}\)和\(J_{θ_0}\)。实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要同时更新\(θ_0\)和 \(θ_1\).<br>让我进一步阐述这个过程：<br>$$temp_0:=\theta_0-\alpha\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)\\\\temp_1:=\theta_1-\alpha\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1) \\\ \theta_0:=temp_0 \\\ \theta_1:=temp_1$$<br>在梯度下降算法中，这是正确实现同时更新的方法。我不打算解释为什么你需要同时更新，同时更新是梯度下降中的一种常用方法。我们之后会讲到，同步更新是更自然的实现方法。当人们谈到梯度下降时，他们的意思就是同步更新。</p>
<h2 id="梯度下降理解"><a href="#梯度下降理解" class="headerlink" title="梯度下降理解"></a>梯度下降理解</h2><p>$$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)$$<br>描述：对θ赋值，使得J(θ)按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中 α是学习率（learning  rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。<br><img src="/picture/machine-learning/gradient_descent2.jpg" alt="gradient"><br>对于这个问题，求导的目的，基本上可以说取这个红点的切线，就是这样一条红色的直线，刚好与函数相切于这一点，让我们看看这条红色直线的斜率，就是这条刚好与函数曲线相切的这条直线，这条直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此，我得到的新的\(θ_1\)，\(θ_1\)更新后等于\(θ_1\)减去一个正数乘以 α。这就是我梯度下降法的更新规则：\(\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\)<br>让我们来看看如果 α太小或α太大会出现什么情况：</p>
<ul>
<li>如果α太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点，所以如果 α太小的话，可能会很慢因为它会一点点挪动，它会需要很多步才能到达全局最低点。</li>
<li>如果 α太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果 α太大，它会导致无法收敛，甚至发散。</li>
</ul>
<p>现在，还有一个问题，<strong>如果我们预先把\(θ_1\)放在一个局部的最低点，你认为下一步梯度下降法会怎样工作？</strong><br>假设你将\(θ_1\)初始化在局部最低点，在这儿，它已经在一个局部的最优处或局部最低点。<br>结果是局部最优点的导数将等于零，因为它是那条切线的斜率。这意味着你已经在局部最优点，它使得\(θ_1\)不再改变，也就是新的\(θ_1\)等于原来的\(θ_1\)，因此，如果你的参数已经处于局部最低点，那么梯度下降法更新其实什么都没做，它不会改变参数的值。这也解释了为什么即使学习速率α保持不变时，梯度下降也可以收敛到局部最低点。<br>我们来看一个例子，这是代价函数 J(θ)。<br><img src="/picture/machine-learning/gradient_descent3.jpg" alt="gradient"><br>我想找到它的最小值，首先初始化我的梯度下降算法，在那个品红色的点初始化，如果我更新一步梯度下降，也许它会带我到这个点，因为这个点的导数是相当陡的。现在，在这个绿色的点，如果我再更新一步，你会发现我的导数，也即斜率，是没那么陡的。随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所以，我再进行一步梯度下降时，我的导数项是更小的，\(θ_1\)更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。<br>回顾一下，在梯度下降法中，当我们接近局部最低点时，梯度下降法会自动采取更小的幅度，这是因为当我们接近局部最低点时，很显然在局部最低时导数等于零，所以当我们接近局部最低时，导数值会自动变得越来越小，所以梯度下降将自动采取较小的幅度，这就是梯度下降的做法。所以实际上没有必要再另外减小 α。这就是梯度下降算法，你可以用它来最小化任何代价函数 J，不只是线性回归中的代价函数J。</p>
<h2 id="梯度下降的线性回归"><a href="#梯度下降的线性回归" class="headerlink" title="梯度下降的线性回归"></a>梯度下降的线性回归</h2><p>梯度下降是很常用的算法，它不仅被用在线性回归上和线性回归模型、平方误差代价函数。接下来我们要将梯度下降和代价函数结合。我们将用到此算法，并将其应用于具体的拟合直线的线性回归算法里。<br>梯度下降算法和线性回归算法比较如图：<br><img src="/picture/machine-learning/gradient_descent_line.jpg" alt="gradient"><br>对我们之前的线性回归问题运用梯度下降法，关键在于求出代价函数的导数，即：<br>$$\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)=\frac{\partial}{\partial\theta_j}\left(\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\right)$$ </p>
<ul>
<li>j = 0时,<br>$$\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})$$</li>
<li>j = 1时，<br>$$\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)})$$<br>则算法改写成：<br><strong>repeat until convergence</strong>{<br>$$\theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)}) \\\ \theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x^{(i)})$$<br>}<br>我们刚刚使用的算法，有时也称为批量梯度下降。实际上，在机器学习中，通常不太会给算法起名字，但这个名字”批量梯度下降”，指的是在梯度下降的每一步中，我们都用到了所有的训练样本，在梯度下降中，在计算微分求导项时，我们需要进行求和运算，所以，在每一个单独的梯度下降中，我们最终都要计算这样一个东西，这个项需要对所有m个训练样本求和。因此，批量梯度下降法这个名字说明了我们需要考虑所有这一”批”训练样本，而事实上，有时也有其他类型的梯度下降法，不是这种”批量”型的，不考虑整个的训练集，而是每次只关注训练集中的一些小的子集。<br>有一种计算代价函数J最小值的数值解法，不需要梯度下降这种迭代算法。它可以在不需要多步梯度下降的情况下，也能解出代价函数J的最小值，这是另一种称为正规方程(normal equations)的方法。实际上在数据量较大的情况下，梯度下降法比正规方程要更适用一些。</li>
</ul>
<h1 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h1><h2 id="多维特征"><a href="#多维特征" class="headerlink" title="多维特征"></a>多维特征</h2><p>目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，<br>例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为\((x_1,x_2,…,x_n)\)<br><img src="/picture/machine-learning/multple_feature.jpg" alt="multiple feature"><br>增添更多特征后，我们引入一系列新的注释：<br>n代表特征的数量<br>\(x^{(i)}\) 代表第i个训练实例，是特征矩阵中的第i行，是一个向量（vector）。例如上图中：$$x^{(2)}=\begin{bmatrix} 1416 \\\ 3 \\\ 2 \\\ 40\end{bmatrix}$$</p>
<p>\(x_j^{(i)}\) 代表特征矩阵中第i行的第j个特征，也就是第i个训练实例的第j个特征。例如上图中， \(x_3^{(2)}=2\)<br>支持多变量的假设h表示为：<br>$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n$$<br>这个公式中有 n+1个参数和n个变量，为了使得公式能够简化一些，引入 \(x_0=1\)， 此时模型中的参数是一个n+1维的向量，任何一个训练实例也都是n+1维的向量，特征矩阵\(X\)的维度是m*(n+1)。因此公式可以简化为：<br>$$h_{\theta}(x)=\theta^TX$$ </p>
<h2 id="多变量梯度下降"><a href="#多变量梯度下降" class="headerlink" title="多变量梯度下降"></a>多变量梯度下降</h2><p>与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价<br>函数是所有建模误差的平方和，即：<br>$$J(\theta_{0},\theta_{1}…,\theta_{n})=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$<br>其中 \(h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+…+\theta_nx_n\)<br>我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。<br>多变量线性回归的批量梯度下降算法为：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,…,\theta_n)$$<br>}<br>即：<br><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}\left(\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\right)$$<br>}<br>求导后得到：</p>
<p><strong>repeat until convergence</strong>{<br>   $$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m((h_{\theta}(x^{(i)})-y^{(i)})*x_j^{(i)}) \\\ (simultaneously \ update \ \theta_j \ for \ j=0,1,2,…,n)$$<br>}<br>我们开始随机选择一系列的参数值，计算所有的预测结果后，再给所有的参数一个新的值，如此循环直到收敛。</p>
<h2 id="梯度下降实践——特征缩放"><a href="#梯度下降实践——特征缩放" class="headerlink" title="梯度下降实践——特征缩放"></a>梯度下降实践——特征缩放</h2><p>在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。<br>以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为   0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。<br><img src="/picture/machine-learning/feature_scale.jpg" alt="feature_scale"><br>解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。如图：<br><img src="/picture/machine-learning/feature_scale2.jpg" alt="feature_scale"><br>最简单的方法是令：<br>$$x_n = \frac{x_n-\mu_n}{S_n} \\\ 其中, \mu_n是平均值，S_n是标准差$$</p>
<h2 id="梯度下降实践——学习率"><a href="#梯度下降实践——学习率" class="headerlink" title="梯度下降实践——学习率"></a>梯度下降实践——学习率</h2><p>梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。<br><img src="/picture/machine-learning/learn_rate.jpg" alt="learn_rate"><br>梯度下降算法的每次迭代受到学习率的影响，如果学习率 α过小，则达到收敛所需的迭代次数会非常高；如果学习率 α过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。通常可以考虑尝试些学习率：\(α=0.01，0.03，0.1，0.3，1，3，10\)</p>
<h2 id="特征与多项式回归"><a href="#特征与多项式回归" class="headerlink" title="特征与多项式回归"></a>特征与多项式回归</h2><p>如房价预测问题，<br>$$h_\theta(x)=\theta_0+\theta_1*frontage+\theta_2*depth\\\ x_1=frontage(临街宽度),x_2=depth(纵向深度) \\\ x=frontage*depth=area(面积) ， 则：h_\theta(x)=\theta_0+\theta_1x$$<br>线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：<br>$$h_\theta(x)=\theta_0+\theta_1x+\theta_2x_2^2$$<br>或者三次方模型：<br>$$h_\theta(x)=\theta_0+\theta_1x+\theta_2x_2^2+\theta_3x_3^3$$<br><img src="/picture/machine-learning/polynomial_regression.jpg" alt="polynomial_regression"><br>通常我们需要先观察数据然后再决定准备尝试怎样的模型。另外，我们可以令：<br>$$x_2=x_2^2 \\\ x_3=x_3^2$$<br>从而将模型转化为线性回归模型。<br>根据函数图形特性，我们还可以使：<br>$$h_\theta(x)=\theta_0+\theta_1(size)+\theta_2(size)^2<br>\\\ 或者 \\\\<br>h_\theta(x)=\theta_0+\theta_1(size)+\theta_2\sqrt{(size)}$$<br>注：如果我们采用多项式回归模型，在运行梯度下降算法前，特征缩放非常有必要。</p>
<h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>到目前为止，我们都在使用梯度下降算法，但是对于某些线性回归问题，正规方程方法正规方程是通过求解下面的方程来找出使得代价函数最小的参数的是更好的解决方案。<br>正规方程是通过求解下面的方程来找出使得代价函数最小的参数的：<br>$$\frac{\partial}{\partial\theta_j}J(\theta_j)=0$$<br>假设我们的训练集特征矩阵为:\(X\)（包含 \(x_0=1\) ）,并且我们的训练集结果为向量   y，则利用正规方程解出向量:<br>$$\theta=\left(X^TX\right)^{-1}X^Ty \\\\<br>设矩阵A=X^TX，则：(X^TX)^{-1}=A^{-1} \\\\<br>上标T代表矩阵转置，-1代表矩阵的逆。$$</p>
<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><p><img src="/picture/machine-learning/normal_example.jpg" alt="normal_example"></p>
<p><table><br>    <tr><br>        <td>X(0)</td> <td>X(1)</td> <td>X(2)</td> <td>X(3)</td> <td>X(4)</td><td>y</td><br>    </tr><br>    <tr><br>        <td>1</td><td>2104</td> <td>5</td> <td>1</td> <td>45</td> <td>460</td><br>    </tr><br>    <tr><br>        <td>1</td><td>1416</td> <td>3</td> <td>2</td> <td>40</td> <td>232</td><br>    </tr><br>    <tr><br>        <td>1</td><td>1534</td> <td>3</td> <td>2</td> <td>30</td> <td>315</td><br>    </tr><br>    <tr><br>        <td>1</td><td>852</td> <td>2</td> <td>1</td> <td>36</td> <td>178</td><br>    </tr><br></table><br>再运用正规方程求解参数：<br><img src="/picture/machine-learning/normal_example2.jpg" alt="normal_example"><br>注：<strong>对于那些不可逆的矩阵</strong>（通常是因为特征之间不独立，如同时包含英尺为单位的尺寸和米为单位的尺寸两个特征，也有可能是特征数量大于训练集的数量），正规方程方法是不能用的。<br> |编号|说明|国外|   </p>
<h3 id="梯度下降和正规方程比较："><a href="#梯度下降和正规方程比较：" class="headerlink" title="梯度下降和正规方程比较："></a>梯度下降和正规方程比较：</h3><p><table><br>    <tr><br>        <td><strong>梯度下降</strong></td> <td><strong>正规方程</strong></td><br>    </tr><br>    <tr><br>        <td>需要选择学习率</td><td>不需要</td><br>    </tr><br>    <tr><br>        <td>需要多次迭代</td><td>一次运算得出</td><br>    </tr><br>    <tr><br>        <td>当特征数量 n大时也能较好适用</td> <td>需要计算 \((X^TX)^{-1}\) 如果特征数量n较大则运算代价大，因为矩阵逆的计算时间复杂度为 \(O(n^3)\)，通常来说当n小于10000时还是可以接受的</td><br>    </tr><br>    <tr><br>        <td>适用于各种类型的模型</td><td>只适用于线性模型，不适合逻辑回归模型等其他模型</td><br>    </tr><br></table><br>总结一下，只要特征变量的数目并不大，标准方程是一个很好的计算参数  θ的替代方法。具体地说，只要特征变量数量小于一万，我通常使用标准方程法，而不使用梯度下降法。随着学习算法越来越复杂，例如，当我们讲到分类算法，像逻辑回归算法，我们会看到，实际上对于那些算法，并不能使用标准方程法。对于那些更复杂的学习算法，我们将不得不仍然使用梯度下降法。因此，梯度下降法是一个非常有用的算法，可以用在有大量特征变量的线性回归问题。</p>
<h3 id="正规方程之不可逆性"><a href="#正规方程之不可逆性" class="headerlink" title="正规方程之不可逆性"></a>正规方程之不可逆性</h3><p>我们要讲的问题如下：<br>$$\theta=\left(X^TX\right)^{-1}X^Ty$$<br>对于矩阵，\(X^TX\) 不可逆的情况怎么解决？<br>如果你懂一点线性代数的知识，你或许会知道，有些矩阵可逆，而有些矩阵不可逆。我们称那些不可逆矩阵为奇异或退化矩阵。问题的重点在于 X’X的不可逆的问题很少发生。</p>
<ul>
<li>特征值存在线性关联。<br>例如，在预测住房价格时，如果x1是以英尺为尺寸规格计算的房子，x2是以平方米为尺寸规格计算的房子，同时，你也知道 1米等于3.28英尺(四舍五入到两位小数)，这样，你的这两个特征值将始终满足约束：\(x_1=x_2*(3.28)\)。</li>
<li>大量的特征<br>第二个原因是，在你想用大量的特征值，尝试实践你的学习算法的时候，可能会导致矩阵 \(X^TX\)的结果是不可逆的。<br>具体地说，在 m小于或等于n的时候，例如，有m等于10个的训练样本,n等于100的特征数量。要找到适合的(n+1)维参数矢量\(θ\)，这将会变成一个101维的矢量，尝试从10个训练样本中找到满足101个参数的值，这工作可能会让你花上一阵.<br>稍后我们将看到，如何使用小数据样本以得到这 100或  101个参数，通常，我们会使用一种叫做正则化的线性代数方法，通过删除某些特征或者是使用某些技术，来解决当m比n小的时候的问题。即使你有一个相对较小的训练集，也可使用很多的特征来找到很多合适的参数。</li>
</ul>
<p><strong>总之当你发现的矩阵 X’X的结果是奇异矩阵，或者找到的其它矩阵是不可逆的，要怎么做？</strong><br>首先，看特征值里是否有一些多余的特征，像这些 x1和x2是线性相关的，互为线性函数。同时，当有一些多余的特征时，可以删除这两个重复特征里的其中一个，无须两个特征同时保留，将解决不可逆性的问题。如果特征数量实在太多，我会删除些用较少的特征来反映尽可能多内容，否则我会考虑使用正规化方法。</p>
<h1 id="拓展-广义线性模型与线性回归"><a href="#拓展-广义线性模型与线性回归" class="headerlink" title="拓展 广义线性模型与线性回归"></a>拓展 广义线性模型与线性回归</h1><p>线性回归是广义线性模型的一种特殊形式。</p>
<h2 id="广义线性模型GLM"><a href="#广义线性模型GLM" class="headerlink" title="广义线性模型GLM"></a>广义线性模型GLM</h2><p>三个假设：</p>
<ul>
<li>\(y|x;\sim ExponentialFamily(\eta) \)，即y的条件概率属于指数分布簇（The exponential Family）</li>
<li>给定x广义线性模型的目标是求解\(T(y)|x\),不过由于很多情况下\(T(y)=y\),所以我们的目标就变成\(y|x\),也即我们希望拟合函数为\(h(x)=E[y|x]\) (备注：这个条件在线性回归中满足)</li>
<li>自然参数\(\eta\)与\(x\)是线性关系：\(\eta=\theta^Tx\) (\(\eta为向量时,\eta_i=\theta_i^Tx\))</li>
</ul>
<h2 id="指数分布簇-The-exponential-Family）"><a href="#指数分布簇-The-exponential-Family）" class="headerlink" title="指数分布簇(The exponential Family）"></a>指数分布簇(The exponential Family）</h2><p>首先定义一下指数分布，它有如下形式:<br>$$p(y;\eta)=b(y)exp(\eta^{T}T(y)-a(\eta)) \\\\<br>其中，\eta是自然参数(natural \ parameter), \\\ <br>T(y)是充分统计量(sufficient \ statistic,一般T(y)=y),\\\\<br>a(\eta)是log \ partition \ function(e^{-a(\eta)}充当正规化常量的角色，保证\sum p(y;\eta)=1)<br>$$<br>也就是说，T,a,b确定了一种分布，\(\eta\)是该分布的参数。选择合适的T,a,b我们可以得到高斯分布Gaussian和伯努利分布Bernoulli等。</p>
<p>即，有了广义线性模型，我们只需要把符合指数分布的一般模型的参数转换为它对应的广义线性模型参数，然后按照广义线性模型的求解步骤，即可轻松求解问题。</p>
<h2 id="Gaussian高斯分布的指数分布簇形式"><a href="#Gaussian高斯分布的指数分布簇形式" class="headerlink" title="Gaussian高斯分布的指数分布簇形式"></a>Gaussian高斯分布的指数分布簇形式</h2><p>在线性回归中，\(\sigma对于模型参数\theta的选择没有影响，为了推导方便我们将其设为1：\)<br>$$p(y;\mu)=\frac{1}{\sqrt{2\pi}}exp\left(-\frac{1}{2}(y-\mu)^2\right) \\\\<br>    = \frac{1}{\sqrt{2\pi}}exp\left(-\frac{1}{2}y^2\right)*exp\left(\mu y-\frac{1}{2}\mu^2\right)<br>$$<br>得到对应参数：<br>$$T(y)=y \\\\<br>\eta=\mu \\\\<br>a(\eta)=\mu^2/2=\eta^2/2 \\\\<br>b(y)=(1/\sqrt{2\pi})exp(-y^2/2)<br>$$</p>
<h2 id="广义线性模型推导线性回归"><a href="#广义线性模型推导线性回归" class="headerlink" title="广义线性模型推导线性回归"></a>广义线性模型推导线性回归</h2><p>我们重新审视一下线性回归,线性回归的表达如下：<br>$$y=\theta^TX+\epsilon$$<br>最重要的假设是，我们认为\(\epsilon\)满足均值为0，方差为\(\sigma^2\)的高斯分布，且满足\(iid\),即独立同分布,  $$\\\epsilon \sim N(0,\sigma^2)$$<br>因此有\(E(\epsilon)=0\),根据上述线性回归表达式我们实际上有，\(E(y)=E(\theta^TX+\epsilon)\), 可以得出y实际上是满足均值为\(\theta^TX\),方差为\(\sigma^2\)的高斯分布，这里的y可以写做\(y|x;\theta\),即：<br>$$y|x;\theta \sim N(\theta^TX,\sigma^2)$$</p>
<p>下面从广义线性模型角度进行推导：</p>
<ul>
<li>step1: \(y|x; \sim N(\mu,\theta)\)</li>
<li>step2: 由假设2: \(h(x)=E[y|x]\) 得到：<br>$$h_\theta(x)=E[y|x;\Theta]\\\\<br>=\mu \\\\<br>=\eta  \\\\<br>=\Theta^Tx  \\\\<br>其中, E[y|x;\Theta]=\mu由假设1得到；\\\\<br>\mu=\eta由高斯分布对应的广义线性模型参数得到；\\\\<br>\eta = \Theta^Tx由假设3得到。<br>$$<br>可以看出\(h_\theta(x)=E[y|x;\Theta]=\Theta^Tx\), \(h_\theta(x)\)实际上就是\(y|x;\theta\)的期望，跟最初的假设是一致的。最后注意一下，\(\theta\)不是随机变量，我们把它看作是某个固定的值，我们要找到这个固定的值。</li>
</ul>
<h2 id="代价函数推导"><a href="#代价函数推导" class="headerlink" title="代价函数推导"></a>代价函数推导</h2><p>根据前面的假设，我们知道\(\epsilon\)满足独立同分布。<br>根据最大似然估计法，我们定义：<br>$$L(\theta)=P(y|X;\theta)$$<br>我们希望每个样本出现的概率最大。再根据独立同分布假设以及高斯分布概率密度函数，我们有：<br>$$L(\theta)=P(y|X;\theta)=\prod_{i=1}^mP(y^{(i)}|x^{(i)};\theta) \\\\<br>=\prod_{i=1}^m\frac{1}{\sqrt{2\pi}\sigma}exp\left(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)<br>$$<br>两边取对数，有:<br>$$l(\theta)=log(L(\theta))=mlog(\frac{1}{\sqrt{2\pi}\sigma})+\sum_{i=1}^m\left(-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\right)$$</p>
<p>为了使\(l(\theta)\)最大化，我们需要最小化：<br>$$\frac{1}{2}\sum_{i=1}^m(y^{(i)}-\theta^Tx^{(i)})^2$$<br>再调整系数，我们取样本平均，得到：<br>$$J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2$$</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以看出，广义线性模型要求被解释变量属于指数分布簇。为什么呢？<br>逆推：被解释变量属于指数分布簇-&gt;被解释变可以写成指数分布的形式-&gt;其指数分布形式的参数\(\eta\)与原分布参数会发生联系-&gt;联系的方式是\(\eta=f(原分布中的参数,比如\mu等，则f(\mu)即连接函数)\)</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a><br><a href="https://www.zhihu.com/question/47637500?sort=created" target="_blank" rel="external">知乎：为什么广义线性模型GLM要求被解释变量属于指数分布簇</a><br><a href="https://zhuanlan.zhihu.com/p/22876460" target="_blank" rel="external">知乎：广义线性模型</a>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;模型表示&quot;&gt;&lt;a href=&quot;#模型表示&quot; class=&quot;headerlink&quot; title=&quot;模型表示&quot;&gt;&lt;/a&gt;模型表示&lt;/h1&gt;&lt;h2 id=&quot;房价预测例子&quot;&gt;&lt;a href=&quot;#房价预测例子&quot; class=&quot;headerlink&quot; title=&quot;房价预测例子&quot;&gt;&lt;/a&gt;房价预测例子&lt;/h2&gt;&lt;p&gt;  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子&lt;br&gt;&lt;img src=&quot;/picture/machine-learning/house_price.jpg&quot; alt=&quot;house_price&quot;&gt;&lt;br&gt;   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。下图是房价预测数据格式：&lt;br&gt;  &lt;img src=&quot;/picture/machine-learning/train_set_representation.jpg&quot; alt=&quot;train_set_representation&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="线性回归" scheme="xtf615.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
      <category term="广义线性模型" scheme="xtf615.com/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="梯度下降" scheme="xtf615.com/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    
  </entry>
  
  <entry>
    <title>机器学习概念</title>
    <link href="xtf615.com/2017/01/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B5/"/>
    <id>xtf615.com/2017/01/18/机器学习概念/</id>
    <published>2017-01-18T01:25:34.000Z</published>
    <updated>2017-01-18T03:56:17.623Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>机器学习是目前信息技术中最激动人心的方向之一。你或许每天都在不知不觉中使用了机器学习的算法。</p>
<ul>
<li>你打开谷歌、必应搜索到你需要的内容，正是因为他们有良好的学习算法，谷歌和微软实现了学习算法来排行网页。</li>
<li>你用Facebook或苹果的图片分类程序他能认出你朋友的照片，这也是机器学习。</li>
<li>每次您阅读您的电子邮件垃圾邮件筛选器，可以帮你过滤大量的垃圾邮件这也是一种学习算法。</li>
</ul>
<p><strong>那么，为什么机器学习如此受欢迎呢？</strong><br>机器学习不只是用于人工智能领域。我们创造智能的机器，有很多基础的知识。比如，我们可以让机器找到A与B之间的最短路径，但我们仍然不知道怎么让机器做更有趣的事情，如web搜索、照片标记、反垃圾邮件。我们发现，<strong>唯一方法是让机器自己学习怎么来解决问题</strong>。所以，机器学习已经成为计算机的一个能力，现在它涉及到各个行业和基础科学中。</p>
<p><strong>这里有一些机器学习的案例。</strong></p>
<ul>
<li><strong>数据挖掘</strong>。机器学习被用于数据挖掘的原因之一是网络和自动化技术的增长，这意味着，我们有史上最大的数据集比如说，大量的硅谷公司正在收集  web上的单击数据，也称为点击流数据，并尝试使用机器学习算法来分析数据，更好的了解用户，并为用户提供更好的服务。这在硅谷有巨大的市场。</li>
<li><strong>医疗记录</strong>。随着自动化的出现，我们现在有了电子医疗记录。如果我们可以把医疗记录变成医学知识，我们就可以更好地理解疾病。</li>
<li><strong>计算生物学</strong>。还是因为自动化技术，生物学家们收集的大量基因数据序列、DNA序列和等等，机器运行算法让我们更好地了解人类基因组，大家都知道这对人类意味着什么。</li>
<li><strong>工程方面</strong>。在工程的所有领域，我们有越来越大、越来越大的数据集，我们试图使用学习算法，来理解这些数据。另外，在机械应用中，有些人不能直接操作。例如，我已经在无人直升机领域工作了许多年。我们不知道如何写一段程序让直升机自己飞。我们唯一能做的就是让计算机自己学习如何驾驶直升机。</li>
<li><p><strong>手写识别</strong>。现在我们能够非常便宜地把信寄到这个美国甚至全世界的原因之一就是当你<br>写一个像这样的信封，一种学习算法已经学会如何读你信封，它可以自动选择路径，所以我们只需要花几个美分把这封信寄到数千英里外。</p>
</li>
<li><p><strong>自然语言处理或计算机视觉</strong>。这些语言理解或图像理解都是属于AI领域。大部分的自然语言处理和大部分的计算机视觉，都应用了机器学习。学习算法还广泛用于自定制程序。每次你去亚马逊或 Netflix或  iTunes Genius，它都会给出其他电影或产品或音乐的建议，这是一种学习算法。仔细想一想，他们有百万的用户；但他们没有办法为百万用户，编写百万个不同程序。软件能给这些自定制的建议的唯一方法是通过学习你的行为，来为你定制服务。</p>
<a id="more"></a>
</li>
</ul>
<h1 id="机器学习概念"><a href="#机器学习概念" class="headerlink" title="机器学习概念"></a>机器学习概念</h1><ul>
<li><strong>Arthur Samuel</strong>： 他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。<br>   <code>Samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。然后就牛逼大发了，程序通过学习后，玩西洋棋的水平超过了Samuel。这绝对是令人注目的成果。</code></li>
<li><strong>Tom Mitchell</strong>: 一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。<br>   <code>e就是程序上万次的自我练习的经验, 而任务t就是下棋。性能度量值p呢，就是它在与一些新的对手比赛时，赢得比赛的概率。</code></li>
</ul>
<h1 id="监督学习概念"><a href="#监督学习概念" class="headerlink" title="监督学习概念"></a>监督学习概念</h1><ul>
<li><strong>回归问题</strong>（房价预测）：<br><img src="/picture/machine-learning/house_price_prediction.jpg" alt="house_price_prediction"><br>我们应用学习算法，可以在这组数据中画一条直线，或者换句话说，拟合一条直线，根据这条线我们可以推测出，这套房子可能卖$150, 000，当然这不是唯一的算法。可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近$200, 000。<br>可以看出，<strong>监督学习指的就是我们给学习算法一个数据集，这个数据集由“正确答案”组成。</strong>在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做回归问题。我们试着推测出一个连续值的结果，即房子的价格。一般房子的价格会记到美分，所以房价实际上是一系列离散的值，但是我们通常又把房价看成实数，看成是标量，所以又把它看成一个连续的数值。</li>
<li><strong>分类问题</strong>（乳腺癌良性与否）：<br><img src="/picture/machine-learning/breast_cancer.jpg" alt="breast_cancer"><br> 假设说你想通过查看病历来推测乳腺癌良性与否，假如有人检测出乳腺肿瘤，恶性肿瘤有害并且十分危险，而良性的肿瘤危害就没那么大，所以人们显然会很在意这个问题。让我们来看一组数据：这个数据集中，横轴表示肿瘤的大小，纵轴上，我标出 1和  0表示是或者不是恶性肿瘤。我们之前见过的肿瘤，如果是恶性则记为 1，不是恶性，或者说良性记为 0。我有 5个良性肿瘤样本，在1的位置有5个恶性肿瘤样本。现在我们有一个朋友很不幸检查出乳腺肿瘤。假设说她的肿瘤大概这么大，那么机器学习的问题就在于，你能否估算出肿瘤是恶性的或是良性的概率。用术语来讲，这是一个分类问题。分类指的是，我们试着推测出离散的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。比如说可能有三种乳腺癌，所以你希望预测离散输出  0、1、2、3。0代表良性，1表示第一类乳腺癌，2表示第二类癌症，3表示第三类，但这也是分类问题。因为这几个离散的输出分别对应良性，第一类第二类或者第三类癌症，在分类问题中我们可以用另一种方式绘制这些数据点。现在我用不同的符号来表示这些数据。既然我们把肿瘤的尺寸看做区分恶性或良性的特征，那么我可以这么画，我用不同的符号来表示良性和恶性肿瘤。或者说是负样本和正样本现在我们不全部画 X，良性的肿瘤改成用 O表示，恶性的继续用  X表示。来预测肿瘤的恶性与否。在其它一些机器学习问题中，可能会遇到不止一种特征。举个例子，我们不仅知道肿瘤的尺寸，还知道对应患者的年龄。在其他机器学习问题中，我们通常有更多的特征，比如肿块密度，肿瘤细胞尺寸的一致性和形状的一致性等等，还有一些其他的特征。这就是我们即将学到最有趣的学习算法之一。</li>
<li><strong>总结</strong><br>现在来回顾一下，这节课我们介绍了监督学习。其基本思想是，<strong>我们数据集中的每个样本都有相应的“正确答案”。</strong>再根据这些样本作出预测，就像房子和肿瘤的例子中做的那样。我们还介绍了回归问题，即通过回归来推出一个连续的输出，之后我们介绍了分类问题，其目标是推出一组离散的结果。</li>
</ul>
<h1 id="无监督学习概念"><a href="#无监督学习概念" class="headerlink" title="无监督学习概念"></a>无监督学习概念</h1><p>   &emsp;在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子，即<strong>无监督学习中没有任何的标签或者是有相同的标签或者就是没标签</strong>。所以我们已知数据集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同的簇。所以叫做聚类算法。事实证明，它能被用在很多地方。</p>
<ul>
<li><strong>谷歌新闻</strong>：<br>聚类应用的一个例子就是在谷歌新闻中。如果你以前从来没见过它，你可以到这个  URL网址 news.google.com去看看。谷歌新闻每天都在，收集非常多，非常多的网络的新闻内容。它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件，自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。事实证明，聚类算法和无监督学习算法同样还用在很多其它的问题上。</li>
<li><strong>基因学</strong>：<br><img src="/picture/machine-learning/DNA.jpg" alt="DNA"><br>一个 DNA微观数据的例子。基本思想是输入一组不同个体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的类或不同类型的组（人）……</li>
<li><strong>组织大型计算机集群</strong>:<br>在大数据中心工作，那里有大型的计算机集群，他们想解决什么样的机器易于协同地工作，如果你能够让那些机器协同工作，你就能让你的数据中心工作得更高效。</li>
<li><strong>社交网络</strong>:<br>所以已知你朋友的信息，比如你经常发email的，或是你Facebook的朋友、谷歌+圈子的朋友，我们能否自动地给出朋友的分组呢？即每组里的人们彼此都熟识，认识组里的所有人？</li>
<li><strong>市场分割</strong>：<br>许多公司有大型的数据库，存储消费者信息。所以，你能检索这些顾客数据集，自动地发现市场分类，并自动地把顾客划分到不同的细分市场中，你才能自动并更有效地销售或不同的细分市场一起进行销售。</li>
<li><strong>天文数据分析</strong>：<br>这些聚类算法给出了令人惊讶、有趣、有用的理论，解释了星系是如何诞生的。这些都是聚类的例子，聚类只是无监督学习中的一种。</li>
<li><strong>语音识别</strong>：<br><img src="/picture/machine-learning/cocktail_party.jpg" alt="party"><br>鸡尾酒宴问题。嗯，你参加过鸡尾酒宴吧？你可以想像下，有个宴会房间里满是人，全部坐着，都在聊天，这么多人同时在聊天，声音彼此重叠，因为每个人都在说话，同一时间都在说话，你几乎听不到你面前那人的声音。所以，可能在一个这样的鸡尾酒宴中的两个人，他俩同时都在说话，假设现在是在个有些小的鸡尾酒宴中。我们放两个麦克风在房间中，因为这些麦克风在两个地方，离说话人的距离不同每个麦克风记录下不同的声音，虽然是同样的两个说话人。听起来像是份录音被叠加到一起，或是被归结到一起，产生了我们现在的这些录音。另外，这个算法还会区分出两个音频资源，这两个可以合成或合并成之前的录音，实际上，鸡尾酒算法的第一个输出结果是：1，2，3，4，5，6，7，8，9，10。<br>看看这个无监督学习算法，实现这个得要多么的复杂，是吧？它似乎是这样，为了构建这个应用，完成这个音频处理似乎需要你去写大量的代码或链接到一堆的合成器JAVA库,处理音频的库，看上去绝对是个复杂的程序，去完成这个从音频中分离出音频。事实上，这个算法对应你刚才知道的那个问题的算法可以就用一行代码来完成.就是这里展示的代码：<br><code>[W,s,v] = svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&#39;);</code><br>研究人员花费了大量时间才最终实现这行代码。我不是说这个是简单的问题，但它证明了，当你使用正确的编程环境，许多学习算法是相当短的程序。所以，这也是为什么在本课中，我们打算使用 Octave编程环境。Octave,是免费的开源软件，使用一个像Octave或Matlab的工具，许多学习算法变得只有几行代码就可实现。</li>
</ul>
<p>所以这个就是无监督学习，因为我们没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是说，是的，这是有一堆数据。我不知道数据里面有什么。我不知道谁是什么类型。我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？就是说你要自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://open.163.com/special/opencourse/machinelearning.html" target="_blank" rel="external">斯坦福大学机器学习视频教程</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;机器学习是目前信息技术中最激动人心的方向之一。你或许每天都在不知不觉中使用了机器学习的算法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你打开谷歌、必应搜索到你需要的内容，正是因为他们有良好的学习算法，谷歌和微软实现了学习算法来排行网页。&lt;/li&gt;
&lt;li&gt;你用Facebook或苹果的图片分类程序他能认出你朋友的照片，这也是机器学习。&lt;/li&gt;
&lt;li&gt;每次您阅读您的电子邮件垃圾邮件筛选器，可以帮你过滤大量的垃圾邮件这也是一种学习算法。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;那么，为什么机器学习如此受欢迎呢？&lt;/strong&gt;&lt;br&gt;机器学习不只是用于人工智能领域。我们创造智能的机器，有很多基础的知识。比如，我们可以让机器找到A与B之间的最短路径，但我们仍然不知道怎么让机器做更有趣的事情，如web搜索、照片标记、反垃圾邮件。我们发现，&lt;strong&gt;唯一方法是让机器自己学习怎么来解决问题&lt;/strong&gt;。所以，机器学习已经成为计算机的一个能力，现在它涉及到各个行业和基础科学中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这里有一些机器学习的案例。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据挖掘&lt;/strong&gt;。机器学习被用于数据挖掘的原因之一是网络和自动化技术的增长，这意味着，我们有史上最大的数据集比如说，大量的硅谷公司正在收集  web上的单击数据，也称为点击流数据，并尝试使用机器学习算法来分析数据，更好的了解用户，并为用户提供更好的服务。这在硅谷有巨大的市场。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;医疗记录&lt;/strong&gt;。随着自动化的出现，我们现在有了电子医疗记录。如果我们可以把医疗记录变成医学知识，我们就可以更好地理解疾病。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;计算生物学&lt;/strong&gt;。还是因为自动化技术，生物学家们收集的大量基因数据序列、DNA序列和等等，机器运行算法让我们更好地了解人类基因组，大家都知道这对人类意味着什么。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工程方面&lt;/strong&gt;。在工程的所有领域，我们有越来越大、越来越大的数据集，我们试图使用学习算法，来理解这些数据。另外，在机械应用中，有些人不能直接操作。例如，我已经在无人直升机领域工作了许多年。我们不知道如何写一段程序让直升机自己飞。我们唯一能做的就是让计算机自己学习如何驾驶直升机。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;手写识别&lt;/strong&gt;。现在我们能够非常便宜地把信寄到这个美国甚至全世界的原因之一就是当你&lt;br&gt;写一个像这样的信封，一种学习算法已经学会如何读你信封，它可以自动选择路径，所以我们只需要花几个美分把这封信寄到数千英里外。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;自然语言处理或计算机视觉&lt;/strong&gt;。这些语言理解或图像理解都是属于AI领域。大部分的自然语言处理和大部分的计算机视觉，都应用了机器学习。学习算法还广泛用于自定制程序。每次你去亚马逊或 Netflix或  iTunes Genius，它都会给出其他电影或产品或音乐的建议，这是一种学习算法。仔细想一想，他们有百万的用户；但他们没有办法为百万用户，编写百万个不同程序。软件能给这些自定制的建议的唯一方法是通过学习你的行为，来为你定制服务。&lt;/p&gt;
    
    </summary>
    
      <category term="机器学习" scheme="xtf615.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="人工智能" scheme="xtf615.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="xtf615.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="概念" scheme="xtf615.com/tags/%E6%A6%82%E5%BF%B5/"/>
    
  </entry>
  
  <entry>
    <title>windows下idea编程实现远程发布任务到Spark集群</title>
    <link href="xtf615.com/2016/12/30/windows%E4%B8%8Bidea%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E5%8F%91%E5%B8%83%E4%BB%BB%E5%8A%A1%E5%88%B0Spark%E9%9B%86%E7%BE%A4/"/>
    <id>xtf615.com/2016/12/30/windows下idea编程实现远程发布任务到Spark集群/</id>
    <published>2016-12-30T11:47:13.000Z</published>
    <updated>2017-01-06T01:26:30.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本文的目标是：在windows下，使用idea编写spark任务，并可直接右键运行提交至远程Linux Spark集群上，不需要打包后再拷贝至远程Linux服务器上，再使用命令运行。</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul>
<li>软件<ul>
<li>win10</li>
<li>jdk1.7(windows版本:1.7.0_79)</li>
<li>scala2.11.8(windows版本：scala-2.11.8.zip)</li>
<li>idea 2016.3.2(windows版本：ideaIU-2016.3.2.exe)</li>
<li>hadoop2.7.3(linux版本：hadoop-2.7.3.tar.gz)</li>
<li>spark2.0.2(linux版本：spark-2.0.2-bin-hadoop2.7.tgz)</li>
<li>idea scala插件（scala-intellij-bin-2016.3.4.zip，<a href="https://plugins.jetbrains.com/idea/plugin/1347-scala）" target="_blank" rel="external">https://plugins.jetbrains.com/idea/plugin/1347-scala）</a></li>
<li>winutil.exe等（<a href="https://github.com/xuetf/spark/blob/master/idea/hadoop-common-2.2.0-bin.rar?raw=true" target="_blank" rel="external">winutil下载地址</a>）</li>
<li>maven3.3.9(windows版本：apache-maven-3.3.9-bin.zip)<a id="more"></a></li>
</ul>
</li>
<li>搭建Spark集群<br><a href="/2016/12/29/Spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">分布式Spark集群搭建</a></li>
<li>配置windows环境变量<ul>
<li>jdk(windows版本) JAVA_HOME</li>
<li>scala(windows版本) SCALA_HOME</li>
<li>hadoop(linux版本) HADOOP_HOME</li>
<li>maven(windows版本) MAVEN_HOME<br><strong>注意：以上环境变量均在windows下配置，括号中强调了软件包的平台版本。</strong></li>
</ul>
</li>
<li><p>配置idea</p>
<ul>
<li><p>maven配置：</p>
<ul>
<li><p><strong>修改setting.xml</strong><br>修改%MAVEN_HOME%下的conf/setting.xml为阿里云镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">在mirrors节点添加：</div><div class="line">&lt;mirror&gt; </div><div class="line">    &lt;id&gt;nexus-aliyun&lt;/id&gt;</div><div class="line">    &lt;name&gt;Nexus aliyun&lt;/name&gt;</div><div class="line">    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; </div><div class="line">    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; </div><div class="line">&lt;/mirror&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>修改idea的maven配置</strong><br>主要是为了加快建立maven项目时的速度<br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_setting1.png" alt="maven-idea-setting1"><br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_setting2.png" alt="maven-idea-setting2"> </p>
</li>
</ul>
</li>
<li><p>scala pluin配置<br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/idea_scala_plugin1.png" alt="scala-idea-setting1"><br> <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/idea_scala_plugin2.png" alt="scala-idea-setting1">     </p>
</li>
</ul>
</li>
</ul>
<h1 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h1><ul>
<li><strong>新建MAVEN+SCALA项目</strong><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala.png" alt="maven-scala1"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala2.png" alt="maven-scala2"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala3.png" alt="maven-scala3"> </li>
<li><p><strong>配置JDK、SCALA</strong><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/maven_scala4.png" alt="maven-scala4"> </p>
</li>
<li><p><strong>添加POM依赖</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;properties&gt;</div><div class="line">  &lt;spark.version&gt;2.0.2&lt;/spark.version&gt;</div><div class="line">  &lt;scala.version&gt;2.11&lt;/scala.version&gt;</div><div class="line">&lt;/properties&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;spark-core_$&#123;scala.version&#125;&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;$&#123;spark.version&#125;&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;2.6.0&lt;/version&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>编写代码</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</div><div class="line">import scala.math.random</div><div class="line">object SparkPi &#123;</div><div class="line">  def main(args:Array[String]):Unit = &#123;</div><div class="line">    val conf = new SparkConf().setAppName(&quot;Spark Pi&quot;).setMaster(&quot;spark://172.16.21.121:7077&quot;)</div><div class="line">      .setJars(List(&quot;E:\\idea-workspace\\spark-practice\\out\\artifacts\\spark_practice_jar\\spark-practice.jar&quot;));</div><div class="line"></div><div class="line">    val spark = new SparkContext(conf)</div><div class="line">    val slices = if (args.length &gt; 0) args(0).toInt else 2</div><div class="line">    val n = 100000 * slices</div><div class="line">    val count = spark.parallelize(1 to n, slices).map &#123; i =&gt;</div><div class="line">      val x = random * 2 - 1</div><div class="line">      val y = random * 2 - 1</div><div class="line">      if (x * x + y * y &lt; 1) 1 else 0</div><div class="line">    &#125;.reduce(_ + _)</div><div class="line">    println(&quot;Pi is roughly &quot; + 4.0 * count / n)</div><div class="line">    spark.stop()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  其中setMaster为：spark主节点的地址。setjars为下面步骤生成的jar包在window路径下的目录</p>
</li>
<li><p>添加输出sparkdemo.jar<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts1.png" alt="artifacts1"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts2.png" alt="artifacts2"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts3.png" alt="artifacts3"><br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/artifacts4.png" alt="artifacts4"> </p>
</li>
<li><p>编译代码<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/build.png" alt="build"> </p>
</li>
<li><p><strong>删除输出的sparkdemo.jar中META-INF中多余文件</strong><br>只保留MANIFEST.MF和MAVEN文件夹<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/sparkdemo_mete_inf_delete.png" alt="delete"> </p>
</li>
<li><p><strong>include in build勾掉</strong><br>防止右键运行的时候，重新输出，导致mete-inf又恢复了<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/build2.png" alt="去掉include in build"> </p>
</li>
<li><p>设置VM参数<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/vm.png" alt="VM参数"> </p>
</li>
<li>右键运行<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/run-result.png" alt="run1"> </li>
<li>运行时可查看web控制台<br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/spark-running.png" alt="run2"><br><img src="https://raw.githubusercontent.com/xuetf/spark/master/idea/spark-finished.png" alt="run3"> </li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;p&gt;本文的目标是：在windows下，使用idea编写spark任务，并可直接右键运行提交至远程Linux Spark集群上，不需要打包后再拷贝至远程Linux服务器上，再使用命令运行。&lt;/p&gt;
&lt;h1 id=&quot;准备工作&quot;&gt;&lt;a href=&quot;#准备工作&quot; class=&quot;headerlink&quot; title=&quot;准备工作&quot;&gt;&lt;/a&gt;准备工作&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;软件&lt;ul&gt;
&lt;li&gt;win10&lt;/li&gt;
&lt;li&gt;jdk1.7(windows版本:1.7.0_79)&lt;/li&gt;
&lt;li&gt;scala2.11.8(windows版本：scala-2.11.8.zip)&lt;/li&gt;
&lt;li&gt;idea 2016.3.2(windows版本：ideaIU-2016.3.2.exe)&lt;/li&gt;
&lt;li&gt;hadoop2.7.3(linux版本：hadoop-2.7.3.tar.gz)&lt;/li&gt;
&lt;li&gt;spark2.0.2(linux版本：spark-2.0.2-bin-hadoop2.7.tgz)&lt;/li&gt;
&lt;li&gt;idea scala插件（scala-intellij-bin-2016.3.4.zip，&lt;a href=&quot;https://plugins.jetbrains.com/idea/plugin/1347-scala）&quot;&gt;https://plugins.jetbrains.com/idea/plugin/1347-scala）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;winutil.exe等（&lt;a href=&quot;https://github.com/xuetf/spark/blob/master/idea/hadoop-common-2.2.0-bin.rar?raw=true&quot;&gt;winutil下载地址&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;maven3.3.9(windows版本：apache-maven-3.3.9-bin.zip)
    
    </summary>
    
      <category term="spark" scheme="xtf615.com/categories/spark/"/>
    
    
      <category term="spark" scheme="xtf615.com/tags/spark/"/>
    
      <category term="idea" scheme="xtf615.com/tags/idea/"/>
    
      <category term="scala" scheme="xtf615.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>spark分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/Spark%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/Spark分布式环境搭建教程/</id>
    <published>2016-12-29T13:31:00.000Z</published>
    <updated>2016-12-29T15:34:47.954Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>  本文是对spark2.0.2分布式集群搭建的一个详细说明。旨在通过阅读该文章帮助开发人员快速搭建spark分布式集群。</p>
<h1 id="三种集群资源管理概述"><a href="#三种集群资源管理概述" class="headerlink" title="三种集群资源管理概述"></a>三种集群资源管理概述</h1><ul>
<li><p>Spark Standalone<br>作为Spark的一部分,Standalone是一个简单的集群管理器。它具有master的HA，弹性应对WorkerFailures，对每个应用程序的管理资源的能力，并且可以在现有的Hadoop一起运行和访问HDFS的数据。该发行版包括一些脚本，可以很容易地部署在本地或在AmazonEC2云计算。它可以在Linux，Windows或Mac OSX上运行。</p>
</li>
<li><p>Apache Mesos<br>Apache Mesos ,分布式系统内核，具有HA的masters和slaves，可以管理每个应用程序的资源，并对Docker容器有很好的支持。它可以运行Spark工作， Hadoop的MapReduce的，或任何其他服务的应用程序。它有Java， Python和C ++ 的API。它可以在Linux或Mac OSX上运行。</p>
</li>
<li><p>Hadoop YARN<br>Hadoop YARN，作业调度和集群资源管理的分布式计算框架，具有HA为masters和slaves，在非安全模式下支持Docker容器，在安全模式下支持Linux和Windows Container executors，和可插拔的调度器。它可以运行在Linux和Windows上运行。</p>
</li>
</ul>
<p><strong>本文将使用Hadoop YARN方式进行集群搭建。</strong><br><a id="more"></a></p>
<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ul>
<li><p><strong>装有centOS7的3台服务器</strong></p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">master 172.16.21.121</div><div class="line">node1  172.16.21.129</div><div class="line">node2  172.16.21.130</div></pre></td></tr></table></figure>
</li>
<li><p><strong>搭建hadoop集群环境</strong><br><a href="/2016/12/29/hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/">hadoop分布式环境搭建教程</a></p>
</li>
<li><p><strong>scala: scala-2.12.1.tgz</strong></p>
</li>
<li><strong>spark: sprak-2.0.2-bin-hadoop2.7.tgz</strong></li>
<li><strong>上传sacala和spark到3台服务器</strong><!--more-->
<h1 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h1></li>
<li><strong>解压到/usr/local/scala</strong></li>
<li><p><strong>配置环境变量</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SCALA_HOME=/usr/local/scala/scala-2.12.1</div><div class="line">export PATH=$PATH:$SCALA_HOME/bin</div></pre></td></tr></table></figure>
<p>  scala -version查看版本</p>
</li>
</ul>
<h1 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h1><ul>
<li><strong>解压</strong><br>  tar -zxvf spark-2.0.2-bin-hadoop2.7.tgz到/usr/local/spark</li>
<li><p><strong>配置环境变量</strong></p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SPARK_HOME=/usr/local/spark/spark-2.0.2-bin-hadoop2.7</div><div class="line">export PATH=$PATH:$SPARK_HOME/bin</div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置集群</strong></p>
<ul>
<li><p>master上：$SPARK_HOME/conf/slaves 添加:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node1 </div><div class="line">node2</div></pre></td></tr></table></figure>
</li>
<li><p>spark-env.sh： 添加SCALA_HOME和JAVA_HOME</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">export SCALA_HOME=/usr/local/scala/scala-2.12.1</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div></pre></td></tr></table></figure>
</li>
<li><p>修改spark web 默认端口为8081</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cd $SPARK_HOME/sbin</div><div class="line">vim start-master.sh</div><div class="line">if [ &quot;$SPARK_MASTER_WEBUI_PORT&quot; = &quot;&quot; ]; then</div><div class="line">  SPARK_MASTER_WEBUI_PORT=8081</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>启动</strong></p>
<ul>
<li>启动hadoop集群,master上执行<br>  $HADOOP_HOME/sbin/start-all.sh</li>
<li>启动spark集群，master上执行<br>  $SPARK_HOME/sbin/start-all.sh</li>
<li><p>jps查看<br>  master:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-master-jps.png" alt="spark-master-jps"></p>
<p>  node1:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-node1-jps.png" alt="spark-node1-jps"></p>
<p>  node2:<br>  <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-node2-jps.png" alt="spark-node2-jps"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>验证</strong></p>
<ul>
<li>访问master的8081<br>  <a href="http://172.16.21.121:8081/" target="_blank" rel="external">http://172.16.21.121:8081/</a><br>   <img src="https://raw.githubusercontent.com/xuetf/spark/master/spark-8081.png" alt="spark-node2-jps"></li>
<li><p>运行SparkPi例子</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd $SPARK_HOME</div><div class="line">bin/spark-submit --class org.apache.spark.examples.SparkPi --master     spark://master:7077 examples/jars/spark-examples_2.11-2.0.2.jar 100 2&gt;&amp;1 | grep &quot;Pi is roughly&quot;</div></pre></td></tr></table></figure>
<p>   <img src="https://raw.githubusercontent.com/xuetf/spark/master/sparkpi.png" alt="spark-node2-jps"></p>
</li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.voidcn.com/blog/dream_broken/article/p-6319289.html" target="_blank" rel="external">http://www.voidcn.com/blog/dream_broken/article/p-6319289.html</a>    </p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;  本文是对spark2.0.2分布式集群搭建的一个详细说明。旨在通过阅读该文章帮助开发人员快速搭建spark分布式集群。&lt;/p&gt;
&lt;h1 id=&quot;三种集群资源管理概述&quot;&gt;&lt;a href=&quot;#三种集群资源管理概述&quot; class=&quot;headerlink&quot; title=&quot;三种集群资源管理概述&quot;&gt;&lt;/a&gt;三种集群资源管理概述&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Spark Standalone&lt;br&gt;作为Spark的一部分,Standalone是一个简单的集群管理器。它具有master的HA，弹性应对WorkerFailures，对每个应用程序的管理资源的能力，并且可以在现有的Hadoop一起运行和访问HDFS的数据。该发行版包括一些脚本，可以很容易地部署在本地或在AmazonEC2云计算。它可以在Linux，Windows或Mac OSX上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Apache Mesos&lt;br&gt;Apache Mesos ,分布式系统内核，具有HA的masters和slaves，可以管理每个应用程序的资源，并对Docker容器有很好的支持。它可以运行Spark工作， Hadoop的MapReduce的，或任何其他服务的应用程序。它有Java， Python和C ++ 的API。它可以在Linux或Mac OSX上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hadoop YARN&lt;br&gt;Hadoop YARN，作业调度和集群资源管理的分布式计算框架，具有HA为masters和slaves，在非安全模式下支持Docker容器，在安全模式下支持Linux和Windows Container executors，和可插拔的调度器。它可以运行在Linux和Windows上运行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;本文将使用Hadoop YARN方式进行集群搭建。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
      <category term="spark" scheme="xtf615.com/categories/spark/"/>
    
    
      <category term="spark" scheme="xtf615.com/tags/spark/"/>
    
      <category term="大数据" scheme="xtf615.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="内存" scheme="xtf615.com/tags/%E5%86%85%E5%AD%98/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
  </entry>
  
  <entry>
    <title>hadoop分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/hadoop%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/hadoop分布式环境搭建教程/</id>
    <published>2016-12-29T10:53:29.000Z</published>
    <updated>2017-03-08T02:32:14.342Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本文是搭建hadoop分布式集群的一个详细说明，旨在通过本文，快速入手hadoop</p>
<h1 id="部署方案"><a href="#部署方案" class="headerlink" title="部署方案"></a>部署方案</h1><p>hadoop部署方案包括：单机模式、伪分布模式、完全分布模式</p>
<p><strong>本文将使用完全分布模式进行集群搭建</strong></p>
<a id="more"></a>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul>
<li><strong>64位centos7服务器3台</strong><ul>
<li>master:172.16.21.121</li>
<li>node1:172.16.21.129</li>
<li>node2:172.16.21.130</li>
</ul>
</li>
<li><strong>hadoop-2.7.3.tar.gz</strong></li>
<li><strong>jdk-8u73-linux-x64.tar.gz</strong></li>
<li><strong>关闭防火墙</strong><br><code>service firewalld stop或systemctl stop firewalld.service</code></li>
<li><p><strong>关闭selinux</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">setenforce 0临时关闭，sestatus查看状态:current mode变成permissive</div></pre></td></tr></table></figure>
</li>
<li><p><strong>纠正系统时间</strong></p>
<ul>
<li><p>设置时区</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">timedatectl查看时区</div><div class="line">timedatactl set-timezone Asia/Shanghai</div></pre></td></tr></table></figure>
</li>
<li><p>安装ntp并启动</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">yum -y install ntp</div><div class="line">systemctl enable ntpd</div><div class="line">start ntpd</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>安装jdk</strong>    </p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">解压tar -zxvf jdk-8u73-linux-x64.tar.gz到/usr/local/java</div><div class="line">vim /etc/profile</div><div class="line">添加：</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div><div class="line">export JRE_HOME=/$JAVA_HOME/jre</div><div class="line">export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</div><div class="line">export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin</div><div class="line"></div><div class="line">source /etc/profile配置生效</div><div class="line">java -version查看</div></pre></td></tr></table></figure>
</code></pre></li>
<li><p><strong>配置主机域名</strong></p>
<ul>
<li><p>配置hostname</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">172.16.21.121(master)主机上: </div><div class="line">先输入命令：hostname master，临时修改主机名</div><div class="line">编辑 vim /etc/hostname 输入master，永久修改主机名</div><div class="line"></div><div class="line">172.16.21.129(node1)节点1上: </div><div class="line">输入 hostname node1</div><div class="line">编辑 vim /etc/hostname 输入node1</div><div class="line"></div><div class="line">172.16.21.130(node2)节点2上: </div><div class="line">输入hostname node2</div><div class="line">编辑vim /etc/hostname 输入node2</div></pre></td></tr></table></figure>
</li>
<li><p>配置host(3台服务器同时输入) 增加ip到name的映射，在/etc/hosts文件中。<br>编辑该文件，输入如下三句：</p>
 <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">172.16.21.121 master</div><div class="line">172.16.21.129 node1</div><div class="line">172.16.21.130 node2</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><strong>ssh免密码登录</strong></p>
<ul>
<li><p>master上操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh-keygen -t rsa 一直回车，信息中会看到.ssh/id_rsa.pub的路径</div><div class="line">复制：cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</div></pre></td></tr></table></figure>
</li>
<li><p>node1和node2上操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">创建node1和node2上root/.ssh目录:mkdir /root/.ssh</div></pre></td></tr></table></figure>
</li>
<li><p>master上操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">复制authorized_keys到node1和node2节点：</div><div class="line">scp /root/.ssh/authorized_keys root@172.16.21.129:/root/.ssh/</div><div class="line">scp /root/.ssh/authorized_keys root@172.16.21.130:/root/.ssh/</div></pre></td></tr></table></figure>
</li>
<li><p>master,node1,node2都操作:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chmod 700 /root/.ssh</div></pre></td></tr></table></figure>
</li>
<li><p>master上验证: </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ssh master</div><div class="line">ssh node1</div><div class="line">ssh node2</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h1 id="配置Hadoop集群"><a href="#配置Hadoop集群" class="headerlink" title="配置Hadoop集群"></a>配置Hadoop集群</h1><ul>
<li>解压 tar -zxvf hadoop-2.7.3.tar.gz, 到/usr/local/hadoop</li>
<li><p>配置环境变量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">vim /etc/profile</div><div class="line">添加：</div><div class="line">export HADOOP_HOME=/usr/local/hadoop/hadoop-2.7.3</div><div class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</div><div class="line">生效：source /etc/profile</div><div class="line">查看版本: hadoop version</div></pre></td></tr></table></figure>
<ul>
<li><p>修改hadoop配置添加JAVA_HOME </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">vim /usr/local/hadoop/hadoop-2.7.3/etc/hadoop hadoop-env.sh</div><div class="line">vim /usr/local/hadoop/hadoop-2.7.3/etc/hadoop yarn-env.sh</div><div class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_73</div></pre></td></tr></table></figure>
</li>
<li><p><strong>创建目录</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir -p /usr/local/hadoop/hdfs/data</div><div class="line">mkdir -p /usr/local/hadoop/hdfs/name</div><div class="line">mkdir -p /usr/local/tmp</div></pre></td></tr></table></figure>
</li>
<li><p><strong>配置core-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</div><div class="line">            &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;fs.defaultFS&lt;/name&gt;</div><div class="line">            &lt;value&gt;hdfs://master:9000&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;io.file.buffer.size&lt;/name&gt;</div><div class="line">            &lt;value&gt;4096&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>配置hdfs-site.xml</strong> <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</div><div class="line">      &lt;value&gt;file:/hadoop/hdfs/name&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</div><div class="line">      &lt;value&gt;file:/hadoop/hdfs/data&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.replication&lt;/name&gt;</div><div class="line">      &lt;value&gt;2&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</div><div class="line">      &lt;value&gt;master:9001&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">   &lt;property&gt;</div><div class="line">      &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;</div><div class="line">      &lt;value&gt;true&lt;/value&gt;</div><div class="line">   &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p><strong>复制mapred-site.xml.template为mapred-site.xml,并修改</strong></p>
<pre><code>cp mapred-site.xml.template mapred-site.xml
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">  &lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</div><div class="line">            &lt;value&gt;yarn&lt;/value&gt;</div><div class="line">            &lt;final&gt;true&lt;/final&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobtracker.http.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:50030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:10020&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:19888&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line"></div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;mapred.job.tracker&lt;/name&gt;</div><div class="line">            &lt;value&gt;http://master:9001&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>修改yarn-site.xml</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</div><div class="line">             &lt;value&gt;master&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</div><div class="line">            &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8032&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">             &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;</div><div class="line">             &lt;value&gt;master:8030&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">             &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8031&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8033&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">    &lt;property&gt;</div><div class="line">            &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;</div><div class="line">            &lt;value&gt;master:8088&lt;/value&gt;</div><div class="line">    &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
</li>
<li><p><strong>将以上步骤操作在node1和node2上重复</strong><br>  可将修改的文件拷贝至node1和node2节点</p>
</li>
<li><p><strong>修改master上的slaves文件</strong><br>  $HADOOP_HOME/etc/hadoop/slaves<br>  删除localhost<br>  添加:</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">node1</div><div class="line">node2</div></pre></td></tr></table></figure>
</li>
<li><p><strong>启动</strong></p>
<ul>
<li><p><strong>只在master上操作</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">master上格式化：</div><div class="line">cd $HADOOP_HOME/bin/</div><div class="line">./hadoop namenode -format</div><div class="line">master上启动：</div><div class="line">cd $HADOOP_HOME/sbin/</div><div class="line">./start-all.sh</div></pre></td></tr></table></figure>
</li>
<li><p><strong>查看jps：</strong><br>  jps<br>  master: ResourceManager SecondaryNameNode NameNode<br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/master-jps.png" alt="master-jps"></p>
<p>  node1/node2: DataNode NodeManager<br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/node1-jps.png" alt="node1-jps"><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/node2-jps.png" alt="node2-jps"></p>
</li>
<li><p>访问master的50070：<br>  <a href="http://172.16.21.121:50070" target="_blank" rel="external">http://172.16.21.121:50070</a><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/50070.png" alt="master-50070"></p>
</li>
<li>访问master的8088：<br>   <a href="http://172.16.21.121:8088" target="_blank" rel="external">http://172.16.21.121:8088</a><br>  <img src="https://raw.githubusercontent.com/xuetf/hadoop/master/8088.png" alt="master-8088"></li>
</ul>
</li>
</ul>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://www.voidcn.com/blog/dream_broken/article/p-6319288.html" target="_blank" rel="external">http://www.voidcn.com/blog/dream_broken/article/p-6319288.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;p&gt;本文是搭建hadoop分布式集群的一个详细说明，旨在通过本文，快速入手hadoop&lt;/p&gt;
&lt;h1 id=&quot;部署方案&quot;&gt;&lt;a href=&quot;#部署方案&quot; class=&quot;headerlink&quot; title=&quot;部署方案&quot;&gt;&lt;/a&gt;部署方案&lt;/h1&gt;&lt;p&gt;hadoop部署方案包括：单机模式、伪分布模式、完全分布模式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本文将使用完全分布模式进行集群搭建&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="hadoop" scheme="xtf615.com/categories/hadoop/"/>
    
    
      <category term="大数据" scheme="xtf615.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
      <category term="hadoop" scheme="xtf615.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>redis分布式环境搭建教程</title>
    <link href="xtf615.com/2016/12/29/redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/"/>
    <id>xtf615.com/2016/12/29/redis分布式环境搭建教程/</id>
    <published>2016-12-29T07:56:43.000Z</published>
    <updated>2016-12-29T15:42:48.219Z</updated>
    
    <content type="html"><![CDATA[<h1 id="redis部署说明"><a href="#redis部署说明" class="headerlink" title="redis部署说明"></a>redis部署说明</h1><ul>
<li><strong>版本</strong><br>使用redis最新版3.2.3进行安装</li>
<li><strong>主从关系</strong><br>使用1个主节点，3个从节点。主节点提供读写操作，从节点只提供读操作。主节点Master安装在dbp模块，提供大量的写操作服务；  3个从节点。</li>
<li><strong>哨兵机制</strong><br>配置3个哨兵，主节点dbp安装1个哨兵，另外3台从服务器选其中两台各安装一个。作为HA高可用方案，防止主节点单点失败，通过重新选举主节点实现故障快速转移。<a id="more"></a>
</li>
</ul>
<h1 id="安装具体步骤"><a href="#安装具体步骤" class="headerlink" title="安装具体步骤"></a>安装具体步骤</h1><ul>
<li>解压</li>
<li>安装gcc</li>
<li>进入redis的bin目录，先执行 make MALLOC=libc； 再执行make install</li>
<li>配置文件：先拷贝redis目录下的配置文件redis.conf和sentinel.conf到/usr/local/etc(或其他任意目录)，再修改<ul>
<li><strong>redis节点配置</strong><br>  <code><strong>bind 主机ip</strong>                        #主机ip<br>  <strong>protected-mode no</strong>                     #保护模式关闭，否则不能通过远程连接，哨兵机制也不起作用，下面使用密码进行安全保证<br>  <strong>port 端口</strong>                          #端口<br>  <strong>daemonize yes</strong>                       #守护进程<br>  <strong>pidfile  /var/run/redis_端口.pid</strong>            #进程号，命名规则redis_端口号.pid<br>  logfile /usr/local/logs/redis/redis_端口.log   #日志文件<br>  <strong>dir  /usr/local/data/redis/端口</strong>          #持久化文件夹，必须是空文件夹<br>  <strong>requirepass 密码</strong>    #认证密码<br>  <strong>masterauth 密码</strong>    #和认证密码一致<br>  <strong>maxmemory 最大内存</strong>  #eg:10g<br>  <strong>maxmemory-policy</strong>        allkeys-lru   #lru算法回收<br>  </code></li>
<li><strong>从节点需要额外配置</strong><br>  <code>slaveof 主机 ip  #例如slaveof  172.16.21.127  6379</code></li>
<li><strong>Sentinel哨兵节点</strong><br><code>port  端口    #命名规则： 本机redis端口前加个2,比如redis:6379: 则sentinel：26379<br>  <strong>sentinel announce-ip</strong>  主机ip<br>  <strong>protected-mode  no</strong>  #需要手动添加这条。<br>  <strong>dir</strong>  /usr/local/data/sentinel_端口    #空文件夹<br>  <strong>logfile</strong>  /usr/local/logs/redis/sentinel_端口.log<br>  <strong>sentinel monitor 主节点名称 主节点ip 主节点端口 仲裁至少需要的哨兵数</strong> #eg：sentinel monitor mymaster  172.16.21.127 6379 2<br>  <strong>sentinel auth-pass 主节点名称 密码</strong>   #认证<br>  </code></li>
</ul>
</li>
<li><strong>进入redis的src目录启动redis和sentinel</strong><br>  <code><strong>reids-server redis配置文件</strong><br>  #eg:redis-server /usr/local/etc/redis_6379.conf<br>  <strong>redis-sentinel sentinel配置文件</strong> &amp;<br>  #eg:redis-sentinel /usr/local/etc/sentinel_26379.conf &amp;<br>  </code></li>
<li><strong>依次启动主节点和从节点后，使用redis-cli连接</strong><br>  <code><strong>reids-cli -h ip地址 -p 端口 -a 密码</strong><br> <strong>sentinel reset mymaster</strong> #重置哨兵状态*<br>  使用命令查看部署情况，info replication可查看集群状态<br>  </code></li>
</ul>
<h1 id="具体配置参见"><a href="#具体配置参见" class="headerlink" title="具体配置参见"></a>具体配置参见</h1><p><a href="https://github.com/xuetf/redis" target="_blank" rel="external">https://github.com/xuetf/redis</a></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="http://blog.csdn.net/ownfire/article/details/51546543" target="_blank" rel="external">http://blog.csdn.net/ownfire/article/details/51546543</a><br><a href="http://www.ilanni.com/?p=11838" target="_blank" rel="external">http://www.ilanni.com/?p=11838</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;redis部署说明&quot;&gt;&lt;a href=&quot;#redis部署说明&quot; class=&quot;headerlink&quot; title=&quot;redis部署说明&quot;&gt;&lt;/a&gt;redis部署说明&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;版本&lt;/strong&gt;&lt;br&gt;使用redis最新版3.2.3进行安装&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;主从关系&lt;/strong&gt;&lt;br&gt;使用1个主节点，3个从节点。主节点提供读写操作，从节点只提供读操作。主节点Master安装在dbp模块，提供大量的写操作服务；  3个从节点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;哨兵机制&lt;/strong&gt;&lt;br&gt;配置3个哨兵，主节点dbp安装1个哨兵，另外3台从服务器选其中两台各安装一个。作为HA高可用方案，防止主节点单点失败，通过重新选举主节点实现故障快速转移。
    
    </summary>
    
      <category term="redis" scheme="xtf615.com/categories/redis/"/>
    
    
      <category term="分布式" scheme="xtf615.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="环境" scheme="xtf615.com/tags/%E7%8E%AF%E5%A2%83/"/>
    
      <category term="redis" scheme="xtf615.com/tags/redis/"/>
    
      <category term="缓存" scheme="xtf615.com/tags/%E7%BC%93%E5%AD%98/"/>
    
      <category term="HA方案" scheme="xtf615.com/tags/HA%E6%96%B9%E6%A1%88/"/>
    
  </entry>
  
</feed>
