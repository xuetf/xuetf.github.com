<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  
    

    
  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="蘑菇先生学习记" />





  <link rel="alternate" href="/atom.xml" title="蘑菇先生学习记" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="蘑菇先生学习记">
<meta property="og:url" content="xtf615.com/index.html">
<meta property="og:site_name" content="蘑菇先生学习记">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="蘑菇先生学习记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="xtf615.com/"/>





  <title> 蘑菇先生学习记 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">蘑菇先生学习记</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'WgLy48WeXh1aXsWx1x7L','2.0.0');
</script>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/03/28/SVM支持向量机/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/28/SVM支持向量机/" itemprop="url">
                  SVM支持向量机
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-28T08:26:31+08:00">
                2017-03-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>　　本文将介绍SVM(Support Vector Machine)学习算法。SVMs是现有的最强大的监督学习算法。我们首先讨论什么是间隔以及使用最大间隔来分类数据的思想。接着讨论最优间隔分类器，这里面会涉及拉格朗日对偶问题。我们也会讨论关于核方法以及如何有效地应用核方法到高维特征空间。最后我们会讨论SMO算法，它是SVMs的一种实现方法。</p>
<h1 id="间隔的直观理解"><a href="#间隔的直观理解" class="headerlink" title="间隔的直观理解"></a>间隔的直观理解</h1><p>　　要理解支持向量机，首先必须先了解间隔以及关于预测置信度的概念。考虑一下逻辑回归，模型是\(h_\theta(x)=g(\theta^Tx)\),当且仅当\(h_\theta(x) \geq 0.5\),也即\(\theta^Tx \geq 0\)时，我们预测结果为1。考虑一个正例样本，显然\(\theta^Tx\)的值越大，\(h_\theta(x)=p(y=1|x;w;b)\)的值也越大，则预测样本label为1的置信程度也越高。更正式的，当\(\theta^Tx \gg 0\)时，可以认为我们的预测样本label为1的置信程度很高，同样，当\(\theta^Tx \ll 0\)时,可以认为我们的预测样本label为0的置信程度很高。给定一个训练集，如果我们能够在标签为1的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \gg 0\)，那么这样拟合的效果就很好。同样，在标签为0的样本中，找到合适的\(\theta\)，使得\(\theta^Tx^{(i)} \ll 0\)。这样的拟合效果能够体现出分类器对于样本分类的置信程度很高。后面我们会使用函数间隔来形式化该思想。<br>　　我们可以换一种方式来理解。考虑下图，X代表正例，O代表反例，判定边界或称作分离超平面(separating hyperplane)将正反例分开，边界上，我们有\(\theta^T X = 0\)。考虑三个点A,B,C。<br><img src="/picture/machine-learning/svm1.jpg" alt="svm"><br>如上图所示，A点离判定边界很远。如果要预测A点的y值,显然可以很自信的预测y=1. 相反，C点离判定边界很近，尽管目前看我们可以判定C点y=1，但是如果我们对判定稍微移动一点，就很容易导致C点跑到另一侧y=0。因此可以说对A点预测的置信程度是高于C点的。B点介于两种情况之间。更通用的，对于离分离超平面远的点，我们可以对我们的预测结果很自信。因此，对于给定的训练集，我们希望找到一个判定边界，能够使得对于所有的样本都分类正确并且置信程度高，这也就意味着样本点要离判定边界远一点。后面我们会使用几何间隔来形式化该思想。</p>
<h1 id="符号变化"><a href="#符号变化" class="headerlink" title="符号变化"></a>符号变化</h1><p>　　为了使SVMs的讨论更加容易，我们需要对以前习惯的符号进行略微修正。我们首先考虑二分类线性分类器。对于标签y，我们现在不使用\(y \in \{0,1\}\),而使用\(y \in \{-1,1\}\)。对于线性分类器的参数，我们不使用向量\(\theta\),而使用参数\(w,b\)来表示：<br>$$h_{w,b}(x)=g(w^T x + b)$$<br>因此当\(z \geq 0\)时，g(z)=1, 当\(z&lt;0\)时，g(z)=-1。新的标志可以使得我们将截距项b和其他参数分开讨论。我们不再使用之前的\(x_0=1\), b相当于之前的\(\theta_0\),\(w\)相当于之前的\([\theta_1,\theta_2,…,\theta_n]^T\)<br>　　根据上文g的定义，我们的分类器会直接预测样本为1或者-1，而不是像逻辑回归那样先预测样本类别如果为1的概率，再根据概率大小确定样本类别。</p>
<h1 id="函数间隔和几何间隔"><a href="#函数间隔和几何间隔" class="headerlink" title="函数间隔和几何间隔"></a>函数间隔和几何间隔</h1><h2 id="函数间隔"><a href="#函数间隔" class="headerlink" title="函数间隔"></a>函数间隔</h2><p>　　对于一个给定的训练样本\((x^{(i)},y^{(i)})\), 我们定义该样本到w,b确定的分离超平面的函数间隔为：<br>$$\hat{\gamma}^{(i)}=y^{(i)}(w^T x + b)$$<br>　　注意为了使得预测更准确并且置信度更高，函数间隔越大越好。当\(y^{(i)}=1\)时,即\(w^T x + b\)在正方向越大越好。当当\(y^{(i)}=-1\)时,即\(w^T x + b\)在负方向越大越好。归纳起来，当\(y^{(i)}(w^T x + b)&gt;0\)时，我们对该样本的预测结果就是正确的。而最大函数间隔可以代表我们的预测结果是正确并且置信度高。<br>　　对于一个线性分类器, 在我们选择的g函数的基础上(取值为-1和1)，函数间隔的问题在于，只要成倍增大\(w,b\)，\(g(w^Tx+b)=g(2w^Tx+2b)\)，这不会改变\(h_{w,b}\)的值，因为\(h_{w,b}\)的值只取决于其符号，即正负性，而不取决于\(w^T x + b\)的数量级。但是我们发现函数间隔却变大了2倍。这意味着，放大\(w,b\),会使得函数间隔任意大，但是却对模型的改进没有任何帮助。我们可以引入正则化条件，例如规定\(||w||_2=1\)，即二阶范式的值。然后将\((w,b)\)替换成，\((\frac{w}{||w||_2},\frac{b}{||w||_2})\).<br>　　对于给定的训练集\(S=\{(x^{(i)},y^{(i)});i=1,…,m\}\),我们定义训练集S相对于\((w,b)\)决定的分离超平面的函数间隔为，每个样本相对于分离超平面函数间隔中的最小的那个值。即：<br>$$\hat{\gamma}=\min_\limits{i=1,…,m} \hat{\gamma}^{(i)}$$</p>
<h2 id="几何间隔"><a href="#几何间隔" class="headerlink" title="几何间隔"></a>几何间隔</h2><p><img src="/picture/machine-learning/svm2.jpg" alt="svm"><br>　　如上图，\((w,b)\)决定了分离超平面。可以证明\(w\)就是分离超平面的法向量。证明如下，考虑在分离超平面上取两点，\(x^{\\’}和x^{\\’’}\)<br>，则\(w^Tx^{\\’}+b=0\),\(w^Tx^{\\’’}+b=0\),两式相减有：<br>$$w^T(x^{\\’}-x^{\\’’})=0$$<br>因为\(x^{\\’}-x^{\\’’}\)是超平面上的向量，则根据垂直向量乘积为0，可以得到\(w\)就是分离超平面的法向量。<br>　　考虑点Ａ，Ａ代表了某个输入样本\(x^{(i)}\)且标签\(y^{(i)}=1\),设它到分离超平面的距离为\(\gamma^{(i)}\),就是图中AB代表的线段。<br>　　如何求\(\gamma^{(i)}\)的值呢？因为\(\frac{w}{||w||}\)代表和法向量同方向的单位向量，A点为\(x^{(i)}\),设B点位\(x^{(j)}\),BA和法向量同方向。则:<br>$$x^{(i)}-x^{(j)}=\gamma^{(i)}\frac{w}{||w||}$$<br>得出B点为：<br>$$x^{(j)}=x^{(i)}-\gamma^{(i)}\frac{w}{||w||}$$<br>因为B点位于分离超平面上，则：<br>$$w^T\left(x^{(i)}-\gamma^{(i)}\frac{w}{||w||}\right)+b=0$$<br>解的：<br>$$\gamma^{(i)}=\frac{w^Tx^{(i)}+b}{||w||}=\left(\frac{w}{||w||}\right)^T x^{(i)}+\frac{b}{||w||}$$<br>　　上面的结果是针对正样本，对于负样本，结果是一样的。<br>　　更通用的，我们定义某个训练样本\(x^{(i)},y^{(i)})\)相对于由\((w,b)\)决定的分离超平面的几何间隔为：<br>$$\gamma^{(i)}=y^{(i)}\left(\left(\frac{w}{||w||}\right)^T x^{(i)}+\frac{b}{||w||}\right)$$<br>注意到，如果\(||w||=1\),函数间隔等于几何间隔。这也是两种间隔之间的联系。几何间隔不受参数量级的影响，如果同时成倍放大w和b，几何间隔不会改变。正因为如此，在使用训练集拟合w和b的时候，我们可以施加任意的放大缩小约束条件，例如，可以限制||w||=1或者\(||w_1||=5\),或者||w_1+b||+|w_2|=2,所有的这些可以通过重新调整w和b来恢复。<br>　　对于给定的训练集\(S=\{(x^{(i)},y^{(i)});i=1,…,m\}\),我们定义训练集S相对于\((w,b)\)决定的分离超平面的几何间隔为，每个样本相对于分离超平面几何间隔中的最小的那个值。即：<br>$$\gamma=\min_\limits{i=1,…,m} \gamma^{(i)}$$</p>
<h1 id="最优间隔分类器"><a href="#最优间隔分类器" class="headerlink" title="最优间隔分类器"></a>最优间隔分类器</h1><p>　　对于给定的训练集，根据前面的讨论，我们很自然的希望能够找到一个分离超平面使得几何间隔最大化，只有这样，对于预测结果我们的置信度才足够高，样本拟合的结果才足够好。<br>　　开始前，我们要强调下，本文所讨论的内容仍然是假设数据集市线性可分的。我们可以写出如下的优化问题：<br>$$\max_{\gamma,w,b} \gamma \\\\<br>使得，y^{(i)}(w^T x^{(i)} + b) \geq \gamma,　　i=1,2,…,m \\\\<br>||w||=1<br>$$<br>　　我们要最大化\(\gamma\)，使得每一个训练样本的函数间隔都至少为\(\gamma\)。\(||w||=1\)约束保证了函数间隔等于几何间隔。也即，我们保证了每一个训练样本的几何间隔都至少为\(\gamma\)。因此，解决该优化问题的方法就是不断调整\((w,b)\)，来最大化几何间隔。<br>　　但是||w||=1的约束条件是非凸性约束，最优解容易陷入局部最优，因此我们无法使用现成的标准优化方法来解该优化问题。我们尝试修改该优化问题，考虑如下：<br>$$\max_{\gamma,w,b} \frac{\hat{\gamma}}{||w||} \\\\<br>使得，y^{(i)}(w^T x^{(i)} + b) \geq \hat{\gamma},　　i=1,…,m<br>$$<br>　　我们尝试最大化几何间隔\(\frac{\hat{\gamma}}{||w||}\),使得每个样本的函数间隔都至少为\(\hat{\gamma}\)。几何间隔和函数间隔通过\(\gamma=\frac{\hat{\gamma}}{||w||}\)来联系。我们去掉了非凸约束||w||。我们通过将非凸约束转移到目标函数上，从而使得问题变成了非凸性问题。该问题目前仍然无法用标准通用方法解决。<br>　　对于上式，我们还可以再做一次变换。我们知道，等比例对\(w,b\)进行缩放，不会改变分离超平面的位置，假设已经得到了\(w,b\)，那么就能求得\(\hat{\gamma}\)的值，那么我们可以通过缩放w,b(同时除以\(\hat{\gamma}\)),使得\(\hat{\gamma}\)变为1.这样得到的分离超平面与最开始就将\(\hat{\gamma}\)设为1是一样的。因此优化问题可以改写成：<br>$$\max_{\gamma,w,b} \frac{1}{||w||}$$<br>也即：（加上1/2系数是为了使结果更漂亮）<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2 \\\\<br>使得, y^{(i)}(w^T x^{(i)} + b) \geq 1, 　　i=1,…,m<br>$$<br>　　上述问题已经转换成凸性问题了，约束条件只有线性约束。该优化问题的结果就是最优间隔分类器。为了更好解决该问题，需要使用它的对偶问题，下面首先介绍拉格朗日对偶性。</p>
<h2 id="拉格朗日对偶性"><a href="#拉格朗日对偶性" class="headerlink" title="拉格朗日对偶性"></a>拉格朗日对偶性</h2><p>　　下面回顾一下线性约束优化问题。如下形式：<br>$$\min_w f(w) \\\\<br>使得， h_i(w)=0,　　i=1,…,l<br>$$<br>　　我们使用拉格朗日乘子(Lagrange multipliers)，拉格朗日方程如下：<br>$$L(w,\beta)=f(w)+\sum_{i=1}^l \beta_i h_i(w)$$<br>　　这里，\(\beta_i\)称作拉格朗日乘子，我们对其求偏导数并设为0.求得的值就是原问题的解了。<br>$$\frac{\partial L}{\partial w_i}=0; \frac{\partial L}{\partial \beta_i}=0$$<br>　　至于为什么引入拉格朗日算子可以求出极值，原因是f(w)的方向导数dw受等式的约束，dw的变化方向与f(w)的梯度度垂直时才能获得极值，而且在极值处，f(w)的梯度与其他等式梯度的线性组合平行，因此他们之间存在线性关系。<br>　　上述问题对应的是等式约束条件，我们需要将其扩展为不等式约束条件。考虑如下原始优化问题(primal optimization problem):<br>$$\min_w f(w) \\\\<br>使得， g_i(w) \leq 0,　　i=1,…,k \\\\<br>h_i(w)=0,　　i=1,…,l<br>$$<br>　　我们定义通用的拉格朗日方程(generalized Lagrangian)：<br>$$L(w,\alpha,\beta)=f(w)+\sum_{i=1}^k \alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w)$$<br>\(\alpha_i和\beta_i\)是拉格朗日乘子。考虑如下等式:<br>$$\theta_p(w)=\max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta)$$<br>  　这里的下标p代表原始Primal。对于某些给定的\(w\)，如果w不符合约束条件，例如当某个\(g_i(w)&gt;0\)时，我们可以使得和该\(g_i(w)&gt;0\)相乘的乘子\(\alpha_i\)趋向于正无穷，则\(\theta_p(w)\)也趋向于正无穷；同样，当\(h_i(w) \neq 0\)时，根据\(h_i(w)\)的正负性，选择相应的\(\beta_i\)趋向于正无穷或负无穷，则\(\theta_p(w)\)也趋向于正无穷。因此对于不满足约束条件时，上述问题结果是：<br>  $$\theta_p(w)=\max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) \\\\<br>  =f(w)+\sum_{i=1}^k \alpha_i g_i(w) + \sum_{i=1}^l \beta_i h_i(w) \\\\<br>  =\infty$$<br>  　　相反，如果约束条件满足的话，对于给定的\(w\)，我们有,\(\theta_p(w)=f(w)\),这里的关键是我们的\(\alpha_i \geq 0且g_i(w) \leq 0\), 则\(\sum_{i=1}^k \alpha_i g_i(w) \leq 0\)，那么为了最大化\(\theta_p(w)\),有\(\sum_{i=1}^k \alpha_i g_i(w)=0\)。<br>  　　因此，我们有：<br>  $$<br>\begin{eqnarray} \theta_p(w)=\begin{cases} f(w),　　if \ w \ satisfies \ primal \ constraints \cr \infty,　　otherwise. \end{cases} \end{eqnarray}<br>  $$<br>　　因而，我们可以认为\(\theta_p(w)\)即使将约束条件与目标函数融合在一起的表达方法，考虑最小化问题，我们得到了如下公式：<br>$$\min_w \theta_p(w) = \min_w \max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) 　　　　　　　　　　　(1)$$<br>　　因为,\(\theta_p(w)\)在满足约束条件下等价于\(f(w)\)问题，则\(\min_w \theta_p(w)\)问题等价于我们最初的原始优化问题(primal problem) \(\min_w f(w)\)。<br>　　我们定义\(p^{*}\)为原始问题取得最优解时的函数值，也即:<br>$$p^{*} = \min_w \theta_p(w)$$<br>　　接着定义：<br>$$\theta_D(\alpha,\beta)=\min_w L(w,\alpha,\beta)$$<br>　　上式中的下标D代表对偶(dual)。注意，\(\theta_p(w)\)优化的参数是\(\alpha,\beta\)，而这里\(\theta_D\)优化的参数是w.<br>　　我们可以得到对偶问题：<br>$$\max_{\alpha,\beta:\alpha_i \geq 0} \theta_D(\alpha,\beta)=\max_{\alpha,\beta:\alpha_i \geq 0} \min_w L(w,\alpha,\beta)　　　　　　　　　　(2)$$<br>　　该式就是我们原始问题的对偶形式，我们对比(1)和(2)发现：两个式子很相似，只是max和min位置调换了。<br>　　我们定义对偶问题的最优解为:<br>$$d^{*}=\max_{\alpha,\beta:\alpha_i \geq 0} \theta_D(w)$$<br>　　对偶问题和原始问题的关联如下：<br>$$d^{*}=\max_{\alpha,\beta:\alpha_i \geq 0} \min_w L(w,\alpha,\beta) \leq \min_w \max_{\alpha,\beta:\alpha_i \geq 0} L(w,\alpha,\beta) = p^{*}$$<br>　　可以证明,对于任意函数,max min的结果总是小于等于min max。在特定条件下, 我们有：<br>$$d^{*}=p^{*}$$<br>　　这些特定的条件包括，约束不等式\(g_i\)都是凸函数(线性函数都属于凸函数);约束\(h_i\)都是仿射函数(其实就是在线性函数基础上加上截距b);不等式\(g_i(w)\)约束条件严格可行,即对于任意的i,存在w,使得\(g_i(w)&lt;0\)<br>　　在这些假设下，肯定存在\(w^{*},\alpha^{*},\beta^{*}\),使得\(w^{*}\)是原始问题的解，\(\alpha^{*},\beta^{*}\)是对偶问题的解,且\(p^{*}=d^{*}=L(w^{*},\alpha^{*},\beta^{*})\),这样的\(w^{*},\alpha^{*},\beta^{*}\)需要满足KKT(Karush-Kuhn-Tucker)条件，KKT条件如下：<br>$$\frac{\partial}{\partial w_i}L(w^{*},\alpha^{*},\beta^{*})=0,　i=1,…,n \\\\<br>\frac{\partial}{\partial \beta_i}L(w^{*},\alpha^{*},\beta^{*})=0,　i=1,…,l \\\\<br>\alpha_i^{*}g_i(w^{*})=0,　i=1,…,k \\\\<br>g_i(w^{*}) \leq 0,　i=1,…,k \\\\<br>\alpha^{*} \geq 0,　i=1,…,k<br>$$<br>注意第3个式子，特别的:<br>$$当\alpha_i^{*}大于0时,g_i(w^{*})=0$$<br>我们称之为KKT互补条件。也就是说，\(g_i(w^{*})=0\)时，w处于可行域的边界上，这时才是起作用的约束，其他位于可行域内内部(\(g_i(w^{*})小于0\)的点都是不起作用的约束,其\(\alpha_i^{*}=0\))。KKT的总体思想是将极值会在可行域边界上取得，也就是不等式为0或等式约束里取得，而最优下降方向一般是这些等式的线性组合，其中每个元素要么是不等式为0的约束，要么是等式约束。对于在可行域边界内的点，对最优解不起作用，因此前面的系数为0。这个条件比较重要，在后文中，它将展示SVM只有一些支持向量点会起作用，在SMO算法中会给出收敛测试。</p>
<h1 id="最优间隔分类器求解"><a href="#最优间隔分类器求解" class="headerlink" title="最优间隔分类器求解"></a>最优间隔分类器求解</h1><p>　　上面讲述的原始／对偶优化问题(primal/dual optimal problem)，其目的在于对原始问题上不易求解的问题进行转换，使之更易求解。下面介绍通过对最优间隔分类器的对偶问题进行求解，得到的简化后的问题的过程。之前我们的优化问题是：<br>$$\min_{\gamma,w,b} \frac{1}{2}{||w||}^2 \\\ 使得, y^{(i)}(w^T x^{(i)} + b) \geq 1, 　　i=1,…,m$$<br>　　我们将约束条件改写成:<br>$$g_i(w)=-y^{(i)}(w^T x^{(i)} + b)+1 \leq 0$$<br>　　该约束条件对每个样本都成立，根据KKT对偶互补条件，对于函数间隔为1(即满足约束g_i(w)=0)的样本点，我们有\(\alpha_i &gt; 0\)<br>　　考虑下图，最大间隔分离超平面是图中的实线。<br><img src="/picture/machine-learning/svm3.jpg" alt="svm"><br>　　最小间隔的点是那些靠近分离超平面的点，这里有3个这样的点，位于图中虚线处，1个负样本，2个正样本，因此只有该3个点对应的\(\alpha_i\)非零。这3个点叫做该问题的支持向量，意味着在求解问题时，使用到的支持向量数比样本大小少的多。<br>　　上述问题对应的拉格朗日方程是：<br>$$L(w,b,\alpha)=\frac{1}{2}{||w||}^2-\sum_{i=1}^m \alpha_i[y^{(i)}(w^T x^{(i)}+b)-1]$$<br>　　我们的问题只有不等式约束，没有等式约束，故拉格朗日乘子只有\(\alpha\)。并且该问题符合\(d^{*}=p^{*}\)的假设，肯定存在\(w^{*},\alpha^{*},\beta^{*}\)使得原始问题和对偶问题共用最优解。<br>　　求解对偶问题时，首先要固定\(\alpha\),以w,b为变量，最小化L；最小化L时，求解L对w和b的偏导，并将导数设为0，可以得到：<br>$$\nabla_w L(w,b,\alpha)=w-\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}=0$$<br>得到:<br>$$w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}$$<br>对b求偏导，得到：<br>$$\frac{\partial}{\partial b}(w,b,\alpha)=\sum_{i=1}^m \alpha_i y^{(i)}=0$$<br>我们将上式代入拉格朗日方程得到：<br>$$L(w,b,\alpha)=\frac{1}{2}{||w||}^2-\sum_{i=1}^m \alpha_i[y^{(i)}(w^T x^{(i)}+b)-1] \\\\<br>= \frac{1}{2}w^T w-\sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)}-\sum_{i=1}^m \alpha_i y^{(i)} b + \sum_{i=1}^m \alpha_i \\\\<br>= \frac{1}{2}w^T \sum_{i=1}^m \alpha_i y^{(i)}x^{(i)} - \sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)} + \sum_{i=1}^m \alpha_i \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \alpha_i y^{(i)} w^T x^{(i)} \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \alpha_i y^{(i)} \left(\sum_{j=1}^m \alpha_j y^{(j)} (x^{(j)})^T \right)x^{(i)} \\\\<br>= \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i=1}^m \sum_{j=1}^m \alpha_i \alpha_j y^{(i)} y^{(j)} (x^{(j)})^T x^{(i)} \\\\<br>=\sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j (x^{(j)})^T x^{(i)}<br>$$<br>得到如下对偶优化问题：<br>$$<br>\max_{\alpha} W(\alpha) = \sum_{i=1}^m \alpha_i - \frac{1}{2}\sum_{i,j=1}^m y^{(i)} y^{(j)} \alpha_i \alpha_j ＜x^{(i)},x^{(j)}＞ \\\\<br>使得， \alpha_i \geq 0,　　i=1,…,m \\\\<br>\sum_{i=1}^m \alpha_i y^{(i)} = 0<br>$$<br>　　\(＜x^{(i)},x^{(j)}＞\)代表向量的内积,该式子可以当作一个整体，在后续核技巧中发挥重要作用。<br>　　上式第一步为原问题，第二部将累加和展开，第三步代入w和b求导并设置为0后的结果，第四步合并系数，第五步代入w求导结果。<br>　　再强调一次，该问题符合\(d^{*}=p^{*}\)的假设和KKT条件。因此我们可以求解对偶优化问题，从而求得原始优化问题。上述对偶优化问题求解的参数只有\(\alpha_i\)。如果我们能够求解使得对偶问题最大化的\(\alpha\), 我们就可以通过\(w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\)推出原始优化问题的\(w\).如果找到了\(w^{*}\),可以得到截距b的值：<br>$$b^{*}=-\frac{\max_{i:y^{(i)}=-1} {w^{*}}^T x^{(i)} + \min_{i:y^{(i)}=1} {w^{*}}^T x^{(i)}}{2}$$<br>　　上式是在确定\(w^{*}\)后，正例和负例的支持向量所对应的截距的平均值，为了更直观的理解，考虑下图：<br><img src="/picture/machine-learning/svm3.jpg" alt="svm"><br>　　上式即是两条虚线与纵轴的截距的平均值。也可以理解为离超平面最近的正的函数间隔要等于离超平面最近的负的函数间隔，可以将分母2乘到b，再整理式子：<br>$$(\max_{i:y^{(i)}=-1} {w^{*}}^T x^{(i)}+b^{*}) + (\min_{i:y^{(i)}=1} {w^{*}}^T x^{(i)}+b^{*})=0$$<br>　　可以理解为二者函数间隔互为相反数，抵消了。<br>　　我们进一步考察一下式子\(w=\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\)，假设我们已经找到了优化问题的最优解，现在需要对新样本ｘ作出预测,我们可以通过计算\(w^T x+b\)来判断，大于等于0则预测y=1,否则y=0.但是使用上述式子，我们有：<br>$$w^T x+b=\left(\sum_{i=1}^m \alpha_i y^{(i)}x^{(i)}\right)^T x + b \\\\<br>=\sum_{i=1}^m \alpha_i y^{(i)}＜x^{(i)},x＞+b$$<br>　　根据上式，如果我们求得了\(\alpha_i\)，为了对新样本做出预测，我们可以只计算x和每一个训练样本的内积。更进一步，前面我们讨论过，只有在支持向量处，\(\alpha_i\)才非零，因此我们只需要计算新样本和每一个支持向量之间的内积，这样计算数据量就少了很多。相当于只有这些支持向量为目标函数的计算做出贡献。<br>　　下文将引入核技巧到目标函数中，从而得到完全的支持向量机算法，然后介绍SMO序列最小化算法，该算法是优化问题的一种较快的解决方法。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/03/25/生成算法/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/25/生成算法/" itemprop="url">
                  生成算法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-25T10:09:22+08:00">
                2017-03-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>　　这篇笔记主要针对斯坦福ML公开课的第五个视频，主要内容包括生成学习算法(generate learning algorithm)、高斯判别分析(Gaussian Discriminant Analysis)、朴素贝叶斯(Navie Bayes)、拉普拉斯平滑(Laplace Smoothing)。</p>
<h1 id="生成学习算法概述"><a href="#生成学习算法概述" class="headerlink" title="生成学习算法概述"></a>生成学习算法概述</h1><p>　　到目前为止，我们学习的方法主要是直接对问题进行求解，比如二分类问题中的感知机算法和逻辑回归算法，都是在解空间中寻找一条直线从而把两种类别的样例分开，对于新的样例只要判断在直线的哪一侧即可，这种截至对问题求解的方法可以称作判别学习方法(discriminative learning algorithm)。判别学习方法的任务是训练如下模型：<br>$$p(y|x;\theta)$$<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/03/25/生成算法/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/03/08/Python实现时间序列分析/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/08/Python实现时间序列分析/" itemprop="url">
                  Python实现时间序列分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-08T09:54:58+08:00">
                2017-03-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计学/" itemprop="url" rel="index">
                    <span itemprop="name">统计学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>前面花了两章篇幅介绍了时间序列模型的数学基础。 <a href="/2017/03/07/ARIMA时间序列模型/">ARIMA时间序列模型(一)</a>和<a href="/2017/03/07/ARIMA时间序列模型-二/">ARIMA时间序列模型(二)</a> 。本文重点介绍使用python开源库进行时间序列模型实践。</p>
<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>回顾一下自回归移动平均模型ARMA，它主要由两部分组成：AR代表p阶自回归过程，MA代表q阶移动平均过程，形式如下：<br>$$Z_t=\theta_0+\phi_1 Z_{t-1}+\phi_2 Z_{t-2}+…+\phi_p Z_{t-p} \\\\<br>+a_t-\theta_1a_{t-1}-\theta_2a_{t-2}-…-\theta_qa_{t-q}$$<br>为了方便，我们重写以上等式为：<br>$$\phi(B)Z_t=\theta_0+\theta(B)a_t \\\\<br>其中，\phi(x)和\theta(x)分别是AR模型和MA模型的的特征多项式$$<br>$$\phi(x)=1-\phi_1x-\phi_2x^2-…-\phi_px^p$$<br>$$\theta(x)=1-\theta_1x-\theta_2x^2-…-\theta_px^q$$<br>根据前两篇的分析，我们总结ARMA模型的性质如下：<br><img src="/picture/machine-learning/arima5.jpg" alt="arima"><br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/03/08/Python实现时间序列分析/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/03/07/ARIMA时间序列模型-二/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/07/ARIMA时间序列模型-二/" itemprop="url">
                  ARIMA时间序列模型(二)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-07T13:49:28+08:00">
                2017-03-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计学/" itemprop="url" rel="index">
                    <span itemprop="name">统计学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>　　前面我们介绍了时间序列模型的概念、数学基础等。本文将接着介绍时间序列模型的更多理论性质，包括一般线性过程(general linear process)，自回归模型AR(the autoregressive model),移动平均模型MA(the moving average)以及ARMA模型。</p>
<h1 id="一般线性过程"><a href="#一般线性过程" class="headerlink" title="一般线性过程"></a>一般线性过程</h1><h2 id="定义："><a href="#定义：" class="headerlink" title="定义："></a>定义：</h2><ul>
<li>时间序列\({Z_t}\)是线性(linear)的，当且仅当\(Z_t\)的值是白噪声系列的线性函数。</li>
<li>时间序列\({Z_t}\)是有因果的(causal),当且仅当\(Z_t\)的值只受到目前为止的信息影响，换句话说\(Z_t\)是独立于未来信息\(a_s\)的，s&gt;t</li>
<li>时间序列模型通常是由白噪声驱动的，即\({a_t}\), 时间序列是\({a_t}\)的函数。随机变量\(a_t\)可以被时刻t的信息所解释。白噪声通常叫做新息序列（innovation sequence）或信息序列(information sequence).</li>
</ul>
<p>因此，一个线性的、有因果的、平稳的时间序列也被称作一般线性过程(a general linear process)。</p>
<p>一般线性过程具有如下形式：<br>$$Z_t=\mu+\sum_{j=0}^{\infty}\psi_j a_{t-j}=\mu+\psi_0a_t+\psi_1a_{t-1}+\psi_2a_{t-2} \\\\<br>其中，{a_t} \sim WN(0,\sigma_a^2) \ and \  \sigma_a^2\sum_{j=0}^{\infty}\psi_j^2&lt;\infty$$<br>不失一般性，我们可以设\(\psi_0=1\)<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/03/07/ARIMA时间序列模型-二/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/03/07/ARIMA时间序列模型/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/07/ARIMA时间序列模型/" itemprop="url">
                  ARIMA时间序列模型(一)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-03-07T09:33:02+08:00">
                2017-03-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/统计学/" itemprop="url" rel="index">
                    <span itemprop="name">统计学</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="时间序列是什么？"><a href="#时间序列是什么？" class="headerlink" title="时间序列是什么？"></a>时间序列是什么？</h2><p>定义：时间序列数据是按时间排序的观察序列，是目标在不同时间点下的一系列观察值。</p>
<p>所有的时间观察序列数据可以被标记为：\(z_1,z_2,…,z_T\) , 可以当作T个随机变量的一个实例：$$(Z_1,Z_2,..,Z_T)$$</p>
<p>进一步定义：时间序列是一系列按照时间排序的随机变量。通常定义为双无穷随机变量序列。标记为：\({Z_t,t \in \mathbb{Z}}\), 或者简记为：\({Z_t}\) 。时间序列是离散时间下的随机过程。</p>
<p>回顾线性模型，响应变量Y和多个因变量X，线性模型表示为：$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i$$</p>
<p>因变量X的信息是已知的，我们希望对响应变量Y做出推断。</p>
<p>在时间序列分析中，我们提出如下模型：$$Y_t=\beta_o+\beta_1Y_{t-1}+\varepsilon_t$$</p>
<p>在时间序列中，已知的信息包括：</p>
<ul>
<li>时间下标t</li>
<li>过去的信息</li>
</ul>
<p>两个典型的时间序列模型如下：</p>
<p>$$Z_t=a+bt+\varepsilon_t$$</p>
<p>and</p>
<p>$$Z_t=\theta_0+\phi Z_{t-1}+\varepsilon_t$$</p>
<p>它们分别对应于确定性模型和随机模型，本文将讨论后者。<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/03/07/ARIMA时间序列模型/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/02/17/神经网络-系列2/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/17/神经网络-系列2/" itemprop="url">
                  神经网络(系列2)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-17T16:28:37+08:00">
                2017-02-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>神经网络的入门知识参见<a href="/2017/02/13/神经网络/">神经网络(系列1)</a><br>本文主要对神经网络进行深入，探讨神经网络模型的学习。</p>
<h1 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h1><p>首先引入一些便于稍后讨论的新标记方法：<br>假设神经网络的训练样本有m个，每个包含一组输入x和一组输出信号y，L表示神经网络层数，\(S_l\)表示每层的neuron个数(\(S_L\)表示输出层神经元个数),(\(S_L\)代表最后一层中处理单元的个数。<br>将神经网络的分类定义为两种情况：二类分类和多类分类:<br>二类分类：\(S_L=1\), y=0 or 1表示哪一类；<br>K类分类：\(S_L=K\),  \(y_i = 1\)表示分到第i类；（K&gt;2）<br><img src="/picture/machine-learning/network_learn1.jpg" alt="network_learn"><br>我们回顾逻辑回归问题中我们的代价函数为：<br>$$J(θ)=-\frac{1}{m}\sum_{i=1}^m\left(y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))\right)+\frac{\lambda}{2m}\sum_{j=1}^nθ_j^2$$<br>在逻辑回归中，我们只有一个输出变量，又称标量（scalar），也只有一个因变量y，但是在神经网络中，我们可以有很多输出变量，我们的\(h_θ(x)\)是一个维度为K的向量，并且训练集中的因变量也是同样维度的一个向量，因此代价函数会比逻辑回归更加复杂一些，为：<br>$$J(\Theta)=-\frac{1}{m}\Big[\sum_{i=1}^m\sum_{k=1}^K\left(y_k^{(i)}log((h_\Theta(x^{(i)}))_k)+(1-y_k^{(i)})log(1-(h_\Theta(x^{(i)}))_k)\right)\Big] \\\ + \frac{\lambda}{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_{l+1}}(\Theta_{ji}^{(l)})^2$$<br><img src="/picture/machine-learning/network_learn2.jpg" alt="network_learn"><br>这个看起来复杂很多的代价函数背后的思想还是一样的，我们希望通过代价函数来观察算法预测的结果与真实情况的误差有多大，唯一不同的是，对于每一行特征，我们都会给出K个预测，基本上我们可以利用循环，对每一行特征都预测K个不同结果，然后在利用循环在K个预测中选择可能性最高的一个。<br>注意：j循环所有的行（由\(s_{l+1}\)层的激活单元数决定,l+1整体是下标），循环i则循环所有的列，由该层（\(s_l\)层）的激活单元数所决定。<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/02/17/神经网络-系列2/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/02/13/神经网络/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/13/神经网络/" itemprop="url">
                  神经网络(系列1)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-13T18:23:23+08:00">
                2017-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="非线性假设"><a href="#非线性假设" class="headerlink" title="非线性假设"></a>非线性假设</h1><p>我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。<br>下面是一个例子：<br><img src="/picture/machine-learning/network1.jpg" alt="network"><br>当我们使用\(x_1,x_2\)的多次项式进行预测时，我们可以应用得很好。<br>之前我们已经看到过，使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合\(x_1x_2+x_1x_3+x_1x_4+…+x_2x_3+x_2x_4+…+x_{99}x_{100}\),我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。<br>假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车）。<br>我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。<br>假如我们只选用灰度图片，每个像素则只有一个值（而非RGB值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：<br><img src="/picture/machine-learning/network2.jpg" alt="network"><br>假使我们采用的都是  50x50像素的小图片，并且我们将所有的像素视为特征，则会有2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约\(\frac{2500^2}{2}\)个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们就需要神经网络。</p>
<h1 id="神经元和大脑"><a href="#神经元和大脑" class="headerlink" title="神经元和大脑"></a>神经元和大脑</h1><p>神经网络是一种很古老的算法，它最初产生的目的是制造能模拟大脑的机器。<br>接下来我将介绍神经网络。它能很好地解决不同的机器学习问题。首先介绍一些神经网络的背景知识，由此我们能知道可以用它们来做什么。不管是将其应用到现代的机器学习问题上，还是应用到那些你可能会感兴趣的问题中。也许，这一伟大的人工智能梦想在未来能制造出真正的智能机器。另外，我们还将讲解神经网络是怎么涉及这些问题的，神经网络产生的原因是人们想尝试设计出模仿大脑的算法，从某种意义上说如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/02/13/神经网络/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/02/11/逻辑回归/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/11/逻辑回归/" itemprop="url">
                  逻辑回归
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-11T15:30:53+08:00">
                2017-02-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h1><p>在分类问题中，你要预测的变量  y是离散的值，我们将学习一种叫做逻辑回归(Logistic Regression)的算法，这是目前最流行使用最广泛的一种学习算法。</p>
<p>在分类问题中，我们尝试预测的是结果是否属于某一个类（例如正确或错误）。分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。</p>
<p>我们从二元的分类问题开始讨论。我们将因变量(dependant variable)可能属于的两个类分别称为负向类（negative class）和正向类（positive class），则因变量 \(y\in{0,1}\) 其中0表示负向类，1表示正向类。<br><img src="/picture/machine-learning/logistic_regression1.jpg" alt="logistic_regression"><br><img src="/picture/machine-learning/logistic_regression2.jpg" alt="logistic_regression2"><br>如果我们要用线性回归算法来解决一个分类问题，对于分类，y取值为     0或者1，但如果你使用的是线性回归，那么假设函数的输出值可能远大于  1，或者远小于0，即使所有训练样本的标签y都等于0或1。尽管我们知道标签应该取值0或者1，但是如果算法得到的值远大于1或者远小于0的话，就会感觉很奇怪。所以我们在接下来的要研究的算法就叫做逻辑回归算法，这个算法的性质是：它的输出值永远在0到1之间。</p>
<p>顺便说一下，逻辑回归算法是分类算法，我们将它作为分类算法使用。有时候可能因为这个算法的名字中出现了“回归”使你感到困惑，但逻辑回归算法实际上是一种分类算法.<br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/02/11/逻辑回归/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/02/10/基于jieba分词和nltk的情感分析/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/10/基于jieba分词和nltk的情感分析/" itemprop="url">
                  基于jieba分词和nltk的情感分析
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-10T18:45:56+08:00">
                2017-02-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="自然语言处理NLP"><a href="#自然语言处理NLP" class="headerlink" title="自然语言处理NLP"></a>自然语言处理NLP</h1><p>情感分析作为自然语言处理的一个部分，让我们首先看一下自然语言处理。</p>
<h2 id="相关技术及运用"><a href="#相关技术及运用" class="headerlink" title="相关技术及运用"></a>相关技术及运用</h2><p>自动问答（Question Answering，QA）：它是一套可以理解复杂问题，并以充分的准确度、可信度和速度给出答案的计算系统，以IBM‘s Waston为代表；<br>信息抽取（Information Extraction，IE）：其目的是将非结构化或半结构化的自然语言描述文本转化结构化的数据，如自动根据邮件内容生成Calendar；<br>情感分析（Sentiment Analysis，SA）：又称倾向性分析和意见挖掘，它是对带有情感色彩的主观性文本进行分析、处理、归纳和推理的过程，如从大量网页文本中分析用户对“数码相机”的“变焦、价格、大小、重量、闪光、易用性”等属性的情感倾向；<br>机器翻译（Machine Translation，MT）：将文本从一种语言转成另一种语言，如中英机器翻译。</p>
<h2 id="发展现状"><a href="#发展现状" class="headerlink" title="发展现状"></a>发展现状</h2><p>基本解决：词性标注、命名实体识别、Spam识别<br>取得长足进展：情感分析、共指消解、词义消歧、句法分析、机器翻译、信息抽取<br>挑战：自动问答、复述、文摘、会话机器人<br><img src="/picture/machine-learning/nlp_process.png" alt="nlp_process"><br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/02/10/基于jieba分词和nltk的情感分析/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2017/02/09/线性回归/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/02/09/线性回归/" itemprop="url">
                  线性回归
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-09T22:27:47+08:00">
                2017-02-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="模型表示"><a href="#模型表示" class="headerlink" title="模型表示"></a>模型表示</h1><h2 id="房价预测例子"><a href="#房价预测例子" class="headerlink" title="房价预测例子"></a>房价预测例子</h2><p>  让我们通过一个例子来开始：这个例子是预测住房价格的，我们要使用一个数据集，数据集包含俄勒冈州波特兰市的住房价格。在这里，我要根据不同房屋尺寸所售出的价格，画出我的数据集。比方说，如果你朋友的房子是1250平方尺大小，你要告诉他们这房子能卖多少钱。那么，你可以做的一件事就是构建一个模型，也许是条直线，从这个数据模型上来看，也许你可以告诉你的朋友，他能以大约 220000(美元)左右的价格卖掉这个房子。这就是监督学习算法的一个例子<br><img src="/picture/machine-learning/house_price.jpg" alt="house_price"><br>   它被称作监督学习是因为对于每个数据来说，我们给出了“正确的答案”，即告诉我们：根据我们的数据来说，房子实际的价格是多少，而且，更具体来说，这是一个回归问题。回归一词指的是，我们根据之前的数据预测出一个准确的输出值，对于这个例子就是价格，同时，还有另一种最常见的监督学习方式，叫做分类问题，当我们想要预测离散的输出值，例如，我们正在寻找癌症肿瘤，并想要确定肿瘤是良性的还是恶性的，这就是 0/1离散输出的问题。更进一步来说，在监督学习中我们有一个数据集，这个数据集被称训练集。下图是房价预测数据格式：<br>  <img src="/picture/machine-learning/train_set_representation.jpg" alt="train_set_representation"><br>
          <!--noindex-->
          <div class="post-more-link text-center">
            <a class="btn" href="/2017/02/09/线性回归/#more" rel="contents">
              阅读全文 &raquo;
            </a>
          </div>
          <!--/noindex-->
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>


    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          
        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400"
               alt="xuetf" />
          <p class="site-author-name" itemprop="name">xuetf</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">33</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://lsxj615.com/" title="小王子" target="_blank">小王子</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/xuetf/" title="My Github" target="_blank">My Github</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xuetf</span>
</div>




<script type="text/x-mathjax-config">
 MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
 tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
 TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
 messageStyle: "none"
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>
<script charset="utf-8" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  



  
    
  
 



	





  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  <!-- custom analytics part create by xiamo -->
<script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("DFlRFg5OyISCpmUurUC3Vk4s-gzGzoHsz", "0ayDjXz6ELVOVmPMjLQH3llQ");</script>
<script>
function showTime(Counter) {
  var query = new AV.Query(Counter);
  $(".leancloud_visitors").each(function() {
    var url = $(this).attr("id").trim();
    query.equalTo("url", url);
    query.find({
      success: function(results) {
        if (results.length == 0) {
          var content = '0 ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
          return;
        }
        for (var i = 0; i < results.length; i++) {
          var object = results[i];
          var content = object.get('time') + ' ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
        }
      },
      error: function(object, error) {
        console.log("Error: " + error.code + " " + error.message);
      }
    });

  });
}

function addCount(Counter) {
  var Counter = AV.Object.extend("Counter");
  url = $(".leancloud_visitors").attr('id').trim();
  title = $(".leancloud_visitors").attr('data-flag-title').trim();
  var query = new AV.Query(Counter);
  query.equalTo("url", url);
  query.find({
    success: function(results) {
      if (results.length > 0) {
        var counter = results[0];
        counter.fetchWhenSave(true);
        counter.increment("time");
        counter.save(null, {
          success: function(counter) {
            var content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(counter, error) {
            console.log('Failed to save Visitor num, with error message: ' + error.message);
          }
        });
      } else {
        var newcounter = new Counter();
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {
          success: function(newcounter) {
              console.log("newcounter.get('time')="+newcounter.get('time'));
            var content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(newcounter, error) {
            console.log('Failed to create');
          }
        });
      }
    },
    error: function(error) {
      console.log('Error:' + error.code + " " + error.message);
    }
  });
}
$(function() {
  var Counter = AV.Object.extend("Counter");
  if ($('.leancloud_visitors').length == 1) {
    addCount(Counter);
  } else if ($('.post-title-link').length > 1) {
    showTime(Counter);
  }
}); 
</script>
  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
