<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  
    

    
  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="推荐系统,paper,GNN,图神经网络," />





  <link rel="alternate" href="/atom.xml" title="蘑菇先生学习记" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/picture/logo.ico?v=5.1.0" />






<meta name="description" content="MA-GNN是华为诺亚实验室发表在 AAAI 2020 上的序列推荐工作。主要利用记忆增强的图神经网络来捕获并融合短期兴趣和长期兴趣，应用于序列推荐中。下面仍然围绕Motivation, Contribution, Solution, Evaluation, Summarization，即5tion原则展开介绍。">
<meta name="keywords" content="推荐系统,paper,GNN,图神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="MA-GNN记忆增强的图神经网络序列推荐方法">
<meta property="og:url" content="xtf615.com/2020/11/14/MA-GNN/index.html">
<meta property="og:site_name" content="蘑菇先生学习记">
<meta property="og:description" content="MA-GNN是华为诺亚实验室发表在 AAAI 2020 上的序列推荐工作。主要利用记忆增强的图神经网络来捕获并融合短期兴趣和长期兴趣，应用于序列推荐中。下面仍然围绕Motivation, Contribution, Solution, Evaluation, Summarization，即5tion原则展开介绍。">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="/picture/machine-learning/MA-GNN.png">
<meta property="og:image" content="/picture/machine-learning/session-graph.png">
<meta property="og:image" content="/picture/machine-learning/compare.png">
<meta property="og:image" content="/picture/machine-learning/ablation.png">
<meta property="og:image" content="/picture/machine-learning/vis.png">
<meta property="og:updated_time" content="2021-05-23T14:52:32.295Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="MA-GNN记忆增强的图神经网络序列推荐方法">
<meta name="twitter:description" content="MA-GNN是华为诺亚实验室发表在 AAAI 2020 上的序列推荐工作。主要利用记忆增强的图神经网络来捕获并融合短期兴趣和长期兴趣，应用于序列推荐中。下面仍然围绕Motivation, Contribution, Solution, Evaluation, Summarization，即5tion原则展开介绍。">
<meta name="twitter:image" content="/picture/machine-learning/MA-GNN.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="xtf615.com/2020/11/14/MA-GNN/"/>





  <title> MA-GNN记忆增强的图神经网络序列推荐方法 | 蘑菇先生学习记 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">蘑菇先生学习记</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <!-- <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form> -->

<!-- <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'WgLy48WeXh1aXsWx1x7L','2.0.0');
</script> -->



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="xtf615.com/2020/11/14/MA-GNN/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="xuetf">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="蘑菇先生学习记">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="蘑菇先生学习记" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                MA-GNN记忆增强的图神经网络序列推荐方法
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-14T14:14:51+08:00">
                2020-11-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/GNN/" itemprop="url" rel="index">
                    <span itemprop="name">GNN</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读量 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><strong>MA-GNN</strong>是华为诺亚实验室发表在 <strong>AAAI 2020</strong> 上的序列推荐工作。主要利用记忆增强的图神经网络来捕获并融合短期兴趣和长期兴趣，应用于序列推荐中。下面仍然围绕Motiva<strong>tion</strong>, Contribu<strong>tion</strong>, Solu<strong>tion</strong>, Evalua<strong>tion</strong>, Summariza<strong>tion</strong>，即5<strong>tion</strong>原则展开介绍。<br><a id="more"></a></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>传统的序列推荐方法主要建模的是session-level的短期序列，仅能够捕获蕴含在用户近期交互物品中的短期偏好，缺乏对用户长期偏好的挖掘。因此，本文的主要动机就是考虑用户长期的交互序列，希望能够从中挖掘出用户长期稳定的偏好。除此之外，作者还希望能够显式地建模物品与物品之间的共现关系。为此，作者提出了几种方法来分别捕获用户的短期兴趣，长期兴趣以及物品之间的共现关系，并融合这些因素进行打分和推荐。</p>
<ul>
<li>短期兴趣：基于短期交互序列中物品之间的转移关系图，使用GNN来捕获用户的短期兴趣。</li>
<li>长期兴趣：使用带注意力机制的记忆网络来捕获用户的长期兴趣。</li>
<li>共现关系：使用双线性函数来显式建模物品之间的共现关系。</li>
</ul>
<h2 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h2><ul>
<li>为了捕获用户的短期兴趣和长期兴趣，文章提出了一种记忆增强的图神经网络来捕获短期上下文信息和长距离依赖。</li>
<li>为了有效地融合短期兴趣和长期兴趣，文章采用了一种门控机制来自适应地融合两种兴趣表征。</li>
<li>为了显式建模物品之间的共现关系，文章采用了双线性函数来捕获物品之间相关性。</li>
<li>在五个真实的数据集上取得了state-of-the-art的效果。</li>
</ul>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>先从总体上介绍下整个方法。整个方法实际上很像矩阵分解那一套框架。只不过分解的时候考虑了短期兴趣和长期兴趣。这里头最重要的是理解<strong>输入序列数据怎么规整成矩阵分解的形式，即point-wise分解和打分</strong> (比如：用户嵌入和物品嵌入点积)。</p>
<p>原始的输入数据是user-level的序列。$S^u=(I_1,I_2,…,I_{|S_u|})$，由于是user-level的序列，每条序列长度很长，如果直接建模的话，总的样本量正比于用户数，相对较少。因此需要对序列进行切割来做<strong>数据增强</strong>和<strong>长短期序列</strong>区分。可以通过在user-level的序列数据上做窗口滑动来增强，窗口<strong>内部的子序列</strong>构成了<strong>短期序列</strong>，从窗口<strong>左侧端点开始向左到起始点</strong>的子序列构成了<strong>长期序列</strong>，从窗口<strong>右侧端点</strong>开始向右的子序列构成了<strong>目标序列</strong>。这里头有好几个超参数。<strong>滑动窗口的大小</strong>$|L|$（即：决定了短期序列的长度），<strong>滑动窗口的左端点起始值 </strong>$l$（即：决定了长期序列长度的最小值），以及<strong>目标序列的长度 </strong>$|T|$。</p>
<p>形式化地，增强后的每个sample有3段子序列，即：$S_{u,l}=[H_{u,l} ; L_{u,l} ; T_{u,l}]$，$l$是滑动窗口的左侧端点，则：$H_{u,l}=(I_1, I_2,…,I_{l-1})$是长期交互序列，$L_{u,l}=(I_l,I_{l+1},…,I_{l+|L|-1})$是滑动窗口内部的长度为$|L|$短期交互序列，$T_{u,l}$是大小为$|T|$的目标序列。</p>
<p>则，本文的问题是输入长期序列$H_{u,l}$和短期序列$L_{u,l}$，来输出用户$u$接下来会感兴趣的$\text{Top-K}$个物品，并在目标序列$T_{u,l}$上进行评估。命中越多目标序列$T_{u,l}$中的物品，说明模型泛化性越好。所谓的长短期，实际上就是从物品交互时间的久远来衡量，最近交互的若干个物品构成了短期交互序列，再之前的交互构成了长期交互序列。</p>
<p>在解决序列推荐方法上，除了物品和序列<strong>表征的过程</strong>有所差异之外，目前主流的方法都是利用物品表征和用户表征，来预测next item，即：预测所有的$N$个物品上的概率分布，推荐$K$个概率最大的，实际上是个多分类问题。但是这篇文章将多分类转成了二分类问题，即：将<strong>目标序列</strong>$T_{u,l}$中的物品$i$和用户$u$作配对，转化成$(u,i)$ 正样本对，这样就可以使用矩阵分解的方式来拟合分数。此外，此处采样了负样本，即:$(u,i,j)$三元组，$j$是采样的负样本，最后用pair-wise的BPR损失来训练。总之，<strong>输入</strong>的用户<strong>短期序列和长期序列</strong>都只是为了获取某种刻画<strong>用户兴趣维度</strong>的表征，并<strong>基于多样化的用户兴趣表征来多维度地联合预测分数</strong>。</p>
<p>因此，问题的关键是如何捕获输入的短期和长期序列中蕴含的用户偏好。先总体看下该方法的架构示意图。</p>
<p><img src="/picture/machine-learning/MA-GNN.png" alt="MA-GNN"></p>
<p>如上图所示，最左侧是初始的兴趣表征模块，包含了用户通用兴趣表征，短期序列中的物品表征和长期序列中的物品表征。中间是兴趣建模模块，即：如果对初始的表征进行处理和融合；右侧是基于建模得到的兴趣表征进行分数的预测，包括了3个分数来源，通用兴趣贡献分，长短期融合兴趣贡献分以及物品共现分。<br>$$<br>\hat{r}_{u,j}=\boldsymbol{p_u}^T \boldsymbol{q}_j + {\boldsymbol{p}_{u,l}^C}^T \boldsymbol{q}_j + \frac{1}{|L|} \sum_{i \in L_{u,l}}\boldsymbol{e}_i^T\boldsymbol{W}_r\boldsymbol{q}_j<br>$$<br>其中，$\boldsymbol{p}_u$是用户的通用兴趣表征，$\boldsymbol{q}_j$是目标物品的初始表征，$\boldsymbol{p}_{u,l}^C$是用户的长短期兴趣融合表征，最后一项是目标物品和用户短期交互序列中的物品的共现分数。这三项分别对应着通用兴趣建模、短期和长期兴趣建模以及物品共现建模。下面依次来介绍。</p>
<h3 id="通用兴趣建模"><a href="#通用兴趣建模" class="headerlink" title="通用兴趣建模"></a>通用兴趣建模</h3><p>输入的短期序列$S_{u,l}$和长期序列$H_{u,l}$都记录着产生该行为序列的用户$u$，因此作者在做序列建模的时候，将该用户$u$也考虑进去了。作者采用随机初始化的$\boldsymbol{p}_u$来表征用户静态和通用的的兴趣。最后在预测层预测分数的时候，采用了简单矩阵分解策略，即：$\boldsymbol{p}_u^T \boldsymbol{q}_j$，$q_j$是目标预测物品$j$的embedding（实际上就是目标序列集合中的物品），该分数即：通用兴趣贡献分。</p>
<h3 id="短期兴趣建模"><a href="#短期兴趣建模" class="headerlink" title="短期兴趣建模"></a>短期兴趣建模</h3><p>输入是短期序列$S_{u,l}$，输出是蕴含在短期序列中用户的兴趣表征$\boldsymbol{p}_{u,l}^S$，$S$是short-term的缩小。如图所示，左下角的部分。作者采用了两层的GNN网络来捕获蕴含在序列中的局部结构信息，并形成用户短期兴趣表征。为了能够用GNN来建模，需要将序列转成session graph。策略是，短期序列中的每个物品和其后面的3个物品做连接，并对形成的邻接矩阵按照行做归一化。如下图所示：</p>
<p><img src="/picture/machine-learning/session-graph.png" alt="session-graph"></p>
<p><strong>信息传播和聚合</strong>：接着，基于该<strong>邻接矩阵</strong>来进行邻域信息传播和汇聚。即：<br>$$<br>\boldsymbol{h}_i=\text{tanh}(\boldsymbol{W}^{(1)}\cdot [\sum_{k \in \mathcal{N}_i} \boldsymbol{e}_k \boldsymbol{A}_{i,k} || \boldsymbol{e}_i]), \forall i \in L_{u,l}<br>$$<br>$\sum_{k \in \mathcal{N}_i}  \boldsymbol{e}_k \boldsymbol{A}_{i,k}$是从邻域传播的信息；和自身$\boldsymbol{e}_i$做一个拼接($||$)，再过一个非线性变换。</p>
<p>上述得到了序列中每个物品的表征后，需要形成用户的短期兴趣表征。先mean pooling得到短期序列表征，再和用户的<strong>通用表征</strong>做一个拼接并过一层非线性变换融合。即：<br>$$<br>\boldsymbol{p}_{u,l}^S=\text{tanh}(\boldsymbol{W}^{(2)}[\frac{1}{|L|}\sum_{i \in L_{u,l}}\boldsymbol{h}_i || \boldsymbol{p}_u])<br>$$</p>
<h3 id="长期兴趣建模"><a href="#长期兴趣建模" class="headerlink" title="长期兴趣建模"></a>长期兴趣建模</h3><p>这个是本文主要的亮点所在，如果对多维度注意力机制和带记忆网络的注意力机制不太熟悉的话，强烈建议先阅读我之前的一篇博客：<a href="http://xtf615.com/2019/01/06/attention/">深度学习中的注意力机制调研</a>。这部分的输入是长期序列$H_{u,l}$，输出是用户的<strong>长期兴趣表征</strong>。为了能够捕获长期兴趣，通常可以采用<strong>外部记忆单元</strong>来存储用户随时间变化的动态偏好，但是如果为每个用户都存储这样的偏好，会耗费很大的存储空间，而且通过这种方式捕获到的兴趣可能和通用兴趣$p_u$相似。为了解决这些问题，作者采用了一个记忆网络来存储<strong>所有用户共享的隐兴趣表征</strong>，每种隐单元都代表着某种特定的用户隐兴趣，给定用户长期交互序列$H_{u,l}$，我们可以学习到多种<strong>不同兴趣融合</strong>的用户长期兴趣表征。记长期序列中每个物品的表征形成的表征矩阵为：$\boldsymbol{H}_{u,l}\in \mathbb{R}^{d \times |H_{u,l}|}$，即：第$j$列为长期序列中第$j$个物品的表征向量。记忆网络中存储着所有用户<strong>共享的隐兴趣表征</strong>，针对每一个<strong>用户</strong>以及其<strong>长期交互序列</strong>，我们需要为该用户生成与其兴趣匹配的query embedding $\boldsymbol{z}_{u,l}$，然后根据该query embedding去记忆网络中检索有用的隐兴趣表征，从而形成该用户特定的长期兴趣表征。这里面最重要的就是query embedding的产生，作者采用了多维度的注意力机制。具体而言，</p>
<ul>
<li>首先模仿Transformer给序列中每个item引入了位置语义信息，$PE(·)$为sinusoidal positional encoding function</li>
</ul>
<p>$$<br>\boldsymbol{H}_{u,l}:=\boldsymbol{H}_{u,l}+PE(H_{u,l})<br>$$</p>
<ul>
<li>计算用户通用兴趣表征$\boldsymbol{p}_u$和长期序列$H_{u,l}$<strong>感知</strong>的多维度注意力权重矩阵MDAtt，即：$\boldsymbol{S}_{u,l} \in \mathbb{R}^{h\times |H_{u,l}|}$，</li>
</ul>
<p>$$<br>\boldsymbol{S}_{u,l} = \text{softmax}\Big(W_a^{(3)} \tanh\big(W_a^{(1)}\boldsymbol{H}_{u,l}+(W_a^{(2)} \boldsymbol{p}_u)\otimes \boldsymbol{1}_{|H_{u,l}|}\big)\Big)<br>$$<br>其中，$W_a^{(1)}, W_a^{(2)}\in\mathbb{R}^{d\times d}, W_a^{(3)}\in\mathbb{R}^{h\times d}$是可学习的注意力参数，$\otimes$是外积操作。上述注意力机制考虑了用户的<strong>通用兴趣表征</strong>和<strong>长期行为序列</strong>，因此该注意力是general-interest and long-term sequence <strong>aware</strong>的。多维度注意力机制和通常的注意力机制其实差不太多。从语义上而言，$\boldsymbol{S}_{u,l}$每一行向量从某个语义角度衡量了长期行为序列中每个物品在该语义上的权重值，softmax应该是按照每行来做的，即：求每个序列中每个物品在该语义下的概率分布；基于该行向量所代表的注意力概率分布对长期序列做加权汇聚，可以得到在该语义上的用户query表征；共$h$行，则会形成$h$个用户query表征向量，即形成表征矩阵$\boldsymbol{Z}_{u,l} \in \mathbb{R}^{h \times d}$。</p>
<ul>
<li>具体而言，根据上述的注意力权重矩阵来对用户长期行为序列做一个聚合，形成表征矩阵。</li>
</ul>
<p>$$<br>\boldsymbol{Z}_{u,l} = \tanh(\boldsymbol{S}_{u,l} \cdot \boldsymbol{H}_{u,l}^T)<br>$$</p>
<ul>
<li>对上述表征矩阵按照<strong>行方向</strong>(把h维度归约掉)做mean pooling来形成最终的用户query embedding，$\boldsymbol{z}_{u,l} \in \mathbb{R}^{d}$。</li>
</ul>
<p>$$<br>\boldsymbol{z}_{u,l}=\text{avg}(\boldsymbol{Z}_{u,l})<br>$$<br>​   实际上从语义上来讲，相当于将不同语义汇聚到的query embedding通过mean pooling汇聚在一起形成最终的query embedding。</p>
<p>​      总之，通过上述步骤，就能够形成<strong>用户通用兴趣和长期行为序列感知</strong>的检索向量$\boldsymbol{z}_{u,l}$。接下来就是根据该检索向量去记忆网络中检索出和该用户兴趣就相关的记忆，从而形成用户的长期兴趣表征。</p>
<ul>
<li>记忆网络的的Key和Value矩阵分别记为：$\boldsymbol{K} \in \mathbb{R}^{d \times m}$和$\boldsymbol{V} \in \mathbb{R}^{d \times m}$，每一列都代表着某个维度下，所有用户共享的<strong>隐兴趣表征向量</strong>。因此，需要计算用户的query embedding和每一种隐兴趣表征的亲和度值，并转成概率分布。<br>$$<br>s_i = \text{softmax}(\boldsymbol{z}_{u,l}^T \times \boldsymbol{k_i})<br>$$<br>基于该概率分布对所有的隐兴趣表征（列向量）做加权汇聚。<br>$$<br>\boldsymbol{o}_{u,l}=\sum_{i} s_i \boldsymbol{v}_i<br>$$<br>最后做个skip-connection，<br>$$<br>\boldsymbol{p}_{u,l}^H=\boldsymbol{z}_{u,l} + \boldsymbol{o}_{u,l}<br>$$</li>
</ul>
<h3 id="长短期兴趣融合"><a href="#长短期兴趣融合" class="headerlink" title="长短期兴趣融合"></a>长短期兴趣融合</h3><p>使用门控机制来融合短期兴趣和长期兴趣。这里头的做法借鉴了LSTM/GRU，实际上和SR-GNN做结点信息更新的时候的策略是类型的，不作赘述。唯一要提的点就是，这里头实际上可以直接融合长短期序列表征$\boldsymbol{p}_{u,l}^S$和$\boldsymbol{p}_{u,l}^H$，但是作者实际用的时候融合的是，用户长期交互序列表征$\boldsymbol{p}_{u,l}^H$以及$\sum_{i \in L_{u,l}}\boldsymbol{h}_i$。可能是因为$\boldsymbol{p}_{u,l}^S$中融入了通用兴趣表征，而最后预测分数的时候，通用兴趣表征是单独作为一项贡献分的，再融合进长短期兴趣表征显得冗余。</p>
<p>做法很简单，门控的输出值是近期交互行为、通用兴趣表征、长期兴趣表征感知的，<br>$$<br>\boldsymbol{g}_{u,l}=\sigma(\boldsymbol{W}_g^{(1)} \cdot \frac{1}{|L|} \sum_{i \in L_{u,l}}\boldsymbol{h}_i + \boldsymbol{W}_g^{(2)} \boldsymbol{p}_{u,l}^H + \boldsymbol{W}_g^{(3)} \boldsymbol{p}_u)<br>$$<br>基于该门控值进行融合，得到的融合后的兴趣表征为：<br>$$<br>\boldsymbol{p}_{u,l}^C=\boldsymbol{g}_{u,l} \odot \frac{1}{|L|} \sum_{i \in L_{u,l}}\boldsymbol{h}_i + (\boldsymbol{I}_d - \boldsymbol{g}_{u,l}) \odot \boldsymbol{p}_{u,l}^H<br>$$</p>
<h3 id="物品共现建模"><a href="#物品共现建模" class="headerlink" title="物品共现建模"></a>物品共现建模</h3><p>显式地对用户短期交互过的物品和目标物品做共现建模，采用了双线性函数：<br>$$<br>\boldsymbol{e}_i^T\boldsymbol{W}_r\boldsymbol{q}_j<br>$$<br>$\boldsymbol{W}_r$是可学习的物品相关性矩阵。$\boldsymbol{e}_i$是短期交互序列中的物品$i$的初始表征，$\boldsymbol{q}_j$是目标物品。</p>
<p>最后用BPR Loss来学习。不做赘述。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>实验主要包括几个部分，</p>
<ul>
<li><p>对比实验（方法包括：BPRMF，GRU4Rec，GRU4Rec+，GC-SAN，Caser，SASRec，MARank），居然没有选SR-GNN（个人认为虽然GC-SAN论文中战胜了SR-GNN，但是本人在很多实践中发现SR-GNN比GC-SAN好）。</p>
<p><img src="/picture/machine-learning/compare.png" alt="compare"></p>
</li>
<li><p>消融实验：主要考察了通用兴趣，通用兴趣+短期兴趣，通用兴趣+短期兴趣+长期兴趣+gating长短期融合，通用兴趣+短期兴趣+长期兴趣+concat长短期融合，通用兴趣+短期兴趣+长期兴趣+GRU长短期融合。</p>
<p><img src="/picture/machine-learning/ablation.png" alt="ablation"></p>
<p>(3)和(6)对比可以看出共现建模的好处；(1)和(2)对比看出短期兴趣建模的好处；(3)和(4)和(5)的结果说明gating机制的有效性，但是这个结果太不可思议了，gating比concat以及GRU好这么多？gating和GRU的差异主要就是有没有用$\boldsymbol{p}_u$吧？为了公平性，$\boldsymbol{p}_u$可以直接用到GRU里面来对比的。对此表示疑惑。</p>
</li>
<li><p><strong>记忆单元的可视化：</strong> 验证每个记忆单元是否可以表示某种特定的兴趣。作者在MovieLens上做了case study。作者随机选了某个用户以及他观看过的电影，用其观看的电影直接作为query embedding，去计算在memory network上的注意力分数，即$s_i $。期望观察到的效果是，给定不同的电影query embedding，注意力分数分布不一样，在类似的电影上，某些维度的注意力分数也应该类似。</p>
<p><img src="/picture/machine-learning/vis.png" alt="vis"></p>
<p>可以看到有三部Three Colors的电影的注意力分数分布挺近似的。DIe Hard是惊悚片，和其他的分布不一样。</p>
<p>这种可视化应该是目前论文写作的标配。</p>
</li>
</ul>
<h2 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h2><p>这篇文章总体上有一些借鉴的地方。全文最大的亮点在于长期兴趣的建模。基于长期行为序列来构造query embedding，然后去memory network中检索有用的兴趣。这种长期兴趣的建模范式可以借鉴到日常工作优化中。但是缺点是长期序列长度可能比较长，多维度注意力机制可能复杂度相对高一些。但是，另一方面，这篇文章创新度一般，主要是一些已有的机制的叠加和尝试，是否真正有效还有待实践和验证。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://arxiv.org/abs/1912.11730" target="_blank" rel="noopener">AAAI 2020：Memory Augmented Graph Neural Networks for Sequential Recommendation</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/picture/wechatpay.JPG" alt="xuetf WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/picture/alipay.JPG" alt="xuetf Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/推荐系统/" rel="tag"># 推荐系统</a>
          
            <a href="/tags/paper/" rel="tag"># paper</a>
          
            <a href="/tags/GNN/" rel="tag"># GNN</a>
          
            <a href="/tags/图神经网络/" rel="tag"># 图神经网络</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/11/14/GCE-GNN/" rel="next" title="GCE-GNN基于全局上下文增强的图神经网络序列推荐方法">
                <i class="fa fa-chevron-left"></i> GCE-GNN基于全局上下文增强的图神经网络序列推荐方法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/11/20/Disen-GNN/" rel="prev" title="基于分离式表征的图神经网络调研">
                基于分离式表征的图神经网络调研 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
         <div id="uyan_frame"></div>
    
  </div>

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://avatars1.githubusercontent.com/u/11912425?v=3&u=11f9f5dc75aaf84f020a06c0b9cb2b6f401c586b&s=400"
               alt="xuetf" />
          <p class="site-author-name" itemprop="name">xuetf</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">70</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">127</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://lsxj615.com/" title="小王子" target="_blank">小王子</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://github.com/xuetf/" title="My Github" target="_blank">My Github</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Motivation"><span class="nav-number">1.</span> <span class="nav-text">Motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Contribution"><span class="nav-number">2.</span> <span class="nav-text">Contribution</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Solution"><span class="nav-number">3.</span> <span class="nav-text">Solution</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#通用兴趣建模"><span class="nav-number">3.1.</span> <span class="nav-text">通用兴趣建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#短期兴趣建模"><span class="nav-number">3.2.</span> <span class="nav-text">短期兴趣建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#长期兴趣建模"><span class="nav-number">3.3.</span> <span class="nav-text">长期兴趣建模</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#长短期兴趣融合"><span class="nav-number">3.4.</span> <span class="nav-text">长短期兴趣融合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#物品共现建模"><span class="nav-number">3.5.</span> <span class="nav-text">物品共现建模</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evaluation"><span class="nav-number">4.</span> <span class="nav-text">Evaluation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Summarization"><span class="nav-number">5.</span> <span class="nav-text">Summarization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-number">6.</span> <span class="nav-text">References</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xuetf</span>
</div>




<script type="text/x-mathjax-config">
 MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
 tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
 TeX: { noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
 messageStyle: "none"
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Queue(function() {
 var all = MathJax.Hub.getAllJax(), i;
 for(i=0; i < all.length; i += 1) {
 all[i].SourceElement().parentNode.className += ' has-jax';
 }
 });
</script>

<!-- <script charset="utf-8" src="/js/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->

<script charset="utf-8" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>











        

<div class="busuanzi-count">

  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  



  
    
  
 
      <!-- UY BEGIN -->
      <script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2122877"></script>
      <!-- UY END -->
  



	





  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  <!-- custom analytics part create by xiamo -->
<script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("DFlRFg5OyISCpmUurUC3Vk4s-gzGzoHsz", "0ayDjXz6ELVOVmPMjLQH3llQ");</script>
<script>
function showTime(Counter) {
  var query = new AV.Query(Counter);
  $(".leancloud_visitors").each(function() {
    var url = $(this).attr("id").trim();
    query.equalTo("url", url);
    query.find({
      success: function(results) {
        if (results.length == 0) {
          var content = '0 ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
          return;
        }
        for (var i = 0; i < results.length; i++) {
          var object = results[i];
          var content = object.get('time') + ' ' + $(document.getElementById(url)).text();
          $(document.getElementById(url)).text(content);
        }
      },
      error: function(object, error) {
        console.log("Error: " + error.code + " " + error.message);
      }
    });

  });
}

function addCount(Counter) {
  var Counter = AV.Object.extend("Counter");
  url = $(".leancloud_visitors").attr('id').trim();
  title = $(".leancloud_visitors").attr('data-flag-title').trim();
  var query = new AV.Query(Counter);
  query.equalTo("url", url);
  query.find({
    success: function(results) {
      if (results.length > 0) {
        var counter = results[0];
        counter.fetchWhenSave(true);
        counter.increment("time");
        counter.save(null, {
          success: function(counter) {
            var content =  counter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(counter, error) {
            console.log('Failed to save Visitor num, with error message: ' + error.message);
          }
        });
      } else {
        var newcounter = new Counter();
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {
          success: function(newcounter) {
              console.log("newcounter.get('time')="+newcounter.get('time'));
            var content = newcounter.get('time') + ' ' + $(document.getElementById(url)).text();
            $(document.getElementById(url)).text(content);
          },
          error: function(newcounter, error) {
            console.log('Failed to create');
          }
        });
      }
    },
    error: function(error) {
      console.log('Error:' + error.code + " " + error.message);
    }
  });
}
$(function() {
  var Counter = AV.Object.extend("Counter");
  if ($('.leancloud_visitors').length == 1) {
    addCount(Counter);
  } else if ($('.post-title-link').length > 1) {
    showTime(Counter);
  }
}); 
</script>
  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
